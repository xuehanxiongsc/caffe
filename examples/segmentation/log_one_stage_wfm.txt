I0908 13:55:18.947393  4668 caffe.cpp:217] Using GPUs 2
I0908 13:55:18.967610  4668 caffe.cpp:222] GPU 2: GeForce GTX TITAN X
I0908 13:55:19.737287  4668 solver.cpp:48] Initializing solver from parameters: 
test_iter: 14
test_interval: 200
base_lr: 1e-05
display: 50
max_iter: 16000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 1e-05
stepsize: 4000
snapshot: 4000
snapshot_prefix: "portrait_wfm_one_stage"
solver_mode: GPU
device_id: 2
net: "portrait_wfm_train_test_one_stage.prototxt"
train_state {
  level: 0
  stage: ""
}
I0908 13:55:19.737395  4668 solver.cpp:91] Creating training net from net file: portrait_wfm_train_test_one_stage.prototxt
I0908 13:55:19.737946  4668 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0908 13:55:19.738107  4668 net.cpp:58] Initializing net from parameters: 
name: "segmentation"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "SegData"
  top: "image"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 200
  }
  data_param {
    source: "/raid/xuehan/segmentation_wfm_train_split"
    batch_size: 128
    backend: LMDB
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "image"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 50
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1_1_bn"
  type: "BatchNorm"
  bottom: "pool1"
  top: "conv1_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv1_1_bn_scale"
  type: "Scale"
  bottom: "conv1_1_bn"
  top: "conv1_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_1_relu"
  type: "ReLU"
  bottom: "conv1_1_bn"
  top: "conv1_1_bn"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv1_1_bn"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_1"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1_bn"
  type: "BatchNorm"
  bottom: "pool2"
  top: "conv2_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv2_1_bn_scale"
  type: "Scale"
  bottom: "conv2_1_bn"
  top: "conv2_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1_relu"
  type: "ReLU"
  bottom: "conv2_1_bn"
  top: "conv2_1_bn"
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv2_1_bn"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_1"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1_bn"
  type: "BatchNorm"
  bottom: "pool3"
  top: "conv3_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv3_1_bn_scale"
  type: "Scale"
  bottom: "conv3_1_bn"
  top: "conv3_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1_relu"
  type: "ReLU"
  bottom: "conv3_1_bn"
  top: "conv3_1_bn"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv3_1_bn"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_1"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1_bn"
  type: "BatchNorm"
  bottom: "pool4"
  top: "conv4_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv4_1_bn_scale"
  type: "Scale"
  bottom: "conv4_1_bn"
  top: "conv4_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1_relu"
  type: "ReLU"
  bottom: "conv4_1_bn"
  top: "conv4_1_bn"
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "conv4_1_bn"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv5_1_bn"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv5_1_bn_scale"
  type: "Scale"
  bottom: "conv5_1_bn"
  top: "conv5_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_1_relu"
  type: "ReLU"
  bottom: "conv5_1_bn"
  top: "conv5_1_bn"
}
layer {
  name: "conv6_1"
  type: "Convolution"
  bottom: "conv5_1_bn"
  top: "conv6_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv6_1_bn"
  type: "BatchNorm"
  bottom: "conv6_1"
  top: "conv6_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv6_1_bn_scale"
  type: "Scale"
  bottom: "conv6_1_bn"
  top: "conv6_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv6_1_relu"
  type: "ReLU"
  bottom: "conv6_1_bn"
  top: "conv6_1_bn"
}
layer {
  name: "conv7_1"
  type: "Convolution"
  bottom: "conv6_1_bn"
  top: "conv7_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv7_1_bn"
  type: "BatchNorm"
  bottom: "conv7_1"
  top: "conv7_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv7_1_bn_scale"
  type: "Scale"
  bottom: "conv7_1_bn"
  top: "conv7_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv7_1_relu"
  type: "ReLU"
  bottom: "conv7_1_bn"
  top: "conv7_1_bn"
}
layer {
  name: "score"
  type: "Convolution"
  bottom: "conv7_1_bn"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 4
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "upscore"
  type: "Deconvolution"
  bottom: "score"
  top: "upscore"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 4
    bias_term: false
    pad: 0
    kernel_size: 32
    stride: 16
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "cropscore"
  type: "Crop"
  bottom: "upscore"
  bottom: "image"
  top: "cropscore"
  crop_param {
    axis: 2
    offset: 12
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "cropscore"
  bottom: "label"
  top: "loss"
  loss_weight: 1
  loss_param {
    normalize: false
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "cropscore"
  bottom: "label"
  top: "accuracy"
}
I0908 13:55:19.738258  4668 layer_factory.hpp:77] Creating layer data
I0908 13:55:19.738719  4668 net.cpp:100] Creating Layer data
I0908 13:55:19.738731  4668 net.cpp:408] data -> image
I0908 13:55:19.738759  4668 net.cpp:408] data -> label
I0908 13:55:19.739696  4674 db_lmdb.cpp:35] Opened lmdb /raid/xuehan/segmentation_wfm_train_split
I0908 13:55:19.739908  4668 seg_data_layer.cpp:38] 200 200 5
I0908 13:55:19.747429  4668 seg_data_layer.cpp:51] output data size: 128,4,200,200
I0908 13:55:19.747485  4668 seg_data_layer.cpp:63] output label size: 128,1,200,200
I0908 13:55:20.203654  4668 net.cpp:150] Setting up data
I0908 13:55:20.203685  4668 net.cpp:157] Top shape: 128 4 200 200 (20480000)
I0908 13:55:20.203691  4668 net.cpp:157] Top shape: 128 1 200 200 (5120000)
I0908 13:55:20.203693  4668 net.cpp:165] Memory required for data: 102400000
I0908 13:55:20.203704  4668 layer_factory.hpp:77] Creating layer image_data_0_split
I0908 13:55:20.203722  4668 net.cpp:100] Creating Layer image_data_0_split
I0908 13:55:20.203727  4668 net.cpp:434] image_data_0_split <- image
I0908 13:55:20.203738  4668 net.cpp:408] image_data_0_split -> image_data_0_split_0
I0908 13:55:20.203747  4668 net.cpp:408] image_data_0_split -> image_data_0_split_1
I0908 13:55:20.203794  4668 net.cpp:150] Setting up image_data_0_split
I0908 13:55:20.203800  4668 net.cpp:157] Top shape: 128 4 200 200 (20480000)
I0908 13:55:20.203804  4668 net.cpp:157] Top shape: 128 4 200 200 (20480000)
I0908 13:55:20.203806  4668 net.cpp:165] Memory required for data: 266240000
I0908 13:55:20.203809  4668 layer_factory.hpp:77] Creating layer label_data_1_split
I0908 13:55:20.203815  4668 net.cpp:100] Creating Layer label_data_1_split
I0908 13:55:20.203819  4668 net.cpp:434] label_data_1_split <- label
I0908 13:55:20.203822  4668 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0908 13:55:20.203826  4668 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0908 13:55:20.203850  4668 net.cpp:150] Setting up label_data_1_split
I0908 13:55:20.203855  4668 net.cpp:157] Top shape: 128 1 200 200 (5120000)
I0908 13:55:20.203858  4668 net.cpp:157] Top shape: 128 1 200 200 (5120000)
I0908 13:55:20.203861  4668 net.cpp:165] Memory required for data: 307200000
I0908 13:55:20.203863  4668 layer_factory.hpp:77] Creating layer conv1_1
I0908 13:55:20.203876  4668 net.cpp:100] Creating Layer conv1_1
I0908 13:55:20.203879  4668 net.cpp:434] conv1_1 <- image_data_0_split_0
I0908 13:55:20.203886  4668 net.cpp:408] conv1_1 -> conv1_1
I0908 13:55:20.204516  4668 net.cpp:150] Setting up conv1_1
I0908 13:55:20.204526  4668 net.cpp:157] Top shape: 128 8 298 298 (90935296)
I0908 13:55:20.204529  4668 net.cpp:165] Memory required for data: 670941184
I0908 13:55:20.204540  4668 layer_factory.hpp:77] Creating layer pool1
I0908 13:55:20.204546  4668 net.cpp:100] Creating Layer pool1
I0908 13:55:20.204550  4668 net.cpp:434] pool1 <- conv1_1
I0908 13:55:20.204553  4668 net.cpp:408] pool1 -> pool1
I0908 13:55:20.204586  4668 net.cpp:150] Setting up pool1
I0908 13:55:20.204591  4668 net.cpp:157] Top shape: 128 8 149 149 (22733824)
I0908 13:55:20.204593  4668 net.cpp:165] Memory required for data: 761876480
I0908 13:55:20.204596  4668 layer_factory.hpp:77] Creating layer conv1_1_bn
I0908 13:55:20.204603  4668 net.cpp:100] Creating Layer conv1_1_bn
I0908 13:55:20.204607  4668 net.cpp:434] conv1_1_bn <- pool1
I0908 13:55:20.204612  4668 net.cpp:408] conv1_1_bn -> conv1_1_bn
I0908 13:55:20.213629  4668 net.cpp:150] Setting up conv1_1_bn
I0908 13:55:20.213654  4668 net.cpp:157] Top shape: 128 8 149 149 (22733824)
I0908 13:55:20.213657  4668 net.cpp:165] Memory required for data: 852811776
I0908 13:55:20.213671  4668 layer_factory.hpp:77] Creating layer conv1_1_bn_scale
I0908 13:55:20.213681  4668 net.cpp:100] Creating Layer conv1_1_bn_scale
I0908 13:55:20.213686  4668 net.cpp:434] conv1_1_bn_scale <- conv1_1_bn
I0908 13:55:20.213691  4668 net.cpp:395] conv1_1_bn_scale -> conv1_1_bn (in-place)
I0908 13:55:20.213732  4668 layer_factory.hpp:77] Creating layer conv1_1_bn_scale
I0908 13:55:20.213845  4668 net.cpp:150] Setting up conv1_1_bn_scale
I0908 13:55:20.213850  4668 net.cpp:157] Top shape: 128 8 149 149 (22733824)
I0908 13:55:20.213853  4668 net.cpp:165] Memory required for data: 943747072
I0908 13:55:20.213860  4668 layer_factory.hpp:77] Creating layer conv1_1_relu
I0908 13:55:20.213867  4668 net.cpp:100] Creating Layer conv1_1_relu
I0908 13:55:20.213886  4668 net.cpp:434] conv1_1_relu <- conv1_1_bn
I0908 13:55:20.213891  4668 net.cpp:395] conv1_1_relu -> conv1_1_bn (in-place)
I0908 13:55:20.213896  4668 net.cpp:150] Setting up conv1_1_relu
I0908 13:55:20.213901  4668 net.cpp:157] Top shape: 128 8 149 149 (22733824)
I0908 13:55:20.213902  4668 net.cpp:165] Memory required for data: 1034682368
I0908 13:55:20.213906  4668 layer_factory.hpp:77] Creating layer conv2_1
I0908 13:55:20.213915  4668 net.cpp:100] Creating Layer conv2_1
I0908 13:55:20.213918  4668 net.cpp:434] conv2_1 <- conv1_1_bn
I0908 13:55:20.213924  4668 net.cpp:408] conv2_1 -> conv2_1
I0908 13:55:20.214581  4668 net.cpp:150] Setting up conv2_1
I0908 13:55:20.214592  4668 net.cpp:157] Top shape: 128 16 149 149 (45467648)
I0908 13:55:20.214594  4668 net.cpp:165] Memory required for data: 1216552960
I0908 13:55:20.214599  4668 layer_factory.hpp:77] Creating layer pool2
I0908 13:55:20.214607  4668 net.cpp:100] Creating Layer pool2
I0908 13:55:20.214609  4668 net.cpp:434] pool2 <- conv2_1
I0908 13:55:20.214613  4668 net.cpp:408] pool2 -> pool2
I0908 13:55:20.214643  4668 net.cpp:150] Setting up pool2
I0908 13:55:20.214648  4668 net.cpp:157] Top shape: 128 16 75 75 (11520000)
I0908 13:55:20.214650  4668 net.cpp:165] Memory required for data: 1262632960
I0908 13:55:20.214653  4668 layer_factory.hpp:77] Creating layer conv2_1_bn
I0908 13:55:20.214658  4668 net.cpp:100] Creating Layer conv2_1_bn
I0908 13:55:20.214660  4668 net.cpp:434] conv2_1_bn <- pool2
I0908 13:55:20.214665  4668 net.cpp:408] conv2_1_bn -> conv2_1_bn
I0908 13:55:20.215230  4668 net.cpp:150] Setting up conv2_1_bn
I0908 13:55:20.215241  4668 net.cpp:157] Top shape: 128 16 75 75 (11520000)
I0908 13:55:20.215245  4668 net.cpp:165] Memory required for data: 1308712960
I0908 13:55:20.215253  4668 layer_factory.hpp:77] Creating layer conv2_1_bn_scale
I0908 13:55:20.215260  4668 net.cpp:100] Creating Layer conv2_1_bn_scale
I0908 13:55:20.215262  4668 net.cpp:434] conv2_1_bn_scale <- conv2_1_bn
I0908 13:55:20.215267  4668 net.cpp:395] conv2_1_bn_scale -> conv2_1_bn (in-place)
I0908 13:55:20.215294  4668 layer_factory.hpp:77] Creating layer conv2_1_bn_scale
I0908 13:55:20.215374  4668 net.cpp:150] Setting up conv2_1_bn_scale
I0908 13:55:20.215380  4668 net.cpp:157] Top shape: 128 16 75 75 (11520000)
I0908 13:55:20.215382  4668 net.cpp:165] Memory required for data: 1354792960
I0908 13:55:20.215389  4668 layer_factory.hpp:77] Creating layer conv2_1_relu
I0908 13:55:20.215392  4668 net.cpp:100] Creating Layer conv2_1_relu
I0908 13:55:20.215395  4668 net.cpp:434] conv2_1_relu <- conv2_1_bn
I0908 13:55:20.215400  4668 net.cpp:395] conv2_1_relu -> conv2_1_bn (in-place)
I0908 13:55:20.215405  4668 net.cpp:150] Setting up conv2_1_relu
I0908 13:55:20.215409  4668 net.cpp:157] Top shape: 128 16 75 75 (11520000)
I0908 13:55:20.215411  4668 net.cpp:165] Memory required for data: 1400872960
I0908 13:55:20.215415  4668 layer_factory.hpp:77] Creating layer conv3_1
I0908 13:55:20.215422  4668 net.cpp:100] Creating Layer conv3_1
I0908 13:55:20.215425  4668 net.cpp:434] conv3_1 <- conv2_1_bn
I0908 13:55:20.215430  4668 net.cpp:408] conv3_1 -> conv3_1
I0908 13:55:20.215648  4668 net.cpp:150] Setting up conv3_1
I0908 13:55:20.215654  4668 net.cpp:157] Top shape: 128 32 75 75 (23040000)
I0908 13:55:20.215657  4668 net.cpp:165] Memory required for data: 1493032960
I0908 13:55:20.215662  4668 layer_factory.hpp:77] Creating layer pool3
I0908 13:55:20.215667  4668 net.cpp:100] Creating Layer pool3
I0908 13:55:20.215669  4668 net.cpp:434] pool3 <- conv3_1
I0908 13:55:20.215674  4668 net.cpp:408] pool3 -> pool3
I0908 13:55:20.215698  4668 net.cpp:150] Setting up pool3
I0908 13:55:20.215701  4668 net.cpp:157] Top shape: 128 32 38 38 (5914624)
I0908 13:55:20.215704  4668 net.cpp:165] Memory required for data: 1516691456
I0908 13:55:20.215706  4668 layer_factory.hpp:77] Creating layer conv3_1_bn
I0908 13:55:20.215713  4668 net.cpp:100] Creating Layer conv3_1_bn
I0908 13:55:20.215715  4668 net.cpp:434] conv3_1_bn <- pool3
I0908 13:55:20.215729  4668 net.cpp:408] conv3_1_bn -> conv3_1_bn
I0908 13:55:20.215863  4668 net.cpp:150] Setting up conv3_1_bn
I0908 13:55:20.215868  4668 net.cpp:157] Top shape: 128 32 38 38 (5914624)
I0908 13:55:20.215872  4668 net.cpp:165] Memory required for data: 1540349952
I0908 13:55:20.215876  4668 layer_factory.hpp:77] Creating layer conv3_1_bn_scale
I0908 13:55:20.215883  4668 net.cpp:100] Creating Layer conv3_1_bn_scale
I0908 13:55:20.215885  4668 net.cpp:434] conv3_1_bn_scale <- conv3_1_bn
I0908 13:55:20.215891  4668 net.cpp:395] conv3_1_bn_scale -> conv3_1_bn (in-place)
I0908 13:55:20.215915  4668 layer_factory.hpp:77] Creating layer conv3_1_bn_scale
I0908 13:55:20.215993  4668 net.cpp:150] Setting up conv3_1_bn_scale
I0908 13:55:20.215999  4668 net.cpp:157] Top shape: 128 32 38 38 (5914624)
I0908 13:55:20.216001  4668 net.cpp:165] Memory required for data: 1564008448
I0908 13:55:20.216009  4668 layer_factory.hpp:77] Creating layer conv3_1_relu
I0908 13:55:20.216013  4668 net.cpp:100] Creating Layer conv3_1_relu
I0908 13:55:20.216017  4668 net.cpp:434] conv3_1_relu <- conv3_1_bn
I0908 13:55:20.216022  4668 net.cpp:395] conv3_1_relu -> conv3_1_bn (in-place)
I0908 13:55:20.216027  4668 net.cpp:150] Setting up conv3_1_relu
I0908 13:55:20.216029  4668 net.cpp:157] Top shape: 128 32 38 38 (5914624)
I0908 13:55:20.216032  4668 net.cpp:165] Memory required for data: 1587666944
I0908 13:55:20.216035  4668 layer_factory.hpp:77] Creating layer conv4_1
I0908 13:55:20.216042  4668 net.cpp:100] Creating Layer conv4_1
I0908 13:55:20.216045  4668 net.cpp:434] conv4_1 <- conv3_1_bn
I0908 13:55:20.216049  4668 net.cpp:408] conv4_1 -> conv4_1
I0908 13:55:20.216562  4668 net.cpp:150] Setting up conv4_1
I0908 13:55:20.216567  4668 net.cpp:157] Top shape: 128 64 38 38 (11829248)
I0908 13:55:20.216570  4668 net.cpp:165] Memory required for data: 1634983936
I0908 13:55:20.216573  4668 layer_factory.hpp:77] Creating layer pool4
I0908 13:55:20.216578  4668 net.cpp:100] Creating Layer pool4
I0908 13:55:20.216581  4668 net.cpp:434] pool4 <- conv4_1
I0908 13:55:20.216586  4668 net.cpp:408] pool4 -> pool4
I0908 13:55:20.216612  4668 net.cpp:150] Setting up pool4
I0908 13:55:20.216617  4668 net.cpp:157] Top shape: 128 64 19 19 (2957312)
I0908 13:55:20.216619  4668 net.cpp:165] Memory required for data: 1646813184
I0908 13:55:20.216622  4668 layer_factory.hpp:77] Creating layer conv4_1_bn
I0908 13:55:20.216629  4668 net.cpp:100] Creating Layer conv4_1_bn
I0908 13:55:20.216630  4668 net.cpp:434] conv4_1_bn <- pool4
I0908 13:55:20.216634  4668 net.cpp:408] conv4_1_bn -> conv4_1_bn
I0908 13:55:20.216763  4668 net.cpp:150] Setting up conv4_1_bn
I0908 13:55:20.216768  4668 net.cpp:157] Top shape: 128 64 19 19 (2957312)
I0908 13:55:20.216769  4668 net.cpp:165] Memory required for data: 1658642432
I0908 13:55:20.216775  4668 layer_factory.hpp:77] Creating layer conv4_1_bn_scale
I0908 13:55:20.216781  4668 net.cpp:100] Creating Layer conv4_1_bn_scale
I0908 13:55:20.216784  4668 net.cpp:434] conv4_1_bn_scale <- conv4_1_bn
I0908 13:55:20.216789  4668 net.cpp:395] conv4_1_bn_scale -> conv4_1_bn (in-place)
I0908 13:55:20.216811  4668 layer_factory.hpp:77] Creating layer conv4_1_bn_scale
I0908 13:55:20.216891  4668 net.cpp:150] Setting up conv4_1_bn_scale
I0908 13:55:20.216895  4668 net.cpp:157] Top shape: 128 64 19 19 (2957312)
I0908 13:55:20.216898  4668 net.cpp:165] Memory required for data: 1670471680
I0908 13:55:20.216902  4668 layer_factory.hpp:77] Creating layer conv4_1_relu
I0908 13:55:20.216907  4668 net.cpp:100] Creating Layer conv4_1_relu
I0908 13:55:20.216910  4668 net.cpp:434] conv4_1_relu <- conv4_1_bn
I0908 13:55:20.216915  4668 net.cpp:395] conv4_1_relu -> conv4_1_bn (in-place)
I0908 13:55:20.216919  4668 net.cpp:150] Setting up conv4_1_relu
I0908 13:55:20.216923  4668 net.cpp:157] Top shape: 128 64 19 19 (2957312)
I0908 13:55:20.216927  4668 net.cpp:165] Memory required for data: 1682300928
I0908 13:55:20.216928  4668 layer_factory.hpp:77] Creating layer conv5_1
I0908 13:55:20.216935  4668 net.cpp:100] Creating Layer conv5_1
I0908 13:55:20.216943  4668 net.cpp:434] conv5_1 <- conv4_1_bn
I0908 13:55:20.216951  4668 net.cpp:408] conv5_1 -> conv5_1
I0908 13:55:20.217854  4668 net.cpp:150] Setting up conv5_1
I0908 13:55:20.217861  4668 net.cpp:157] Top shape: 128 64 17 17 (2367488)
I0908 13:55:20.217864  4668 net.cpp:165] Memory required for data: 1691770880
I0908 13:55:20.217869  4668 layer_factory.hpp:77] Creating layer conv5_1_bn
I0908 13:55:20.217874  4668 net.cpp:100] Creating Layer conv5_1_bn
I0908 13:55:20.217877  4668 net.cpp:434] conv5_1_bn <- conv5_1
I0908 13:55:20.217881  4668 net.cpp:408] conv5_1_bn -> conv5_1_bn
I0908 13:55:20.218015  4668 net.cpp:150] Setting up conv5_1_bn
I0908 13:55:20.218020  4668 net.cpp:157] Top shape: 128 64 17 17 (2367488)
I0908 13:55:20.218024  4668 net.cpp:165] Memory required for data: 1701240832
I0908 13:55:20.218029  4668 layer_factory.hpp:77] Creating layer conv5_1_bn_scale
I0908 13:55:20.218034  4668 net.cpp:100] Creating Layer conv5_1_bn_scale
I0908 13:55:20.218036  4668 net.cpp:434] conv5_1_bn_scale <- conv5_1_bn
I0908 13:55:20.218040  4668 net.cpp:395] conv5_1_bn_scale -> conv5_1_bn (in-place)
I0908 13:55:20.218065  4668 layer_factory.hpp:77] Creating layer conv5_1_bn_scale
I0908 13:55:20.218140  4668 net.cpp:150] Setting up conv5_1_bn_scale
I0908 13:55:20.218145  4668 net.cpp:157] Top shape: 128 64 17 17 (2367488)
I0908 13:55:20.218147  4668 net.cpp:165] Memory required for data: 1710710784
I0908 13:55:20.218152  4668 layer_factory.hpp:77] Creating layer conv5_1_relu
I0908 13:55:20.218158  4668 net.cpp:100] Creating Layer conv5_1_relu
I0908 13:55:20.218161  4668 net.cpp:434] conv5_1_relu <- conv5_1_bn
I0908 13:55:20.218164  4668 net.cpp:395] conv5_1_relu -> conv5_1_bn (in-place)
I0908 13:55:20.218168  4668 net.cpp:150] Setting up conv5_1_relu
I0908 13:55:20.218173  4668 net.cpp:157] Top shape: 128 64 17 17 (2367488)
I0908 13:55:20.218175  4668 net.cpp:165] Memory required for data: 1720180736
I0908 13:55:20.218178  4668 layer_factory.hpp:77] Creating layer conv6_1
I0908 13:55:20.218184  4668 net.cpp:100] Creating Layer conv6_1
I0908 13:55:20.218188  4668 net.cpp:434] conv6_1 <- conv5_1_bn
I0908 13:55:20.218191  4668 net.cpp:408] conv6_1 -> conv6_1
I0908 13:55:20.219106  4668 net.cpp:150] Setting up conv6_1
I0908 13:55:20.219115  4668 net.cpp:157] Top shape: 128 64 15 15 (1843200)
I0908 13:55:20.219117  4668 net.cpp:165] Memory required for data: 1727553536
I0908 13:55:20.219121  4668 layer_factory.hpp:77] Creating layer conv6_1_bn
I0908 13:55:20.219126  4668 net.cpp:100] Creating Layer conv6_1_bn
I0908 13:55:20.219130  4668 net.cpp:434] conv6_1_bn <- conv6_1
I0908 13:55:20.219133  4668 net.cpp:408] conv6_1_bn -> conv6_1_bn
I0908 13:55:20.219261  4668 net.cpp:150] Setting up conv6_1_bn
I0908 13:55:20.219266  4668 net.cpp:157] Top shape: 128 64 15 15 (1843200)
I0908 13:55:20.219269  4668 net.cpp:165] Memory required for data: 1734926336
I0908 13:55:20.219281  4668 layer_factory.hpp:77] Creating layer conv6_1_bn_scale
I0908 13:55:20.219287  4668 net.cpp:100] Creating Layer conv6_1_bn_scale
I0908 13:55:20.219290  4668 net.cpp:434] conv6_1_bn_scale <- conv6_1_bn
I0908 13:55:20.219295  4668 net.cpp:395] conv6_1_bn_scale -> conv6_1_bn (in-place)
I0908 13:55:20.219318  4668 layer_factory.hpp:77] Creating layer conv6_1_bn_scale
I0908 13:55:20.219389  4668 net.cpp:150] Setting up conv6_1_bn_scale
I0908 13:55:20.219394  4668 net.cpp:157] Top shape: 128 64 15 15 (1843200)
I0908 13:55:20.219396  4668 net.cpp:165] Memory required for data: 1742299136
I0908 13:55:20.219401  4668 layer_factory.hpp:77] Creating layer conv6_1_relu
I0908 13:55:20.219406  4668 net.cpp:100] Creating Layer conv6_1_relu
I0908 13:55:20.219409  4668 net.cpp:434] conv6_1_relu <- conv6_1_bn
I0908 13:55:20.219414  4668 net.cpp:395] conv6_1_relu -> conv6_1_bn (in-place)
I0908 13:55:20.219419  4668 net.cpp:150] Setting up conv6_1_relu
I0908 13:55:20.219422  4668 net.cpp:157] Top shape: 128 64 15 15 (1843200)
I0908 13:55:20.219425  4668 net.cpp:165] Memory required for data: 1749671936
I0908 13:55:20.219427  4668 layer_factory.hpp:77] Creating layer conv7_1
I0908 13:55:20.219439  4668 net.cpp:100] Creating Layer conv7_1
I0908 13:55:20.219449  4668 net.cpp:434] conv7_1 <- conv6_1_bn
I0908 13:55:20.219455  4668 net.cpp:408] conv7_1 -> conv7_1
I0908 13:55:20.221652  4668 net.cpp:150] Setting up conv7_1
I0908 13:55:20.221673  4668 net.cpp:157] Top shape: 128 128 13 13 (2768896)
I0908 13:55:20.221675  4668 net.cpp:165] Memory required for data: 1760747520
I0908 13:55:20.221680  4668 layer_factory.hpp:77] Creating layer conv7_1_bn
I0908 13:55:20.221695  4668 net.cpp:100] Creating Layer conv7_1_bn
I0908 13:55:20.221699  4668 net.cpp:434] conv7_1_bn <- conv7_1
I0908 13:55:20.221704  4668 net.cpp:408] conv7_1_bn -> conv7_1_bn
I0908 13:55:20.221833  4668 net.cpp:150] Setting up conv7_1_bn
I0908 13:55:20.221839  4668 net.cpp:157] Top shape: 128 128 13 13 (2768896)
I0908 13:55:20.221843  4668 net.cpp:165] Memory required for data: 1771823104
I0908 13:55:20.221848  4668 layer_factory.hpp:77] Creating layer conv7_1_bn_scale
I0908 13:55:20.221855  4668 net.cpp:100] Creating Layer conv7_1_bn_scale
I0908 13:55:20.221859  4668 net.cpp:434] conv7_1_bn_scale <- conv7_1_bn
I0908 13:55:20.221863  4668 net.cpp:395] conv7_1_bn_scale -> conv7_1_bn (in-place)
I0908 13:55:20.221887  4668 layer_factory.hpp:77] Creating layer conv7_1_bn_scale
I0908 13:55:20.221956  4668 net.cpp:150] Setting up conv7_1_bn_scale
I0908 13:55:20.221961  4668 net.cpp:157] Top shape: 128 128 13 13 (2768896)
I0908 13:55:20.221963  4668 net.cpp:165] Memory required for data: 1782898688
I0908 13:55:20.221968  4668 layer_factory.hpp:77] Creating layer conv7_1_relu
I0908 13:55:20.221973  4668 net.cpp:100] Creating Layer conv7_1_relu
I0908 13:55:20.221976  4668 net.cpp:434] conv7_1_relu <- conv7_1_bn
I0908 13:55:20.221981  4668 net.cpp:395] conv7_1_relu -> conv7_1_bn (in-place)
I0908 13:55:20.221985  4668 net.cpp:150] Setting up conv7_1_relu
I0908 13:55:20.221989  4668 net.cpp:157] Top shape: 128 128 13 13 (2768896)
I0908 13:55:20.221992  4668 net.cpp:165] Memory required for data: 1793974272
I0908 13:55:20.221994  4668 layer_factory.hpp:77] Creating layer score
I0908 13:55:20.222002  4668 net.cpp:100] Creating Layer score
I0908 13:55:20.222005  4668 net.cpp:434] score <- conv7_1_bn
I0908 13:55:20.222010  4668 net.cpp:408] score -> score
I0908 13:55:20.222173  4668 net.cpp:150] Setting up score
I0908 13:55:20.222179  4668 net.cpp:157] Top shape: 128 4 13 13 (86528)
I0908 13:55:20.222182  4668 net.cpp:165] Memory required for data: 1794320384
I0908 13:55:20.222187  4668 layer_factory.hpp:77] Creating layer upscore
I0908 13:55:20.222193  4668 net.cpp:100] Creating Layer upscore
I0908 13:55:20.222196  4668 net.cpp:434] upscore <- score
I0908 13:55:20.222201  4668 net.cpp:408] upscore -> upscore
I0908 13:55:20.222682  4668 net.cpp:150] Setting up upscore
I0908 13:55:20.222690  4668 net.cpp:157] Top shape: 128 4 224 224 (25690112)
I0908 13:55:20.222692  4668 net.cpp:165] Memory required for data: 1897080832
I0908 13:55:20.222697  4668 layer_factory.hpp:77] Creating layer cropscore
I0908 13:55:20.222702  4668 net.cpp:100] Creating Layer cropscore
I0908 13:55:20.222705  4668 net.cpp:434] cropscore <- upscore
I0908 13:55:20.222708  4668 net.cpp:434] cropscore <- image_data_0_split_1
I0908 13:55:20.222712  4668 net.cpp:408] cropscore -> cropscore
I0908 13:55:20.222731  4668 net.cpp:150] Setting up cropscore
I0908 13:55:20.222735  4668 net.cpp:157] Top shape: 128 4 200 200 (20480000)
I0908 13:55:20.222738  4668 net.cpp:165] Memory required for data: 1979000832
I0908 13:55:20.222741  4668 layer_factory.hpp:77] Creating layer cropscore_cropscore_0_split
I0908 13:55:20.222748  4668 net.cpp:100] Creating Layer cropscore_cropscore_0_split
I0908 13:55:20.222750  4668 net.cpp:434] cropscore_cropscore_0_split <- cropscore
I0908 13:55:20.222754  4668 net.cpp:408] cropscore_cropscore_0_split -> cropscore_cropscore_0_split_0
I0908 13:55:20.222759  4668 net.cpp:408] cropscore_cropscore_0_split -> cropscore_cropscore_0_split_1
I0908 13:55:20.222784  4668 net.cpp:150] Setting up cropscore_cropscore_0_split
I0908 13:55:20.222789  4668 net.cpp:157] Top shape: 128 4 200 200 (20480000)
I0908 13:55:20.222806  4668 net.cpp:157] Top shape: 128 4 200 200 (20480000)
I0908 13:55:20.222810  4668 net.cpp:165] Memory required for data: 2142840832
I0908 13:55:20.222812  4668 layer_factory.hpp:77] Creating layer loss
I0908 13:55:20.222817  4668 net.cpp:100] Creating Layer loss
I0908 13:55:20.222821  4668 net.cpp:434] loss <- cropscore_cropscore_0_split_0
I0908 13:55:20.222826  4668 net.cpp:434] loss <- label_data_1_split_0
I0908 13:55:20.222829  4668 net.cpp:408] loss -> loss
I0908 13:55:20.222836  4668 layer_factory.hpp:77] Creating layer loss
I0908 13:55:20.260542  4668 net.cpp:150] Setting up loss
I0908 13:55:20.260571  4668 net.cpp:157] Top shape: (1)
I0908 13:55:20.260573  4668 net.cpp:160]     with loss weight 1
I0908 13:55:20.260592  4668 net.cpp:165] Memory required for data: 2142840836
I0908 13:55:20.260596  4668 layer_factory.hpp:77] Creating layer accuracy
I0908 13:55:20.260606  4668 net.cpp:100] Creating Layer accuracy
I0908 13:55:20.260609  4668 net.cpp:434] accuracy <- cropscore_cropscore_0_split_1
I0908 13:55:20.260615  4668 net.cpp:434] accuracy <- label_data_1_split_1
I0908 13:55:20.260624  4668 net.cpp:408] accuracy -> accuracy
I0908 13:55:20.260633  4668 net.cpp:150] Setting up accuracy
I0908 13:55:20.260637  4668 net.cpp:157] Top shape: (1)
I0908 13:55:20.260639  4668 net.cpp:165] Memory required for data: 2142840840
I0908 13:55:20.260643  4668 net.cpp:228] accuracy does not need backward computation.
I0908 13:55:20.260648  4668 net.cpp:226] loss needs backward computation.
I0908 13:55:20.260651  4668 net.cpp:226] cropscore_cropscore_0_split needs backward computation.
I0908 13:55:20.260654  4668 net.cpp:226] cropscore needs backward computation.
I0908 13:55:20.260658  4668 net.cpp:226] upscore needs backward computation.
I0908 13:55:20.260660  4668 net.cpp:226] score needs backward computation.
I0908 13:55:20.260664  4668 net.cpp:226] conv7_1_relu needs backward computation.
I0908 13:55:20.260666  4668 net.cpp:226] conv7_1_bn_scale needs backward computation.
I0908 13:55:20.260669  4668 net.cpp:226] conv7_1_bn needs backward computation.
I0908 13:55:20.260673  4668 net.cpp:226] conv7_1 needs backward computation.
I0908 13:55:20.260675  4668 net.cpp:226] conv6_1_relu needs backward computation.
I0908 13:55:20.260679  4668 net.cpp:226] conv6_1_bn_scale needs backward computation.
I0908 13:55:20.260681  4668 net.cpp:226] conv6_1_bn needs backward computation.
I0908 13:55:20.260684  4668 net.cpp:226] conv6_1 needs backward computation.
I0908 13:55:20.260687  4668 net.cpp:226] conv5_1_relu needs backward computation.
I0908 13:55:20.260689  4668 net.cpp:226] conv5_1_bn_scale needs backward computation.
I0908 13:55:20.260692  4668 net.cpp:226] conv5_1_bn needs backward computation.
I0908 13:55:20.260695  4668 net.cpp:226] conv5_1 needs backward computation.
I0908 13:55:20.260699  4668 net.cpp:226] conv4_1_relu needs backward computation.
I0908 13:55:20.260701  4668 net.cpp:226] conv4_1_bn_scale needs backward computation.
I0908 13:55:20.260704  4668 net.cpp:226] conv4_1_bn needs backward computation.
I0908 13:55:20.260707  4668 net.cpp:226] pool4 needs backward computation.
I0908 13:55:20.260710  4668 net.cpp:226] conv4_1 needs backward computation.
I0908 13:55:20.260713  4668 net.cpp:226] conv3_1_relu needs backward computation.
I0908 13:55:20.260716  4668 net.cpp:226] conv3_1_bn_scale needs backward computation.
I0908 13:55:20.260718  4668 net.cpp:226] conv3_1_bn needs backward computation.
I0908 13:55:20.260721  4668 net.cpp:226] pool3 needs backward computation.
I0908 13:55:20.260725  4668 net.cpp:226] conv3_1 needs backward computation.
I0908 13:55:20.260727  4668 net.cpp:226] conv2_1_relu needs backward computation.
I0908 13:55:20.260730  4668 net.cpp:226] conv2_1_bn_scale needs backward computation.
I0908 13:55:20.260733  4668 net.cpp:226] conv2_1_bn needs backward computation.
I0908 13:55:20.260736  4668 net.cpp:226] pool2 needs backward computation.
I0908 13:55:20.260740  4668 net.cpp:226] conv2_1 needs backward computation.
I0908 13:55:20.260742  4668 net.cpp:226] conv1_1_relu needs backward computation.
I0908 13:55:20.260761  4668 net.cpp:226] conv1_1_bn_scale needs backward computation.
I0908 13:55:20.260764  4668 net.cpp:226] conv1_1_bn needs backward computation.
I0908 13:55:20.260767  4668 net.cpp:226] pool1 needs backward computation.
I0908 13:55:20.260771  4668 net.cpp:226] conv1_1 needs backward computation.
I0908 13:55:20.260774  4668 net.cpp:228] label_data_1_split does not need backward computation.
I0908 13:55:20.260778  4668 net.cpp:228] image_data_0_split does not need backward computation.
I0908 13:55:20.260782  4668 net.cpp:228] data does not need backward computation.
I0908 13:55:20.260784  4668 net.cpp:270] This network produces output accuracy
I0908 13:55:20.260787  4668 net.cpp:270] This network produces output loss
I0908 13:55:20.260809  4668 net.cpp:283] Network initialization done.
I0908 13:55:20.261386  4668 solver.cpp:181] Creating test net (#0) specified by net file: portrait_wfm_train_test_one_stage.prototxt
I0908 13:55:20.261426  4668 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0908 13:55:20.261577  4668 net.cpp:58] Initializing net from parameters: 
name: "segmentation"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "SegData"
  top: "image"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 200
  }
  data_param {
    source: "/raid/xuehan/segmentation_wfm_test_split"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "image"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 50
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1_1_bn"
  type: "BatchNorm"
  bottom: "pool1"
  top: "conv1_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv1_1_bn_scale"
  type: "Scale"
  bottom: "conv1_1_bn"
  top: "conv1_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_1_relu"
  type: "ReLU"
  bottom: "conv1_1_bn"
  top: "conv1_1_bn"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv1_1_bn"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_1"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1_bn"
  type: "BatchNorm"
  bottom: "pool2"
  top: "conv2_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv2_1_bn_scale"
  type: "Scale"
  bottom: "conv2_1_bn"
  top: "conv2_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1_relu"
  type: "ReLU"
  bottom: "conv2_1_bn"
  top: "conv2_1_bn"
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv2_1_bn"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_1"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1_bn"
  type: "BatchNorm"
  bottom: "pool3"
  top: "conv3_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv3_1_bn_scale"
  type: "Scale"
  bottom: "conv3_1_bn"
  top: "conv3_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1_relu"
  type: "ReLU"
  bottom: "conv3_1_bn"
  top: "conv3_1_bn"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv3_1_bn"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_1"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1_bn"
  type: "BatchNorm"
  bottom: "pool4"
  top: "conv4_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv4_1_bn_scale"
  type: "Scale"
  bottom: "conv4_1_bn"
  top: "conv4_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1_relu"
  type: "ReLU"
  bottom: "conv4_1_bn"
  top: "conv4_1_bn"
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "conv4_1_bn"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv5_1_bn"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv5_1_bn_scale"
  type: "Scale"
  bottom: "conv5_1_bn"
  top: "conv5_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_1_relu"
  type: "ReLU"
  bottom: "conv5_1_bn"
  top: "conv5_1_bn"
}
layer {
  name: "conv6_1"
  type: "Convolution"
  bottom: "conv5_1_bn"
  top: "conv6_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv6_1_bn"
  type: "BatchNorm"
  bottom: "conv6_1"
  top: "conv6_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv6_1_bn_scale"
  type: "Scale"
  bottom: "conv6_1_bn"
  top: "conv6_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv6_1_relu"
  type: "ReLU"
  bottom: "conv6_1_bn"
  top: "conv6_1_bn"
}
layer {
  name: "conv7_1"
  type: "Convolution"
  bottom: "conv6_1_bn"
  top: "conv7_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv7_1_bn"
  type: "BatchNorm"
  bottom: "conv7_1"
  top: "conv7_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv7_1_bn_scale"
  type: "Scale"
  bottom: "conv7_1_bn"
  top: "conv7_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv7_1_relu"
  type: "ReLU"
  bottom: "conv7_1_bn"
  top: "conv7_1_bn"
}
layer {
  name: "score"
  type: "Convolution"
  bottom: "conv7_1_bn"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 4
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "upscore"
  type: "Deconvolution"
  bottom: "score"
  top: "upscore"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 4
    bias_term: false
    pad: 0
    kernel_size: 32
    stride: 16
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "cropscore"
  type: "Crop"
  bottom: "upscore"
  bottom: "image"
  top: "cropscore"
  crop_param {
    axis: 2
    offset: 12
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "cropscore"
  bottom: "label"
  top: "loss"
  loss_weight: 1
  loss_param {
    normalize: false
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "cropscore"
  bottom: "label"
  top: "accuracy"
}
I0908 13:55:20.261699  4668 layer_factory.hpp:77] Creating layer data
I0908 13:55:20.261796  4668 net.cpp:100] Creating Layer data
I0908 13:55:20.261804  4668 net.cpp:408] data -> image
I0908 13:55:20.261814  4668 net.cpp:408] data -> label
I0908 13:55:20.262876  4678 db_lmdb.cpp:35] Opened lmdb /raid/xuehan/segmentation_wfm_test_split
I0908 13:55:20.263094  4668 seg_data_layer.cpp:38] 200 200 5
I0908 13:55:20.263182  4668 seg_data_layer.cpp:51] output data size: 64,4,200,200
I0908 13:55:20.263228  4668 seg_data_layer.cpp:63] output label size: 64,1,200,200
I0908 13:55:20.341280  4668 net.cpp:150] Setting up data
I0908 13:55:20.341315  4668 net.cpp:157] Top shape: 64 4 200 200 (10240000)
I0908 13:55:20.341320  4668 net.cpp:157] Top shape: 64 1 200 200 (2560000)
I0908 13:55:20.341323  4668 net.cpp:165] Memory required for data: 51200000
I0908 13:55:20.341330  4668 layer_factory.hpp:77] Creating layer image_data_0_split
I0908 13:55:20.341344  4668 net.cpp:100] Creating Layer image_data_0_split
I0908 13:55:20.341348  4668 net.cpp:434] image_data_0_split <- image
I0908 13:55:20.341356  4668 net.cpp:408] image_data_0_split -> image_data_0_split_0
I0908 13:55:20.341364  4668 net.cpp:408] image_data_0_split -> image_data_0_split_1
I0908 13:55:20.341462  4668 net.cpp:150] Setting up image_data_0_split
I0908 13:55:20.341471  4668 net.cpp:157] Top shape: 64 4 200 200 (10240000)
I0908 13:55:20.341475  4668 net.cpp:157] Top shape: 64 4 200 200 (10240000)
I0908 13:55:20.341477  4668 net.cpp:165] Memory required for data: 133120000
I0908 13:55:20.341480  4668 layer_factory.hpp:77] Creating layer label_data_1_split
I0908 13:55:20.341486  4668 net.cpp:100] Creating Layer label_data_1_split
I0908 13:55:20.341492  4668 net.cpp:434] label_data_1_split <- label
I0908 13:55:20.341497  4668 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0908 13:55:20.341502  4668 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0908 13:55:20.341531  4668 net.cpp:150] Setting up label_data_1_split
I0908 13:55:20.341538  4668 net.cpp:157] Top shape: 64 1 200 200 (2560000)
I0908 13:55:20.341543  4668 net.cpp:157] Top shape: 64 1 200 200 (2560000)
I0908 13:55:20.341545  4668 net.cpp:165] Memory required for data: 153600000
I0908 13:55:20.341548  4668 layer_factory.hpp:77] Creating layer conv1_1
I0908 13:55:20.341562  4668 net.cpp:100] Creating Layer conv1_1
I0908 13:55:20.341564  4668 net.cpp:434] conv1_1 <- image_data_0_split_0
I0908 13:55:20.341569  4668 net.cpp:408] conv1_1 -> conv1_1
I0908 13:55:20.341758  4668 net.cpp:150] Setting up conv1_1
I0908 13:55:20.341764  4668 net.cpp:157] Top shape: 64 8 298 298 (45467648)
I0908 13:55:20.341768  4668 net.cpp:165] Memory required for data: 335470592
I0908 13:55:20.341774  4668 layer_factory.hpp:77] Creating layer pool1
I0908 13:55:20.341781  4668 net.cpp:100] Creating Layer pool1
I0908 13:55:20.341784  4668 net.cpp:434] pool1 <- conv1_1
I0908 13:55:20.341789  4668 net.cpp:408] pool1 -> pool1
I0908 13:55:20.341816  4668 net.cpp:150] Setting up pool1
I0908 13:55:20.341821  4668 net.cpp:157] Top shape: 64 8 149 149 (11366912)
I0908 13:55:20.341825  4668 net.cpp:165] Memory required for data: 380938240
I0908 13:55:20.341827  4668 layer_factory.hpp:77] Creating layer conv1_1_bn
I0908 13:55:20.341832  4668 net.cpp:100] Creating Layer conv1_1_bn
I0908 13:55:20.341835  4668 net.cpp:434] conv1_1_bn <- pool1
I0908 13:55:20.341840  4668 net.cpp:408] conv1_1_bn -> conv1_1_bn
I0908 13:55:20.342002  4668 net.cpp:150] Setting up conv1_1_bn
I0908 13:55:20.342010  4668 net.cpp:157] Top shape: 64 8 149 149 (11366912)
I0908 13:55:20.342011  4668 net.cpp:165] Memory required for data: 426405888
I0908 13:55:20.342021  4668 layer_factory.hpp:77] Creating layer conv1_1_bn_scale
I0908 13:55:20.342027  4668 net.cpp:100] Creating Layer conv1_1_bn_scale
I0908 13:55:20.342031  4668 net.cpp:434] conv1_1_bn_scale <- conv1_1_bn
I0908 13:55:20.342034  4668 net.cpp:395] conv1_1_bn_scale -> conv1_1_bn (in-place)
I0908 13:55:20.342064  4668 layer_factory.hpp:77] Creating layer conv1_1_bn_scale
I0908 13:55:20.342185  4668 net.cpp:150] Setting up conv1_1_bn_scale
I0908 13:55:20.342198  4668 net.cpp:157] Top shape: 64 8 149 149 (11366912)
I0908 13:55:20.342201  4668 net.cpp:165] Memory required for data: 471873536
I0908 13:55:20.342208  4668 layer_factory.hpp:77] Creating layer conv1_1_relu
I0908 13:55:20.342216  4668 net.cpp:100] Creating Layer conv1_1_relu
I0908 13:55:20.342218  4668 net.cpp:434] conv1_1_relu <- conv1_1_bn
I0908 13:55:20.342222  4668 net.cpp:395] conv1_1_relu -> conv1_1_bn (in-place)
I0908 13:55:20.342227  4668 net.cpp:150] Setting up conv1_1_relu
I0908 13:55:20.342231  4668 net.cpp:157] Top shape: 64 8 149 149 (11366912)
I0908 13:55:20.342233  4668 net.cpp:165] Memory required for data: 517341184
I0908 13:55:20.342236  4668 layer_factory.hpp:77] Creating layer conv2_1
I0908 13:55:20.342245  4668 net.cpp:100] Creating Layer conv2_1
I0908 13:55:20.342248  4668 net.cpp:434] conv2_1 <- conv1_1_bn
I0908 13:55:20.342252  4668 net.cpp:408] conv2_1 -> conv2_1
I0908 13:55:20.342459  4668 net.cpp:150] Setting up conv2_1
I0908 13:55:20.342468  4668 net.cpp:157] Top shape: 64 16 149 149 (22733824)
I0908 13:55:20.342471  4668 net.cpp:165] Memory required for data: 608276480
I0908 13:55:20.342475  4668 layer_factory.hpp:77] Creating layer pool2
I0908 13:55:20.342481  4668 net.cpp:100] Creating Layer pool2
I0908 13:55:20.342484  4668 net.cpp:434] pool2 <- conv2_1
I0908 13:55:20.342489  4668 net.cpp:408] pool2 -> pool2
I0908 13:55:20.347277  4668 net.cpp:150] Setting up pool2
I0908 13:55:20.347301  4668 net.cpp:157] Top shape: 64 16 75 75 (5760000)
I0908 13:55:20.347302  4668 net.cpp:165] Memory required for data: 631316480
I0908 13:55:20.347307  4668 layer_factory.hpp:77] Creating layer conv2_1_bn
I0908 13:55:20.347317  4668 net.cpp:100] Creating Layer conv2_1_bn
I0908 13:55:20.347322  4668 net.cpp:434] conv2_1_bn <- pool2
I0908 13:55:20.347327  4668 net.cpp:408] conv2_1_bn -> conv2_1_bn
I0908 13:55:20.347491  4668 net.cpp:150] Setting up conv2_1_bn
I0908 13:55:20.347496  4668 net.cpp:157] Top shape: 64 16 75 75 (5760000)
I0908 13:55:20.347498  4668 net.cpp:165] Memory required for data: 654356480
I0908 13:55:20.347510  4668 layer_factory.hpp:77] Creating layer conv2_1_bn_scale
I0908 13:55:20.347517  4668 net.cpp:100] Creating Layer conv2_1_bn_scale
I0908 13:55:20.347519  4668 net.cpp:434] conv2_1_bn_scale <- conv2_1_bn
I0908 13:55:20.347523  4668 net.cpp:395] conv2_1_bn_scale -> conv2_1_bn (in-place)
I0908 13:55:20.347558  4668 layer_factory.hpp:77] Creating layer conv2_1_bn_scale
I0908 13:55:20.347671  4668 net.cpp:150] Setting up conv2_1_bn_scale
I0908 13:55:20.347681  4668 net.cpp:157] Top shape: 64 16 75 75 (5760000)
I0908 13:55:20.347683  4668 net.cpp:165] Memory required for data: 677396480
I0908 13:55:20.347688  4668 layer_factory.hpp:77] Creating layer conv2_1_relu
I0908 13:55:20.347694  4668 net.cpp:100] Creating Layer conv2_1_relu
I0908 13:55:20.347697  4668 net.cpp:434] conv2_1_relu <- conv2_1_bn
I0908 13:55:20.347702  4668 net.cpp:395] conv2_1_relu -> conv2_1_bn (in-place)
I0908 13:55:20.347707  4668 net.cpp:150] Setting up conv2_1_relu
I0908 13:55:20.347709  4668 net.cpp:157] Top shape: 64 16 75 75 (5760000)
I0908 13:55:20.347712  4668 net.cpp:165] Memory required for data: 700436480
I0908 13:55:20.347715  4668 layer_factory.hpp:77] Creating layer conv3_1
I0908 13:55:20.347724  4668 net.cpp:100] Creating Layer conv3_1
I0908 13:55:20.347728  4668 net.cpp:434] conv3_1 <- conv2_1_bn
I0908 13:55:20.347733  4668 net.cpp:408] conv3_1 -> conv3_1
I0908 13:55:20.347985  4668 net.cpp:150] Setting up conv3_1
I0908 13:55:20.347993  4668 net.cpp:157] Top shape: 64 32 75 75 (11520000)
I0908 13:55:20.347995  4668 net.cpp:165] Memory required for data: 746516480
I0908 13:55:20.348001  4668 layer_factory.hpp:77] Creating layer pool3
I0908 13:55:20.348006  4668 net.cpp:100] Creating Layer pool3
I0908 13:55:20.348009  4668 net.cpp:434] pool3 <- conv3_1
I0908 13:55:20.348013  4668 net.cpp:408] pool3 -> pool3
I0908 13:55:20.348047  4668 net.cpp:150] Setting up pool3
I0908 13:55:20.348057  4668 net.cpp:157] Top shape: 64 32 38 38 (2957312)
I0908 13:55:20.348072  4668 net.cpp:165] Memory required for data: 758345728
I0908 13:55:20.348088  4668 layer_factory.hpp:77] Creating layer conv3_1_bn
I0908 13:55:20.348098  4668 net.cpp:100] Creating Layer conv3_1_bn
I0908 13:55:20.348103  4668 net.cpp:434] conv3_1_bn <- pool3
I0908 13:55:20.348109  4668 net.cpp:408] conv3_1_bn -> conv3_1_bn
I0908 13:55:20.348300  4668 net.cpp:150] Setting up conv3_1_bn
I0908 13:55:20.348309  4668 net.cpp:157] Top shape: 64 32 38 38 (2957312)
I0908 13:55:20.348311  4668 net.cpp:165] Memory required for data: 770174976
I0908 13:55:20.348318  4668 layer_factory.hpp:77] Creating layer conv3_1_bn_scale
I0908 13:55:20.348327  4668 net.cpp:100] Creating Layer conv3_1_bn_scale
I0908 13:55:20.348330  4668 net.cpp:434] conv3_1_bn_scale <- conv3_1_bn
I0908 13:55:20.348335  4668 net.cpp:395] conv3_1_bn_scale -> conv3_1_bn (in-place)
I0908 13:55:20.348366  4668 layer_factory.hpp:77] Creating layer conv3_1_bn_scale
I0908 13:55:20.348496  4668 net.cpp:150] Setting up conv3_1_bn_scale
I0908 13:55:20.348512  4668 net.cpp:157] Top shape: 64 32 38 38 (2957312)
I0908 13:55:20.348516  4668 net.cpp:165] Memory required for data: 782004224
I0908 13:55:20.348531  4668 layer_factory.hpp:77] Creating layer conv3_1_relu
I0908 13:55:20.348536  4668 net.cpp:100] Creating Layer conv3_1_relu
I0908 13:55:20.348539  4668 net.cpp:434] conv3_1_relu <- conv3_1_bn
I0908 13:55:20.348546  4668 net.cpp:395] conv3_1_relu -> conv3_1_bn (in-place)
I0908 13:55:20.348551  4668 net.cpp:150] Setting up conv3_1_relu
I0908 13:55:20.348556  4668 net.cpp:157] Top shape: 64 32 38 38 (2957312)
I0908 13:55:20.348558  4668 net.cpp:165] Memory required for data: 793833472
I0908 13:55:20.348562  4668 layer_factory.hpp:77] Creating layer conv4_1
I0908 13:55:20.348570  4668 net.cpp:100] Creating Layer conv4_1
I0908 13:55:20.348573  4668 net.cpp:434] conv4_1 <- conv3_1_bn
I0908 13:55:20.348578  4668 net.cpp:408] conv4_1 -> conv4_1
I0908 13:55:20.358073  4668 net.cpp:150] Setting up conv4_1
I0908 13:55:20.358124  4668 net.cpp:157] Top shape: 64 64 38 38 (5914624)
I0908 13:55:20.358129  4668 net.cpp:165] Memory required for data: 817491968
I0908 13:55:20.358140  4668 layer_factory.hpp:77] Creating layer pool4
I0908 13:55:20.358155  4668 net.cpp:100] Creating Layer pool4
I0908 13:55:20.358163  4668 net.cpp:434] pool4 <- conv4_1
I0908 13:55:20.358175  4668 net.cpp:408] pool4 -> pool4
I0908 13:55:20.358237  4668 net.cpp:150] Setting up pool4
I0908 13:55:20.358250  4668 net.cpp:157] Top shape: 64 64 19 19 (1478656)
I0908 13:55:20.358255  4668 net.cpp:165] Memory required for data: 823406592
I0908 13:55:20.358260  4668 layer_factory.hpp:77] Creating layer conv4_1_bn
I0908 13:55:20.358270  4668 net.cpp:100] Creating Layer conv4_1_bn
I0908 13:55:20.358276  4668 net.cpp:434] conv4_1_bn <- pool4
I0908 13:55:20.358284  4668 net.cpp:408] conv4_1_bn -> conv4_1_bn
I0908 13:55:20.358543  4668 net.cpp:150] Setting up conv4_1_bn
I0908 13:55:20.358554  4668 net.cpp:157] Top shape: 64 64 19 19 (1478656)
I0908 13:55:20.358557  4668 net.cpp:165] Memory required for data: 829321216
I0908 13:55:20.358564  4668 layer_factory.hpp:77] Creating layer conv4_1_bn_scale
I0908 13:55:20.358572  4668 net.cpp:100] Creating Layer conv4_1_bn_scale
I0908 13:55:20.358575  4668 net.cpp:434] conv4_1_bn_scale <- conv4_1_bn
I0908 13:55:20.358582  4668 net.cpp:395] conv4_1_bn_scale -> conv4_1_bn (in-place)
I0908 13:55:20.358618  4668 layer_factory.hpp:77] Creating layer conv4_1_bn_scale
I0908 13:55:20.358712  4668 net.cpp:150] Setting up conv4_1_bn_scale
I0908 13:55:20.358718  4668 net.cpp:157] Top shape: 64 64 19 19 (1478656)
I0908 13:55:20.358721  4668 net.cpp:165] Memory required for data: 835235840
I0908 13:55:20.358726  4668 layer_factory.hpp:77] Creating layer conv4_1_relu
I0908 13:55:20.358733  4668 net.cpp:100] Creating Layer conv4_1_relu
I0908 13:55:20.358736  4668 net.cpp:434] conv4_1_relu <- conv4_1_bn
I0908 13:55:20.358739  4668 net.cpp:395] conv4_1_relu -> conv4_1_bn (in-place)
I0908 13:55:20.358744  4668 net.cpp:150] Setting up conv4_1_relu
I0908 13:55:20.358748  4668 net.cpp:157] Top shape: 64 64 19 19 (1478656)
I0908 13:55:20.358772  4668 net.cpp:165] Memory required for data: 841150464
I0908 13:55:20.358774  4668 layer_factory.hpp:77] Creating layer conv5_1
I0908 13:55:20.358785  4668 net.cpp:100] Creating Layer conv5_1
I0908 13:55:20.358788  4668 net.cpp:434] conv5_1 <- conv4_1_bn
I0908 13:55:20.358793  4668 net.cpp:408] conv5_1 -> conv5_1
I0908 13:55:20.360903  4668 net.cpp:150] Setting up conv5_1
I0908 13:55:20.360937  4668 net.cpp:157] Top shape: 64 64 17 17 (1183744)
I0908 13:55:20.360942  4668 net.cpp:165] Memory required for data: 845885440
I0908 13:55:20.360952  4668 layer_factory.hpp:77] Creating layer conv5_1_bn
I0908 13:55:20.360965  4668 net.cpp:100] Creating Layer conv5_1_bn
I0908 13:55:20.360970  4668 net.cpp:434] conv5_1_bn <- conv5_1
I0908 13:55:20.360980  4668 net.cpp:408] conv5_1_bn -> conv5_1_bn
I0908 13:55:20.361199  4668 net.cpp:150] Setting up conv5_1_bn
I0908 13:55:20.361209  4668 net.cpp:157] Top shape: 64 64 17 17 (1183744)
I0908 13:55:20.361213  4668 net.cpp:165] Memory required for data: 850620416
I0908 13:55:20.361224  4668 layer_factory.hpp:77] Creating layer conv5_1_bn_scale
I0908 13:55:20.361234  4668 net.cpp:100] Creating Layer conv5_1_bn_scale
I0908 13:55:20.361239  4668 net.cpp:434] conv5_1_bn_scale <- conv5_1_bn
I0908 13:55:20.361246  4668 net.cpp:395] conv5_1_bn_scale -> conv5_1_bn (in-place)
I0908 13:55:20.361294  4668 layer_factory.hpp:77] Creating layer conv5_1_bn_scale
I0908 13:55:20.361418  4668 net.cpp:150] Setting up conv5_1_bn_scale
I0908 13:55:20.361428  4668 net.cpp:157] Top shape: 64 64 17 17 (1183744)
I0908 13:55:20.361433  4668 net.cpp:165] Memory required for data: 855355392
I0908 13:55:20.361439  4668 layer_factory.hpp:77] Creating layer conv5_1_relu
I0908 13:55:20.361449  4668 net.cpp:100] Creating Layer conv5_1_relu
I0908 13:55:20.361454  4668 net.cpp:434] conv5_1_relu <- conv5_1_bn
I0908 13:55:20.361459  4668 net.cpp:395] conv5_1_relu -> conv5_1_bn (in-place)
I0908 13:55:20.361466  4668 net.cpp:150] Setting up conv5_1_relu
I0908 13:55:20.361471  4668 net.cpp:157] Top shape: 64 64 17 17 (1183744)
I0908 13:55:20.361476  4668 net.cpp:165] Memory required for data: 860090368
I0908 13:55:20.361480  4668 layer_factory.hpp:77] Creating layer conv6_1
I0908 13:55:20.361492  4668 net.cpp:100] Creating Layer conv6_1
I0908 13:55:20.361497  4668 net.cpp:434] conv6_1 <- conv5_1_bn
I0908 13:55:20.361505  4668 net.cpp:408] conv6_1 -> conv6_1
I0908 13:55:20.362987  4668 net.cpp:150] Setting up conv6_1
I0908 13:55:20.363013  4668 net.cpp:157] Top shape: 64 64 15 15 (921600)
I0908 13:55:20.363016  4668 net.cpp:165] Memory required for data: 863776768
I0908 13:55:20.363025  4668 layer_factory.hpp:77] Creating layer conv6_1_bn
I0908 13:55:20.363045  4668 net.cpp:100] Creating Layer conv6_1_bn
I0908 13:55:20.363051  4668 net.cpp:434] conv6_1_bn <- conv6_1
I0908 13:55:20.363059  4668 net.cpp:408] conv6_1_bn -> conv6_1_bn
I0908 13:55:20.363266  4668 net.cpp:150] Setting up conv6_1_bn
I0908 13:55:20.363276  4668 net.cpp:157] Top shape: 64 64 15 15 (921600)
I0908 13:55:20.363281  4668 net.cpp:165] Memory required for data: 867463168
I0908 13:55:20.363297  4668 layer_factory.hpp:77] Creating layer conv6_1_bn_scale
I0908 13:55:20.363308  4668 net.cpp:100] Creating Layer conv6_1_bn_scale
I0908 13:55:20.363314  4668 net.cpp:434] conv6_1_bn_scale <- conv6_1_bn
I0908 13:55:20.363320  4668 net.cpp:395] conv6_1_bn_scale -> conv6_1_bn (in-place)
I0908 13:55:20.363364  4668 layer_factory.hpp:77] Creating layer conv6_1_bn_scale
I0908 13:55:20.363476  4668 net.cpp:150] Setting up conv6_1_bn_scale
I0908 13:55:20.363486  4668 net.cpp:157] Top shape: 64 64 15 15 (921600)
I0908 13:55:20.363489  4668 net.cpp:165] Memory required for data: 871149568
I0908 13:55:20.363497  4668 layer_factory.hpp:77] Creating layer conv6_1_relu
I0908 13:55:20.363507  4668 net.cpp:100] Creating Layer conv6_1_relu
I0908 13:55:20.363512  4668 net.cpp:434] conv6_1_relu <- conv6_1_bn
I0908 13:55:20.363517  4668 net.cpp:395] conv6_1_relu -> conv6_1_bn (in-place)
I0908 13:55:20.363523  4668 net.cpp:150] Setting up conv6_1_relu
I0908 13:55:20.363541  4668 net.cpp:157] Top shape: 64 64 15 15 (921600)
I0908 13:55:20.363555  4668 net.cpp:165] Memory required for data: 874835968
I0908 13:55:20.363559  4668 layer_factory.hpp:77] Creating layer conv7_1
I0908 13:55:20.363571  4668 net.cpp:100] Creating Layer conv7_1
I0908 13:55:20.363576  4668 net.cpp:434] conv7_1 <- conv6_1_bn
I0908 13:55:20.363584  4668 net.cpp:408] conv7_1 -> conv7_1
I0908 13:55:20.366382  4668 net.cpp:150] Setting up conv7_1
I0908 13:55:20.366416  4668 net.cpp:157] Top shape: 64 128 13 13 (1384448)
I0908 13:55:20.366420  4668 net.cpp:165] Memory required for data: 880373760
I0908 13:55:20.366430  4668 layer_factory.hpp:77] Creating layer conv7_1_bn
I0908 13:55:20.366446  4668 net.cpp:100] Creating Layer conv7_1_bn
I0908 13:55:20.366453  4668 net.cpp:434] conv7_1_bn <- conv7_1
I0908 13:55:20.366461  4668 net.cpp:408] conv7_1_bn -> conv7_1_bn
I0908 13:55:20.366663  4668 net.cpp:150] Setting up conv7_1_bn
I0908 13:55:20.366673  4668 net.cpp:157] Top shape: 64 128 13 13 (1384448)
I0908 13:55:20.366677  4668 net.cpp:165] Memory required for data: 885911552
I0908 13:55:20.366686  4668 layer_factory.hpp:77] Creating layer conv7_1_bn_scale
I0908 13:55:20.366695  4668 net.cpp:100] Creating Layer conv7_1_bn_scale
I0908 13:55:20.366699  4668 net.cpp:434] conv7_1_bn_scale <- conv7_1_bn
I0908 13:55:20.366705  4668 net.cpp:395] conv7_1_bn_scale -> conv7_1_bn (in-place)
I0908 13:55:20.366750  4668 layer_factory.hpp:77] Creating layer conv7_1_bn_scale
I0908 13:55:20.366852  4668 net.cpp:150] Setting up conv7_1_bn_scale
I0908 13:55:20.366860  4668 net.cpp:157] Top shape: 64 128 13 13 (1384448)
I0908 13:55:20.366864  4668 net.cpp:165] Memory required for data: 891449344
I0908 13:55:20.366873  4668 layer_factory.hpp:77] Creating layer conv7_1_relu
I0908 13:55:20.366879  4668 net.cpp:100] Creating Layer conv7_1_relu
I0908 13:55:20.366884  4668 net.cpp:434] conv7_1_relu <- conv7_1_bn
I0908 13:55:20.366891  4668 net.cpp:395] conv7_1_relu -> conv7_1_bn (in-place)
I0908 13:55:20.366899  4668 net.cpp:150] Setting up conv7_1_relu
I0908 13:55:20.366904  4668 net.cpp:157] Top shape: 64 128 13 13 (1384448)
I0908 13:55:20.366909  4668 net.cpp:165] Memory required for data: 896987136
I0908 13:55:20.366912  4668 layer_factory.hpp:77] Creating layer score
I0908 13:55:20.366930  4668 net.cpp:100] Creating Layer score
I0908 13:55:20.366935  4668 net.cpp:434] score <- conv7_1_bn
I0908 13:55:20.366942  4668 net.cpp:408] score -> score
I0908 13:55:20.367203  4668 net.cpp:150] Setting up score
I0908 13:55:20.367213  4668 net.cpp:157] Top shape: 64 4 13 13 (43264)
I0908 13:55:20.367218  4668 net.cpp:165] Memory required for data: 897160192
I0908 13:55:20.367224  4668 layer_factory.hpp:77] Creating layer upscore
I0908 13:55:20.367235  4668 net.cpp:100] Creating Layer upscore
I0908 13:55:20.367240  4668 net.cpp:434] upscore <- score
I0908 13:55:20.367249  4668 net.cpp:408] upscore -> upscore
I0908 13:55:20.368018  4668 net.cpp:150] Setting up upscore
I0908 13:55:20.368031  4668 net.cpp:157] Top shape: 64 4 224 224 (12845056)
I0908 13:55:20.368036  4668 net.cpp:165] Memory required for data: 948540416
I0908 13:55:20.368042  4668 layer_factory.hpp:77] Creating layer cropscore
I0908 13:55:20.368051  4668 net.cpp:100] Creating Layer cropscore
I0908 13:55:20.368055  4668 net.cpp:434] cropscore <- upscore
I0908 13:55:20.368062  4668 net.cpp:434] cropscore <- image_data_0_split_1
I0908 13:55:20.368067  4668 net.cpp:408] cropscore -> cropscore
I0908 13:55:20.368093  4668 net.cpp:150] Setting up cropscore
I0908 13:55:20.368100  4668 net.cpp:157] Top shape: 64 4 200 200 (10240000)
I0908 13:55:20.368104  4668 net.cpp:165] Memory required for data: 989500416
I0908 13:55:20.368108  4668 layer_factory.hpp:77] Creating layer cropscore_cropscore_0_split
I0908 13:55:20.368115  4668 net.cpp:100] Creating Layer cropscore_cropscore_0_split
I0908 13:55:20.368120  4668 net.cpp:434] cropscore_cropscore_0_split <- cropscore
I0908 13:55:20.368125  4668 net.cpp:408] cropscore_cropscore_0_split -> cropscore_cropscore_0_split_0
I0908 13:55:20.368144  4668 net.cpp:408] cropscore_cropscore_0_split -> cropscore_cropscore_0_split_1
I0908 13:55:20.368191  4668 net.cpp:150] Setting up cropscore_cropscore_0_split
I0908 13:55:20.368198  4668 net.cpp:157] Top shape: 64 4 200 200 (10240000)
I0908 13:55:20.368206  4668 net.cpp:157] Top shape: 64 4 200 200 (10240000)
I0908 13:55:20.368209  4668 net.cpp:165] Memory required for data: 1071420416
I0908 13:55:20.368214  4668 layer_factory.hpp:77] Creating layer loss
I0908 13:55:20.368222  4668 net.cpp:100] Creating Layer loss
I0908 13:55:20.368227  4668 net.cpp:434] loss <- cropscore_cropscore_0_split_0
I0908 13:55:20.368232  4668 net.cpp:434] loss <- label_data_1_split_0
I0908 13:55:20.368243  4668 net.cpp:408] loss -> loss
I0908 13:55:20.368252  4668 layer_factory.hpp:77] Creating layer loss
I0908 13:55:20.390571  4668 net.cpp:150] Setting up loss
I0908 13:55:20.390604  4668 net.cpp:157] Top shape: (1)
I0908 13:55:20.390607  4668 net.cpp:160]     with loss weight 1
I0908 13:55:20.390619  4668 net.cpp:165] Memory required for data: 1071420420
I0908 13:55:20.390622  4668 layer_factory.hpp:77] Creating layer accuracy
I0908 13:55:20.390632  4668 net.cpp:100] Creating Layer accuracy
I0908 13:55:20.390637  4668 net.cpp:434] accuracy <- cropscore_cropscore_0_split_1
I0908 13:55:20.390643  4668 net.cpp:434] accuracy <- label_data_1_split_1
I0908 13:55:20.390650  4668 net.cpp:408] accuracy -> accuracy
I0908 13:55:20.390658  4668 net.cpp:150] Setting up accuracy
I0908 13:55:20.390661  4668 net.cpp:157] Top shape: (1)
I0908 13:55:20.390664  4668 net.cpp:165] Memory required for data: 1071420424
I0908 13:55:20.390667  4668 net.cpp:228] accuracy does not need backward computation.
I0908 13:55:20.390671  4668 net.cpp:226] loss needs backward computation.
I0908 13:55:20.390674  4668 net.cpp:226] cropscore_cropscore_0_split needs backward computation.
I0908 13:55:20.390677  4668 net.cpp:226] cropscore needs backward computation.
I0908 13:55:20.390681  4668 net.cpp:226] upscore needs backward computation.
I0908 13:55:20.390684  4668 net.cpp:226] score needs backward computation.
I0908 13:55:20.390687  4668 net.cpp:226] conv7_1_relu needs backward computation.
I0908 13:55:20.390691  4668 net.cpp:226] conv7_1_bn_scale needs backward computation.
I0908 13:55:20.390692  4668 net.cpp:226] conv7_1_bn needs backward computation.
I0908 13:55:20.390696  4668 net.cpp:226] conv7_1 needs backward computation.
I0908 13:55:20.390698  4668 net.cpp:226] conv6_1_relu needs backward computation.
I0908 13:55:20.390702  4668 net.cpp:226] conv6_1_bn_scale needs backward computation.
I0908 13:55:20.390704  4668 net.cpp:226] conv6_1_bn needs backward computation.
I0908 13:55:20.390707  4668 net.cpp:226] conv6_1 needs backward computation.
I0908 13:55:20.390710  4668 net.cpp:226] conv5_1_relu needs backward computation.
I0908 13:55:20.390713  4668 net.cpp:226] conv5_1_bn_scale needs backward computation.
I0908 13:55:20.390717  4668 net.cpp:226] conv5_1_bn needs backward computation.
I0908 13:55:20.390719  4668 net.cpp:226] conv5_1 needs backward computation.
I0908 13:55:20.390722  4668 net.cpp:226] conv4_1_relu needs backward computation.
I0908 13:55:20.390724  4668 net.cpp:226] conv4_1_bn_scale needs backward computation.
I0908 13:55:20.390727  4668 net.cpp:226] conv4_1_bn needs backward computation.
I0908 13:55:20.390730  4668 net.cpp:226] pool4 needs backward computation.
I0908 13:55:20.390733  4668 net.cpp:226] conv4_1 needs backward computation.
I0908 13:55:20.390736  4668 net.cpp:226] conv3_1_relu needs backward computation.
I0908 13:55:20.390739  4668 net.cpp:226] conv3_1_bn_scale needs backward computation.
I0908 13:55:20.390743  4668 net.cpp:226] conv3_1_bn needs backward computation.
I0908 13:55:20.390745  4668 net.cpp:226] pool3 needs backward computation.
I0908 13:55:20.390748  4668 net.cpp:226] conv3_1 needs backward computation.
I0908 13:55:20.390750  4668 net.cpp:226] conv2_1_relu needs backward computation.
I0908 13:55:20.390753  4668 net.cpp:226] conv2_1_bn_scale needs backward computation.
I0908 13:55:20.390756  4668 net.cpp:226] conv2_1_bn needs backward computation.
I0908 13:55:20.390774  4668 net.cpp:226] pool2 needs backward computation.
I0908 13:55:20.390777  4668 net.cpp:226] conv2_1 needs backward computation.
I0908 13:55:20.390780  4668 net.cpp:226] conv1_1_relu needs backward computation.
I0908 13:55:20.390784  4668 net.cpp:226] conv1_1_bn_scale needs backward computation.
I0908 13:55:20.390786  4668 net.cpp:226] conv1_1_bn needs backward computation.
I0908 13:55:20.390789  4668 net.cpp:226] pool1 needs backward computation.
I0908 13:55:20.390792  4668 net.cpp:226] conv1_1 needs backward computation.
I0908 13:55:20.390795  4668 net.cpp:228] label_data_1_split does not need backward computation.
I0908 13:55:20.390799  4668 net.cpp:228] image_data_0_split does not need backward computation.
I0908 13:55:20.390802  4668 net.cpp:228] data does not need backward computation.
I0908 13:55:20.390805  4668 net.cpp:270] This network produces output accuracy
I0908 13:55:20.390807  4668 net.cpp:270] This network produces output loss
I0908 13:55:20.390825  4668 net.cpp:283] Network initialization done.
I0908 13:55:20.390931  4668 solver.cpp:60] Solver scaffolding done.
I0908 13:55:20.392030  4668 caffe.cpp:251] Starting Optimization
I0908 13:55:20.392040  4668 solver.cpp:279] Solving segmentation
I0908 13:55:20.392042  4668 solver.cpp:280] Learning Rate Policy: step
I0908 13:55:20.393167  4668 solver.cpp:337] Iteration 0, Testing net (#0)
I0908 13:55:27.485911  4668 solver.cpp:404]     Test net output #0: accuracy = 0.247257
I0908 13:55:27.485951  4668 solver.cpp:404]     Test net output #1: loss = 2.62968e+06 (* 1 = 2.62968e+06 loss)
I0908 13:55:28.899843  4668 solver.cpp:228] Iteration 0, loss = 55452.2
I0908 13:55:28.899870  4668 solver.cpp:244]     Train net output #0: accuracy = 0.249622
I0908 13:55:28.899878  4668 solver.cpp:244]     Train net output #1: loss = 55452.2 (* 1 = 55452.2 loss)
I0908 13:55:28.899890  4668 sgd_solver.cpp:106] Iteration 0, lr = 1e-05
I0908 13:55:42.269753  4668 solver.cpp:454] Snapshotting to binary proto file portrait_wfm_one_stage_iter_10.caffemodel
I0908 13:55:42.273972  4668 sgd_solver.cpp:273] Snapshotting solver state to binary proto file portrait_wfm_one_stage_iter_10.solverstate
I0908 13:56:41.888556  4668 solver.cpp:228] Iteration 50, loss = 41995.8
I0908 13:56:41.888625  4668 solver.cpp:244]     Train net output #0: accuracy = 0.536035
I0908 13:56:41.888635  4668 solver.cpp:244]     Train net output #1: loss = 41995.8 (* 1 = 41995.8 loss)
I0908 13:56:41.888643  4668 sgd_solver.cpp:106] Iteration 50, lr = 1e-05
I0908 13:57:56.085134  4668 solver.cpp:228] Iteration 100, loss = 32329.6
I0908 13:57:56.085217  4668 solver.cpp:244]     Train net output #0: accuracy = 0.67429
I0908 13:57:56.085228  4668 solver.cpp:244]     Train net output #1: loss = 32329.6 (* 1 = 32329.6 loss)
I0908 13:57:56.085235  4668 sgd_solver.cpp:106] Iteration 100, lr = 1e-05
I0908 13:59:09.085000  4668 solver.cpp:228] Iteration 150, loss = 33456.7
I0908 13:59:09.085091  4668 solver.cpp:244]     Train net output #0: accuracy = 0.627259
I0908 13:59:09.085103  4668 solver.cpp:244]     Train net output #1: loss = 33456.7 (* 1 = 33456.7 loss)
I0908 13:59:09.085109  4668 sgd_solver.cpp:106] Iteration 150, lr = 1e-05
I0908 14:00:20.086086  4668 solver.cpp:337] Iteration 200, Testing net (#0)
I0908 14:00:26.978516  4668 solver.cpp:404]     Test net output #0: accuracy = 0.597148
I0908 14:00:26.978561  4668 solver.cpp:404]     Test net output #1: loss = 85806.5 (* 1 = 85806.5 loss)
I0908 14:00:28.299835  4668 solver.cpp:228] Iteration 200, loss = 22157.2
I0908 14:00:28.299877  4668 solver.cpp:244]     Train net output #0: accuracy = 0.814992
I0908 14:00:28.299887  4668 solver.cpp:244]     Train net output #1: loss = 22157.2 (* 1 = 22157.2 loss)
I0908 14:00:28.299896  4668 sgd_solver.cpp:106] Iteration 200, lr = 1e-05
I0908 14:01:40.406522  4668 solver.cpp:228] Iteration 250, loss = 43960.2
I0908 14:01:40.406649  4668 solver.cpp:244]     Train net output #0: accuracy = 0.463645
I0908 14:01:40.406662  4668 solver.cpp:244]     Train net output #1: loss = 43960.2 (* 1 = 43960.2 loss)
I0908 14:01:40.406673  4668 sgd_solver.cpp:106] Iteration 250, lr = 1e-05
I0908 14:02:55.250435  4668 solver.cpp:228] Iteration 300, loss = 31447
I0908 14:02:55.250536  4668 solver.cpp:244]     Train net output #0: accuracy = 0.671485
I0908 14:02:55.250550  4668 solver.cpp:244]     Train net output #1: loss = 31447 (* 1 = 31447 loss)
I0908 14:02:55.250556  4668 sgd_solver.cpp:106] Iteration 300, lr = 1e-05
I0908 14:04:07.681869  4668 solver.cpp:228] Iteration 350, loss = 18600.7
I0908 14:04:07.681973  4668 solver.cpp:244]     Train net output #0: accuracy = 0.856785
I0908 14:04:07.681984  4668 solver.cpp:244]     Train net output #1: loss = 18600.7 (* 1 = 18600.7 loss)
I0908 14:04:07.681990  4668 sgd_solver.cpp:106] Iteration 350, lr = 1e-05
I0908 14:05:20.061177  4668 solver.cpp:337] Iteration 400, Testing net (#0)
I0908 14:05:26.928947  4668 solver.cpp:404]     Test net output #0: accuracy = 0.398732
I0908 14:05:26.928993  4668 solver.cpp:404]     Test net output #1: loss = 204107 (* 1 = 204107 loss)
I0908 14:05:28.216575  4668 solver.cpp:228] Iteration 400, loss = 21402.9
I0908 14:05:28.216614  4668 solver.cpp:244]     Train net output #0: accuracy = 0.797889
I0908 14:05:28.216624  4668 solver.cpp:244]     Train net output #1: loss = 21402.9 (* 1 = 21402.9 loss)
I0908 14:05:28.216630  4668 sgd_solver.cpp:106] Iteration 400, lr = 1e-05
I0908 14:06:40.563668  4668 solver.cpp:228] Iteration 450, loss = 22617.9
I0908 14:06:40.563755  4668 solver.cpp:244]     Train net output #0: accuracy = 0.819716
I0908 14:06:40.563767  4668 solver.cpp:244]     Train net output #1: loss = 22617.9 (* 1 = 22617.9 loss)
I0908 14:06:40.563776  4668 sgd_solver.cpp:106] Iteration 450, lr = 1e-05
I0908 14:07:53.013429  4668 solver.cpp:228] Iteration 500, loss = 40748
I0908 14:07:53.013522  4668 solver.cpp:244]     Train net output #0: accuracy = 0.573522
I0908 14:07:53.013535  4668 solver.cpp:244]     Train net output #1: loss = 40748 (* 1 = 40748 loss)
I0908 14:07:53.013543  4668 sgd_solver.cpp:106] Iteration 500, lr = 1e-05
I0908 14:09:06.000483  4668 solver.cpp:228] Iteration 550, loss = 27299.5
I0908 14:09:06.000583  4668 solver.cpp:244]     Train net output #0: accuracy = 0.707498
I0908 14:09:06.000596  4668 solver.cpp:244]     Train net output #1: loss = 27299.5 (* 1 = 27299.5 loss)
I0908 14:09:06.000602  4668 sgd_solver.cpp:106] Iteration 550, lr = 1e-05
I0908 14:10:18.938330  4668 solver.cpp:337] Iteration 600, Testing net (#0)
I0908 14:10:25.764132  4668 solver.cpp:404]     Test net output #0: accuracy = 0.486461
I0908 14:10:25.764176  4668 solver.cpp:404]     Test net output #1: loss = 78676.4 (* 1 = 78676.4 loss)
I0908 14:10:27.054016  4668 solver.cpp:228] Iteration 600, loss = 16961.4
I0908 14:10:27.054052  4668 solver.cpp:244]     Train net output #0: accuracy = 0.860366
I0908 14:10:27.054062  4668 solver.cpp:244]     Train net output #1: loss = 16961.4 (* 1 = 16961.4 loss)
I0908 14:10:27.054069  4668 sgd_solver.cpp:106] Iteration 600, lr = 1e-05
I0908 14:11:38.940497  4668 solver.cpp:228] Iteration 650, loss = 31986.2
I0908 14:11:38.940575  4668 solver.cpp:244]     Train net output #0: accuracy = 0.704493
I0908 14:11:38.940587  4668 solver.cpp:244]     Train net output #1: loss = 31986.2 (* 1 = 31986.2 loss)
I0908 14:11:38.940593  4668 sgd_solver.cpp:106] Iteration 650, lr = 1e-05
I0908 14:12:50.940965  4668 solver.cpp:228] Iteration 700, loss = 26631.2
I0908 14:12:50.941048  4668 solver.cpp:244]     Train net output #0: accuracy = 0.731898
I0908 14:12:50.941061  4668 solver.cpp:244]     Train net output #1: loss = 26631.2 (* 1 = 26631.2 loss)
I0908 14:12:50.941068  4668 sgd_solver.cpp:106] Iteration 700, lr = 1e-05
I0908 14:14:03.413389  4668 solver.cpp:228] Iteration 750, loss = 35223.6
I0908 14:14:03.413491  4668 solver.cpp:244]     Train net output #0: accuracy = 0.632412
I0908 14:14:03.413503  4668 solver.cpp:244]     Train net output #1: loss = 35223.6 (* 1 = 35223.6 loss)
I0908 14:14:03.413511  4668 sgd_solver.cpp:106] Iteration 750, lr = 1e-05
I0908 14:15:14.480254  4668 solver.cpp:337] Iteration 800, Testing net (#0)
I0908 14:15:21.236258  4668 solver.cpp:404]     Test net output #0: accuracy = 0.502088
I0908 14:15:21.236299  4668 solver.cpp:404]     Test net output #1: loss = 92487.4 (* 1 = 92487.4 loss)
I0908 14:15:22.515324  4668 solver.cpp:228] Iteration 800, loss = 91159.6
I0908 14:15:22.515367  4668 solver.cpp:244]     Train net output #0: accuracy = 0.517156
I0908 14:15:22.515377  4668 solver.cpp:244]     Train net output #1: loss = 91159.6 (* 1 = 91159.6 loss)
I0908 14:15:22.515383  4668 sgd_solver.cpp:106] Iteration 800, lr = 1e-05
I0908 14:16:34.670433  4668 solver.cpp:228] Iteration 850, loss = 27930.1
I0908 14:16:34.670542  4668 solver.cpp:244]     Train net output #0: accuracy = 0.703264
I0908 14:16:34.670553  4668 solver.cpp:244]     Train net output #1: loss = 27930.1 (* 1 = 27930.1 loss)
I0908 14:16:34.670560  4668 sgd_solver.cpp:106] Iteration 850, lr = 1e-05
I0908 14:17:48.509156  4668 solver.cpp:228] Iteration 900, loss = 27763.3
I0908 14:17:48.509260  4668 solver.cpp:244]     Train net output #0: accuracy = 0.727337
I0908 14:17:48.509276  4668 solver.cpp:244]     Train net output #1: loss = 27763.3 (* 1 = 27763.3 loss)
I0908 14:17:48.509286  4668 sgd_solver.cpp:106] Iteration 900, lr = 1e-05
I0908 14:19:01.470142  4668 solver.cpp:228] Iteration 950, loss = 18872.9
I0908 14:19:01.470226  4668 solver.cpp:244]     Train net output #0: accuracy = 0.83418
I0908 14:19:01.470237  4668 solver.cpp:244]     Train net output #1: loss = 18872.9 (* 1 = 18872.9 loss)
I0908 14:19:01.470243  4668 sgd_solver.cpp:106] Iteration 950, lr = 1e-05
I0908 14:20:14.517362  4668 solver.cpp:337] Iteration 1000, Testing net (#0)
I0908 14:20:21.411451  4668 solver.cpp:404]     Test net output #0: accuracy = 0.635104
I0908 14:20:21.411494  4668 solver.cpp:404]     Test net output #1: loss = 76171.6 (* 1 = 76171.6 loss)
I0908 14:20:22.711410  4668 solver.cpp:228] Iteration 1000, loss = 23866.8
I0908 14:20:22.711452  4668 solver.cpp:244]     Train net output #0: accuracy = 0.761256
I0908 14:20:22.711462  4668 solver.cpp:244]     Train net output #1: loss = 23866.8 (* 1 = 23866.8 loss)
I0908 14:20:22.711468  4668 sgd_solver.cpp:106] Iteration 1000, lr = 1e-05
I0908 14:21:37.154428  4668 solver.cpp:228] Iteration 1050, loss = 20303.8
I0908 14:21:37.154532  4668 solver.cpp:244]     Train net output #0: accuracy = 0.836496
I0908 14:21:37.154546  4668 solver.cpp:244]     Train net output #1: loss = 20303.8 (* 1 = 20303.8 loss)
I0908 14:21:37.154552  4668 sgd_solver.cpp:106] Iteration 1050, lr = 1e-05
I0908 14:22:50.022114  4668 solver.cpp:228] Iteration 1100, loss = 22487.8
I0908 14:22:50.022212  4668 solver.cpp:244]     Train net output #0: accuracy = 0.77471
I0908 14:22:50.022224  4668 solver.cpp:244]     Train net output #1: loss = 22487.8 (* 1 = 22487.8 loss)
I0908 14:22:50.022231  4668 sgd_solver.cpp:106] Iteration 1100, lr = 1e-05
I0908 14:24:02.350476  4668 solver.cpp:228] Iteration 1150, loss = 19335.9
I0908 14:24:02.350565  4668 solver.cpp:244]     Train net output #0: accuracy = 0.796204
I0908 14:24:02.350579  4668 solver.cpp:244]     Train net output #1: loss = 19335.9 (* 1 = 19335.9 loss)
I0908 14:24:02.350586  4668 sgd_solver.cpp:106] Iteration 1150, lr = 1e-05
I0908 14:25:13.884091  4668 solver.cpp:337] Iteration 1200, Testing net (#0)
I0908 14:25:20.717154  4668 solver.cpp:404]     Test net output #0: accuracy = 0.750348
I0908 14:25:20.717193  4668 solver.cpp:404]     Test net output #1: loss = 40418.6 (* 1 = 40418.6 loss)
I0908 14:25:22.010234  4668 solver.cpp:228] Iteration 1200, loss = 18219.5
I0908 14:25:22.010277  4668 solver.cpp:244]     Train net output #0: accuracy = 0.840187
I0908 14:25:22.010287  4668 solver.cpp:244]     Train net output #1: loss = 18219.5 (* 1 = 18219.5 loss)
I0908 14:25:22.010293  4668 sgd_solver.cpp:106] Iteration 1200, lr = 1e-05
I0908 14:26:35.231389  4668 solver.cpp:228] Iteration 1250, loss = 25725.3
I0908 14:26:35.231495  4668 solver.cpp:244]     Train net output #0: accuracy = 0.749383
I0908 14:26:35.231508  4668 solver.cpp:244]     Train net output #1: loss = 25725.3 (* 1 = 25725.3 loss)
I0908 14:26:35.231525  4668 sgd_solver.cpp:106] Iteration 1250, lr = 1e-05
I0908 14:27:47.692541  4668 solver.cpp:228] Iteration 1300, loss = 20721.6
I0908 14:27:47.692648  4668 solver.cpp:244]     Train net output #0: accuracy = 0.807172
I0908 14:27:47.692661  4668 solver.cpp:244]     Train net output #1: loss = 20721.6 (* 1 = 20721.6 loss)
I0908 14:27:47.692667  4668 sgd_solver.cpp:106] Iteration 1300, lr = 1e-05
I0908 14:28:59.965647  4668 solver.cpp:228] Iteration 1350, loss = 8106.57
I0908 14:28:59.965741  4668 solver.cpp:244]     Train net output #0: accuracy = 0.972408
I0908 14:28:59.965754  4668 solver.cpp:244]     Train net output #1: loss = 8106.57 (* 1 = 8106.57 loss)
I0908 14:28:59.965760  4668 sgd_solver.cpp:106] Iteration 1350, lr = 1e-05
I0908 14:30:10.765085  4668 solver.cpp:337] Iteration 1400, Testing net (#0)
I0908 14:30:17.640008  4668 solver.cpp:404]     Test net output #0: accuracy = 0.79598
I0908 14:30:17.640056  4668 solver.cpp:404]     Test net output #1: loss = 22667.1 (* 1 = 22667.1 loss)
I0908 14:30:18.931031  4668 solver.cpp:228] Iteration 1400, loss = 12216.6
I0908 14:30:18.931076  4668 solver.cpp:244]     Train net output #0: accuracy = 0.883822
I0908 14:30:18.931085  4668 solver.cpp:244]     Train net output #1: loss = 12216.6 (* 1 = 12216.6 loss)
I0908 14:30:18.931092  4668 sgd_solver.cpp:106] Iteration 1400, lr = 1e-05
I0908 14:31:32.608906  4668 solver.cpp:228] Iteration 1450, loss = 21579.1
I0908 14:31:32.608989  4668 solver.cpp:244]     Train net output #0: accuracy = 0.790565
I0908 14:31:32.609001  4668 solver.cpp:244]     Train net output #1: loss = 21579.1 (* 1 = 21579.1 loss)
I0908 14:31:32.609009  4668 sgd_solver.cpp:106] Iteration 1450, lr = 1e-05
I0908 14:32:44.698894  4668 solver.cpp:228] Iteration 1500, loss = 17478.4
I0908 14:32:44.698993  4668 solver.cpp:244]     Train net output #0: accuracy = 0.827337
I0908 14:32:44.699004  4668 solver.cpp:244]     Train net output #1: loss = 17478.4 (* 1 = 17478.4 loss)
I0908 14:32:44.699012  4668 sgd_solver.cpp:106] Iteration 1500, lr = 1e-05
I0908 14:33:57.205813  4668 solver.cpp:228] Iteration 1550, loss = 20123.7
I0908 14:33:57.205883  4668 solver.cpp:244]     Train net output #0: accuracy = 0.803018
I0908 14:33:57.205894  4668 solver.cpp:244]     Train net output #1: loss = 20123.7 (* 1 = 20123.7 loss)
I0908 14:33:57.205901  4668 sgd_solver.cpp:106] Iteration 1550, lr = 1e-05
I0908 14:35:08.416306  4668 solver.cpp:337] Iteration 1600, Testing net (#0)
I0908 14:35:15.238178  4668 solver.cpp:404]     Test net output #0: accuracy = 0.763714
I0908 14:35:15.238221  4668 solver.cpp:404]     Test net output #1: loss = 23964.5 (* 1 = 23964.5 loss)
I0908 14:35:16.526957  4668 solver.cpp:228] Iteration 1600, loss = 16945.2
I0908 14:35:16.526996  4668 solver.cpp:244]     Train net output #0: accuracy = 0.833942
I0908 14:35:16.527005  4668 solver.cpp:244]     Train net output #1: loss = 16945.2 (* 1 = 16945.2 loss)
I0908 14:35:16.527014  4668 sgd_solver.cpp:106] Iteration 1600, lr = 1e-05
I0908 14:36:29.517813  4668 solver.cpp:228] Iteration 1650, loss = 20946.2
I0908 14:36:29.517901  4668 solver.cpp:244]     Train net output #0: accuracy = 0.793446
I0908 14:36:29.517913  4668 solver.cpp:244]     Train net output #1: loss = 20946.2 (* 1 = 20946.2 loss)
I0908 14:36:29.517920  4668 sgd_solver.cpp:106] Iteration 1650, lr = 1e-05
I0908 14:37:41.865572  4668 solver.cpp:228] Iteration 1700, loss = 17161.7
I0908 14:37:41.865653  4668 solver.cpp:244]     Train net output #0: accuracy = 0.83347
I0908 14:37:41.865664  4668 solver.cpp:244]     Train net output #1: loss = 17161.7 (* 1 = 17161.7 loss)
I0908 14:37:41.865671  4668 sgd_solver.cpp:106] Iteration 1700, lr = 1e-05
I0908 14:38:53.925240  4668 solver.cpp:228] Iteration 1750, loss = 13074.1
I0908 14:38:53.925333  4668 solver.cpp:244]     Train net output #0: accuracy = 0.879291
I0908 14:38:53.925343  4668 solver.cpp:244]     Train net output #1: loss = 13074.1 (* 1 = 13074.1 loss)
I0908 14:38:53.925351  4668 sgd_solver.cpp:106] Iteration 1750, lr = 1e-05
I0908 14:40:06.746338  4668 solver.cpp:337] Iteration 1800, Testing net (#0)
I0908 14:40:13.569775  4668 solver.cpp:404]     Test net output #0: accuracy = 0.735802
I0908 14:40:13.569818  4668 solver.cpp:404]     Test net output #1: loss = 28234 (* 1 = 28234 loss)
I0908 14:40:14.864150  4668 solver.cpp:228] Iteration 1800, loss = 14886.7
I0908 14:40:14.864187  4668 solver.cpp:244]     Train net output #0: accuracy = 0.850713
I0908 14:40:14.864197  4668 solver.cpp:244]     Train net output #1: loss = 14886.7 (* 1 = 14886.7 loss)
I0908 14:40:14.864203  4668 sgd_solver.cpp:106] Iteration 1800, lr = 1e-05
I0908 14:41:28.414942  4668 solver.cpp:228] Iteration 1850, loss = 13871.3
I0908 14:41:28.415035  4668 solver.cpp:244]     Train net output #0: accuracy = 0.870182
I0908 14:41:28.415046  4668 solver.cpp:244]     Train net output #1: loss = 13871.3 (* 1 = 13871.3 loss)
I0908 14:41:28.415053  4668 sgd_solver.cpp:106] Iteration 1850, lr = 1e-05
I0908 14:42:40.570648  4668 solver.cpp:228] Iteration 1900, loss = 1939.83
I0908 14:42:40.570749  4668 solver.cpp:244]     Train net output #0: accuracy = 0.997195
I0908 14:42:40.570762  4668 solver.cpp:244]     Train net output #1: loss = 1939.83 (* 1 = 1939.83 loss)
I0908 14:42:40.570770  4668 sgd_solver.cpp:106] Iteration 1900, lr = 1e-05
I0908 14:43:55.639698  4668 solver.cpp:228] Iteration 1950, loss = 11847.9
I0908 14:43:55.639791  4668 solver.cpp:244]     Train net output #0: accuracy = 0.885616
I0908 14:43:55.639803  4668 solver.cpp:244]     Train net output #1: loss = 11847.9 (* 1 = 11847.9 loss)
I0908 14:43:55.639811  4668 sgd_solver.cpp:106] Iteration 1950, lr = 1e-05
I0908 14:45:06.563733  4668 solver.cpp:337] Iteration 2000, Testing net (#0)
I0908 14:45:13.442327  4668 solver.cpp:404]     Test net output #0: accuracy = 0.812431
I0908 14:45:13.442378  4668 solver.cpp:404]     Test net output #1: loss = 19372.6 (* 1 = 19372.6 loss)
I0908 14:45:14.733778  4668 solver.cpp:228] Iteration 2000, loss = 13445.7
I0908 14:45:14.733819  4668 solver.cpp:244]     Train net output #0: accuracy = 0.869621
I0908 14:45:14.733830  4668 solver.cpp:244]     Train net output #1: loss = 13445.7 (* 1 = 13445.7 loss)
I0908 14:45:14.733837  4668 sgd_solver.cpp:106] Iteration 2000, lr = 1e-05
I0908 14:46:26.934689  4668 solver.cpp:228] Iteration 2050, loss = 15264.1
I0908 14:46:26.934792  4668 solver.cpp:244]     Train net output #0: accuracy = 0.846961
I0908 14:46:26.934804  4668 solver.cpp:244]     Train net output #1: loss = 15264.1 (* 1 = 15264.1 loss)
I0908 14:46:26.934811  4668 sgd_solver.cpp:106] Iteration 2050, lr = 1e-05
I0908 14:47:40.846690  4668 solver.cpp:228] Iteration 2100, loss = 15604.5
I0908 14:47:40.846796  4668 solver.cpp:244]     Train net output #0: accuracy = 0.842174
I0908 14:47:40.846808  4668 solver.cpp:244]     Train net output #1: loss = 15604.5 (* 1 = 15604.5 loss)
I0908 14:47:40.846815  4668 sgd_solver.cpp:106] Iteration 2100, lr = 1e-05
I0908 14:48:53.943223  4668 solver.cpp:228] Iteration 2150, loss = 13899.5
I0908 14:48:53.943330  4668 solver.cpp:244]     Train net output #0: accuracy = 0.92784
I0908 14:48:53.943341  4668 solver.cpp:244]     Train net output #1: loss = 13899.5 (* 1 = 13899.5 loss)
I0908 14:48:53.943347  4668 sgd_solver.cpp:106] Iteration 2150, lr = 1e-05
I0908 14:50:05.795009  4668 solver.cpp:337] Iteration 2200, Testing net (#0)
I0908 14:50:12.627845  4668 solver.cpp:404]     Test net output #0: accuracy = 0.777766
I0908 14:50:12.627888  4668 solver.cpp:404]     Test net output #1: loss = 21371.3 (* 1 = 21371.3 loss)
I0908 14:50:13.922449  4668 solver.cpp:228] Iteration 2200, loss = 17510
I0908 14:50:13.922488  4668 solver.cpp:244]     Train net output #0: accuracy = 0.832632
I0908 14:50:13.922498  4668 solver.cpp:244]     Train net output #1: loss = 17510 (* 1 = 17510 loss)
I0908 14:50:13.922505  4668 sgd_solver.cpp:106] Iteration 2200, lr = 1e-05
I0908 14:51:26.559769  4668 solver.cpp:228] Iteration 2250, loss = 17714.4
I0908 14:51:26.559897  4668 solver.cpp:244]     Train net output #0: accuracy = 0.833479
I0908 14:51:26.559911  4668 solver.cpp:244]     Train net output #1: loss = 17714.4 (* 1 = 17714.4 loss)
I0908 14:51:26.559921  4668 sgd_solver.cpp:106] Iteration 2250, lr = 1e-05
I0908 14:52:39.575073  4668 solver.cpp:228] Iteration 2300, loss = 14131.1
I0908 14:52:39.575202  4668 solver.cpp:244]     Train net output #0: accuracy = 0.865643
I0908 14:52:39.575220  4668 solver.cpp:244]     Train net output #1: loss = 14131.1 (* 1 = 14131.1 loss)
I0908 14:52:39.575232  4668 sgd_solver.cpp:106] Iteration 2300, lr = 1e-05
I0908 14:53:54.197558  4668 solver.cpp:228] Iteration 2350, loss = 16004.5
I0908 14:53:54.197655  4668 solver.cpp:244]     Train net output #0: accuracy = 0.846487
I0908 14:53:54.197670  4668 solver.cpp:244]     Train net output #1: loss = 16004.5 (* 1 = 16004.5 loss)
I0908 14:53:54.197681  4668 sgd_solver.cpp:106] Iteration 2350, lr = 1e-05
I0908 14:55:06.176125  4668 solver.cpp:337] Iteration 2400, Testing net (#0)
I0908 14:55:13.414774  4668 solver.cpp:404]     Test net output #0: accuracy = 0.730413
I0908 14:55:13.414832  4668 solver.cpp:404]     Test net output #1: loss = 31572.2 (* 1 = 31572.2 loss)
I0908 14:55:14.736433  4668 solver.cpp:228] Iteration 2400, loss = 11916.1
I0908 14:55:14.736486  4668 solver.cpp:244]     Train net output #0: accuracy = 0.89227
I0908 14:55:14.736503  4668 solver.cpp:244]     Train net output #1: loss = 11916.1 (* 1 = 11916.1 loss)
I0908 14:55:14.736515  4668 sgd_solver.cpp:106] Iteration 2400, lr = 1e-05
I0908 14:56:29.434317  4668 solver.cpp:228] Iteration 2450, loss = 15087
I0908 14:56:29.434408  4668 solver.cpp:244]     Train net output #0: accuracy = 0.846434
I0908 14:56:29.434422  4668 solver.cpp:244]     Train net output #1: loss = 15087 (* 1 = 15087 loss)
I0908 14:56:29.434428  4668 sgd_solver.cpp:106] Iteration 2450, lr = 1e-05
I0908 14:57:42.413848  4668 solver.cpp:228] Iteration 2500, loss = 12439.3
I0908 14:57:42.413928  4668 solver.cpp:244]     Train net output #0: accuracy = 0.881261
I0908 14:57:42.413939  4668 solver.cpp:244]     Train net output #1: loss = 12439.3 (* 1 = 12439.3 loss)
I0908 14:57:42.413946  4668 sgd_solver.cpp:106] Iteration 2500, lr = 1e-05
I0908 14:58:55.922216  4668 solver.cpp:228] Iteration 2550, loss = 10602.1
I0908 14:58:55.922291  4668 solver.cpp:244]     Train net output #0: accuracy = 0.900536
I0908 14:58:55.922302  4668 solver.cpp:244]     Train net output #1: loss = 10602.1 (* 1 = 10602.1 loss)
I0908 14:58:55.922309  4668 sgd_solver.cpp:106] Iteration 2550, lr = 1e-05
I0908 15:00:06.806149  4668 solver.cpp:337] Iteration 2600, Testing net (#0)
I0908 15:00:13.655153  4668 solver.cpp:404]     Test net output #0: accuracy = 0.777856
I0908 15:00:13.655194  4668 solver.cpp:404]     Test net output #1: loss = 23162.9 (* 1 = 23162.9 loss)
I0908 15:00:14.943043  4668 solver.cpp:228] Iteration 2600, loss = 8298.31
I0908 15:00:14.943084  4668 solver.cpp:244]     Train net output #0: accuracy = 0.922586
I0908 15:00:14.943094  4668 solver.cpp:244]     Train net output #1: loss = 8298.31 (* 1 = 8298.31 loss)
I0908 15:00:14.943101  4668 sgd_solver.cpp:106] Iteration 2600, lr = 1e-05
I0908 15:01:27.161268  4668 solver.cpp:228] Iteration 2650, loss = 13841.7
I0908 15:01:27.161365  4668 solver.cpp:244]     Train net output #0: accuracy = 0.86068
I0908 15:01:27.161376  4668 solver.cpp:244]     Train net output #1: loss = 13841.7 (* 1 = 13841.7 loss)
I0908 15:01:27.161383  4668 sgd_solver.cpp:106] Iteration 2650, lr = 1e-05
I0908 15:02:40.734012  4668 solver.cpp:228] Iteration 2700, loss = 460.016
I0908 15:02:40.734124  4668 solver.cpp:244]     Train net output #0: accuracy = 0.999729
I0908 15:02:40.734144  4668 solver.cpp:244]     Train net output #1: loss = 460.01 (* 1 = 460.01 loss)
I0908 15:02:40.734155  4668 sgd_solver.cpp:106] Iteration 2700, lr = 1e-05
I0908 15:03:53.638157  4668 solver.cpp:228] Iteration 2750, loss = 9103.39
I0908 15:03:53.638257  4668 solver.cpp:244]     Train net output #0: accuracy = 0.913068
I0908 15:03:53.638268  4668 solver.cpp:244]     Train net output #1: loss = 9103.39 (* 1 = 9103.39 loss)
I0908 15:03:53.638276  4668 sgd_solver.cpp:106] Iteration 2750, lr = 1e-05
I0908 15:05:05.264235  4668 solver.cpp:337] Iteration 2800, Testing net (#0)
I0908 15:05:12.157552  4668 solver.cpp:404]     Test net output #0: accuracy = 0.762428
I0908 15:05:12.157596  4668 solver.cpp:404]     Test net output #1: loss = 24386.9 (* 1 = 24386.9 loss)
I0908 15:05:13.447080  4668 solver.cpp:228] Iteration 2800, loss = 13246.7
I0908 15:05:13.447123  4668 solver.cpp:244]     Train net output #0: accuracy = 0.872176
I0908 15:05:13.447132  4668 solver.cpp:244]     Train net output #1: loss = 13246.7 (* 1 = 13246.7 loss)
I0908 15:05:13.447139  4668 sgd_solver.cpp:106] Iteration 2800, lr = 1e-05
I0908 15:06:27.365698  4668 solver.cpp:228] Iteration 2850, loss = 12427.4
I0908 15:06:27.365784  4668 solver.cpp:244]     Train net output #0: accuracy = 0.876607
I0908 15:06:27.365797  4668 solver.cpp:244]     Train net output #1: loss = 12427.4 (* 1 = 12427.4 loss)
I0908 15:06:27.365803  4668 sgd_solver.cpp:106] Iteration 2850, lr = 1e-05
I0908 15:07:40.190397  4668 solver.cpp:228] Iteration 2900, loss = 12370.5
I0908 15:07:40.190484  4668 solver.cpp:244]     Train net output #0: accuracy = 0.87531
I0908 15:07:40.190495  4668 solver.cpp:244]     Train net output #1: loss = 12370.5 (* 1 = 12370.5 loss)
I0908 15:07:40.190501  4668 sgd_solver.cpp:106] Iteration 2900, lr = 1e-05
I0908 15:08:52.862591  4668 solver.cpp:228] Iteration 2950, loss = 10641.2
I0908 15:08:52.862663  4668 solver.cpp:244]     Train net output #0: accuracy = 0.900366
I0908 15:08:52.862675  4668 solver.cpp:244]     Train net output #1: loss = 10641.2 (* 1 = 10641.2 loss)
I0908 15:08:52.862682  4668 sgd_solver.cpp:106] Iteration 2950, lr = 1e-05
I0908 15:10:04.113590  4668 solver.cpp:337] Iteration 3000, Testing net (#0)
I0908 15:10:10.958272  4668 solver.cpp:404]     Test net output #0: accuracy = 0.775774
I0908 15:10:10.958318  4668 solver.cpp:404]     Test net output #1: loss = 22428.7 (* 1 = 22428.7 loss)
I0908 15:10:12.253690  4668 solver.cpp:228] Iteration 3000, loss = 15291.2
I0908 15:10:12.253728  4668 solver.cpp:244]     Train net output #0: accuracy = 0.848663
I0908 15:10:12.253738  4668 solver.cpp:244]     Train net output #1: loss = 15291.2 (* 1 = 15291.2 loss)
I0908 15:10:12.253744  4668 sgd_solver.cpp:106] Iteration 3000, lr = 1e-05
I0908 15:11:24.757774  4668 solver.cpp:228] Iteration 3050, loss = 14012
I0908 15:11:24.757853  4668 solver.cpp:244]     Train net output #0: accuracy = 0.864929
I0908 15:11:24.757863  4668 solver.cpp:244]     Train net output #1: loss = 14012 (* 1 = 14012 loss)
I0908 15:11:24.757870  4668 sgd_solver.cpp:106] Iteration 3050, lr = 1e-05
I0908 15:12:39.475409  4668 solver.cpp:228] Iteration 3100, loss = 9506.77
I0908 15:12:39.475520  4668 solver.cpp:244]     Train net output #0: accuracy = 0.908306
I0908 15:12:39.475538  4668 solver.cpp:244]     Train net output #1: loss = 9506.77 (* 1 = 9506.77 loss)
I0908 15:12:39.475549  4668 sgd_solver.cpp:106] Iteration 3100, lr = 1e-05
I0908 15:13:53.158255  4668 solver.cpp:228] Iteration 3150, loss = 7972.18
I0908 15:13:53.158355  4668 solver.cpp:244]     Train net output #0: accuracy = 0.92451
I0908 15:13:53.158371  4668 solver.cpp:244]     Train net output #1: loss = 7972.17 (* 1 = 7972.17 loss)
I0908 15:13:53.158380  4668 sgd_solver.cpp:106] Iteration 3150, lr = 1e-05
I0908 15:15:07.265530  4668 solver.cpp:337] Iteration 3200, Testing net (#0)
I0908 15:15:14.118201  4668 solver.cpp:404]     Test net output #0: accuracy = 0.765464
I0908 15:15:14.118245  4668 solver.cpp:404]     Test net output #1: loss = 24164.3 (* 1 = 24164.3 loss)
I0908 15:15:15.414098  4668 solver.cpp:228] Iteration 3200, loss = 7792.58
I0908 15:15:15.414134  4668 solver.cpp:244]     Train net output #0: accuracy = 0.924115
I0908 15:15:15.414144  4668 solver.cpp:244]     Train net output #1: loss = 7792.57 (* 1 = 7792.57 loss)
I0908 15:15:15.414150  4668 sgd_solver.cpp:106] Iteration 3200, lr = 1e-05
I0908 15:16:28.524090  4668 solver.cpp:228] Iteration 3250, loss = 13093.3
I0908 15:16:28.524184  4668 solver.cpp:244]     Train net output #0: accuracy = 0.86501
I0908 15:16:28.524196  4668 solver.cpp:244]     Train net output #1: loss = 13093.3 (* 1 = 13093.3 loss)
I0908 15:16:28.524207  4668 sgd_solver.cpp:106] Iteration 3250, lr = 1e-05
I0908 15:17:41.875499  4668 solver.cpp:228] Iteration 3300, loss = 8894.54
I0908 15:17:41.875588  4668 solver.cpp:244]     Train net output #0: accuracy = 0.916427
I0908 15:17:41.875600  4668 solver.cpp:244]     Train net output #1: loss = 8894.54 (* 1 = 8894.54 loss)
I0908 15:17:41.875607  4668 sgd_solver.cpp:106] Iteration 3300, lr = 1e-05
I0908 15:18:55.661892  4668 solver.cpp:228] Iteration 3350, loss = 9022.6
I0908 15:18:55.661993  4668 solver.cpp:244]     Train net output #0: accuracy = 0.915164
I0908 15:18:55.662005  4668 solver.cpp:244]     Train net output #1: loss = 9022.59 (* 1 = 9022.59 loss)
I0908 15:18:55.662012  4668 sgd_solver.cpp:106] Iteration 3350, lr = 1e-05
I0908 15:20:06.741557  4668 solver.cpp:337] Iteration 3400, Testing net (#0)
I0908 15:20:13.589620  4668 solver.cpp:404]     Test net output #0: accuracy = 0.793115
I0908 15:20:13.589663  4668 solver.cpp:404]     Test net output #1: loss = 19801.1 (* 1 = 19801.1 loss)
I0908 15:20:14.876693  4668 solver.cpp:228] Iteration 3400, loss = 6742.05
I0908 15:20:14.876730  4668 solver.cpp:244]     Train net output #0: accuracy = 0.935686
I0908 15:20:14.876739  4668 solver.cpp:244]     Train net output #1: loss = 6742.04 (* 1 = 6742.04 loss)
I0908 15:20:14.876746  4668 sgd_solver.cpp:106] Iteration 3400, lr = 1e-05
I0908 15:21:27.799371  4668 solver.cpp:228] Iteration 3450, loss = 11237.2
I0908 15:21:27.799448  4668 solver.cpp:244]     Train net output #0: accuracy = 0.886841
I0908 15:21:27.799459  4668 solver.cpp:244]     Train net output #1: loss = 11237.2 (* 1 = 11237.2 loss)
I0908 15:21:27.799466  4668 sgd_solver.cpp:106] Iteration 3450, lr = 1e-05
I0908 15:22:40.133026  4668 solver.cpp:228] Iteration 3500, loss = 508.144
I0908 15:22:40.133116  4668 solver.cpp:244]     Train net output #0: accuracy = 0.999945
I0908 15:22:40.133126  4668 solver.cpp:244]     Train net output #1: loss = 508.138 (* 1 = 508.138 loss)
I0908 15:22:40.133134  4668 sgd_solver.cpp:106] Iteration 3500, lr = 1e-05
I0908 15:23:53.739590  4668 solver.cpp:228] Iteration 3550, loss = 7793.88
I0908 15:23:53.739665  4668 solver.cpp:244]     Train net output #0: accuracy = 0.924873
I0908 15:23:53.739676  4668 solver.cpp:244]     Train net output #1: loss = 7793.88 (* 1 = 7793.88 loss)
I0908 15:23:53.739683  4668 sgd_solver.cpp:106] Iteration 3550, lr = 1e-05
I0908 15:25:05.604430  4668 solver.cpp:337] Iteration 3600, Testing net (#0)
I0908 15:25:12.884419  4668 solver.cpp:404]     Test net output #0: accuracy = 0.77
I0908 15:25:12.884459  4668 solver.cpp:404]     Test net output #1: loss = 22761.3 (* 1 = 22761.3 loss)
I0908 15:25:14.178640  4668 solver.cpp:228] Iteration 3600, loss = 14295.5
I0908 15:25:14.178681  4668 solver.cpp:244]     Train net output #0: accuracy = 0.862788
I0908 15:25:14.178690  4668 solver.cpp:244]     Train net output #1: loss = 14295.5 (* 1 = 14295.5 loss)
I0908 15:25:14.178697  4668 sgd_solver.cpp:106] Iteration 3600, lr = 1e-05
I0908 15:26:26.256299  4668 solver.cpp:228] Iteration 3650, loss = 11852.8
I0908 15:26:26.256397  4668 solver.cpp:244]     Train net output #0: accuracy = 0.890773
I0908 15:26:26.256407  4668 solver.cpp:244]     Train net output #1: loss = 11852.8 (* 1 = 11852.8 loss)
I0908 15:26:26.256414  4668 sgd_solver.cpp:106] Iteration 3650, lr = 1e-05
I0908 15:27:39.335144  4668 solver.cpp:228] Iteration 3700, loss = 10729.5
I0908 15:27:39.335232  4668 solver.cpp:244]     Train net output #0: accuracy = 0.892498
I0908 15:27:39.335243  4668 solver.cpp:244]     Train net output #1: loss = 10729.5 (* 1 = 10729.5 loss)
I0908 15:27:39.335250  4668 sgd_solver.cpp:106] Iteration 3700, lr = 1e-05
I0908 15:28:51.385573  4668 solver.cpp:228] Iteration 3750, loss = 8262.33
I0908 15:28:51.385651  4668 solver.cpp:244]     Train net output #0: accuracy = 0.92066
I0908 15:28:51.385663  4668 solver.cpp:244]     Train net output #1: loss = 8262.33 (* 1 = 8262.33 loss)
I0908 15:28:51.385669  4668 sgd_solver.cpp:106] Iteration 3750, lr = 1e-05
I0908 15:30:03.236045  4668 solver.cpp:337] Iteration 3800, Testing net (#0)
I0908 15:30:10.072240  4668 solver.cpp:404]     Test net output #0: accuracy = 0.800005
I0908 15:30:10.072280  4668 solver.cpp:404]     Test net output #1: loss = 19359.3 (* 1 = 19359.3 loss)
I0908 15:30:11.370471  4668 solver.cpp:228] Iteration 3800, loss = 14273.7
I0908 15:30:11.370512  4668 solver.cpp:244]     Train net output #0: accuracy = 0.857372
I0908 15:30:11.370522  4668 solver.cpp:244]     Train net output #1: loss = 14273.7 (* 1 = 14273.7 loss)
I0908 15:30:11.370529  4668 sgd_solver.cpp:106] Iteration 3800, lr = 1e-05
I0908 15:31:23.734602  4668 solver.cpp:228] Iteration 3850, loss = 13108.4
I0908 15:31:23.734700  4668 solver.cpp:244]     Train net output #0: accuracy = 0.874257
I0908 15:31:23.734712  4668 solver.cpp:244]     Train net output #1: loss = 13108.4 (* 1 = 13108.4 loss)
I0908 15:31:23.734719  4668 sgd_solver.cpp:106] Iteration 3850, lr = 1e-05
I0908 15:32:35.826122  4668 solver.cpp:228] Iteration 3900, loss = 8446.45
I0908 15:32:35.826210  4668 solver.cpp:244]     Train net output #0: accuracy = 0.918554
I0908 15:32:35.826222  4668 solver.cpp:244]     Train net output #1: loss = 8446.44 (* 1 = 8446.44 loss)
I0908 15:32:35.826228  4668 sgd_solver.cpp:106] Iteration 3900, lr = 1e-05
I0908 15:33:47.877465  4668 solver.cpp:228] Iteration 3950, loss = 6683.27
I0908 15:33:47.877564  4668 solver.cpp:244]     Train net output #0: accuracy = 0.934704
I0908 15:33:47.877575  4668 solver.cpp:244]     Train net output #1: loss = 6683.27 (* 1 = 6683.27 loss)
I0908 15:33:47.877583  4668 sgd_solver.cpp:106] Iteration 3950, lr = 1e-05
I0908 15:34:58.608309  4668 solver.cpp:454] Snapshotting to binary proto file portrait_wfm_one_stage_iter_4000.caffemodel
I0908 15:34:58.611022  4668 sgd_solver.cpp:273] Snapshotting solver state to binary proto file portrait_wfm_one_stage_iter_4000.solverstate
I0908 15:34:58.612015  4668 solver.cpp:337] Iteration 4000, Testing net (#0)
I0908 15:35:05.463670  4668 solver.cpp:404]     Test net output #0: accuracy = 0.784712
I0908 15:35:05.463714  4668 solver.cpp:404]     Test net output #1: loss = 21625.5 (* 1 = 21625.5 loss)
I0908 15:35:06.752745  4668 solver.cpp:228] Iteration 4000, loss = 6517.23
I0908 15:35:06.752780  4668 solver.cpp:244]     Train net output #0: accuracy = 0.935708
I0908 15:35:06.752790  4668 solver.cpp:244]     Train net output #1: loss = 6517.22 (* 1 = 6517.22 loss)
I0908 15:35:06.752797  4668 sgd_solver.cpp:106] Iteration 4000, lr = 1e-06
I0908 15:36:18.879127  4668 solver.cpp:228] Iteration 4050, loss = 12012
I0908 15:36:18.879222  4668 solver.cpp:244]     Train net output #0: accuracy = 0.884328
I0908 15:36:18.879233  4668 solver.cpp:244]     Train net output #1: loss = 12012 (* 1 = 12012 loss)
I0908 15:36:18.879240  4668 sgd_solver.cpp:106] Iteration 4050, lr = 1e-06
I0908 15:37:30.949606  4668 solver.cpp:228] Iteration 4100, loss = 6473.07
I0908 15:37:30.949693  4668 solver.cpp:244]     Train net output #0: accuracy = 0.935611
I0908 15:37:30.949705  4668 solver.cpp:244]     Train net output #1: loss = 6473.07 (* 1 = 6473.07 loss)
I0908 15:37:30.949712  4668 sgd_solver.cpp:106] Iteration 4100, lr = 1e-06
I0908 15:38:43.439555  4668 solver.cpp:228] Iteration 4150, loss = 8647.46
I0908 15:38:43.439646  4668 solver.cpp:244]     Train net output #0: accuracy = 0.91672
I0908 15:38:43.439657  4668 solver.cpp:244]     Train net output #1: loss = 8647.46 (* 1 = 8647.46 loss)
I0908 15:38:43.439664  4668 sgd_solver.cpp:106] Iteration 4150, lr = 1e-06
I0908 15:39:56.977129  4668 solver.cpp:337] Iteration 4200, Testing net (#0)
I0908 15:40:03.867015  4668 solver.cpp:404]     Test net output #0: accuracy = 0.822591
I0908 15:40:03.867060  4668 solver.cpp:404]     Test net output #1: loss = 17244.3 (* 1 = 17244.3 loss)
I0908 15:40:05.162535  4668 solver.cpp:228] Iteration 4200, loss = 10008.2
I0908 15:40:05.162573  4668 solver.cpp:244]     Train net output #0: accuracy = 0.902852
I0908 15:40:05.162583  4668 solver.cpp:244]     Train net output #1: loss = 10008.2 (* 1 = 10008.2 loss)
I0908 15:40:05.162600  4668 sgd_solver.cpp:106] Iteration 4200, lr = 1e-06
I0908 15:41:17.997431  4668 solver.cpp:228] Iteration 4250, loss = 10465.2
I0908 15:41:17.997552  4668 solver.cpp:244]     Train net output #0: accuracy = 0.896922
I0908 15:41:17.997565  4668 solver.cpp:244]     Train net output #1: loss = 10465.2 (* 1 = 10465.2 loss)
I0908 15:41:17.997572  4668 sgd_solver.cpp:106] Iteration 4250, lr = 1e-06
I0908 15:42:30.081670  4668 solver.cpp:228] Iteration 4300, loss = 82.7102
I0908 15:42:30.081750  4668 solver.cpp:244]     Train net output #0: accuracy = 0.999868
I0908 15:42:30.081763  4668 solver.cpp:244]     Train net output #1: loss = 82.706 (* 1 = 82.706 loss)
I0908 15:42:30.081769  4668 sgd_solver.cpp:106] Iteration 4300, lr = 1e-06
I0908 15:43:42.210888  4668 solver.cpp:228] Iteration 4350, loss = 7006.5
I0908 15:43:42.210958  4668 solver.cpp:244]     Train net output #0: accuracy = 0.932893
I0908 15:43:42.210969  4668 solver.cpp:244]     Train net output #1: loss = 7006.5 (* 1 = 7006.5 loss)
I0908 15:43:42.210976  4668 sgd_solver.cpp:106] Iteration 4350, lr = 1e-06
I0908 15:44:53.129849  4668 solver.cpp:337] Iteration 4400, Testing net (#0)
I0908 15:45:00.077347  4668 solver.cpp:404]     Test net output #0: accuracy = 0.827582
I0908 15:45:00.077390  4668 solver.cpp:404]     Test net output #1: loss = 16726.1 (* 1 = 16726.1 loss)
I0908 15:45:01.371690  4668 solver.cpp:228] Iteration 4400, loss = 13320
I0908 15:45:01.371744  4668 solver.cpp:244]     Train net output #0: accuracy = 0.872872
I0908 15:45:01.371758  4668 solver.cpp:244]     Train net output #1: loss = 13320 (* 1 = 13320 loss)
I0908 15:45:01.371767  4668 sgd_solver.cpp:106] Iteration 4400, lr = 1e-06
I0908 15:46:13.897131  4668 solver.cpp:228] Iteration 4450, loss = 8973.19
I0908 15:46:13.897223  4668 solver.cpp:244]     Train net output #0: accuracy = 0.912328
I0908 15:46:13.897234  4668 solver.cpp:244]     Train net output #1: loss = 8973.18 (* 1 = 8973.18 loss)
I0908 15:46:13.897243  4668 sgd_solver.cpp:106] Iteration 4450, lr = 1e-06
I0908 15:47:27.461272  4668 solver.cpp:228] Iteration 4500, loss = 8653.1
I0908 15:47:27.461364  4668 solver.cpp:244]     Train net output #0: accuracy = 0.917032
I0908 15:47:27.461376  4668 solver.cpp:244]     Train net output #1: loss = 8653.1 (* 1 = 8653.1 loss)
I0908 15:47:27.461382  4668 sgd_solver.cpp:106] Iteration 4500, lr = 1e-06
I0908 15:48:40.843852  4668 solver.cpp:228] Iteration 4550, loss = 6965
I0908 15:48:40.843933  4668 solver.cpp:244]     Train net output #0: accuracy = 0.932721
I0908 15:48:40.843945  4668 solver.cpp:244]     Train net output #1: loss = 6965 (* 1 = 6965 loss)
I0908 15:48:40.843952  4668 sgd_solver.cpp:106] Iteration 4550, lr = 1e-06
I0908 15:49:52.802614  4668 solver.cpp:337] Iteration 4600, Testing net (#0)
I0908 15:49:59.649883  4668 solver.cpp:404]     Test net output #0: accuracy = 0.838156
I0908 15:49:59.649930  4668 solver.cpp:404]     Test net output #1: loss = 15663.1 (* 1 = 15663.1 loss)
I0908 15:50:00.947286  4668 solver.cpp:228] Iteration 4600, loss = 11822.8
I0908 15:50:00.947319  4668 solver.cpp:244]     Train net output #0: accuracy = 0.881522
I0908 15:50:00.947329  4668 solver.cpp:244]     Train net output #1: loss = 11822.8 (* 1 = 11822.8 loss)
I0908 15:50:00.947336  4668 sgd_solver.cpp:106] Iteration 4600, lr = 1e-06
I0908 15:51:14.390185  4668 solver.cpp:228] Iteration 4650, loss = 11584.1
I0908 15:51:14.390274  4668 solver.cpp:244]     Train net output #0: accuracy = 0.88545
I0908 15:51:14.390290  4668 solver.cpp:244]     Train net output #1: loss = 11584.1 (* 1 = 11584.1 loss)
I0908 15:51:14.390298  4668 sgd_solver.cpp:106] Iteration 4650, lr = 1e-06
I0908 15:52:27.745386  4668 solver.cpp:228] Iteration 4700, loss = 7821.21
I0908 15:52:27.745474  4668 solver.cpp:244]     Train net output #0: accuracy = 0.925254
I0908 15:52:27.745486  4668 solver.cpp:244]     Train net output #1: loss = 7821.21 (* 1 = 7821.21 loss)
I0908 15:52:27.745494  4668 sgd_solver.cpp:106] Iteration 4700, lr = 1e-06
I0908 15:53:41.636307  4668 solver.cpp:228] Iteration 4750, loss = 6517.73
I0908 15:53:41.636446  4668 solver.cpp:244]     Train net output #0: accuracy = 0.938507
I0908 15:53:41.636459  4668 solver.cpp:244]     Train net output #1: loss = 6517.73 (* 1 = 6517.73 loss)
I0908 15:53:41.636466  4668 sgd_solver.cpp:106] Iteration 4750, lr = 1e-06
I0908 15:54:53.509402  4668 solver.cpp:337] Iteration 4800, Testing net (#0)
I0908 15:55:00.367951  4668 solver.cpp:404]     Test net output #0: accuracy = 0.846257
I0908 15:55:00.367996  4668 solver.cpp:404]     Test net output #1: loss = 14946.8 (* 1 = 14946.8 loss)
I0908 15:55:01.662693  4668 solver.cpp:228] Iteration 4800, loss = 9080.82
I0908 15:55:01.662730  4668 solver.cpp:244]     Train net output #0: accuracy = 0.91125
I0908 15:55:01.662739  4668 solver.cpp:244]     Train net output #1: loss = 9080.81 (* 1 = 9080.81 loss)
I0908 15:55:01.662746  4668 sgd_solver.cpp:106] Iteration 4800, lr = 1e-06
I0908 15:56:13.747719  4668 solver.cpp:228] Iteration 4850, loss = 72.5244
I0908 15:56:13.747794  4668 solver.cpp:244]     Train net output #0: accuracy = 0.999912
I0908 15:56:13.747805  4668 solver.cpp:244]     Train net output #1: loss = 72.5209 (* 1 = 72.5209 loss)
I0908 15:56:13.747812  4668 sgd_solver.cpp:106] Iteration 4850, lr = 1e-06
I0908 15:57:28.253376  4668 solver.cpp:228] Iteration 4900, loss = 6970.67
I0908 15:57:28.253471  4668 solver.cpp:244]     Train net output #0: accuracy = 0.930952
I0908 15:57:28.253484  4668 solver.cpp:244]     Train net output #1: loss = 6970.67 (* 1 = 6970.67 loss)
I0908 15:57:28.253489  4668 sgd_solver.cpp:106] Iteration 4900, lr = 1e-06
I0908 15:58:41.082562  4668 solver.cpp:228] Iteration 4950, loss = 8504.57
I0908 15:58:41.082636  4668 solver.cpp:244]     Train net output #0: accuracy = 0.916914
I0908 15:58:41.082648  4668 solver.cpp:244]     Train net output #1: loss = 8504.57 (* 1 = 8504.57 loss)
I0908 15:58:41.082655  4668 sgd_solver.cpp:106] Iteration 4950, lr = 1e-06
I0908 15:59:53.000548  4668 solver.cpp:337] Iteration 5000, Testing net (#0)
I0908 15:59:59.871840  4668 solver.cpp:404]     Test net output #0: accuracy = 0.854385
I0908 15:59:59.871882  4668 solver.cpp:404]     Test net output #1: loss = 14250.7 (* 1 = 14250.7 loss)
I0908 16:00:01.181967  4668 solver.cpp:228] Iteration 5000, loss = 9306.95
I0908 16:00:01.182009  4668 solver.cpp:244]     Train net output #0: accuracy = 0.907847
I0908 16:00:01.182019  4668 solver.cpp:244]     Train net output #1: loss = 9306.95 (* 1 = 9306.95 loss)
I0908 16:00:01.182026  4668 sgd_solver.cpp:106] Iteration 5000, lr = 1e-06
I0908 16:01:14.244343  4668 solver.cpp:228] Iteration 5050, loss = 9665.04
I0908 16:01:14.244442  4668 solver.cpp:244]     Train net output #0: accuracy = 0.903495
I0908 16:01:14.244454  4668 solver.cpp:244]     Train net output #1: loss = 9665.04 (* 1 = 9665.04 loss)
I0908 16:01:14.244462  4668 sgd_solver.cpp:106] Iteration 5050, lr = 1e-06
I0908 16:02:28.116299  4668 solver.cpp:228] Iteration 5100, loss = 5551.82
I0908 16:02:28.116385  4668 solver.cpp:244]     Train net output #0: accuracy = 0.948749
I0908 16:02:28.116397  4668 solver.cpp:244]     Train net output #1: loss = 5551.82 (* 1 = 5551.82 loss)
I0908 16:02:28.116405  4668 sgd_solver.cpp:106] Iteration 5100, lr = 1e-06
I0908 16:03:41.990842  4668 solver.cpp:228] Iteration 5150, loss = 11297.6
I0908 16:03:41.990926  4668 solver.cpp:244]     Train net output #0: accuracy = 0.889619
I0908 16:03:41.990937  4668 solver.cpp:244]     Train net output #1: loss = 11297.6 (* 1 = 11297.6 loss)
I0908 16:03:41.990943  4668 sgd_solver.cpp:106] Iteration 5150, lr = 1e-06
I0908 16:04:53.982746  4668 solver.cpp:337] Iteration 5200, Testing net (#0)
I0908 16:05:00.827082  4668 solver.cpp:404]     Test net output #0: accuracy = 0.854054
I0908 16:05:00.827119  4668 solver.cpp:404]     Test net output #1: loss = 14129.4 (* 1 = 14129.4 loss)
I0908 16:05:02.125118  4668 solver.cpp:228] Iteration 5200, loss = 11983.6
I0908 16:05:02.125160  4668 solver.cpp:244]     Train net output #0: accuracy = 0.885938
I0908 16:05:02.125169  4668 solver.cpp:244]     Train net output #1: loss = 11983.6 (* 1 = 11983.6 loss)
I0908 16:05:02.125191  4668 sgd_solver.cpp:106] Iteration 5200, lr = 1e-06
I0908 16:06:14.380079  4668 solver.cpp:228] Iteration 5250, loss = 9522.02
I0908 16:06:14.380199  4668 solver.cpp:244]     Train net output #0: accuracy = 0.90728
I0908 16:06:14.380213  4668 solver.cpp:244]     Train net output #1: loss = 9522.02 (* 1 = 9522.02 loss)
I0908 16:06:14.380219  4668 sgd_solver.cpp:106] Iteration 5250, lr = 1e-06
I0908 16:07:27.167183  4668 solver.cpp:228] Iteration 5300, loss = 6188.41
I0908 16:07:27.167286  4668 solver.cpp:244]     Train net output #0: accuracy = 0.940617
I0908 16:07:27.167299  4668 solver.cpp:244]     Train net output #1: loss = 6188.41 (* 1 = 6188.41 loss)
I0908 16:07:27.167305  4668 sgd_solver.cpp:106] Iteration 5300, lr = 1e-06
I0908 16:08:40.277171  4668 solver.cpp:228] Iteration 5350, loss = 6862.04
I0908 16:08:40.277264  4668 solver.cpp:244]     Train net output #0: accuracy = 0.932109
I0908 16:08:40.277276  4668 solver.cpp:244]     Train net output #1: loss = 6862.03 (* 1 = 6862.03 loss)
I0908 16:08:40.277282  4668 sgd_solver.cpp:106] Iteration 5350, lr = 1e-06
I0908 16:09:52.937440  4668 solver.cpp:337] Iteration 5400, Testing net (#0)
I0908 16:09:59.784435  4668 solver.cpp:404]     Test net output #0: accuracy = 0.861332
I0908 16:09:59.784479  4668 solver.cpp:404]     Test net output #1: loss = 13522.1 (* 1 = 13522.1 loss)
I0908 16:10:01.083039  4668 solver.cpp:228] Iteration 5400, loss = 11891.1
I0908 16:10:01.083076  4668 solver.cpp:244]     Train net output #0: accuracy = 0.877146
I0908 16:10:01.083086  4668 solver.cpp:244]     Train net output #1: loss = 11891.1 (* 1 = 11891.1 loss)
I0908 16:10:01.083092  4668 sgd_solver.cpp:106] Iteration 5400, lr = 1e-06
I0908 16:11:14.657552  4668 solver.cpp:228] Iteration 5450, loss = 6779.38
I0908 16:11:14.657637  4668 solver.cpp:244]     Train net output #0: accuracy = 0.935502
I0908 16:11:14.657649  4668 solver.cpp:244]     Train net output #1: loss = 6779.37 (* 1 = 6779.37 loss)
I0908 16:11:14.657656  4668 sgd_solver.cpp:106] Iteration 5450, lr = 1e-06
I0908 16:12:27.338513  4668 solver.cpp:228] Iteration 5500, loss = 7030.29
I0908 16:12:27.338608  4668 solver.cpp:244]     Train net output #0: accuracy = 0.932283
I0908 16:12:27.338621  4668 solver.cpp:244]     Train net output #1: loss = 7030.29 (* 1 = 7030.29 loss)
I0908 16:12:27.338629  4668 sgd_solver.cpp:106] Iteration 5500, lr = 1e-06
I0908 16:13:40.261852  4668 solver.cpp:228] Iteration 5550, loss = 6308.23
I0908 16:13:40.261955  4668 solver.cpp:244]     Train net output #0: accuracy = 0.939101
I0908 16:13:40.261967  4668 solver.cpp:244]     Train net output #1: loss = 6308.22 (* 1 = 6308.22 loss)
I0908 16:13:40.261975  4668 sgd_solver.cpp:106] Iteration 5550, lr = 1e-06
I0908 16:14:51.146158  4668 solver.cpp:337] Iteration 5600, Testing net (#0)
I0908 16:14:58.055449  4668 solver.cpp:404]     Test net output #0: accuracy = 0.871253
I0908 16:14:58.055490  4668 solver.cpp:404]     Test net output #1: loss = 12744.1 (* 1 = 12744.1 loss)
I0908 16:14:59.368665  4668 solver.cpp:228] Iteration 5600, loss = 10087.8
I0908 16:14:59.368700  4668 solver.cpp:244]     Train net output #0: accuracy = 0.900308
I0908 16:14:59.368710  4668 solver.cpp:244]     Train net output #1: loss = 10087.8 (* 1 = 10087.8 loss)
I0908 16:14:59.368717  4668 sgd_solver.cpp:106] Iteration 5600, lr = 1e-06
I0908 16:16:11.908622  4668 solver.cpp:228] Iteration 5650, loss = 61.5858
I0908 16:16:11.908718  4668 solver.cpp:244]     Train net output #0: accuracy = 0.999911
I0908 16:16:11.908730  4668 solver.cpp:244]     Train net output #1: loss = 61.5796 (* 1 = 61.5796 loss)
I0908 16:16:11.908737  4668 sgd_solver.cpp:106] Iteration 5650, lr = 1e-06
I0908 16:17:26.702999  4668 solver.cpp:228] Iteration 5700, loss = 6944.81
I0908 16:17:26.703073  4668 solver.cpp:244]     Train net output #0: accuracy = 0.931987
I0908 16:17:26.703084  4668 solver.cpp:244]     Train net output #1: loss = 6944.8 (* 1 = 6944.8 loss)
I0908 16:17:26.703091  4668 sgd_solver.cpp:106] Iteration 5700, lr = 1e-06
I0908 16:18:38.927037  4668 solver.cpp:228] Iteration 5750, loss = 11511.8
I0908 16:18:38.927155  4668 solver.cpp:244]     Train net output #0: accuracy = 0.890032
I0908 16:18:38.927168  4668 solver.cpp:244]     Train net output #1: loss = 11511.8 (* 1 = 11511.8 loss)
I0908 16:18:38.927175  4668 sgd_solver.cpp:106] Iteration 5750, lr = 1e-06
I0908 16:19:50.191311  4668 solver.cpp:337] Iteration 5800, Testing net (#0)
I0908 16:19:57.081858  4668 solver.cpp:404]     Test net output #0: accuracy = 0.879738
I0908 16:19:57.081899  4668 solver.cpp:404]     Test net output #1: loss = 12027.2 (* 1 = 12027.2 loss)
I0908 16:19:58.378594  4668 solver.cpp:228] Iteration 5800, loss = 8629.6
I0908 16:19:58.378629  4668 solver.cpp:244]     Train net output #0: accuracy = 0.913631
I0908 16:19:58.378638  4668 solver.cpp:244]     Train net output #1: loss = 8629.59 (* 1 = 8629.59 loss)
I0908 16:19:58.378645  4668 sgd_solver.cpp:106] Iteration 5800, lr = 1e-06
I0908 16:21:11.889423  4668 solver.cpp:228] Iteration 5850, loss = 9843.37
I0908 16:21:11.889504  4668 solver.cpp:244]     Train net output #0: accuracy = 0.902217
I0908 16:21:11.889516  4668 solver.cpp:244]     Train net output #1: loss = 9843.36 (* 1 = 9843.36 loss)
I0908 16:21:11.889523  4668 sgd_solver.cpp:106] Iteration 5850, lr = 1e-06
I0908 16:22:24.470739  4668 solver.cpp:228] Iteration 5900, loss = 6708.38
I0908 16:22:24.470841  4668 solver.cpp:244]     Train net output #0: accuracy = 0.937052
I0908 16:22:24.470854  4668 solver.cpp:244]     Train net output #1: loss = 6708.38 (* 1 = 6708.38 loss)
I0908 16:22:24.470860  4668 sgd_solver.cpp:106] Iteration 5900, lr = 1e-06
I0908 16:23:38.089212  4668 solver.cpp:228] Iteration 5950, loss = 11216.4
I0908 16:23:38.089314  4668 solver.cpp:244]     Train net output #0: accuracy = 0.886028
I0908 16:23:38.089326  4668 solver.cpp:244]     Train net output #1: loss = 11216.4 (* 1 = 11216.4 loss)
I0908 16:23:38.089334  4668 sgd_solver.cpp:106] Iteration 5950, lr = 1e-06
I0908 16:24:48.951468  4668 solver.cpp:337] Iteration 6000, Testing net (#0)
I0908 16:24:55.884784  4668 solver.cpp:404]     Test net output #0: accuracy = 0.873365
I0908 16:24:55.884820  4668 solver.cpp:404]     Test net output #1: loss = 12388.3 (* 1 = 12388.3 loss)
I0908 16:24:57.182296  4668 solver.cpp:228] Iteration 6000, loss = 12340.6
I0908 16:24:57.182332  4668 solver.cpp:244]     Train net output #0: accuracy = 0.881961
I0908 16:24:57.182343  4668 solver.cpp:244]     Train net output #1: loss = 12340.6 (* 1 = 12340.6 loss)
I0908 16:24:57.182348  4668 sgd_solver.cpp:106] Iteration 6000, lr = 1e-06
I0908 16:26:11.053771  4668 solver.cpp:228] Iteration 6050, loss = 8524.46
I0908 16:26:11.053884  4668 solver.cpp:244]     Train net output #0: accuracy = 0.916428
I0908 16:26:11.053905  4668 solver.cpp:244]     Train net output #1: loss = 8524.46 (* 1 = 8524.46 loss)
I0908 16:26:11.053915  4668 sgd_solver.cpp:106] Iteration 6050, lr = 1e-06
I0908 16:27:24.023722  4668 solver.cpp:228] Iteration 6100, loss = 6147.68
I0908 16:27:24.023824  4668 solver.cpp:244]     Train net output #0: accuracy = 0.940899
I0908 16:27:24.023836  4668 solver.cpp:244]     Train net output #1: loss = 6147.68 (* 1 = 6147.68 loss)
I0908 16:27:24.023844  4668 sgd_solver.cpp:106] Iteration 6100, lr = 1e-06
I0908 16:28:37.108090  4668 solver.cpp:228] Iteration 6150, loss = 6143.92
I0908 16:28:37.108181  4668 solver.cpp:244]     Train net output #0: accuracy = 0.941055
I0908 16:28:37.108193  4668 solver.cpp:244]     Train net output #1: loss = 6143.92 (* 1 = 6143.92 loss)
I0908 16:28:37.108201  4668 sgd_solver.cpp:106] Iteration 6150, lr = 1e-06
I0908 16:29:48.625253  4668 solver.cpp:337] Iteration 6200, Testing net (#0)
I0908 16:29:55.550798  4668 solver.cpp:404]     Test net output #0: accuracy = 0.883436
I0908 16:29:55.550846  4668 solver.cpp:404]     Test net output #1: loss = 11585.7 (* 1 = 11585.7 loss)
I0908 16:29:56.849571  4668 solver.cpp:228] Iteration 6200, loss = 11219.6
I0908 16:29:56.849611  4668 solver.cpp:244]     Train net output #0: accuracy = 0.887568
I0908 16:29:56.849622  4668 solver.cpp:244]     Train net output #1: loss = 11219.6 (* 1 = 11219.6 loss)
I0908 16:29:56.849639  4668 sgd_solver.cpp:106] Iteration 6200, lr = 1e-06
I0908 16:31:09.662168  4668 solver.cpp:228] Iteration 6250, loss = 6764.04
I0908 16:31:09.662282  4668 solver.cpp:244]     Train net output #0: accuracy = 0.933738
I0908 16:31:09.662295  4668 solver.cpp:244]     Train net output #1: loss = 6764.04 (* 1 = 6764.04 loss)
I0908 16:31:09.662302  4668 sgd_solver.cpp:106] Iteration 6250, lr = 1e-06
I0908 16:32:22.390697  4668 solver.cpp:228] Iteration 6300, loss = 7397.74
I0908 16:32:22.390800  4668 solver.cpp:244]     Train net output #0: accuracy = 0.927701
I0908 16:32:22.390813  4668 solver.cpp:244]     Train net output #1: loss = 7397.73 (* 1 = 7397.73 loss)
I0908 16:32:22.390820  4668 sgd_solver.cpp:106] Iteration 6300, lr = 1e-06
I0908 16:33:34.655093  4668 solver.cpp:228] Iteration 6350, loss = 7484.56
I0908 16:33:34.655201  4668 solver.cpp:244]     Train net output #0: accuracy = 0.927334
I0908 16:33:34.655215  4668 solver.cpp:244]     Train net output #1: loss = 7484.55 (* 1 = 7484.55 loss)
I0908 16:33:34.655222  4668 sgd_solver.cpp:106] Iteration 6350, lr = 1e-06
I0908 16:34:45.412168  4668 solver.cpp:337] Iteration 6400, Testing net (#0)
I0908 16:34:52.256255  4668 solver.cpp:404]     Test net output #0: accuracy = 0.889012
I0908 16:34:52.256296  4668 solver.cpp:404]     Test net output #1: loss = 11140.6 (* 1 = 11140.6 loss)
I0908 16:34:53.556969  4668 solver.cpp:228] Iteration 6400, loss = 9076.06
I0908 16:34:53.557005  4668 solver.cpp:244]     Train net output #0: accuracy = 0.907984
I0908 16:34:53.557015  4668 solver.cpp:244]     Train net output #1: loss = 9076.05 (* 1 = 9076.05 loss)
I0908 16:34:53.557023  4668 sgd_solver.cpp:106] Iteration 6400, lr = 1e-06
I0908 16:36:06.771227  4668 solver.cpp:228] Iteration 6450, loss = 75.4209
I0908 16:36:06.771325  4668 solver.cpp:244]     Train net output #0: accuracy = 0.999946
I0908 16:36:06.771337  4668 solver.cpp:244]     Train net output #1: loss = 75.4146 (* 1 = 75.4146 loss)
I0908 16:36:06.771344  4668 sgd_solver.cpp:106] Iteration 6450, lr = 1e-06
I0908 16:37:19.315102  4668 solver.cpp:228] Iteration 6500, loss = 6543.43
I0908 16:37:19.315192  4668 solver.cpp:244]     Train net output #0: accuracy = 0.936703
I0908 16:37:19.315203  4668 solver.cpp:244]     Train net output #1: loss = 6543.43 (* 1 = 6543.43 loss)
I0908 16:37:19.315210  4668 sgd_solver.cpp:106] Iteration 6500, lr = 1e-06
I0908 16:38:31.916714  4668 solver.cpp:228] Iteration 6550, loss = 12351.8
I0908 16:38:31.916806  4668 solver.cpp:244]     Train net output #0: accuracy = 0.880682
I0908 16:38:31.916818  4668 solver.cpp:244]     Train net output #1: loss = 12351.8 (* 1 = 12351.8 loss)
I0908 16:38:31.916826  4668 sgd_solver.cpp:106] Iteration 6550, lr = 1e-06
I0908 16:39:43.426060  4668 solver.cpp:337] Iteration 6600, Testing net (#0)
I0908 16:39:50.316541  4668 solver.cpp:404]     Test net output #0: accuracy = 0.891622
I0908 16:39:50.316587  4668 solver.cpp:404]     Test net output #1: loss = 10974.9 (* 1 = 10974.9 loss)
I0908 16:39:51.618085  4668 solver.cpp:228] Iteration 6600, loss = 10738.6
I0908 16:39:51.618120  4668 solver.cpp:244]     Train net output #0: accuracy = 0.902768
I0908 16:39:51.618130  4668 solver.cpp:244]     Train net output #1: loss = 10738.6 (* 1 = 10738.6 loss)
I0908 16:39:51.618137  4668 sgd_solver.cpp:106] Iteration 6600, lr = 1e-06
I0908 16:41:03.895198  4668 solver.cpp:228] Iteration 6650, loss = 9936.46
I0908 16:41:03.895287  4668 solver.cpp:244]     Train net output #0: accuracy = 0.900333
I0908 16:41:03.895298  4668 solver.cpp:244]     Train net output #1: loss = 9936.45 (* 1 = 9936.45 loss)
I0908 16:41:03.895306  4668 sgd_solver.cpp:106] Iteration 6650, lr = 1e-06
I0908 16:42:16.696983  4668 solver.cpp:228] Iteration 6700, loss = 6277.38
I0908 16:42:16.697079  4668 solver.cpp:244]     Train net output #0: accuracy = 0.93936
I0908 16:42:16.697091  4668 solver.cpp:244]     Train net output #1: loss = 6277.37 (* 1 = 6277.37 loss)
I0908 16:42:16.697098  4668 sgd_solver.cpp:106] Iteration 6700, lr = 1e-06
I0908 16:43:29.467255  4668 solver.cpp:228] Iteration 6750, loss = 12733.6
I0908 16:43:29.467382  4668 solver.cpp:244]     Train net output #0: accuracy = 0.874311
I0908 16:43:29.467394  4668 solver.cpp:244]     Train net output #1: loss = 12733.6 (* 1 = 12733.6 loss)
I0908 16:43:29.467401  4668 sgd_solver.cpp:106] Iteration 6750, lr = 1e-06
I0908 16:44:40.491422  4668 solver.cpp:337] Iteration 6800, Testing net (#0)
I0908 16:44:47.347630  4668 solver.cpp:404]     Test net output #0: accuracy = 0.884867
I0908 16:44:47.347671  4668 solver.cpp:404]     Test net output #1: loss = 11435 (* 1 = 11435 loss)
I0908 16:44:48.643501  4668 solver.cpp:228] Iteration 6800, loss = 12186.8
I0908 16:44:48.643533  4668 solver.cpp:244]     Train net output #0: accuracy = 0.882014
I0908 16:44:48.643543  4668 solver.cpp:244]     Train net output #1: loss = 12186.8 (* 1 = 12186.8 loss)
I0908 16:44:48.643549  4668 sgd_solver.cpp:106] Iteration 6800, lr = 1e-06
I0908 16:46:01.549872  4668 solver.cpp:228] Iteration 6850, loss = 6570.08
I0908 16:46:01.549974  4668 solver.cpp:244]     Train net output #0: accuracy = 0.935914
I0908 16:46:01.549988  4668 solver.cpp:244]     Train net output #1: loss = 6570.07 (* 1 = 6570.07 loss)
I0908 16:46:01.549994  4668 sgd_solver.cpp:106] Iteration 6850, lr = 1e-06
I0908 16:47:14.674907  4668 solver.cpp:228] Iteration 6900, loss = 6193.17
I0908 16:47:14.675014  4668 solver.cpp:244]     Train net output #0: accuracy = 0.940238
I0908 16:47:14.675026  4668 solver.cpp:244]     Train net output #1: loss = 6193.16 (* 1 = 6193.16 loss)
I0908 16:47:14.675034  4668 sgd_solver.cpp:106] Iteration 6900, lr = 1e-06
I0908 16:48:26.700867  4668 solver.cpp:228] Iteration 6950, loss = 5819.67
I0908 16:48:26.700951  4668 solver.cpp:244]     Train net output #0: accuracy = 0.944097
I0908 16:48:26.700963  4668 solver.cpp:244]     Train net output #1: loss = 5819.66 (* 1 = 5819.66 loss)
I0908 16:48:26.700970  4668 sgd_solver.cpp:106] Iteration 6950, lr = 1e-06
I0908 16:49:37.552412  4668 solver.cpp:337] Iteration 7000, Testing net (#0)
I0908 16:49:44.843916  4668 solver.cpp:404]     Test net output #0: accuracy = 0.893201
I0908 16:49:44.843961  4668 solver.cpp:404]     Test net output #1: loss = 10785.9 (* 1 = 10785.9 loss)
I0908 16:49:46.130704  4668 solver.cpp:228] Iteration 7000, loss = 9224.87
I0908 16:49:46.130739  4668 solver.cpp:244]     Train net output #0: accuracy = 0.911088
I0908 16:49:46.130749  4668 solver.cpp:244]     Train net output #1: loss = 9224.87 (* 1 = 9224.87 loss)
I0908 16:49:46.130755  4668 sgd_solver.cpp:106] Iteration 7000, lr = 1e-06
I0908 16:50:58.190356  4668 solver.cpp:228] Iteration 7050, loss = 6064.23
I0908 16:50:58.190450  4668 solver.cpp:244]     Train net output #0: accuracy = 0.939383
I0908 16:50:58.190462  4668 solver.cpp:244]     Train net output #1: loss = 6064.22 (* 1 = 6064.22 loss)
I0908 16:50:58.190469  4668 sgd_solver.cpp:106] Iteration 7050, lr = 1e-06
I0908 16:52:10.456512  4668 solver.cpp:228] Iteration 7100, loss = 8368.32
I0908 16:52:10.456609  4668 solver.cpp:244]     Train net output #0: accuracy = 0.917395
I0908 16:52:10.456621  4668 solver.cpp:244]     Train net output #1: loss = 8368.31 (* 1 = 8368.31 loss)
I0908 16:52:10.456629  4668 sgd_solver.cpp:106] Iteration 7100, lr = 1e-06
I0908 16:53:24.034129  4668 solver.cpp:228] Iteration 7150, loss = 9367.12
I0908 16:53:24.034229  4668 solver.cpp:244]     Train net output #0: accuracy = 0.909174
I0908 16:53:24.034241  4668 solver.cpp:244]     Train net output #1: loss = 9367.11 (* 1 = 9367.11 loss)
I0908 16:53:24.034247  4668 sgd_solver.cpp:106] Iteration 7150, lr = 1e-06
I0908 16:54:35.243338  4668 solver.cpp:337] Iteration 7200, Testing net (#0)
I0908 16:54:42.153452  4668 solver.cpp:404]     Test net output #0: accuracy = 0.896538
I0908 16:54:42.153494  4668 solver.cpp:404]     Test net output #1: loss = 10564.5 (* 1 = 10564.5 loss)
I0908 16:54:43.457211  4668 solver.cpp:228] Iteration 7200, loss = 9844.74
I0908 16:54:43.457252  4668 solver.cpp:244]     Train net output #0: accuracy = 0.903387
I0908 16:54:43.457262  4668 solver.cpp:244]     Train net output #1: loss = 9844.74 (* 1 = 9844.74 loss)
I0908 16:54:43.457283  4668 sgd_solver.cpp:106] Iteration 7200, lr = 1e-06
I0908 16:55:55.908762  4668 solver.cpp:228] Iteration 7250, loss = 51.9513
I0908 16:55:55.908865  4668 solver.cpp:244]     Train net output #0: accuracy = 0.999975
I0908 16:55:55.908876  4668 solver.cpp:244]     Train net output #1: loss = 51.9432 (* 1 = 51.9432 loss)
I0908 16:55:55.908882  4668 sgd_solver.cpp:106] Iteration 7250, lr = 1e-06
I0908 16:57:08.201813  4668 solver.cpp:228] Iteration 7300, loss = 8339.95
I0908 16:57:08.201908  4668 solver.cpp:244]     Train net output #0: accuracy = 0.919436
I0908 16:57:08.201920  4668 solver.cpp:244]     Train net output #1: loss = 8339.95 (* 1 = 8339.95 loss)
I0908 16:57:08.201928  4668 sgd_solver.cpp:106] Iteration 7300, lr = 1e-06
I0908 16:58:21.686218  4668 solver.cpp:228] Iteration 7350, loss = 13223.8
I0908 16:58:21.686290  4668 solver.cpp:244]     Train net output #0: accuracy = 0.873374
I0908 16:58:21.686301  4668 solver.cpp:244]     Train net output #1: loss = 13223.8 (* 1 = 13223.8 loss)
I0908 16:58:21.686308  4668 sgd_solver.cpp:106] Iteration 7350, lr = 1e-06
I0908 16:59:33.138289  4668 solver.cpp:337] Iteration 7400, Testing net (#0)
I0908 16:59:39.986253  4668 solver.cpp:404]     Test net output #0: accuracy = 0.896213
I0908 16:59:39.986294  4668 solver.cpp:404]     Test net output #1: loss = 10543.2 (* 1 = 10543.2 loss)
I0908 16:59:41.281543  4668 solver.cpp:228] Iteration 7400, loss = 8315.16
I0908 16:59:41.281584  4668 solver.cpp:244]     Train net output #0: accuracy = 0.918368
I0908 16:59:41.281594  4668 solver.cpp:244]     Train net output #1: loss = 8315.15 (* 1 = 8315.15 loss)
I0908 16:59:41.281601  4668 sgd_solver.cpp:106] Iteration 7400, lr = 1e-06
I0908 17:00:53.551164  4668 solver.cpp:228] Iteration 7450, loss = 5855.11
I0908 17:00:53.551252  4668 solver.cpp:244]     Train net output #0: accuracy = 0.94318
I0908 17:00:53.551264  4668 solver.cpp:244]     Train net output #1: loss = 5855.1 (* 1 = 5855.1 loss)
I0908 17:00:53.551270  4668 sgd_solver.cpp:106] Iteration 7450, lr = 1e-06
I0908 17:02:07.636070  4668 solver.cpp:228] Iteration 7500, loss = 6389.78
I0908 17:02:07.636174  4668 solver.cpp:244]     Train net output #0: accuracy = 0.936614
I0908 17:02:07.636188  4668 solver.cpp:244]     Train net output #1: loss = 6389.77 (* 1 = 6389.77 loss)
I0908 17:02:07.636194  4668 sgd_solver.cpp:106] Iteration 7500, lr = 1e-06
I0908 17:03:21.971716  4668 solver.cpp:228] Iteration 7550, loss = 11275.9
I0908 17:03:21.971814  4668 solver.cpp:244]     Train net output #0: accuracy = 0.887043
I0908 17:03:21.971827  4668 solver.cpp:244]     Train net output #1: loss = 11275.9 (* 1 = 11275.9 loss)
I0908 17:03:21.971834  4668 sgd_solver.cpp:106] Iteration 7550, lr = 1e-06
I0908 17:04:34.127154  4668 solver.cpp:337] Iteration 7600, Testing net (#0)
I0908 17:04:40.990262  4668 solver.cpp:404]     Test net output #0: accuracy = 0.889715
I0908 17:04:40.990309  4668 solver.cpp:404]     Test net output #1: loss = 10999.5 (* 1 = 10999.5 loss)
I0908 17:04:42.288415  4668 solver.cpp:228] Iteration 7600, loss = 11464.2
I0908 17:04:42.288450  4668 solver.cpp:244]     Train net output #0: accuracy = 0.890221
I0908 17:04:42.288460  4668 solver.cpp:244]     Train net output #1: loss = 11464.2 (* 1 = 11464.2 loss)
I0908 17:04:42.288467  4668 sgd_solver.cpp:106] Iteration 7600, lr = 1e-06
I0908 17:05:55.500926  4668 solver.cpp:228] Iteration 7650, loss = 6845.75
I0908 17:05:55.501014  4668 solver.cpp:244]     Train net output #0: accuracy = 0.932496
I0908 17:05:55.501025  4668 solver.cpp:244]     Train net output #1: loss = 6845.74 (* 1 = 6845.74 loss)
I0908 17:05:55.501032  4668 sgd_solver.cpp:106] Iteration 7650, lr = 1e-06
I0908 17:07:08.868522  4668 solver.cpp:228] Iteration 7700, loss = 5724.91
I0908 17:07:08.868621  4668 solver.cpp:244]     Train net output #0: accuracy = 0.944944
I0908 17:07:08.868633  4668 solver.cpp:244]     Train net output #1: loss = 5724.91 (* 1 = 5724.91 loss)
I0908 17:07:08.868641  4668 sgd_solver.cpp:106] Iteration 7700, lr = 1e-06
I0908 17:08:21.126770  4668 solver.cpp:228] Iteration 7750, loss = 9143.58
I0908 17:08:21.126881  4668 solver.cpp:244]     Train net output #0: accuracy = 0.909298
I0908 17:08:21.126894  4668 solver.cpp:244]     Train net output #1: loss = 9143.57 (* 1 = 9143.57 loss)
I0908 17:08:21.126901  4668 sgd_solver.cpp:106] Iteration 7750, lr = 1e-06
I0908 17:09:32.246307  4668 solver.cpp:337] Iteration 7800, Testing net (#0)
I0908 17:09:39.090652  4668 solver.cpp:404]     Test net output #0: accuracy = 0.897862
I0908 17:09:39.090698  4668 solver.cpp:404]     Test net output #1: loss = 10349 (* 1 = 10349 loss)
I0908 17:09:40.369583  4668 solver.cpp:228] Iteration 7800, loss = 50.29
I0908 17:09:40.369623  4668 solver.cpp:244]     Train net output #0: accuracy = 0.99999
I0908 17:09:40.369633  4668 solver.cpp:244]     Train net output #1: loss = 50.2823 (* 1 = 50.2823 loss)
I0908 17:09:40.369640  4668 sgd_solver.cpp:106] Iteration 7800, lr = 1e-06
I0908 17:10:52.984802  4668 solver.cpp:228] Iteration 7850, loss = 6851.06
I0908 17:10:52.984899  4668 solver.cpp:244]     Train net output #0: accuracy = 0.932343
I0908 17:10:52.984910  4668 solver.cpp:244]     Train net output #1: loss = 6851.05 (* 1 = 6851.05 loss)
I0908 17:10:52.984917  4668 sgd_solver.cpp:106] Iteration 7850, lr = 1e-06
I0908 17:12:05.034291  4668 solver.cpp:228] Iteration 7900, loss = 7822.13
I0908 17:12:05.034375  4668 solver.cpp:244]     Train net output #0: accuracy = 0.924243
I0908 17:12:05.034387  4668 solver.cpp:244]     Train net output #1: loss = 7822.12 (* 1 = 7822.12 loss)
I0908 17:12:05.034394  4668 sgd_solver.cpp:106] Iteration 7900, lr = 1e-06
I0908 17:13:18.192824  4668 solver.cpp:228] Iteration 7950, loss = 8383.25
I0908 17:13:18.192925  4668 solver.cpp:244]     Train net output #0: accuracy = 0.915566
I0908 17:13:18.192937  4668 solver.cpp:244]     Train net output #1: loss = 8383.24 (* 1 = 8383.24 loss)
I0908 17:13:18.192945  4668 sgd_solver.cpp:106] Iteration 7950, lr = 1e-06
I0908 17:14:29.327630  4668 solver.cpp:454] Snapshotting to binary proto file portrait_wfm_one_stage_iter_8000.caffemodel
I0908 17:14:29.330365  4668 sgd_solver.cpp:273] Snapshotting solver state to binary proto file portrait_wfm_one_stage_iter_8000.solverstate
I0908 17:14:29.331415  4668 solver.cpp:337] Iteration 8000, Testing net (#0)
I0908 17:14:36.259024  4668 solver.cpp:404]     Test net output #0: accuracy = 0.901284
I0908 17:14:36.259063  4668 solver.cpp:404]     Test net output #1: loss = 10073.7 (* 1 = 10073.7 loss)
I0908 17:14:37.668129  4668 solver.cpp:228] Iteration 8000, loss = 9510.99
I0908 17:14:37.668169  4668 solver.cpp:244]     Train net output #0: accuracy = 0.90415
I0908 17:14:37.668179  4668 solver.cpp:244]     Train net output #1: loss = 9510.99 (* 1 = 9510.99 loss)
I0908 17:14:37.668186  4668 sgd_solver.cpp:106] Iteration 8000, lr = 1e-07
I0908 17:15:50.482897  4668 solver.cpp:228] Iteration 8050, loss = 6381.81
I0908 17:15:50.482991  4668 solver.cpp:244]     Train net output #0: accuracy = 0.938602
I0908 17:15:50.483002  4668 solver.cpp:244]     Train net output #1: loss = 6381.81 (* 1 = 6381.81 loss)
I0908 17:15:50.483009  4668 sgd_solver.cpp:106] Iteration 8050, lr = 1e-07
I0908 17:17:02.734530  4668 solver.cpp:228] Iteration 8100, loss = 10723.9
I0908 17:17:02.734625  4668 solver.cpp:244]     Train net output #0: accuracy = 0.893507
I0908 17:17:02.734637  4668 solver.cpp:244]     Train net output #1: loss = 10723.9 (* 1 = 10723.9 loss)
I0908 17:17:02.734645  4668 sgd_solver.cpp:106] Iteration 8100, lr = 1e-07
I0908 17:18:16.642514  4668 solver.cpp:228] Iteration 8150, loss = 12000.4
I0908 17:18:16.642617  4668 solver.cpp:244]     Train net output #0: accuracy = 0.886557
I0908 17:18:16.642629  4668 solver.cpp:244]     Train net output #1: loss = 12000.4 (* 1 = 12000.4 loss)
I0908 17:18:16.642637  4668 sgd_solver.cpp:106] Iteration 8150, lr = 1e-07
I0908 17:19:28.596720  4668 solver.cpp:337] Iteration 8200, Testing net (#0)
I0908 17:19:35.439290  4668 solver.cpp:404]     Test net output #0: accuracy = 0.899795
I0908 17:19:35.439339  4668 solver.cpp:404]     Test net output #1: loss = 10178.4 (* 1 = 10178.4 loss)
I0908 17:19:36.735712  4668 solver.cpp:228] Iteration 8200, loss = 8716.64
I0908 17:19:36.735744  4668 solver.cpp:244]     Train net output #0: accuracy = 0.914978
I0908 17:19:36.735754  4668 solver.cpp:244]     Train net output #1: loss = 8716.63 (* 1 = 8716.63 loss)
I0908 17:19:36.735760  4668 sgd_solver.cpp:106] Iteration 8200, lr = 1e-07
I0908 17:20:49.794195  4668 solver.cpp:228] Iteration 8250, loss = 5941.42
I0908 17:20:49.794312  4668 solver.cpp:244]     Train net output #0: accuracy = 0.942689
I0908 17:20:49.794323  4668 solver.cpp:244]     Train net output #1: loss = 5941.42 (* 1 = 5941.42 loss)
I0908 17:20:49.794330  4668 sgd_solver.cpp:106] Iteration 8250, lr = 1e-07
I0908 17:22:02.660223  4668 solver.cpp:228] Iteration 8300, loss = 6470.47
I0908 17:22:02.660325  4668 solver.cpp:244]     Train net output #0: accuracy = 0.936745
I0908 17:22:02.660336  4668 solver.cpp:244]     Train net output #1: loss = 6470.46 (* 1 = 6470.46 loss)
I0908 17:22:02.660342  4668 sgd_solver.cpp:106] Iteration 8300, lr = 1e-07
I0908 17:23:14.995152  4668 solver.cpp:228] Iteration 8350, loss = 10771.2
I0908 17:23:14.995240  4668 solver.cpp:244]     Train net output #0: accuracy = 0.888971
I0908 17:23:14.995252  4668 solver.cpp:244]     Train net output #1: loss = 10771.2 (* 1 = 10771.2 loss)
I0908 17:23:14.995260  4668 sgd_solver.cpp:106] Iteration 8350, lr = 1e-07
I0908 17:24:25.769528  4668 solver.cpp:337] Iteration 8400, Testing net (#0)
I0908 17:24:32.625619  4668 solver.cpp:404]     Test net output #0: accuracy = 0.89899
I0908 17:24:32.625658  4668 solver.cpp:404]     Test net output #1: loss = 10224.9 (* 1 = 10224.9 loss)
I0908 17:24:33.916209  4668 solver.cpp:228] Iteration 8400, loss = 6059.88
I0908 17:24:33.916250  4668 solver.cpp:244]     Train net output #0: accuracy = 0.941571
I0908 17:24:33.916260  4668 solver.cpp:244]     Train net output #1: loss = 6059.88 (* 1 = 6059.88 loss)
I0908 17:24:33.916267  4668 sgd_solver.cpp:106] Iteration 8400, lr = 1e-07
I0908 17:25:46.880305  4668 solver.cpp:228] Iteration 8450, loss = 6826
I0908 17:25:46.880429  4668 solver.cpp:244]     Train net output #0: accuracy = 0.934256
I0908 17:25:46.880450  4668 solver.cpp:244]     Train net output #1: loss = 6825.99 (* 1 = 6825.99 loss)
I0908 17:25:46.880462  4668 sgd_solver.cpp:106] Iteration 8450, lr = 1e-07
I0908 17:27:00.644385  4668 solver.cpp:228] Iteration 8500, loss = 6188.74
I0908 17:27:00.644486  4668 solver.cpp:244]     Train net output #0: accuracy = 0.941214
I0908 17:27:00.644498  4668 solver.cpp:244]     Train net output #1: loss = 6188.73 (* 1 = 6188.73 loss)
I0908 17:27:00.644506  4668 sgd_solver.cpp:106] Iteration 8500, lr = 1e-07
I0908 17:28:13.688436  4668 solver.cpp:228] Iteration 8550, loss = 9552.43
I0908 17:28:13.688540  4668 solver.cpp:244]     Train net output #0: accuracy = 0.90521
I0908 17:28:13.688552  4668 solver.cpp:244]     Train net output #1: loss = 9552.42 (* 1 = 9552.42 loss)
I0908 17:28:13.688560  4668 sgd_solver.cpp:106] Iteration 8550, lr = 1e-07
I0908 17:29:25.170310  4668 solver.cpp:337] Iteration 8600, Testing net (#0)
I0908 17:29:32.010710  4668 solver.cpp:404]     Test net output #0: accuracy = 0.898913
I0908 17:29:32.010753  4668 solver.cpp:404]     Test net output #1: loss = 10228.3 (* 1 = 10228.3 loss)
I0908 17:29:33.293282  4668 solver.cpp:228] Iteration 8600, loss = 41.3819
I0908 17:29:33.293323  4668 solver.cpp:244]     Train net output #0: accuracy = 0.999988
I0908 17:29:33.293334  4668 solver.cpp:244]     Train net output #1: loss = 41.373 (* 1 = 41.373 loss)
I0908 17:29:33.293340  4668 sgd_solver.cpp:106] Iteration 8600, lr = 1e-07
I0908 17:30:46.184983  4668 solver.cpp:228] Iteration 8650, loss = 6386.81
I0908 17:30:46.185086  4668 solver.cpp:244]     Train net output #0: accuracy = 0.936224
I0908 17:30:46.185099  4668 solver.cpp:244]     Train net output #1: loss = 6386.8 (* 1 = 6386.8 loss)
I0908 17:30:46.185107  4668 sgd_solver.cpp:106] Iteration 8650, lr = 1e-07
I0908 17:31:58.290491  4668 solver.cpp:228] Iteration 8700, loss = 12102.8
I0908 17:31:58.290606  4668 solver.cpp:244]     Train net output #0: accuracy = 0.883183
I0908 17:31:58.290618  4668 solver.cpp:244]     Train net output #1: loss = 12102.8 (* 1 = 12102.8 loss)
I0908 17:31:58.290624  4668 sgd_solver.cpp:106] Iteration 8700, lr = 1e-07
I0908 17:33:11.977167  4668 solver.cpp:228] Iteration 8750, loss = 8321.74
I0908 17:33:11.977253  4668 solver.cpp:244]     Train net output #0: accuracy = 0.918084
I0908 17:33:11.977265  4668 solver.cpp:244]     Train net output #1: loss = 8321.73 (* 1 = 8321.73 loss)
I0908 17:33:11.977273  4668 sgd_solver.cpp:106] Iteration 8750, lr = 1e-07
I0908 17:34:23.382724  4668 solver.cpp:337] Iteration 8800, Testing net (#0)
I0908 17:34:30.528084  4668 solver.cpp:404]     Test net output #0: accuracy = 0.898765
I0908 17:34:30.528126  4668 solver.cpp:404]     Test net output #1: loss = 10248.2 (* 1 = 10248.2 loss)
I0908 17:34:31.827378  4668 solver.cpp:228] Iteration 8800, loss = 9747.97
I0908 17:34:31.827419  4668 solver.cpp:244]     Train net output #0: accuracy = 0.903302
I0908 17:34:31.827430  4668 solver.cpp:244]     Train net output #1: loss = 9747.97 (* 1 = 9747.97 loss)
I0908 17:34:31.827436  4668 sgd_solver.cpp:106] Iteration 8800, lr = 1e-07
I0908 17:35:44.905027  4668 solver.cpp:228] Iteration 8850, loss = 6458.73
I0908 17:35:44.905128  4668 solver.cpp:244]     Train net output #0: accuracy = 0.938695
I0908 17:35:44.905139  4668 solver.cpp:244]     Train net output #1: loss = 6458.72 (* 1 = 6458.72 loss)
I0908 17:35:44.905148  4668 sgd_solver.cpp:106] Iteration 8850, lr = 1e-07
I0908 17:36:58.300881  4668 solver.cpp:228] Iteration 8900, loss = 11657
I0908 17:36:58.300959  4668 solver.cpp:244]     Train net output #0: accuracy = 0.882464
I0908 17:36:58.300972  4668 solver.cpp:244]     Train net output #1: loss = 11657 (* 1 = 11657 loss)
I0908 17:36:58.300978  4668 sgd_solver.cpp:106] Iteration 8900, lr = 1e-07
I0908 17:38:11.075870  4668 solver.cpp:228] Iteration 8950, loss = 12137.7
I0908 17:38:11.075951  4668 solver.cpp:244]     Train net output #0: accuracy = 0.884267
I0908 17:38:11.075963  4668 solver.cpp:244]     Train net output #1: loss = 12137.7 (* 1 = 12137.7 loss)
I0908 17:38:11.075970  4668 sgd_solver.cpp:106] Iteration 8950, lr = 1e-07
I0908 17:39:24.550459  4668 solver.cpp:337] Iteration 9000, Testing net (#0)
I0908 17:39:31.479970  4668 solver.cpp:404]     Test net output #0: accuracy = 0.899864
I0908 17:39:31.480015  4668 solver.cpp:404]     Test net output #1: loss = 10155.3 (* 1 = 10155.3 loss)
I0908 17:39:32.766167  4668 solver.cpp:228] Iteration 9000, loss = 8532.9
I0908 17:39:32.766201  4668 solver.cpp:244]     Train net output #0: accuracy = 0.917167
I0908 17:39:32.766211  4668 solver.cpp:244]     Train net output #1: loss = 8532.89 (* 1 = 8532.89 loss)
I0908 17:39:32.766218  4668 sgd_solver.cpp:106] Iteration 9000, lr = 1e-07
I0908 17:40:44.811040  4668 solver.cpp:228] Iteration 9050, loss = 5614.84
I0908 17:40:44.811128  4668 solver.cpp:244]     Train net output #0: accuracy = 0.94657
I0908 17:40:44.811141  4668 solver.cpp:244]     Train net output #1: loss = 5614.83 (* 1 = 5614.83 loss)
I0908 17:40:44.811147  4668 sgd_solver.cpp:106] Iteration 9050, lr = 1e-07
I0908 17:41:58.330781  4668 solver.cpp:228] Iteration 9100, loss = 5768.66
I0908 17:41:58.330878  4668 solver.cpp:244]     Train net output #0: accuracy = 0.943846
I0908 17:41:58.330889  4668 solver.cpp:244]     Train net output #1: loss = 5768.65 (* 1 = 5768.65 loss)
I0908 17:41:58.330895  4668 sgd_solver.cpp:106] Iteration 9100, lr = 1e-07
I0908 17:43:12.086381  4668 solver.cpp:228] Iteration 9150, loss = 11566.7
I0908 17:43:12.086483  4668 solver.cpp:244]     Train net output #0: accuracy = 0.884663
I0908 17:43:12.086494  4668 solver.cpp:244]     Train net output #1: loss = 11566.7 (* 1 = 11566.7 loss)
I0908 17:43:12.086501  4668 sgd_solver.cpp:106] Iteration 9150, lr = 1e-07
I0908 17:44:24.390933  4668 solver.cpp:337] Iteration 9200, Testing net (#0)
I0908 17:44:31.258812  4668 solver.cpp:404]     Test net output #0: accuracy = 0.899075
I0908 17:44:31.258869  4668 solver.cpp:404]     Test net output #1: loss = 10214.9 (* 1 = 10214.9 loss)
I0908 17:44:32.553381  4668 solver.cpp:228] Iteration 9200, loss = 6550.78
I0908 17:44:32.553421  4668 solver.cpp:244]     Train net output #0: accuracy = 0.935866
I0908 17:44:32.553431  4668 solver.cpp:244]     Train net output #1: loss = 6550.77 (* 1 = 6550.77 loss)
I0908 17:44:32.553438  4668 sgd_solver.cpp:106] Iteration 9200, lr = 1e-07
I0908 17:45:44.731427  4668 solver.cpp:228] Iteration 9250, loss = 7233.95
I0908 17:45:44.731508  4668 solver.cpp:244]     Train net output #0: accuracy = 0.92874
I0908 17:45:44.731519  4668 solver.cpp:244]     Train net output #1: loss = 7233.94 (* 1 = 7233.94 loss)
I0908 17:45:44.731526  4668 sgd_solver.cpp:106] Iteration 9250, lr = 1e-07
I0908 17:46:57.220985  4668 solver.cpp:228] Iteration 9300, loss = 7663.81
I0908 17:46:57.221048  4668 solver.cpp:244]     Train net output #0: accuracy = 0.926587
I0908 17:46:57.221060  4668 solver.cpp:244]     Train net output #1: loss = 7663.8 (* 1 = 7663.8 loss)
I0908 17:46:57.221065  4668 sgd_solver.cpp:106] Iteration 9300, lr = 1e-07
I0908 17:48:09.267004  4668 solver.cpp:228] Iteration 9350, loss = 8837.03
I0908 17:48:09.267086  4668 solver.cpp:244]     Train net output #0: accuracy = 0.910302
I0908 17:48:09.267098  4668 solver.cpp:244]     Train net output #1: loss = 8837.02 (* 1 = 8837.02 loss)
I0908 17:48:09.267104  4668 sgd_solver.cpp:106] Iteration 9350, lr = 1e-07
I0908 17:49:21.569221  4668 solver.cpp:337] Iteration 9400, Testing net (#0)
I0908 17:49:30.008929  4668 solver.cpp:404]     Test net output #0: accuracy = 0.898128
I0908 17:49:30.008992  4668 solver.cpp:404]     Test net output #1: loss = 10316.1 (* 1 = 10316.1 loss)
I0908 17:49:31.351435  4668 solver.cpp:228] Iteration 9400, loss = 54.8202
I0908 17:49:31.351475  4668 solver.cpp:244]     Train net output #0: accuracy = 0.999921
I0908 17:49:31.351485  4668 solver.cpp:244]     Train net output #1: loss = 54.8124 (* 1 = 54.8124 loss)
I0908 17:49:31.351492  4668 sgd_solver.cpp:106] Iteration 9400, lr = 1e-07
I0908 17:50:43.710382  4668 solver.cpp:228] Iteration 9450, loss = 6289.8
I0908 17:50:43.710472  4668 solver.cpp:244]     Train net output #0: accuracy = 0.939367
I0908 17:50:43.710484  4668 solver.cpp:244]     Train net output #1: loss = 6289.8 (* 1 = 6289.8 loss)
I0908 17:50:43.710491  4668 sgd_solver.cpp:106] Iteration 9450, lr = 1e-07
I0908 17:51:58.987624  4668 solver.cpp:228] Iteration 9500, loss = 12120.6
I0908 17:51:58.987711  4668 solver.cpp:244]     Train net output #0: accuracy = 0.881479
I0908 17:51:58.987723  4668 solver.cpp:244]     Train net output #1: loss = 12120.6 (* 1 = 12120.6 loss)
I0908 17:51:58.987730  4668 sgd_solver.cpp:106] Iteration 9500, lr = 1e-07
I0908 17:53:11.034394  4668 solver.cpp:228] Iteration 9550, loss = 9878.99
I0908 17:53:11.034482  4668 solver.cpp:244]     Train net output #0: accuracy = 0.908484
I0908 17:53:11.034493  4668 solver.cpp:244]     Train net output #1: loss = 9878.98 (* 1 = 9878.98 loss)
I0908 17:53:11.034500  4668 sgd_solver.cpp:106] Iteration 9550, lr = 1e-07
I0908 17:54:22.259341  4668 solver.cpp:337] Iteration 9600, Testing net (#0)
I0908 17:54:29.139935  4668 solver.cpp:404]     Test net output #0: accuracy = 0.898983
I0908 17:54:29.139976  4668 solver.cpp:404]     Test net output #1: loss = 10226.1 (* 1 = 10226.1 loss)
I0908 17:54:30.436008  4668 solver.cpp:228] Iteration 9600, loss = 9789.06
I0908 17:54:30.436049  4668 solver.cpp:244]     Train net output #0: accuracy = 0.902936
I0908 17:54:30.436058  4668 solver.cpp:244]     Train net output #1: loss = 9789.05 (* 1 = 9789.05 loss)
I0908 17:54:30.436065  4668 sgd_solver.cpp:106] Iteration 9600, lr = 1e-07
I0908 17:55:43.320374  4668 solver.cpp:228] Iteration 9650, loss = 6230.91
I0908 17:55:43.320441  4668 solver.cpp:244]     Train net output #0: accuracy = 0.939301
I0908 17:55:43.320452  4668 solver.cpp:244]     Train net output #1: loss = 6230.91 (* 1 = 6230.91 loss)
I0908 17:55:43.320459  4668 sgd_solver.cpp:106] Iteration 9650, lr = 1e-07
I0908 17:56:56.031720  4668 solver.cpp:228] Iteration 9700, loss = 10734.7
I0908 17:56:56.031843  4668 solver.cpp:244]     Train net output #0: accuracy = 0.89265
I0908 17:56:56.031857  4668 solver.cpp:244]     Train net output #1: loss = 10734.7 (* 1 = 10734.7 loss)
I0908 17:56:56.031863  4668 sgd_solver.cpp:106] Iteration 9700, lr = 1e-07
I0908 17:58:08.647560  4668 solver.cpp:228] Iteration 9750, loss = 10889.4
I0908 17:58:08.647667  4668 solver.cpp:244]     Train net output #0: accuracy = 0.89202
I0908 17:58:08.647680  4668 solver.cpp:244]     Train net output #1: loss = 10889.4 (* 1 = 10889.4 loss)
I0908 17:58:08.647686  4668 sgd_solver.cpp:106] Iteration 9750, lr = 1e-07
I0908 17:59:20.084029  4668 solver.cpp:337] Iteration 9800, Testing net (#0)
I0908 17:59:26.930554  4668 solver.cpp:404]     Test net output #0: accuracy = 0.899491
I0908 17:59:26.930598  4668 solver.cpp:404]     Test net output #1: loss = 10198.9 (* 1 = 10198.9 loss)
I0908 17:59:28.219494  4668 solver.cpp:228] Iteration 9800, loss = 6614.23
I0908 17:59:28.219537  4668 solver.cpp:244]     Train net output #0: accuracy = 0.936442
I0908 17:59:28.219547  4668 solver.cpp:244]     Train net output #1: loss = 6614.23 (* 1 = 6614.23 loss)
I0908 17:59:28.219552  4668 sgd_solver.cpp:106] Iteration 9800, lr = 1e-07
I0908 18:00:41.636824  4668 solver.cpp:228] Iteration 9850, loss = 6328.48
I0908 18:00:41.636915  4668 solver.cpp:244]     Train net output #0: accuracy = 0.939647
I0908 18:00:41.636926  4668 solver.cpp:244]     Train net output #1: loss = 6328.48 (* 1 = 6328.48 loss)
I0908 18:00:41.636934  4668 sgd_solver.cpp:106] Iteration 9850, lr = 1e-07
I0908 18:01:54.253535  4668 solver.cpp:228] Iteration 9900, loss = 6115.1
I0908 18:01:54.253605  4668 solver.cpp:244]     Train net output #0: accuracy = 0.940746
I0908 18:01:54.253618  4668 solver.cpp:244]     Train net output #1: loss = 6115.1 (* 1 = 6115.1 loss)
I0908 18:01:54.253624  4668 sgd_solver.cpp:106] Iteration 9900, lr = 1e-07
I0908 18:03:07.867532  4668 solver.cpp:228] Iteration 9950, loss = 5328.23
I0908 18:03:07.867619  4668 solver.cpp:244]     Train net output #0: accuracy = 0.951054
I0908 18:03:07.867630  4668 solver.cpp:244]     Train net output #1: loss = 5328.22 (* 1 = 5328.22 loss)
I0908 18:03:07.867635  4668 sgd_solver.cpp:106] Iteration 9950, lr = 1e-07
I0908 18:04:20.023566  4668 solver.cpp:337] Iteration 10000, Testing net (#0)
I0908 18:04:27.279695  4668 solver.cpp:404]     Test net output #0: accuracy = 0.899066
I0908 18:04:27.279736  4668 solver.cpp:404]     Test net output #1: loss = 10238.8 (* 1 = 10238.8 loss)
I0908 18:04:28.569332  4668 solver.cpp:228] Iteration 10000, loss = 5650.9
I0908 18:04:28.569375  4668 solver.cpp:244]     Train net output #0: accuracy = 0.94455
I0908 18:04:28.569386  4668 solver.cpp:244]     Train net output #1: loss = 5650.9 (* 1 = 5650.9 loss)
I0908 18:04:28.569392  4668 sgd_solver.cpp:106] Iteration 10000, lr = 1e-07
I0908 18:05:43.171033  4668 solver.cpp:228] Iteration 10050, loss = 7812.05
I0908 18:05:43.171125  4668 solver.cpp:244]     Train net output #0: accuracy = 0.924128
I0908 18:05:43.171138  4668 solver.cpp:244]     Train net output #1: loss = 7812.04 (* 1 = 7812.04 loss)
I0908 18:05:43.171144  4668 sgd_solver.cpp:106] Iteration 10050, lr = 1e-07
I0908 18:06:56.263403  4668 solver.cpp:228] Iteration 10100, loss = 9465.91
I0908 18:06:56.263494  4668 solver.cpp:244]     Train net output #0: accuracy = 0.90977
I0908 18:06:56.263505  4668 solver.cpp:244]     Train net output #1: loss = 9465.91 (* 1 = 9465.91 loss)
I0908 18:06:56.263512  4668 sgd_solver.cpp:106] Iteration 10100, lr = 1e-07
I0908 18:08:08.420809  4668 solver.cpp:228] Iteration 10150, loss = 9485.45
I0908 18:08:08.420909  4668 solver.cpp:244]     Train net output #0: accuracy = 0.907074
I0908 18:08:08.420922  4668 solver.cpp:244]     Train net output #1: loss = 9485.44 (* 1 = 9485.44 loss)
I0908 18:08:08.420928  4668 sgd_solver.cpp:106] Iteration 10150, lr = 1e-07
I0908 18:09:19.273322  4668 solver.cpp:337] Iteration 10200, Testing net (#0)
I0908 18:09:26.119124  4668 solver.cpp:404]     Test net output #0: accuracy = 0.899214
I0908 18:09:26.119171  4668 solver.cpp:404]     Test net output #1: loss = 10215.5 (* 1 = 10215.5 loss)
I0908 18:09:27.396482  4668 solver.cpp:228] Iteration 10200, loss = 38.9743
I0908 18:09:27.396525  4668 solver.cpp:244]     Train net output #0: accuracy = 1
I0908 18:09:27.396535  4668 solver.cpp:244]     Train net output #1: loss = 38.9686 (* 1 = 38.9686 loss)
I0908 18:09:27.396543  4668 sgd_solver.cpp:106] Iteration 10200, lr = 1e-07
I0908 18:10:40.881481  4668 solver.cpp:228] Iteration 10250, loss = 9189.87
I0908 18:10:40.881584  4668 solver.cpp:244]     Train net output #0: accuracy = 0.909564
I0908 18:10:40.881597  4668 solver.cpp:244]     Train net output #1: loss = 9189.87 (* 1 = 9189.87 loss)
I0908 18:10:40.881604  4668 sgd_solver.cpp:106] Iteration 10250, lr = 1e-07
I0908 18:11:54.286974  4668 solver.cpp:228] Iteration 10300, loss = 12851.5
I0908 18:11:54.287060  4668 solver.cpp:244]     Train net output #0: accuracy = 0.878381
I0908 18:11:54.287072  4668 solver.cpp:244]     Train net output #1: loss = 12851.5 (* 1 = 12851.5 loss)
I0908 18:11:54.287080  4668 sgd_solver.cpp:106] Iteration 10300, lr = 1e-07
I0908 18:13:06.547586  4668 solver.cpp:228] Iteration 10350, loss = 8470.65
I0908 18:13:06.547708  4668 solver.cpp:244]     Train net output #0: accuracy = 0.918671
I0908 18:13:06.547719  4668 solver.cpp:244]     Train net output #1: loss = 8470.64 (* 1 = 8470.64 loss)
I0908 18:13:06.547725  4668 sgd_solver.cpp:106] Iteration 10350, lr = 1e-07
I0908 18:14:17.444319  4668 solver.cpp:337] Iteration 10400, Testing net (#0)
I0908 18:14:24.541657  4668 solver.cpp:404]     Test net output #0: accuracy = 0.899777
I0908 18:14:24.541700  4668 solver.cpp:404]     Test net output #1: loss = 10155.8 (* 1 = 10155.8 loss)
I0908 18:14:25.831460  4668 solver.cpp:228] Iteration 10400, loss = 5627.32
I0908 18:14:25.831502  4668 solver.cpp:244]     Train net output #0: accuracy = 0.945032
I0908 18:14:25.831511  4668 solver.cpp:244]     Train net output #1: loss = 5627.31 (* 1 = 5627.31 loss)
I0908 18:14:25.831519  4668 sgd_solver.cpp:106] Iteration 10400, lr = 1e-07
I0908 18:15:37.875824  4668 solver.cpp:228] Iteration 10450, loss = 6369.59
I0908 18:15:37.875902  4668 solver.cpp:244]     Train net output #0: accuracy = 0.937335
I0908 18:15:37.875913  4668 solver.cpp:244]     Train net output #1: loss = 6369.58 (* 1 = 6369.58 loss)
I0908 18:15:37.875921  4668 sgd_solver.cpp:106] Iteration 10450, lr = 1e-07
I0908 18:16:50.708523  4668 solver.cpp:228] Iteration 10500, loss = 11185.2
I0908 18:16:50.708627  4668 solver.cpp:244]     Train net output #0: accuracy = 0.885208
I0908 18:16:50.708638  4668 solver.cpp:244]     Train net output #1: loss = 11185.2 (* 1 = 11185.2 loss)
I0908 18:16:50.708645  4668 sgd_solver.cpp:106] Iteration 10500, lr = 1e-07
I0908 18:18:02.909695  4668 solver.cpp:228] Iteration 10550, loss = 10694.7
I0908 18:18:02.909801  4668 solver.cpp:244]     Train net output #0: accuracy = 0.896949
I0908 18:18:02.909811  4668 solver.cpp:244]     Train net output #1: loss = 10694.7 (* 1 = 10694.7 loss)
I0908 18:18:02.909818  4668 sgd_solver.cpp:106] Iteration 10550, lr = 1e-07
I0908 18:19:13.801609  4668 solver.cpp:337] Iteration 10600, Testing net (#0)
I0908 18:19:20.648032  4668 solver.cpp:404]     Test net output #0: accuracy = 0.900434
I0908 18:19:20.648077  4668 solver.cpp:404]     Test net output #1: loss = 10097.5 (* 1 = 10097.5 loss)
I0908 18:19:21.934782  4668 solver.cpp:228] Iteration 10600, loss = 6861.82
I0908 18:19:21.934810  4668 solver.cpp:244]     Train net output #0: accuracy = 0.93167
I0908 18:19:21.934820  4668 solver.cpp:244]     Train net output #1: loss = 6861.81 (* 1 = 6861.81 loss)
I0908 18:19:21.934828  4668 sgd_solver.cpp:106] Iteration 10600, lr = 1e-07
I0908 18:20:34.070943  4668 solver.cpp:228] Iteration 10650, loss = 5492.17
I0908 18:20:34.071028  4668 solver.cpp:244]     Train net output #0: accuracy = 0.946936
I0908 18:20:34.071039  4668 solver.cpp:244]     Train net output #1: loss = 5492.16 (* 1 = 5492.16 loss)
I0908 18:20:34.071046  4668 sgd_solver.cpp:106] Iteration 10650, lr = 1e-07
I0908 18:21:47.565387  4668 solver.cpp:228] Iteration 10700, loss = 9716.46
I0908 18:21:47.565524  4668 solver.cpp:244]     Train net output #0: accuracy = 0.903369
I0908 18:21:47.565536  4668 solver.cpp:244]     Train net output #1: loss = 9716.46 (* 1 = 9716.46 loss)
I0908 18:21:47.565543  4668 sgd_solver.cpp:106] Iteration 10700, lr = 1e-07
I0908 18:22:59.696130  4668 solver.cpp:228] Iteration 10750, loss = 36.3909
I0908 18:22:59.696221  4668 solver.cpp:244]     Train net output #0: accuracy = 0.999991
I0908 18:22:59.696233  4668 solver.cpp:244]     Train net output #1: loss = 36.3851 (* 1 = 36.3851 loss)
I0908 18:22:59.696239  4668 sgd_solver.cpp:106] Iteration 10750, lr = 1e-07
I0908 18:24:12.159471  4668 solver.cpp:337] Iteration 10800, Testing net (#0)
I0908 18:24:18.998560  4668 solver.cpp:404]     Test net output #0: accuracy = 0.900279
I0908 18:24:18.998602  4668 solver.cpp:404]     Test net output #1: loss = 10123.3 (* 1 = 10123.3 loss)
I0908 18:24:20.295570  4668 solver.cpp:228] Iteration 10800, loss = 6925.17
I0908 18:24:20.295614  4668 solver.cpp:244]     Train net output #0: accuracy = 0.932156
I0908 18:24:20.295624  4668 solver.cpp:244]     Train net output #1: loss = 6925.17 (* 1 = 6925.17 loss)
I0908 18:24:20.295630  4668 sgd_solver.cpp:106] Iteration 10800, lr = 1e-07
I0908 18:25:33.001759  4668 solver.cpp:228] Iteration 10850, loss = 8766.8
I0908 18:25:33.001848  4668 solver.cpp:244]     Train net output #0: accuracy = 0.914851
I0908 18:25:33.001859  4668 solver.cpp:244]     Train net output #1: loss = 8766.79 (* 1 = 8766.79 loss)
I0908 18:25:33.001866  4668 sgd_solver.cpp:106] Iteration 10850, lr = 1e-07
I0908 18:26:46.222479  4668 solver.cpp:228] Iteration 10900, loss = 8322.63
I0908 18:26:46.222584  4668 solver.cpp:244]     Train net output #0: accuracy = 0.915717
I0908 18:26:46.222595  4668 solver.cpp:244]     Train net output #1: loss = 8322.62 (* 1 = 8322.62 loss)
I0908 18:26:46.222602  4668 sgd_solver.cpp:106] Iteration 10900, lr = 1e-07
I0908 18:28:00.441903  4668 solver.cpp:228] Iteration 10950, loss = 9480.48
I0908 18:28:00.441998  4668 solver.cpp:244]     Train net output #0: accuracy = 0.904466
I0908 18:28:00.442009  4668 solver.cpp:244]     Train net output #1: loss = 9480.47 (* 1 = 9480.47 loss)
I0908 18:28:00.442016  4668 sgd_solver.cpp:106] Iteration 10950, lr = 1e-07
I0908 18:29:11.530429  4668 solver.cpp:337] Iteration 11000, Testing net (#0)
I0908 18:29:18.422806  4668 solver.cpp:404]     Test net output #0: accuracy = 0.899017
I0908 18:29:18.422850  4668 solver.cpp:404]     Test net output #1: loss = 10219.6 (* 1 = 10219.6 loss)
I0908 18:29:19.723865  4668 solver.cpp:228] Iteration 11000, loss = 7044.82
I0908 18:29:19.723906  4668 solver.cpp:244]     Train net output #0: accuracy = 0.932581
I0908 18:29:19.723917  4668 solver.cpp:244]     Train net output #1: loss = 7044.81 (* 1 = 7044.81 loss)
I0908 18:29:19.723923  4668 sgd_solver.cpp:106] Iteration 11000, lr = 1e-07
I0908 18:30:32.057922  4668 solver.cpp:228] Iteration 11050, loss = 10508.2
I0908 18:30:32.057994  4668 solver.cpp:244]     Train net output #0: accuracy = 0.896613
I0908 18:30:32.058006  4668 solver.cpp:244]     Train net output #1: loss = 10508.2 (* 1 = 10508.2 loss)
I0908 18:30:32.058012  4668 sgd_solver.cpp:106] Iteration 11050, lr = 1e-07
I0908 18:31:44.122599  4668 solver.cpp:228] Iteration 11100, loss = 11252.2
I0908 18:31:44.122676  4668 solver.cpp:244]     Train net output #0: accuracy = 0.891995
I0908 18:31:44.122689  4668 solver.cpp:244]     Train net output #1: loss = 11252.2 (* 1 = 11252.2 loss)
I0908 18:31:44.122695  4668 sgd_solver.cpp:106] Iteration 11100, lr = 1e-07
I0908 18:32:56.223155  4668 solver.cpp:228] Iteration 11150, loss = 8451.59
I0908 18:32:56.223245  4668 solver.cpp:244]     Train net output #0: accuracy = 0.917723
I0908 18:32:56.223258  4668 solver.cpp:244]     Train net output #1: loss = 8451.58 (* 1 = 8451.58 loss)
I0908 18:32:56.223264  4668 sgd_solver.cpp:106] Iteration 11150, lr = 1e-07
I0908 18:34:08.632052  4668 solver.cpp:337] Iteration 11200, Testing net (#0)
I0908 18:34:15.482192  4668 solver.cpp:404]     Test net output #0: accuracy = 0.899423
I0908 18:34:15.482236  4668 solver.cpp:404]     Test net output #1: loss = 10195.1 (* 1 = 10195.1 loss)
I0908 18:34:16.776978  4668 solver.cpp:228] Iteration 11200, loss = 5707.6
I0908 18:34:16.777024  4668 solver.cpp:244]     Train net output #0: accuracy = 0.944691
I0908 18:34:16.777034  4668 solver.cpp:244]     Train net output #1: loss = 5707.6 (* 1 = 5707.6 loss)
I0908 18:34:16.777040  4668 sgd_solver.cpp:106] Iteration 11200, lr = 1e-07
I0908 18:35:29.323408  4668 solver.cpp:228] Iteration 11250, loss = 6376.26
I0908 18:35:29.323516  4668 solver.cpp:244]     Train net output #0: accuracy = 0.93833
I0908 18:35:29.323529  4668 solver.cpp:244]     Train net output #1: loss = 6376.26 (* 1 = 6376.26 loss)
I0908 18:35:29.323535  4668 sgd_solver.cpp:106] Iteration 11250, lr = 1e-07
I0908 18:36:42.656878  4668 solver.cpp:228] Iteration 11300, loss = 10348.3
I0908 18:36:42.656972  4668 solver.cpp:244]     Train net output #0: accuracy = 0.894984
I0908 18:36:42.656983  4668 solver.cpp:244]     Train net output #1: loss = 10348.3 (* 1 = 10348.3 loss)
I0908 18:36:42.656991  4668 sgd_solver.cpp:106] Iteration 11300, lr = 1e-07
I0908 18:37:56.268134  4668 solver.cpp:228] Iteration 11350, loss = 6179.49
I0908 18:37:56.268229  4668 solver.cpp:244]     Train net output #0: accuracy = 0.941617
I0908 18:37:56.268240  4668 solver.cpp:244]     Train net output #1: loss = 6179.49 (* 1 = 6179.49 loss)
I0908 18:37:56.268247  4668 sgd_solver.cpp:106] Iteration 11350, lr = 1e-07
I0908 18:39:07.171221  4668 solver.cpp:337] Iteration 11400, Testing net (#0)
I0908 18:39:14.018543  4668 solver.cpp:404]     Test net output #0: accuracy = 0.900519
I0908 18:39:14.018584  4668 solver.cpp:404]     Test net output #1: loss = 10090.7 (* 1 = 10090.7 loss)
I0908 18:39:15.306948  4668 solver.cpp:228] Iteration 11400, loss = 7071.1
I0908 18:39:15.306989  4668 solver.cpp:244]     Train net output #0: accuracy = 0.931549
I0908 18:39:15.306999  4668 solver.cpp:244]     Train net output #1: loss = 7071.09 (* 1 = 7071.09 loss)
I0908 18:39:15.307006  4668 sgd_solver.cpp:106] Iteration 11400, lr = 1e-07
I0908 18:40:27.496898  4668 solver.cpp:228] Iteration 11450, loss = 6116.47
I0908 18:40:27.496990  4668 solver.cpp:244]     Train net output #0: accuracy = 0.942221
I0908 18:40:27.497001  4668 solver.cpp:244]     Train net output #1: loss = 6116.47 (* 1 = 6116.47 loss)
I0908 18:40:27.497009  4668 sgd_solver.cpp:106] Iteration 11450, lr = 1e-07
I0908 18:41:41.124125  4668 solver.cpp:228] Iteration 11500, loss = 9610
I0908 18:41:41.124202  4668 solver.cpp:244]     Train net output #0: accuracy = 0.902993
I0908 18:41:41.124212  4668 solver.cpp:244]     Train net output #1: loss = 9610 (* 1 = 9610 loss)
I0908 18:41:41.124219  4668 sgd_solver.cpp:106] Iteration 11500, lr = 1e-07
I0908 18:42:55.504804  4668 solver.cpp:228] Iteration 11550, loss = 51.8177
I0908 18:42:55.504906  4668 solver.cpp:244]     Train net output #0: accuracy = 0.999962
I0908 18:42:55.504917  4668 solver.cpp:244]     Train net output #1: loss = 51.8139 (* 1 = 51.8139 loss)
I0908 18:42:55.504925  4668 sgd_solver.cpp:106] Iteration 11550, lr = 1e-07
I0908 18:44:07.108296  4668 solver.cpp:337] Iteration 11600, Testing net (#0)
I0908 18:44:14.396944  4668 solver.cpp:404]     Test net output #0: accuracy = 0.899404
I0908 18:44:14.396984  4668 solver.cpp:404]     Test net output #1: loss = 10191.3 (* 1 = 10191.3 loss)
I0908 18:44:16.148180  4668 solver.cpp:228] Iteration 11600, loss = 6251.47
I0908 18:44:16.148223  4668 solver.cpp:244]     Train net output #0: accuracy = 0.938489
I0908 18:44:16.148233  4668 solver.cpp:244]     Train net output #1: loss = 6251.47 (* 1 = 6251.47 loss)
I0908 18:44:16.148241  4668 sgd_solver.cpp:106] Iteration 11600, lr = 1e-07
I0908 18:45:28.213364  4668 solver.cpp:228] Iteration 11650, loss = 12012.4
I0908 18:45:28.213446  4668 solver.cpp:244]     Train net output #0: accuracy = 0.885138
I0908 18:45:28.213459  4668 solver.cpp:244]     Train net output #1: loss = 12012.4 (* 1 = 12012.4 loss)
I0908 18:45:28.213477  4668 sgd_solver.cpp:106] Iteration 11650, lr = 1e-07
I0908 18:46:40.289486  4668 solver.cpp:228] Iteration 11700, loss = 8727.37
I0908 18:46:40.289598  4668 solver.cpp:244]     Train net output #0: accuracy = 0.915969
I0908 18:46:40.289611  4668 solver.cpp:244]     Train net output #1: loss = 8727.36 (* 1 = 8727.36 loss)
I0908 18:46:40.289618  4668 sgd_solver.cpp:106] Iteration 11700, lr = 1e-07
I0908 18:47:52.426892  4668 solver.cpp:228] Iteration 11750, loss = 9963.23
I0908 18:47:52.426990  4668 solver.cpp:244]     Train net output #0: accuracy = 0.900915
I0908 18:47:52.427001  4668 solver.cpp:244]     Train net output #1: loss = 9963.23 (* 1 = 9963.23 loss)
I0908 18:47:52.427008  4668 sgd_solver.cpp:106] Iteration 11750, lr = 1e-07
I0908 18:49:04.330435  4668 solver.cpp:337] Iteration 11800, Testing net (#0)
I0908 18:49:11.180141  4668 solver.cpp:404]     Test net output #0: accuracy = 0.89881
I0908 18:49:11.180183  4668 solver.cpp:404]     Test net output #1: loss = 10245.9 (* 1 = 10245.9 loss)
I0908 18:49:12.468101  4668 solver.cpp:228] Iteration 11800, loss = 6257.73
I0908 18:49:12.468142  4668 solver.cpp:244]     Train net output #0: accuracy = 0.940836
I0908 18:49:12.468152  4668 solver.cpp:244]     Train net output #1: loss = 6257.73 (* 1 = 6257.73 loss)
I0908 18:49:12.468158  4668 sgd_solver.cpp:106] Iteration 11800, lr = 1e-07
I0908 18:50:24.644815  4668 solver.cpp:228] Iteration 11850, loss = 12187
I0908 18:50:24.644930  4668 solver.cpp:244]     Train net output #0: accuracy = 0.88004
I0908 18:50:24.644942  4668 solver.cpp:244]     Train net output #1: loss = 12187 (* 1 = 12187 loss)
I0908 18:50:24.644948  4668 sgd_solver.cpp:106] Iteration 11850, lr = 1e-07
I0908 18:51:38.414763  4668 solver.cpp:228] Iteration 11900, loss = 12539
I0908 18:51:38.414854  4668 solver.cpp:244]     Train net output #0: accuracy = 0.880485
I0908 18:51:38.414865  4668 solver.cpp:244]     Train net output #1: loss = 12539 (* 1 = 12539 loss)
I0908 18:51:38.414872  4668 sgd_solver.cpp:106] Iteration 11900, lr = 1e-07
I0908 18:52:50.494441  4668 solver.cpp:228] Iteration 11950, loss = 7297.56
I0908 18:52:50.494525  4668 solver.cpp:244]     Train net output #0: accuracy = 0.92926
I0908 18:52:50.494537  4668 solver.cpp:244]     Train net output #1: loss = 7297.55 (* 1 = 7297.55 loss)
I0908 18:52:50.494544  4668 sgd_solver.cpp:106] Iteration 11950, lr = 1e-07
I0908 18:54:01.649098  4668 solver.cpp:454] Snapshotting to binary proto file portrait_wfm_one_stage_iter_12000.caffemodel
I0908 18:54:01.651757  4668 sgd_solver.cpp:273] Snapshotting solver state to binary proto file portrait_wfm_one_stage_iter_12000.solverstate
I0908 18:54:01.652768  4668 solver.cpp:337] Iteration 12000, Testing net (#0)
I0908 18:54:08.516577  4668 solver.cpp:404]     Test net output #0: accuracy = 0.899631
I0908 18:54:08.516620  4668 solver.cpp:404]     Test net output #1: loss = 10165.8 (* 1 = 10165.8 loss)
I0908 18:54:09.804997  4668 solver.cpp:228] Iteration 12000, loss = 5817.07
I0908 18:54:09.805045  4668 solver.cpp:244]     Train net output #0: accuracy = 0.943432
I0908 18:54:09.806584  4668 solver.cpp:244]     Train net output #1: loss = 5817.06 (* 1 = 5817.06 loss)
I0908 18:54:09.806599  4668 sgd_solver.cpp:106] Iteration 12000, lr = 1e-08
I0908 18:55:23.356312  4668 solver.cpp:228] Iteration 12050, loss = 5634.6
I0908 18:55:23.356381  4668 solver.cpp:244]     Train net output #0: accuracy = 0.944618
I0908 18:55:23.356392  4668 solver.cpp:244]     Train net output #1: loss = 5634.59 (* 1 = 5634.59 loss)
I0908 18:55:23.356400  4668 sgd_solver.cpp:106] Iteration 12050, lr = 1e-08
I0908 18:56:36.053731  4668 solver.cpp:228] Iteration 12100, loss = 11900
I0908 18:56:36.053818  4668 solver.cpp:244]     Train net output #0: accuracy = 0.882074
I0908 18:56:36.053829  4668 solver.cpp:244]     Train net output #1: loss = 11900 (* 1 = 11900 loss)
I0908 18:56:36.053838  4668 sgd_solver.cpp:106] Iteration 12100, lr = 1e-08
I0908 18:57:49.377511  4668 solver.cpp:228] Iteration 12150, loss = 6184.23
I0908 18:57:49.377622  4668 solver.cpp:244]     Train net output #0: accuracy = 0.93823
I0908 18:57:49.377640  4668 solver.cpp:244]     Train net output #1: loss = 6184.23 (* 1 = 6184.23 loss)
I0908 18:57:49.377646  4668 sgd_solver.cpp:106] Iteration 12150, lr = 1e-08
I0908 18:59:00.310137  4668 solver.cpp:337] Iteration 12200, Testing net (#0)
I0908 18:59:07.147732  4668 solver.cpp:404]     Test net output #0: accuracy = 0.900584
I0908 18:59:07.147778  4668 solver.cpp:404]     Test net output #1: loss = 10079.6 (* 1 = 10079.6 loss)
I0908 18:59:08.433243  4668 solver.cpp:228] Iteration 12200, loss = 7240
I0908 18:59:08.433279  4668 solver.cpp:244]     Train net output #0: accuracy = 0.928562
I0908 18:59:08.433289  4668 solver.cpp:244]     Train net output #1: loss = 7239.99 (* 1 = 7239.99 loss)
I0908 18:59:08.433296  4668 sgd_solver.cpp:106] Iteration 12200, lr = 1e-08
I0908 19:00:20.498775  4668 solver.cpp:228] Iteration 12250, loss = 8503.38
I0908 19:00:20.498863  4668 solver.cpp:244]     Train net output #0: accuracy = 0.918256
I0908 19:00:20.498874  4668 solver.cpp:244]     Train net output #1: loss = 8503.38 (* 1 = 8503.38 loss)
I0908 19:00:20.498883  4668 sgd_solver.cpp:106] Iteration 12250, lr = 1e-08
I0908 19:01:34.975586  4668 solver.cpp:228] Iteration 12300, loss = 8935.2
I0908 19:01:34.975703  4668 solver.cpp:244]     Train net output #0: accuracy = 0.910582
I0908 19:01:34.975721  4668 solver.cpp:244]     Train net output #1: loss = 8935.2 (* 1 = 8935.2 loss)
I0908 19:01:34.975734  4668 sgd_solver.cpp:106] Iteration 12300, lr = 1e-08
I0908 19:02:47.445597  4668 solver.cpp:228] Iteration 12350, loss = 59.3639
I0908 19:02:47.445688  4668 solver.cpp:244]     Train net output #0: accuracy = 0.999911
I0908 19:02:47.445699  4668 solver.cpp:244]     Train net output #1: loss = 59.36 (* 1 = 59.36 loss)
I0908 19:02:47.445708  4668 sgd_solver.cpp:106] Iteration 12350, lr = 1e-08
I0908 19:03:59.173259  4668 solver.cpp:337] Iteration 12400, Testing net (#0)
I0908 19:04:06.024241  4668 solver.cpp:404]     Test net output #0: accuracy = 0.900923
I0908 19:04:06.024292  4668 solver.cpp:404]     Test net output #1: loss = 10058 (* 1 = 10058 loss)
I0908 19:04:07.315891  4668 solver.cpp:228] Iteration 12400, loss = 6014.23
I0908 19:04:07.315932  4668 solver.cpp:244]     Train net output #0: accuracy = 0.941663
I0908 19:04:07.315942  4668 solver.cpp:244]     Train net output #1: loss = 6014.22 (* 1 = 6014.22 loss)
I0908 19:04:07.315950  4668 sgd_solver.cpp:106] Iteration 12400, lr = 1e-08
I0908 19:05:19.363478  4668 solver.cpp:228] Iteration 12450, loss = 12389.4
I0908 19:05:19.363577  4668 solver.cpp:244]     Train net output #0: accuracy = 0.878963
I0908 19:05:19.363590  4668 solver.cpp:244]     Train net output #1: loss = 12389.4 (* 1 = 12389.4 loss)
I0908 19:05:19.363597  4668 sgd_solver.cpp:106] Iteration 12450, lr = 1e-08
I0908 19:06:31.601706  4668 solver.cpp:228] Iteration 12500, loss = 8839.04
I0908 19:06:31.601765  4668 solver.cpp:244]     Train net output #0: accuracy = 0.914058
I0908 19:06:31.601776  4668 solver.cpp:244]     Train net output #1: loss = 8839.04 (* 1 = 8839.04 loss)
I0908 19:06:31.601784  4668 sgd_solver.cpp:106] Iteration 12500, lr = 1e-08
I0908 19:07:44.739675  4668 solver.cpp:228] Iteration 12550, loss = 9491.83
I0908 19:07:44.739753  4668 solver.cpp:244]     Train net output #0: accuracy = 0.907665
I0908 19:07:44.739764  4668 solver.cpp:244]     Train net output #1: loss = 9491.83 (* 1 = 9491.83 loss)
I0908 19:07:44.739773  4668 sgd_solver.cpp:106] Iteration 12550, lr = 1e-08
I0908 19:08:56.167726  4668 solver.cpp:337] Iteration 12600, Testing net (#0)
I0908 19:09:03.149786  4668 solver.cpp:404]     Test net output #0: accuracy = 0.899638
I0908 19:09:03.149821  4668 solver.cpp:404]     Test net output #1: loss = 10169 (* 1 = 10169 loss)
I0908 19:09:04.460541  4668 solver.cpp:228] Iteration 12600, loss = 6052.06
I0908 19:09:04.460582  4668 solver.cpp:244]     Train net output #0: accuracy = 0.940735
I0908 19:09:04.460592  4668 solver.cpp:244]     Train net output #1: loss = 6052.06 (* 1 = 6052.06 loss)
I0908 19:09:04.460599  4668 sgd_solver.cpp:106] Iteration 12600, lr = 1e-08
I0908 19:10:18.579782  4668 solver.cpp:228] Iteration 12650, loss = 11065.6
I0908 19:10:18.579880  4668 solver.cpp:244]     Train net output #0: accuracy = 0.890247
I0908 19:10:18.579892  4668 solver.cpp:244]     Train net output #1: loss = 11065.6 (* 1 = 11065.6 loss)
I0908 19:10:18.579900  4668 sgd_solver.cpp:106] Iteration 12650, lr = 1e-08
I0908 19:11:32.884642  4668 solver.cpp:228] Iteration 12700, loss = 10896.7
I0908 19:11:32.884732  4668 solver.cpp:244]     Train net output #0: accuracy = 0.891398
I0908 19:11:32.884742  4668 solver.cpp:244]     Train net output #1: loss = 10896.7 (* 1 = 10896.7 loss)
I0908 19:11:32.884749  4668 sgd_solver.cpp:106] Iteration 12700, lr = 1e-08
I0908 19:12:45.708293  4668 solver.cpp:228] Iteration 12750, loss = 6937.07
I0908 19:12:45.708374  4668 solver.cpp:244]     Train net output #0: accuracy = 0.933194
I0908 19:12:45.708386  4668 solver.cpp:244]     Train net output #1: loss = 6937.07 (* 1 = 6937.07 loss)
I0908 19:12:45.708394  4668 sgd_solver.cpp:106] Iteration 12750, lr = 1e-08
I0908 19:13:56.639727  4668 solver.cpp:337] Iteration 12800, Testing net (#0)
I0908 19:14:03.484896  4668 solver.cpp:404]     Test net output #0: accuracy = 0.89967
I0908 19:14:03.484936  4668 solver.cpp:404]     Test net output #1: loss = 10167.2 (* 1 = 10167.2 loss)
I0908 19:14:04.770526  4668 solver.cpp:228] Iteration 12800, loss = 5998.67
I0908 19:14:04.770563  4668 solver.cpp:244]     Train net output #0: accuracy = 0.943002
I0908 19:14:04.770572  4668 solver.cpp:244]     Train net output #1: loss = 5998.67 (* 1 = 5998.67 loss)
I0908 19:14:04.770581  4668 sgd_solver.cpp:106] Iteration 12800, lr = 1e-08
I0908 19:15:17.353642  4668 solver.cpp:228] Iteration 12850, loss = 7308.09
I0908 19:15:17.353734  4668 solver.cpp:244]     Train net output #0: accuracy = 0.92805
I0908 19:15:17.353747  4668 solver.cpp:244]     Train net output #1: loss = 7308.09 (* 1 = 7308.09 loss)
I0908 19:15:17.353755  4668 sgd_solver.cpp:106] Iteration 12850, lr = 1e-08
I0908 19:16:32.002377  4668 solver.cpp:228] Iteration 12900, loss = 49.9629
I0908 19:16:32.002475  4668 solver.cpp:244]     Train net output #0: accuracy = 0.999953
I0908 19:16:32.002485  4668 solver.cpp:244]     Train net output #1: loss = 49.9588 (* 1 = 49.9588 loss)
I0908 19:16:32.002492  4668 sgd_solver.cpp:106] Iteration 12900, lr = 1e-08
I0908 19:17:46.115401  4668 solver.cpp:228] Iteration 12950, loss = 6015.66
I0908 19:17:46.115486  4668 solver.cpp:244]     Train net output #0: accuracy = 0.94097
I0908 19:17:46.115499  4668 solver.cpp:244]     Train net output #1: loss = 6015.65 (* 1 = 6015.65 loss)
I0908 19:17:46.115505  4668 sgd_solver.cpp:106] Iteration 12950, lr = 1e-08
I0908 19:18:57.775002  4668 solver.cpp:337] Iteration 13000, Testing net (#0)
I0908 19:19:04.625438  4668 solver.cpp:404]     Test net output #0: accuracy = 0.899635
I0908 19:19:04.625481  4668 solver.cpp:404]     Test net output #1: loss = 10195.3 (* 1 = 10195.3 loss)
I0908 19:19:05.913933  4668 solver.cpp:228] Iteration 13000, loss = 7726.8
I0908 19:19:05.913967  4668 solver.cpp:244]     Train net output #0: accuracy = 0.924285
I0908 19:19:05.913976  4668 solver.cpp:244]     Train net output #1: loss = 7726.8 (* 1 = 7726.8 loss)
I0908 19:19:05.913985  4668 sgd_solver.cpp:106] Iteration 13000, lr = 1e-08
I0908 19:20:18.712749  4668 solver.cpp:228] Iteration 13050, loss = 8698.95
I0908 19:20:18.712858  4668 solver.cpp:244]     Train net output #0: accuracy = 0.915264
I0908 19:20:18.712872  4668 solver.cpp:244]     Train net output #1: loss = 8698.94 (* 1 = 8698.94 loss)
I0908 19:20:18.712878  4668 sgd_solver.cpp:106] Iteration 13050, lr = 1e-08
I0908 19:21:30.988050  4668 solver.cpp:228] Iteration 13100, loss = 9356.87
I0908 19:21:30.988154  4668 solver.cpp:244]     Train net output #0: accuracy = 0.907799
I0908 19:21:30.988167  4668 solver.cpp:244]     Train net output #1: loss = 9356.87 (* 1 = 9356.87 loss)
I0908 19:21:30.988174  4668 sgd_solver.cpp:106] Iteration 13100, lr = 1e-08
I0908 19:22:44.059181  4668 solver.cpp:228] Iteration 13150, loss = 1674.15
I0908 19:22:44.059303  4668 solver.cpp:244]     Train net output #0: accuracy = 0.989288
I0908 19:22:44.059315  4668 solver.cpp:244]     Train net output #1: loss = 1674.14 (* 1 = 1674.14 loss)
I0908 19:22:44.059322  4668 sgd_solver.cpp:106] Iteration 13150, lr = 1e-08
I0908 19:23:55.073443  4668 solver.cpp:337] Iteration 13200, Testing net (#0)
I0908 19:24:03.214823  4668 solver.cpp:404]     Test net output #0: accuracy = 0.89911
I0908 19:24:03.214866  4668 solver.cpp:404]     Test net output #1: loss = 10223.1 (* 1 = 10223.1 loss)
I0908 19:24:04.557828  4668 solver.cpp:228] Iteration 13200, loss = 10365.4
I0908 19:24:04.557871  4668 solver.cpp:244]     Train net output #0: accuracy = 0.897008
I0908 19:24:04.557880  4668 solver.cpp:244]     Train net output #1: loss = 10365.4 (* 1 = 10365.4 loss)
I0908 19:24:04.557888  4668 sgd_solver.cpp:106] Iteration 13200, lr = 1e-08
I0908 19:25:16.726073  4668 solver.cpp:228] Iteration 13250, loss = 13117.6
I0908 19:25:16.726153  4668 solver.cpp:244]     Train net output #0: accuracy = 0.875935
I0908 19:25:16.726164  4668 solver.cpp:244]     Train net output #1: loss = 13117.6 (* 1 = 13117.6 loss)
I0908 19:25:16.726172  4668 sgd_solver.cpp:106] Iteration 13250, lr = 1e-08
I0908 19:26:28.787457  4668 solver.cpp:228] Iteration 13300, loss = 8617.24
I0908 19:26:28.787554  4668 solver.cpp:244]     Train net output #0: accuracy = 0.916526
I0908 19:26:28.787565  4668 solver.cpp:244]     Train net output #1: loss = 8617.24 (* 1 = 8617.24 loss)
I0908 19:26:28.787573  4668 sgd_solver.cpp:106] Iteration 13300, lr = 1e-08
I0908 19:27:41.871954  4668 solver.cpp:228] Iteration 13350, loss = 5419.48
I0908 19:27:41.872047  4668 solver.cpp:244]     Train net output #0: accuracy = 0.946973
I0908 19:27:41.872058  4668 solver.cpp:244]     Train net output #1: loss = 5419.48 (* 1 = 5419.48 loss)
I0908 19:27:41.872066  4668 sgd_solver.cpp:106] Iteration 13350, lr = 1e-08
I0908 19:28:52.721653  4668 solver.cpp:337] Iteration 13400, Testing net (#0)
I0908 19:28:59.570858  4668 solver.cpp:404]     Test net output #0: accuracy = 0.898593
I0908 19:28:59.570900  4668 solver.cpp:404]     Test net output #1: loss = 10260.2 (* 1 = 10260.2 loss)
I0908 19:29:00.861872  4668 solver.cpp:228] Iteration 13400, loss = 6568.09
I0908 19:29:00.861908  4668 solver.cpp:244]     Train net output #0: accuracy = 0.934942
I0908 19:29:00.861917  4668 solver.cpp:244]     Train net output #1: loss = 6568.09 (* 1 = 6568.09 loss)
I0908 19:29:00.861925  4668 sgd_solver.cpp:106] Iteration 13400, lr = 1e-08
I0908 19:30:13.759789  4668 solver.cpp:228] Iteration 13450, loss = 11249.7
I0908 19:30:13.759886  4668 solver.cpp:244]     Train net output #0: accuracy = 0.886016
I0908 19:30:13.759897  4668 solver.cpp:244]     Train net output #1: loss = 11249.7 (* 1 = 11249.7 loss)
I0908 19:30:13.759904  4668 sgd_solver.cpp:106] Iteration 13450, lr = 1e-08
I0908 19:31:27.307991  4668 solver.cpp:228] Iteration 13500, loss = 9584.29
I0908 19:31:27.308081  4668 solver.cpp:244]     Train net output #0: accuracy = 0.909762
I0908 19:31:27.308094  4668 solver.cpp:244]     Train net output #1: loss = 9584.29 (* 1 = 9584.29 loss)
I0908 19:31:27.308100  4668 sgd_solver.cpp:106] Iteration 13500, lr = 1e-08
I0908 19:32:40.085474  4668 solver.cpp:228] Iteration 13550, loss = 6535.26
I0908 19:32:40.085559  4668 solver.cpp:244]     Train net output #0: accuracy = 0.935602
I0908 19:32:40.085572  4668 solver.cpp:244]     Train net output #1: loss = 6535.25 (* 1 = 6535.25 loss)
I0908 19:32:40.085578  4668 sgd_solver.cpp:106] Iteration 13550, lr = 1e-08
I0908 19:33:51.149359  4668 solver.cpp:337] Iteration 13600, Testing net (#0)
I0908 19:33:57.995123  4668 solver.cpp:404]     Test net output #0: accuracy = 0.899099
I0908 19:33:57.995164  4668 solver.cpp:404]     Test net output #1: loss = 10217.2 (* 1 = 10217.2 loss)
I0908 19:33:59.282681  4668 solver.cpp:228] Iteration 13600, loss = 5680.29
I0908 19:33:59.282716  4668 solver.cpp:244]     Train net output #0: accuracy = 0.944954
I0908 19:33:59.282726  4668 solver.cpp:244]     Train net output #1: loss = 5680.29 (* 1 = 5680.29 loss)
I0908 19:33:59.282747  4668 sgd_solver.cpp:106] Iteration 13600, lr = 1e-08
I0908 19:35:11.374522  4668 solver.cpp:228] Iteration 13650, loss = 9494.75
I0908 19:35:11.374644  4668 solver.cpp:244]     Train net output #0: accuracy = 0.905572
I0908 19:35:11.374656  4668 solver.cpp:244]     Train net output #1: loss = 9494.75 (* 1 = 9494.75 loss)
I0908 19:35:11.374665  4668 sgd_solver.cpp:106] Iteration 13650, lr = 1e-08
I0908 19:36:24.447957  4668 solver.cpp:228] Iteration 13700, loss = 47.7538
I0908 19:36:24.448053  4668 solver.cpp:244]     Train net output #0: accuracy = 0.999902
I0908 19:36:24.448065  4668 solver.cpp:244]     Train net output #1: loss = 47.7499 (* 1 = 47.7499 loss)
I0908 19:36:24.448073  4668 sgd_solver.cpp:106] Iteration 13700, lr = 1e-08
I0908 19:37:36.763789  4668 solver.cpp:228] Iteration 13750, loss = 6480.22
I0908 19:37:36.763871  4668 solver.cpp:244]     Train net output #0: accuracy = 0.935936
I0908 19:37:36.763882  4668 solver.cpp:244]     Train net output #1: loss = 6480.21 (* 1 = 6480.21 loss)
I0908 19:37:36.763890  4668 sgd_solver.cpp:106] Iteration 13750, lr = 1e-08
I0908 19:38:50.216583  4668 solver.cpp:337] Iteration 13800, Testing net (#0)
I0908 19:38:57.933625  4668 solver.cpp:404]     Test net output #0: accuracy = 0.899185
I0908 19:38:57.933668  4668 solver.cpp:404]     Test net output #1: loss = 10226 (* 1 = 10226 loss)
I0908 19:38:59.224133  4668 solver.cpp:228] Iteration 13800, loss = 9697.31
I0908 19:38:59.224171  4668 solver.cpp:244]     Train net output #0: accuracy = 0.907242
I0908 19:38:59.224180  4668 solver.cpp:244]     Train net output #1: loss = 9697.3 (* 1 = 9697.3 loss)
I0908 19:38:59.224189  4668 sgd_solver.cpp:106] Iteration 13800, lr = 1e-08
I0908 19:40:12.427822  4668 solver.cpp:228] Iteration 13850, loss = 8177.95
I0908 19:40:12.427937  4668 solver.cpp:244]     Train net output #0: accuracy = 0.918297
I0908 19:40:12.427949  4668 solver.cpp:244]     Train net output #1: loss = 8177.95 (* 1 = 8177.95 loss)
I0908 19:40:12.427958  4668 sgd_solver.cpp:106] Iteration 13850, lr = 1e-08
I0908 19:41:25.533087  4668 solver.cpp:228] Iteration 13900, loss = 9470.55
I0908 19:41:25.533166  4668 solver.cpp:244]     Train net output #0: accuracy = 0.907249
I0908 19:41:25.533179  4668 solver.cpp:244]     Train net output #1: loss = 9470.54 (* 1 = 9470.54 loss)
I0908 19:41:25.533186  4668 sgd_solver.cpp:106] Iteration 13900, lr = 1e-08
I0908 19:42:38.216876  4668 solver.cpp:228] Iteration 13950, loss = 6245.17
I0908 19:42:38.216971  4668 solver.cpp:244]     Train net output #0: accuracy = 0.940826
I0908 19:42:38.216982  4668 solver.cpp:244]     Train net output #1: loss = 6245.17 (* 1 = 6245.17 loss)
I0908 19:42:38.216990  4668 sgd_solver.cpp:106] Iteration 13950, lr = 1e-08
I0908 19:43:50.299096  4668 solver.cpp:337] Iteration 14000, Testing net (#0)
I0908 19:43:57.204218  4668 solver.cpp:404]     Test net output #0: accuracy = 0.900043
I0908 19:43:57.204263  4668 solver.cpp:404]     Test net output #1: loss = 10136.6 (* 1 = 10136.6 loss)
I0908 19:43:58.502660  4668 solver.cpp:228] Iteration 14000, loss = 10439.3
I0908 19:43:58.502691  4668 solver.cpp:244]     Train net output #0: accuracy = 0.895294
I0908 19:43:58.502701  4668 solver.cpp:244]     Train net output #1: loss = 10439.3 (* 1 = 10439.3 loss)
I0908 19:43:58.502708  4668 sgd_solver.cpp:106] Iteration 14000, lr = 1e-08
I0908 19:45:11.366566  4668 solver.cpp:228] Iteration 14050, loss = 11461.9
I0908 19:45:11.366664  4668 solver.cpp:244]     Train net output #0: accuracy = 0.890115
I0908 19:45:11.366675  4668 solver.cpp:244]     Train net output #1: loss = 11461.9 (* 1 = 11461.9 loss)
I0908 19:45:11.366683  4668 sgd_solver.cpp:106] Iteration 14050, lr = 1e-08
I0908 19:46:23.953102  4668 solver.cpp:228] Iteration 14100, loss = 8275.46
I0908 19:46:23.953199  4668 solver.cpp:244]     Train net output #0: accuracy = 0.918926
I0908 19:46:23.953212  4668 solver.cpp:244]     Train net output #1: loss = 8275.46 (* 1 = 8275.46 loss)
I0908 19:46:23.953219  4668 sgd_solver.cpp:106] Iteration 14100, lr = 1e-08
I0908 19:47:36.053617  4668 solver.cpp:228] Iteration 14150, loss = 5721.2
I0908 19:47:36.053752  4668 solver.cpp:244]     Train net output #0: accuracy = 0.945327
I0908 19:47:36.053766  4668 solver.cpp:244]     Train net output #1: loss = 5721.2 (* 1 = 5721.2 loss)
I0908 19:47:36.053773  4668 sgd_solver.cpp:106] Iteration 14150, lr = 1e-08
I0908 19:48:46.952008  4668 solver.cpp:337] Iteration 14200, Testing net (#0)
I0908 19:48:53.804240  4668 solver.cpp:404]     Test net output #0: accuracy = 0.899826
I0908 19:48:53.804288  4668 solver.cpp:404]     Test net output #1: loss = 10150.3 (* 1 = 10150.3 loss)
I0908 19:48:55.098901  4668 solver.cpp:228] Iteration 14200, loss = 5891.34
I0908 19:48:55.098942  4668 solver.cpp:244]     Train net output #0: accuracy = 0.942408
I0908 19:48:55.098953  4668 solver.cpp:244]     Train net output #1: loss = 5891.33 (* 1 = 5891.33 loss)
I0908 19:48:55.098960  4668 sgd_solver.cpp:106] Iteration 14200, lr = 1e-08
I0908 19:50:09.217871  4668 solver.cpp:228] Iteration 14250, loss = 10578.3
I0908 19:50:09.217941  4668 solver.cpp:244]     Train net output #0: accuracy = 0.891963
I0908 19:50:09.217952  4668 solver.cpp:244]     Train net output #1: loss = 10578.3 (* 1 = 10578.3 loss)
I0908 19:50:09.217960  4668 sgd_solver.cpp:106] Iteration 14250, lr = 1e-08
I0908 19:51:21.867302  4668 solver.cpp:228] Iteration 14300, loss = 6533.17
I0908 19:51:21.867406  4668 solver.cpp:244]     Train net output #0: accuracy = 0.936292
I0908 19:51:21.867419  4668 solver.cpp:244]     Train net output #1: loss = 6533.17 (* 1 = 6533.17 loss)
I0908 19:51:21.867427  4668 sgd_solver.cpp:106] Iteration 14300, lr = 1e-08
I0908 19:52:36.022837  4668 solver.cpp:228] Iteration 14350, loss = 7135.59
I0908 19:52:36.022913  4668 solver.cpp:244]     Train net output #0: accuracy = 0.931302
I0908 19:52:36.022925  4668 solver.cpp:244]     Train net output #1: loss = 7135.59 (* 1 = 7135.59 loss)
I0908 19:52:36.022933  4668 sgd_solver.cpp:106] Iteration 14350, lr = 1e-08
I0908 19:53:47.697196  4668 solver.cpp:337] Iteration 14400, Testing net (#0)
I0908 19:53:54.550051  4668 solver.cpp:404]     Test net output #0: accuracy = 0.89984
I0908 19:53:54.550094  4668 solver.cpp:404]     Test net output #1: loss = 10149.7 (* 1 = 10149.7 loss)
I0908 19:53:55.837080  4668 solver.cpp:228] Iteration 14400, loss = 5768.08
I0908 19:53:55.837118  4668 solver.cpp:244]     Train net output #0: accuracy = 0.94505
I0908 19:53:55.837128  4668 solver.cpp:244]     Train net output #1: loss = 5768.08 (* 1 = 5768.08 loss)
I0908 19:53:55.837136  4668 sgd_solver.cpp:106] Iteration 14400, lr = 1e-08
I0908 19:55:12.819771  4668 solver.cpp:228] Iteration 14450, loss = 9375.54
I0908 19:55:12.819854  4668 solver.cpp:244]     Train net output #0: accuracy = 0.906829
I0908 19:55:12.819865  4668 solver.cpp:244]     Train net output #1: loss = 9375.54 (* 1 = 9375.54 loss)
I0908 19:55:12.819874  4668 sgd_solver.cpp:106] Iteration 14450, lr = 1e-08
I0908 19:56:26.276024  4668 solver.cpp:228] Iteration 14500, loss = 52.8863
I0908 19:56:26.276100  4668 solver.cpp:244]     Train net output #0: accuracy = 0.999994
I0908 19:56:26.276111  4668 solver.cpp:244]     Train net output #1: loss = 52.8845 (* 1 = 52.8845 loss)
I0908 19:56:26.276119  4668 sgd_solver.cpp:106] Iteration 14500, lr = 1e-08
I0908 19:57:39.066182  4668 solver.cpp:228] Iteration 14550, loss = 6328.45
I0908 19:57:39.066279  4668 solver.cpp:244]     Train net output #0: accuracy = 0.93921
I0908 19:57:39.066292  4668 solver.cpp:244]     Train net output #1: loss = 6328.44 (* 1 = 6328.44 loss)
I0908 19:57:39.066299  4668 sgd_solver.cpp:106] Iteration 14550, lr = 1e-08
I0908 19:58:49.929610  4668 solver.cpp:337] Iteration 14600, Testing net (#0)
I0908 19:58:56.781035  4668 solver.cpp:404]     Test net output #0: accuracy = 0.900228
I0908 19:58:56.781080  4668 solver.cpp:404]     Test net output #1: loss = 10130.7 (* 1 = 10130.7 loss)
I0908 19:58:58.076972  4668 solver.cpp:228] Iteration 14600, loss = 11250.2
I0908 19:58:58.077013  4668 solver.cpp:244]     Train net output #0: accuracy = 0.890741
I0908 19:58:58.077034  4668 solver.cpp:244]     Train net output #1: loss = 11250.2 (* 1 = 11250.2 loss)
I0908 19:58:58.077042  4668 sgd_solver.cpp:106] Iteration 14600, lr = 1e-08
I0908 20:00:11.246881  4668 solver.cpp:228] Iteration 14650, loss = 9889.73
I0908 20:00:11.247000  4668 solver.cpp:244]     Train net output #0: accuracy = 0.909729
I0908 20:00:11.247014  4668 solver.cpp:244]     Train net output #1: loss = 9889.73 (* 1 = 9889.73 loss)
I0908 20:00:11.247020  4668 sgd_solver.cpp:106] Iteration 14650, lr = 1e-08
I0908 20:01:24.240279  4668 solver.cpp:228] Iteration 14700, loss = 9743.36
I0908 20:01:24.240384  4668 solver.cpp:244]     Train net output #0: accuracy = 0.902599
I0908 20:01:24.240396  4668 solver.cpp:244]     Train net output #1: loss = 9743.36 (* 1 = 9743.36 loss)
I0908 20:01:24.240404  4668 sgd_solver.cpp:106] Iteration 14700, lr = 1e-08
I0908 20:02:36.780699  4668 solver.cpp:228] Iteration 14750, loss = 6250.92
I0908 20:02:36.780781  4668 solver.cpp:244]     Train net output #0: accuracy = 0.939852
I0908 20:02:36.780792  4668 solver.cpp:244]     Train net output #1: loss = 6250.92 (* 1 = 6250.92 loss)
I0908 20:02:36.780800  4668 sgd_solver.cpp:106] Iteration 14750, lr = 1e-08
I0908 20:03:49.017940  4668 solver.cpp:337] Iteration 14800, Testing net (#0)
I0908 20:03:55.870033  4668 solver.cpp:404]     Test net output #0: accuracy = 0.900533
I0908 20:03:55.870074  4668 solver.cpp:404]     Test net output #1: loss = 10086.5 (* 1 = 10086.5 loss)
I0908 20:03:57.167495  4668 solver.cpp:228] Iteration 14800, loss = 11948.7
I0908 20:03:57.167538  4668 solver.cpp:244]     Train net output #0: accuracy = 0.880749
I0908 20:03:57.167548  4668 solver.cpp:244]     Train net output #1: loss = 11948.7 (* 1 = 11948.7 loss)
I0908 20:03:57.167557  4668 sgd_solver.cpp:106] Iteration 14800, lr = 1e-08
I0908 20:05:10.232797  4668 solver.cpp:228] Iteration 14850, loss = 12029.6
I0908 20:05:10.232923  4668 solver.cpp:244]     Train net output #0: accuracy = 0.885713
I0908 20:05:10.232944  4668 solver.cpp:244]     Train net output #1: loss = 12029.6 (* 1 = 12029.6 loss)
I0908 20:05:10.232957  4668 sgd_solver.cpp:106] Iteration 14850, lr = 1e-08
I0908 20:06:23.047695  4668 solver.cpp:228] Iteration 14900, loss = 6890.73
I0908 20:06:23.047794  4668 solver.cpp:244]     Train net output #0: accuracy = 0.933861
I0908 20:06:23.047806  4668 solver.cpp:244]     Train net output #1: loss = 6890.73 (* 1 = 6890.73 loss)
I0908 20:06:23.047814  4668 sgd_solver.cpp:106] Iteration 14900, lr = 1e-08
I0908 20:07:36.408330  4668 solver.cpp:228] Iteration 14950, loss = 5702.38
I0908 20:07:36.408437  4668 solver.cpp:244]     Train net output #0: accuracy = 0.944247
I0908 20:07:36.408449  4668 solver.cpp:244]     Train net output #1: loss = 5702.38 (* 1 = 5702.38 loss)
I0908 20:07:36.408457  4668 sgd_solver.cpp:106] Iteration 14950, lr = 1e-08
I0908 20:08:48.630441  4668 solver.cpp:337] Iteration 15000, Testing net (#0)
I0908 20:08:55.491381  4668 solver.cpp:404]     Test net output #0: accuracy = 0.897882
I0908 20:08:55.491421  4668 solver.cpp:404]     Test net output #1: loss = 10378 (* 1 = 10378 loss)
I0908 20:08:56.782546  4668 solver.cpp:228] Iteration 15000, loss = 5581.08
I0908 20:08:56.782578  4668 solver.cpp:244]     Train net output #0: accuracy = 0.94522
I0908 20:08:56.782588  4668 solver.cpp:244]     Train net output #1: loss = 5581.07 (* 1 = 5581.07 loss)
I0908 20:08:56.782596  4668 sgd_solver.cpp:106] Iteration 15000, lr = 1e-08
I0908 20:10:10.031368  4668 solver.cpp:228] Iteration 15050, loss = 11413.3
I0908 20:10:10.031450  4668 solver.cpp:244]     Train net output #0: accuracy = 0.891058
I0908 20:10:10.031461  4668 solver.cpp:244]     Train net output #1: loss = 11413.3 (* 1 = 11413.3 loss)
I0908 20:10:10.031468  4668 sgd_solver.cpp:106] Iteration 15050, lr = 1e-08
I0908 20:11:23.484066  4668 solver.cpp:228] Iteration 15100, loss = 5765.55
I0908 20:11:23.484159  4668 solver.cpp:244]     Train net output #0: accuracy = 0.94298
I0908 20:11:23.484171  4668 solver.cpp:244]     Train net output #1: loss = 5765.55 (* 1 = 5765.55 loss)
I0908 20:11:23.484189  4668 sgd_solver.cpp:106] Iteration 15100, lr = 1e-08
I0908 20:12:35.955739  4668 solver.cpp:228] Iteration 15150, loss = 7783.66
I0908 20:12:35.955854  4668 solver.cpp:244]     Train net output #0: accuracy = 0.923705
I0908 20:12:35.955868  4668 solver.cpp:244]     Train net output #1: loss = 7783.66 (* 1 = 7783.66 loss)
I0908 20:12:35.955875  4668 sgd_solver.cpp:106] Iteration 15150, lr = 1e-08
I0908 20:13:47.309900  4668 solver.cpp:337] Iteration 15200, Testing net (#0)
I0908 20:13:54.174552  4668 solver.cpp:404]     Test net output #0: accuracy = 0.898183
I0908 20:13:54.174597  4668 solver.cpp:404]     Test net output #1: loss = 10296.6 (* 1 = 10296.6 loss)
I0908 20:13:55.473198  4668 solver.cpp:228] Iteration 15200, loss = 9120.4
I0908 20:13:55.473240  4668 solver.cpp:244]     Train net output #0: accuracy = 0.912114
I0908 20:13:55.473251  4668 solver.cpp:244]     Train net output #1: loss = 9120.39 (* 1 = 9120.39 loss)
I0908 20:13:55.473259  4668 sgd_solver.cpp:106] Iteration 15200, lr = 1e-08
I0908 20:15:08.271867  4668 solver.cpp:228] Iteration 15250, loss = 9697.53
I0908 20:15:08.271966  4668 solver.cpp:244]     Train net output #0: accuracy = 0.904063
I0908 20:15:08.271978  4668 solver.cpp:244]     Train net output #1: loss = 9697.53 (* 1 = 9697.53 loss)
I0908 20:15:08.271986  4668 sgd_solver.cpp:106] Iteration 15250, lr = 1e-08
I0908 20:16:20.740523  4668 solver.cpp:228] Iteration 15300, loss = 45.5782
I0908 20:16:20.740627  4668 solver.cpp:244]     Train net output #0: accuracy = 0.999981
I0908 20:16:20.740638  4668 solver.cpp:244]     Train net output #1: loss = 45.5744 (* 1 = 45.5744 loss)
I0908 20:16:20.740646  4668 sgd_solver.cpp:106] Iteration 15300, lr = 1e-08
I0908 20:17:33.897511  4668 solver.cpp:228] Iteration 15350, loss = 6047.8
I0908 20:17:33.897614  4668 solver.cpp:244]     Train net output #0: accuracy = 0.941858
I0908 20:17:33.897624  4668 solver.cpp:244]     Train net output #1: loss = 6047.8 (* 1 = 6047.8 loss)
I0908 20:17:33.897632  4668 sgd_solver.cpp:106] Iteration 15350, lr = 1e-08
I0908 20:18:44.708247  4668 solver.cpp:337] Iteration 15400, Testing net (#0)
I0908 20:18:51.560681  4668 solver.cpp:404]     Test net output #0: accuracy = 0.898798
I0908 20:18:51.560726  4668 solver.cpp:404]     Test net output #1: loss = 10247.2 (* 1 = 10247.2 loss)
I0908 20:18:52.857931  4668 solver.cpp:228] Iteration 15400, loss = 12697.4
I0908 20:18:52.857969  4668 solver.cpp:244]     Train net output #0: accuracy = 0.876687
I0908 20:18:52.857978  4668 solver.cpp:244]     Train net output #1: loss = 12697.4 (* 1 = 12697.4 loss)
I0908 20:18:52.857985  4668 sgd_solver.cpp:106] Iteration 15400, lr = 1e-08
I0908 20:20:05.691723  4668 solver.cpp:228] Iteration 15450, loss = 8364.57
I0908 20:20:05.691854  4668 solver.cpp:244]     Train net output #0: accuracy = 0.918494
I0908 20:20:05.691872  4668 solver.cpp:244]     Train net output #1: loss = 8364.57 (* 1 = 8364.57 loss)
I0908 20:20:05.691886  4668 sgd_solver.cpp:106] Iteration 15450, lr = 1e-08
I0908 20:21:18.988880  4668 solver.cpp:228] Iteration 15500, loss = 8230.18
I0908 20:21:18.988947  4668 solver.cpp:244]     Train net output #0: accuracy = 0.919371
I0908 20:21:18.988957  4668 solver.cpp:244]     Train net output #1: loss = 8230.17 (* 1 = 8230.17 loss)
I0908 20:21:18.988965  4668 sgd_solver.cpp:106] Iteration 15500, lr = 1e-08
I0908 20:22:31.488925  4668 solver.cpp:228] Iteration 15550, loss = 6091.56
I0908 20:22:31.489007  4668 solver.cpp:244]     Train net output #0: accuracy = 0.940285
I0908 20:22:31.489018  4668 solver.cpp:244]     Train net output #1: loss = 6091.55 (* 1 = 6091.55 loss)
I0908 20:22:31.489027  4668 sgd_solver.cpp:106] Iteration 15550, lr = 1e-08
I0908 20:23:43.560386  4668 solver.cpp:337] Iteration 15600, Testing net (#0)
I0908 20:23:50.408339  4668 solver.cpp:404]     Test net output #0: accuracy = 0.899115
I0908 20:23:50.408380  4668 solver.cpp:404]     Test net output #1: loss = 10235.5 (* 1 = 10235.5 loss)
I0908 20:23:51.706508  4668 solver.cpp:228] Iteration 15600, loss = 11163.4
I0908 20:23:51.706545  4668 solver.cpp:244]     Train net output #0: accuracy = 0.887763
I0908 20:23:51.706567  4668 solver.cpp:244]     Train net output #1: loss = 11163.4 (* 1 = 11163.4 loss)
I0908 20:23:51.706573  4668 sgd_solver.cpp:106] Iteration 15600, lr = 1e-08
I0908 20:25:03.801789  4668 solver.cpp:228] Iteration 15650, loss = 10956.8
I0908 20:25:03.801910  4668 solver.cpp:244]     Train net output #0: accuracy = 0.891332
I0908 20:25:03.801923  4668 solver.cpp:244]     Train net output #1: loss = 10956.8 (* 1 = 10956.8 loss)
I0908 20:25:03.801930  4668 sgd_solver.cpp:106] Iteration 15650, lr = 1e-08
I0908 20:26:17.112215  4668 solver.cpp:228] Iteration 15700, loss = 7196.2
I0908 20:26:17.112315  4668 solver.cpp:244]     Train net output #0: accuracy = 0.931148
I0908 20:26:17.112326  4668 solver.cpp:244]     Train net output #1: loss = 7196.19 (* 1 = 7196.19 loss)
I0908 20:26:17.112334  4668 sgd_solver.cpp:106] Iteration 15700, lr = 1e-08
I0908 20:27:29.137706  4668 solver.cpp:228] Iteration 15750, loss = 6136.37
I0908 20:27:29.137795  4668 solver.cpp:244]     Train net output #0: accuracy = 0.941282
I0908 20:27:29.137807  4668 solver.cpp:244]     Train net output #1: loss = 6136.36 (* 1 = 6136.36 loss)
I0908 20:27:29.137814  4668 sgd_solver.cpp:106] Iteration 15750, lr = 1e-08
I0908 20:28:40.456696  4668 solver.cpp:337] Iteration 15800, Testing net (#0)
I0908 20:28:47.419792  4668 solver.cpp:404]     Test net output #0: accuracy = 0.89899
I0908 20:28:47.419836  4668 solver.cpp:404]     Test net output #1: loss = 10229.7 (* 1 = 10229.7 loss)
I0908 20:28:48.713676  4668 solver.cpp:228] Iteration 15800, loss = 8417.4
I0908 20:28:48.713723  4668 solver.cpp:244]     Train net output #0: accuracy = 0.917314
I0908 20:28:48.713733  4668 solver.cpp:244]     Train net output #1: loss = 8417.4 (* 1 = 8417.4 loss)
I0908 20:28:48.713742  4668 sgd_solver.cpp:106] Iteration 15800, lr = 1e-08
I0908 20:30:02.271672  4668 solver.cpp:228] Iteration 15850, loss = 44.7656
I0908 20:30:02.271761  4668 solver.cpp:244]     Train net output #0: accuracy = 0.999988
I0908 20:30:02.271772  4668 solver.cpp:244]     Train net output #1: loss = 44.7621 (* 1 = 44.7621 loss)
I0908 20:30:02.271780  4668 sgd_solver.cpp:106] Iteration 15850, lr = 1e-08
I0908 20:31:14.835561  4668 solver.cpp:228] Iteration 15900, loss = 6471.91
I0908 20:31:14.835657  4668 solver.cpp:244]     Train net output #0: accuracy = 0.936252
I0908 20:31:14.835674  4668 solver.cpp:244]     Train net output #1: loss = 6471.91 (* 1 = 6471.91 loss)
I0908 20:31:14.835686  4668 sgd_solver.cpp:106] Iteration 15900, lr = 1e-08
I0908 20:32:27.543478  4668 solver.cpp:228] Iteration 15950, loss = 7946.99
I0908 20:32:27.543591  4668 solver.cpp:244]     Train net output #0: accuracy = 0.922192
I0908 20:32:27.543601  4668 solver.cpp:244]     Train net output #1: loss = 7946.99 (* 1 = 7946.99 loss)
I0908 20:32:27.543609  4668 sgd_solver.cpp:106] Iteration 15950, lr = 1e-08
I0908 20:33:38.827476  4668 solver.cpp:454] Snapshotting to binary proto file portrait_wfm_one_stage_iter_16000.caffemodel
I0908 20:33:38.830040  4668 sgd_solver.cpp:273] Snapshotting solver state to binary proto file portrait_wfm_one_stage_iter_16000.solverstate
I0908 20:33:39.837031  4668 solver.cpp:317] Iteration 16000, loss = 8942.16
I0908 20:33:39.837072  4668 solver.cpp:337] Iteration 16000, Testing net (#0)
I0908 20:33:47.585108  4668 solver.cpp:404]     Test net output #0: accuracy = 0.900707
I0908 20:33:47.585150  4668 solver.cpp:404]     Test net output #1: loss = 10054.2 (* 1 = 10054.2 loss)
I0908 20:33:47.585155  4668 solver.cpp:322] Optimization Done.
I0908 20:33:47.585158  4668 caffe.cpp:254] Optimization Done.
