I0819 09:16:19.270988 24477 caffe.cpp:217] Using GPUs 1
I0819 09:16:19.293572 24477 caffe.cpp:222] GPU 1: GeForce GTX TITAN X
I0819 09:16:19.489437 24477 solver.cpp:48] Initializing solver from parameters: 
test_iter: 15
test_interval: 200
base_lr: 1e-05
display: 50
max_iter: 8000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 1e-05
stepsize: 2000
snapshot: 2000
snapshot_prefix: "portrait_one_stage"
solver_mode: GPU
device_id: 1
net: "portrait_train_test_one_stage.prototxt2"
train_state {
  level: 0
  stage: ""
}
I0819 09:16:19.489538 24477 solver.cpp:91] Creating training net from net file: portrait_train_test_one_stage.prototxt2
I0819 09:16:19.490088 24477 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0819 09:16:19.490247 24477 net.cpp:58] Initializing net from parameters: 
name: "segmentation"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "SegData"
  top: "image"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 200
  }
  data_param {
    source: "/raid/xuehan/segmentation_train_split"
    batch_size: 128
    backend: LMDB
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "image"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 50
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv1_1_bn"
  type: "BatchNorm"
  bottom: "conv1_1"
  top: "conv1_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv1_1_bn_scale"
  type: "Scale"
  bottom: "conv1_1_bn"
  top: "conv1_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_1_relu"
  type: "ReLU"
  bottom: "conv1_1_bn"
  top: "conv1_1_bn"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_1_bn"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv2_1_bn"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv2_1_bn_scale"
  type: "Scale"
  bottom: "conv2_1_bn"
  top: "conv2_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1_relu"
  type: "ReLU"
  bottom: "conv2_1_bn"
  top: "conv2_1_bn"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_1_bn"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv3_1_bn"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv3_1_bn_scale"
  type: "Scale"
  bottom: "conv3_1_bn"
  top: "conv3_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1_relu"
  type: "ReLU"
  bottom: "conv3_1_bn"
  top: "conv3_1_bn"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_1_bn"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv4_1_bn"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv4_1_bn_scale"
  type: "Scale"
  bottom: "conv4_1_bn"
  top: "conv4_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1_relu"
  type: "ReLU"
  bottom: "conv4_1_bn"
  top: "conv4_1_bn"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_1_bn"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv5_1_bn"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv5_1_bn_scale"
  type: "Scale"
  bottom: "conv5_1_bn"
  top: "conv5_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_1_relu"
  type: "ReLU"
  bottom: "conv5_1_bn"
  top: "conv5_1_bn"
}
layer {
  name: "conv6_1"
  type: "Convolution"
  bottom: "conv5_1_bn"
  top: "conv6_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv6_1_bn"
  type: "BatchNorm"
  bottom: "conv6_1"
  top: "conv6_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv6_1_bn_scale"
  type: "Scale"
  bottom: "conv6_1_bn"
  top: "conv6_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv6_1_relu"
  type: "ReLU"
  bottom: "conv6_1_bn"
  top: "conv6_1_bn"
}
layer {
  name: "conv7_1"
  type: "Convolution"
  bottom: "conv6_1_bn"
  top: "conv7_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv7_1_bn"
  type: "BatchNorm"
  bottom: "conv7_1"
  top: "conv7_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv7_1_bn_scale"
  type: "Scale"
  bottom: "conv7_1_bn"
  top: "conv7_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv7_1_relu"
  type: "ReLU"
  bottom: "conv7_1_bn"
  top: "conv7_1_bn"
}
layer {
  name: "score"
  type: "Convolution"
  bottom: "conv7_1_bn"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 4
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "upscore"
  type: "Deconvolution"
  bottom: "score"
  top: "upscore"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 4
    bias_term: false
    pad: 0
    kernel_size: 32
    stride: 16
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "cropscore"
  type: "Crop"
  bottom: "upscore"
  bottom: "image"
  top: "cropscore"
  crop_param {
    axis: 2
    offset: 12
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "cropscore"
  bottom: "label"
  top: "loss"
  loss_weight: 1
  loss_param {
    normalize: false
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "cropscore"
  bottom: "label"
  top: "accuracy"
}
I0819 09:16:19.490394 24477 layer_factory.hpp:77] Creating layer data
I0819 09:16:19.490834 24477 net.cpp:100] Creating Layer data
I0819 09:16:19.490844 24477 net.cpp:408] data -> image
I0819 09:16:19.490860 24477 net.cpp:408] data -> label
I0819 09:16:19.491854 24481 db_lmdb.cpp:35] Opened lmdb /raid/xuehan/segmentation_train_split
I0819 09:16:19.492034 24477 seg_data_layer.cpp:38] 200 200 4
I0819 09:16:19.499167 24477 seg_data_layer.cpp:51] output data size: 128,3,200,200
I0819 09:16:19.499225 24477 seg_data_layer.cpp:63] output label size: 128,1,200,200
I0819 09:16:19.604614 24477 net.cpp:150] Setting up data
I0819 09:16:19.604645 24477 net.cpp:157] Top shape: 128 3 200 200 (15360000)
I0819 09:16:19.604650 24477 net.cpp:157] Top shape: 128 1 200 200 (5120000)
I0819 09:16:19.604652 24477 net.cpp:165] Memory required for data: 81920000
I0819 09:16:19.604662 24477 layer_factory.hpp:77] Creating layer image_data_0_split
I0819 09:16:19.604678 24477 net.cpp:100] Creating Layer image_data_0_split
I0819 09:16:19.604683 24477 net.cpp:434] image_data_0_split <- image
I0819 09:16:19.604694 24477 net.cpp:408] image_data_0_split -> image_data_0_split_0
I0819 09:16:19.604702 24477 net.cpp:408] image_data_0_split -> image_data_0_split_1
I0819 09:16:19.604743 24477 net.cpp:150] Setting up image_data_0_split
I0819 09:16:19.604748 24477 net.cpp:157] Top shape: 128 3 200 200 (15360000)
I0819 09:16:19.604750 24477 net.cpp:157] Top shape: 128 3 200 200 (15360000)
I0819 09:16:19.604753 24477 net.cpp:165] Memory required for data: 204800000
I0819 09:16:19.604755 24477 layer_factory.hpp:77] Creating layer label_data_1_split
I0819 09:16:19.604760 24477 net.cpp:100] Creating Layer label_data_1_split
I0819 09:16:19.604763 24477 net.cpp:434] label_data_1_split <- label
I0819 09:16:19.604768 24477 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0819 09:16:19.604773 24477 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0819 09:16:19.604794 24477 net.cpp:150] Setting up label_data_1_split
I0819 09:16:19.604799 24477 net.cpp:157] Top shape: 128 1 200 200 (5120000)
I0819 09:16:19.604802 24477 net.cpp:157] Top shape: 128 1 200 200 (5120000)
I0819 09:16:19.604804 24477 net.cpp:165] Memory required for data: 245760000
I0819 09:16:19.604807 24477 layer_factory.hpp:77] Creating layer conv1_1
I0819 09:16:19.604820 24477 net.cpp:100] Creating Layer conv1_1
I0819 09:16:19.604822 24477 net.cpp:434] conv1_1 <- image_data_0_split_0
I0819 09:16:19.604827 24477 net.cpp:408] conv1_1 -> conv1_1
I0819 09:16:19.604980 24477 net.cpp:150] Setting up conv1_1
I0819 09:16:19.604987 24477 net.cpp:157] Top shape: 128 8 298 298 (90935296)
I0819 09:16:19.604990 24477 net.cpp:165] Memory required for data: 609501184
I0819 09:16:19.604998 24477 layer_factory.hpp:77] Creating layer conv1_1_bn
I0819 09:16:19.605005 24477 net.cpp:100] Creating Layer conv1_1_bn
I0819 09:16:19.605008 24477 net.cpp:434] conv1_1_bn <- conv1_1
I0819 09:16:19.605012 24477 net.cpp:408] conv1_1_bn -> conv1_1_bn
I0819 09:16:19.605592 24477 net.cpp:150] Setting up conv1_1_bn
I0819 09:16:19.605602 24477 net.cpp:157] Top shape: 128 8 298 298 (90935296)
I0819 09:16:19.605605 24477 net.cpp:165] Memory required for data: 973242368
I0819 09:16:19.605614 24477 layer_factory.hpp:77] Creating layer conv1_1_bn_scale
I0819 09:16:19.605621 24477 net.cpp:100] Creating Layer conv1_1_bn_scale
I0819 09:16:19.605625 24477 net.cpp:434] conv1_1_bn_scale <- conv1_1_bn
I0819 09:16:19.605629 24477 net.cpp:395] conv1_1_bn_scale -> conv1_1_bn (in-place)
I0819 09:16:19.605657 24477 layer_factory.hpp:77] Creating layer conv1_1_bn_scale
I0819 09:16:19.606240 24477 net.cpp:150] Setting up conv1_1_bn_scale
I0819 09:16:19.606251 24477 net.cpp:157] Top shape: 128 8 298 298 (90935296)
I0819 09:16:19.606252 24477 net.cpp:165] Memory required for data: 1336983552
I0819 09:16:19.606261 24477 layer_factory.hpp:77] Creating layer conv1_1_relu
I0819 09:16:19.606267 24477 net.cpp:100] Creating Layer conv1_1_relu
I0819 09:16:19.606271 24477 net.cpp:434] conv1_1_relu <- conv1_1_bn
I0819 09:16:19.606276 24477 net.cpp:395] conv1_1_relu -> conv1_1_bn (in-place)
I0819 09:16:19.606281 24477 net.cpp:150] Setting up conv1_1_relu
I0819 09:16:19.606284 24477 net.cpp:157] Top shape: 128 8 298 298 (90935296)
I0819 09:16:19.606287 24477 net.cpp:165] Memory required for data: 1700724736
I0819 09:16:19.606289 24477 layer_factory.hpp:77] Creating layer pool1
I0819 09:16:19.606302 24477 net.cpp:100] Creating Layer pool1
I0819 09:16:19.606312 24477 net.cpp:434] pool1 <- conv1_1_bn
I0819 09:16:19.606317 24477 net.cpp:408] pool1 -> pool1
I0819 09:16:19.612948 24477 net.cpp:150] Setting up pool1
I0819 09:16:19.612958 24477 net.cpp:157] Top shape: 128 8 149 149 (22733824)
I0819 09:16:19.612960 24477 net.cpp:165] Memory required for data: 1791660032
I0819 09:16:19.612963 24477 layer_factory.hpp:77] Creating layer conv2_1
I0819 09:16:19.612973 24477 net.cpp:100] Creating Layer conv2_1
I0819 09:16:19.612977 24477 net.cpp:434] conv2_1 <- pool1
I0819 09:16:19.612982 24477 net.cpp:408] conv2_1 -> conv2_1
I0819 09:16:19.613548 24477 net.cpp:150] Setting up conv2_1
I0819 09:16:19.613559 24477 net.cpp:157] Top shape: 128 16 149 149 (45467648)
I0819 09:16:19.613561 24477 net.cpp:165] Memory required for data: 1973530624
I0819 09:16:19.613565 24477 layer_factory.hpp:77] Creating layer conv2_1_bn
I0819 09:16:19.613572 24477 net.cpp:100] Creating Layer conv2_1_bn
I0819 09:16:19.613575 24477 net.cpp:434] conv2_1_bn <- conv2_1
I0819 09:16:19.613579 24477 net.cpp:408] conv2_1_bn -> conv2_1_bn
I0819 09:16:19.614156 24477 net.cpp:150] Setting up conv2_1_bn
I0819 09:16:19.614166 24477 net.cpp:157] Top shape: 128 16 149 149 (45467648)
I0819 09:16:19.614168 24477 net.cpp:165] Memory required for data: 2155401216
I0819 09:16:19.614177 24477 layer_factory.hpp:77] Creating layer conv2_1_bn_scale
I0819 09:16:19.614184 24477 net.cpp:100] Creating Layer conv2_1_bn_scale
I0819 09:16:19.614188 24477 net.cpp:434] conv2_1_bn_scale <- conv2_1_bn
I0819 09:16:19.614193 24477 net.cpp:395] conv2_1_bn_scale -> conv2_1_bn (in-place)
I0819 09:16:19.614219 24477 layer_factory.hpp:77] Creating layer conv2_1_bn_scale
I0819 09:16:19.614308 24477 net.cpp:150] Setting up conv2_1_bn_scale
I0819 09:16:19.614315 24477 net.cpp:157] Top shape: 128 16 149 149 (45467648)
I0819 09:16:19.614317 24477 net.cpp:165] Memory required for data: 2337271808
I0819 09:16:19.614321 24477 layer_factory.hpp:77] Creating layer conv2_1_relu
I0819 09:16:19.614327 24477 net.cpp:100] Creating Layer conv2_1_relu
I0819 09:16:19.614331 24477 net.cpp:434] conv2_1_relu <- conv2_1_bn
I0819 09:16:19.614336 24477 net.cpp:395] conv2_1_relu -> conv2_1_bn (in-place)
I0819 09:16:19.614341 24477 net.cpp:150] Setting up conv2_1_relu
I0819 09:16:19.614346 24477 net.cpp:157] Top shape: 128 16 149 149 (45467648)
I0819 09:16:19.614348 24477 net.cpp:165] Memory required for data: 2519142400
I0819 09:16:19.614351 24477 layer_factory.hpp:77] Creating layer pool2
I0819 09:16:19.614356 24477 net.cpp:100] Creating Layer pool2
I0819 09:16:19.614358 24477 net.cpp:434] pool2 <- conv2_1_bn
I0819 09:16:19.614362 24477 net.cpp:408] pool2 -> pool2
I0819 09:16:19.614387 24477 net.cpp:150] Setting up pool2
I0819 09:16:19.614392 24477 net.cpp:157] Top shape: 128 16 75 75 (11520000)
I0819 09:16:19.614394 24477 net.cpp:165] Memory required for data: 2565222400
I0819 09:16:19.614397 24477 layer_factory.hpp:77] Creating layer conv3_1
I0819 09:16:19.614403 24477 net.cpp:100] Creating Layer conv3_1
I0819 09:16:19.614406 24477 net.cpp:434] conv3_1 <- pool2
I0819 09:16:19.614410 24477 net.cpp:408] conv3_1 -> conv3_1
I0819 09:16:19.615056 24477 net.cpp:150] Setting up conv3_1
I0819 09:16:19.615067 24477 net.cpp:157] Top shape: 128 32 75 75 (23040000)
I0819 09:16:19.615069 24477 net.cpp:165] Memory required for data: 2657382400
I0819 09:16:19.615073 24477 layer_factory.hpp:77] Creating layer conv3_1_bn
I0819 09:16:19.615080 24477 net.cpp:100] Creating Layer conv3_1_bn
I0819 09:16:19.615083 24477 net.cpp:434] conv3_1_bn <- conv3_1
I0819 09:16:19.615087 24477 net.cpp:408] conv3_1_bn -> conv3_1_bn
I0819 09:16:19.615216 24477 net.cpp:150] Setting up conv3_1_bn
I0819 09:16:19.615221 24477 net.cpp:157] Top shape: 128 32 75 75 (23040000)
I0819 09:16:19.615223 24477 net.cpp:165] Memory required for data: 2749542400
I0819 09:16:19.615229 24477 layer_factory.hpp:77] Creating layer conv3_1_bn_scale
I0819 09:16:19.615234 24477 net.cpp:100] Creating Layer conv3_1_bn_scale
I0819 09:16:19.615237 24477 net.cpp:434] conv3_1_bn_scale <- conv3_1_bn
I0819 09:16:19.615254 24477 net.cpp:395] conv3_1_bn_scale -> conv3_1_bn (in-place)
I0819 09:16:19.615279 24477 layer_factory.hpp:77] Creating layer conv3_1_bn_scale
I0819 09:16:19.615356 24477 net.cpp:150] Setting up conv3_1_bn_scale
I0819 09:16:19.615361 24477 net.cpp:157] Top shape: 128 32 75 75 (23040000)
I0819 09:16:19.615365 24477 net.cpp:165] Memory required for data: 2841702400
I0819 09:16:19.615373 24477 layer_factory.hpp:77] Creating layer conv3_1_relu
I0819 09:16:19.615378 24477 net.cpp:100] Creating Layer conv3_1_relu
I0819 09:16:19.615381 24477 net.cpp:434] conv3_1_relu <- conv3_1_bn
I0819 09:16:19.615386 24477 net.cpp:395] conv3_1_relu -> conv3_1_bn (in-place)
I0819 09:16:19.615391 24477 net.cpp:150] Setting up conv3_1_relu
I0819 09:16:19.615393 24477 net.cpp:157] Top shape: 128 32 75 75 (23040000)
I0819 09:16:19.615396 24477 net.cpp:165] Memory required for data: 2933862400
I0819 09:16:19.615398 24477 layer_factory.hpp:77] Creating layer pool3
I0819 09:16:19.615404 24477 net.cpp:100] Creating Layer pool3
I0819 09:16:19.615407 24477 net.cpp:434] pool3 <- conv3_1_bn
I0819 09:16:19.615411 24477 net.cpp:408] pool3 -> pool3
I0819 09:16:19.615458 24477 net.cpp:150] Setting up pool3
I0819 09:16:19.615463 24477 net.cpp:157] Top shape: 128 32 38 38 (5914624)
I0819 09:16:19.615465 24477 net.cpp:165] Memory required for data: 2957520896
I0819 09:16:19.615468 24477 layer_factory.hpp:77] Creating layer conv4_1
I0819 09:16:19.615474 24477 net.cpp:100] Creating Layer conv4_1
I0819 09:16:19.615478 24477 net.cpp:434] conv4_1 <- pool3
I0819 09:16:19.615481 24477 net.cpp:408] conv4_1 -> conv4_1
I0819 09:16:19.615986 24477 net.cpp:150] Setting up conv4_1
I0819 09:16:19.615993 24477 net.cpp:157] Top shape: 128 64 38 38 (11829248)
I0819 09:16:19.615995 24477 net.cpp:165] Memory required for data: 3004837888
I0819 09:16:19.615998 24477 layer_factory.hpp:77] Creating layer conv4_1_bn
I0819 09:16:19.616005 24477 net.cpp:100] Creating Layer conv4_1_bn
I0819 09:16:19.616009 24477 net.cpp:434] conv4_1_bn <- conv4_1
I0819 09:16:19.616013 24477 net.cpp:408] conv4_1_bn -> conv4_1_bn
I0819 09:16:19.616138 24477 net.cpp:150] Setting up conv4_1_bn
I0819 09:16:19.616143 24477 net.cpp:157] Top shape: 128 64 38 38 (11829248)
I0819 09:16:19.616147 24477 net.cpp:165] Memory required for data: 3052154880
I0819 09:16:19.616152 24477 layer_factory.hpp:77] Creating layer conv4_1_bn_scale
I0819 09:16:19.616156 24477 net.cpp:100] Creating Layer conv4_1_bn_scale
I0819 09:16:19.616158 24477 net.cpp:434] conv4_1_bn_scale <- conv4_1_bn
I0819 09:16:19.616163 24477 net.cpp:395] conv4_1_bn_scale -> conv4_1_bn (in-place)
I0819 09:16:19.616186 24477 layer_factory.hpp:77] Creating layer conv4_1_bn_scale
I0819 09:16:19.616264 24477 net.cpp:150] Setting up conv4_1_bn_scale
I0819 09:16:19.616271 24477 net.cpp:157] Top shape: 128 64 38 38 (11829248)
I0819 09:16:19.616273 24477 net.cpp:165] Memory required for data: 3099471872
I0819 09:16:19.616277 24477 layer_factory.hpp:77] Creating layer conv4_1_relu
I0819 09:16:19.616282 24477 net.cpp:100] Creating Layer conv4_1_relu
I0819 09:16:19.616284 24477 net.cpp:434] conv4_1_relu <- conv4_1_bn
I0819 09:16:19.616288 24477 net.cpp:395] conv4_1_relu -> conv4_1_bn (in-place)
I0819 09:16:19.616292 24477 net.cpp:150] Setting up conv4_1_relu
I0819 09:16:19.616295 24477 net.cpp:157] Top shape: 128 64 38 38 (11829248)
I0819 09:16:19.616298 24477 net.cpp:165] Memory required for data: 3146788864
I0819 09:16:19.616302 24477 layer_factory.hpp:77] Creating layer pool4
I0819 09:16:19.616305 24477 net.cpp:100] Creating Layer pool4
I0819 09:16:19.616307 24477 net.cpp:434] pool4 <- conv4_1_bn
I0819 09:16:19.616313 24477 net.cpp:408] pool4 -> pool4
I0819 09:16:19.616338 24477 net.cpp:150] Setting up pool4
I0819 09:16:19.616341 24477 net.cpp:157] Top shape: 128 64 19 19 (2957312)
I0819 09:16:19.616343 24477 net.cpp:165] Memory required for data: 3158618112
I0819 09:16:19.616346 24477 layer_factory.hpp:77] Creating layer conv5_1
I0819 09:16:19.616353 24477 net.cpp:100] Creating Layer conv5_1
I0819 09:16:19.616360 24477 net.cpp:434] conv5_1 <- pool4
I0819 09:16:19.616369 24477 net.cpp:408] conv5_1 -> conv5_1
I0819 09:16:19.617281 24477 net.cpp:150] Setting up conv5_1
I0819 09:16:19.617287 24477 net.cpp:157] Top shape: 128 64 17 17 (2367488)
I0819 09:16:19.617290 24477 net.cpp:165] Memory required for data: 3168088064
I0819 09:16:19.617295 24477 layer_factory.hpp:77] Creating layer conv5_1_bn
I0819 09:16:19.617300 24477 net.cpp:100] Creating Layer conv5_1_bn
I0819 09:16:19.617301 24477 net.cpp:434] conv5_1_bn <- conv5_1
I0819 09:16:19.617306 24477 net.cpp:408] conv5_1_bn -> conv5_1_bn
I0819 09:16:19.617892 24477 net.cpp:150] Setting up conv5_1_bn
I0819 09:16:19.617903 24477 net.cpp:157] Top shape: 128 64 17 17 (2367488)
I0819 09:16:19.617905 24477 net.cpp:165] Memory required for data: 3177558016
I0819 09:16:19.617913 24477 layer_factory.hpp:77] Creating layer conv5_1_bn_scale
I0819 09:16:19.617918 24477 net.cpp:100] Creating Layer conv5_1_bn_scale
I0819 09:16:19.617921 24477 net.cpp:434] conv5_1_bn_scale <- conv5_1_bn
I0819 09:16:19.617926 24477 net.cpp:395] conv5_1_bn_scale -> conv5_1_bn (in-place)
I0819 09:16:19.617954 24477 layer_factory.hpp:77] Creating layer conv5_1_bn_scale
I0819 09:16:19.618036 24477 net.cpp:150] Setting up conv5_1_bn_scale
I0819 09:16:19.618041 24477 net.cpp:157] Top shape: 128 64 17 17 (2367488)
I0819 09:16:19.618043 24477 net.cpp:165] Memory required for data: 3187027968
I0819 09:16:19.618048 24477 layer_factory.hpp:77] Creating layer conv5_1_relu
I0819 09:16:19.618052 24477 net.cpp:100] Creating Layer conv5_1_relu
I0819 09:16:19.618055 24477 net.cpp:434] conv5_1_relu <- conv5_1_bn
I0819 09:16:19.618059 24477 net.cpp:395] conv5_1_relu -> conv5_1_bn (in-place)
I0819 09:16:19.618063 24477 net.cpp:150] Setting up conv5_1_relu
I0819 09:16:19.618067 24477 net.cpp:157] Top shape: 128 64 17 17 (2367488)
I0819 09:16:19.618069 24477 net.cpp:165] Memory required for data: 3196497920
I0819 09:16:19.618072 24477 layer_factory.hpp:77] Creating layer conv6_1
I0819 09:16:19.618079 24477 net.cpp:100] Creating Layer conv6_1
I0819 09:16:19.618083 24477 net.cpp:434] conv6_1 <- conv5_1_bn
I0819 09:16:19.618088 24477 net.cpp:408] conv6_1 -> conv6_1
I0819 09:16:19.618988 24477 net.cpp:150] Setting up conv6_1
I0819 09:16:19.618994 24477 net.cpp:157] Top shape: 128 64 15 15 (1843200)
I0819 09:16:19.618998 24477 net.cpp:165] Memory required for data: 3203870720
I0819 09:16:19.619000 24477 layer_factory.hpp:77] Creating layer conv6_1_bn
I0819 09:16:19.619005 24477 net.cpp:100] Creating Layer conv6_1_bn
I0819 09:16:19.619009 24477 net.cpp:434] conv6_1_bn <- conv6_1
I0819 09:16:19.619012 24477 net.cpp:408] conv6_1_bn -> conv6_1_bn
I0819 09:16:19.619139 24477 net.cpp:150] Setting up conv6_1_bn
I0819 09:16:19.619143 24477 net.cpp:157] Top shape: 128 64 15 15 (1843200)
I0819 09:16:19.619146 24477 net.cpp:165] Memory required for data: 3211243520
I0819 09:16:19.619158 24477 layer_factory.hpp:77] Creating layer conv6_1_bn_scale
I0819 09:16:19.619163 24477 net.cpp:100] Creating Layer conv6_1_bn_scale
I0819 09:16:19.619166 24477 net.cpp:434] conv6_1_bn_scale <- conv6_1_bn
I0819 09:16:19.619169 24477 net.cpp:395] conv6_1_bn_scale -> conv6_1_bn (in-place)
I0819 09:16:19.619194 24477 layer_factory.hpp:77] Creating layer conv6_1_bn_scale
I0819 09:16:19.619266 24477 net.cpp:150] Setting up conv6_1_bn_scale
I0819 09:16:19.619272 24477 net.cpp:157] Top shape: 128 64 15 15 (1843200)
I0819 09:16:19.619274 24477 net.cpp:165] Memory required for data: 3218616320
I0819 09:16:19.619279 24477 layer_factory.hpp:77] Creating layer conv6_1_relu
I0819 09:16:19.619283 24477 net.cpp:100] Creating Layer conv6_1_relu
I0819 09:16:19.619287 24477 net.cpp:434] conv6_1_relu <- conv6_1_bn
I0819 09:16:19.619289 24477 net.cpp:395] conv6_1_relu -> conv6_1_bn (in-place)
I0819 09:16:19.619293 24477 net.cpp:150] Setting up conv6_1_relu
I0819 09:16:19.619297 24477 net.cpp:157] Top shape: 128 64 15 15 (1843200)
I0819 09:16:19.619299 24477 net.cpp:165] Memory required for data: 3225989120
I0819 09:16:19.619302 24477 layer_factory.hpp:77] Creating layer conv7_1
I0819 09:16:19.619314 24477 net.cpp:100] Creating Layer conv7_1
I0819 09:16:19.619324 24477 net.cpp:434] conv7_1 <- conv6_1_bn
I0819 09:16:19.619328 24477 net.cpp:408] conv7_1 -> conv7_1
I0819 09:16:19.621039 24477 net.cpp:150] Setting up conv7_1
I0819 09:16:19.621045 24477 net.cpp:157] Top shape: 128 128 13 13 (2768896)
I0819 09:16:19.621048 24477 net.cpp:165] Memory required for data: 3237064704
I0819 09:16:19.621052 24477 layer_factory.hpp:77] Creating layer conv7_1_bn
I0819 09:16:19.621059 24477 net.cpp:100] Creating Layer conv7_1_bn
I0819 09:16:19.621062 24477 net.cpp:434] conv7_1_bn <- conv7_1
I0819 09:16:19.621068 24477 net.cpp:408] conv7_1_bn -> conv7_1_bn
I0819 09:16:19.621197 24477 net.cpp:150] Setting up conv7_1_bn
I0819 09:16:19.621202 24477 net.cpp:157] Top shape: 128 128 13 13 (2768896)
I0819 09:16:19.621206 24477 net.cpp:165] Memory required for data: 3248140288
I0819 09:16:19.621211 24477 layer_factory.hpp:77] Creating layer conv7_1_bn_scale
I0819 09:16:19.621217 24477 net.cpp:100] Creating Layer conv7_1_bn_scale
I0819 09:16:19.621219 24477 net.cpp:434] conv7_1_bn_scale <- conv7_1_bn
I0819 09:16:19.621223 24477 net.cpp:395] conv7_1_bn_scale -> conv7_1_bn (in-place)
I0819 09:16:19.621245 24477 layer_factory.hpp:77] Creating layer conv7_1_bn_scale
I0819 09:16:19.621310 24477 net.cpp:150] Setting up conv7_1_bn_scale
I0819 09:16:19.621315 24477 net.cpp:157] Top shape: 128 128 13 13 (2768896)
I0819 09:16:19.621318 24477 net.cpp:165] Memory required for data: 3259215872
I0819 09:16:19.621322 24477 layer_factory.hpp:77] Creating layer conv7_1_relu
I0819 09:16:19.621327 24477 net.cpp:100] Creating Layer conv7_1_relu
I0819 09:16:19.621330 24477 net.cpp:434] conv7_1_relu <- conv7_1_bn
I0819 09:16:19.621335 24477 net.cpp:395] conv7_1_relu -> conv7_1_bn (in-place)
I0819 09:16:19.621338 24477 net.cpp:150] Setting up conv7_1_relu
I0819 09:16:19.621342 24477 net.cpp:157] Top shape: 128 128 13 13 (2768896)
I0819 09:16:19.621345 24477 net.cpp:165] Memory required for data: 3270291456
I0819 09:16:19.621347 24477 layer_factory.hpp:77] Creating layer score
I0819 09:16:19.621354 24477 net.cpp:100] Creating Layer score
I0819 09:16:19.621357 24477 net.cpp:434] score <- conv7_1_bn
I0819 09:16:19.621362 24477 net.cpp:408] score -> score
I0819 09:16:19.621521 24477 net.cpp:150] Setting up score
I0819 09:16:19.621528 24477 net.cpp:157] Top shape: 128 4 13 13 (86528)
I0819 09:16:19.621531 24477 net.cpp:165] Memory required for data: 3270637568
I0819 09:16:19.621536 24477 layer_factory.hpp:77] Creating layer upscore
I0819 09:16:19.621541 24477 net.cpp:100] Creating Layer upscore
I0819 09:16:19.621544 24477 net.cpp:434] upscore <- score
I0819 09:16:19.621549 24477 net.cpp:408] upscore -> upscore
I0819 09:16:19.622053 24477 net.cpp:150] Setting up upscore
I0819 09:16:19.622061 24477 net.cpp:157] Top shape: 128 4 224 224 (25690112)
I0819 09:16:19.622063 24477 net.cpp:165] Memory required for data: 3373398016
I0819 09:16:19.622066 24477 layer_factory.hpp:77] Creating layer cropscore
I0819 09:16:19.622072 24477 net.cpp:100] Creating Layer cropscore
I0819 09:16:19.622076 24477 net.cpp:434] cropscore <- upscore
I0819 09:16:19.622078 24477 net.cpp:434] cropscore <- image_data_0_split_1
I0819 09:16:19.622082 24477 net.cpp:408] cropscore -> cropscore
I0819 09:16:19.622102 24477 net.cpp:150] Setting up cropscore
I0819 09:16:19.622105 24477 net.cpp:157] Top shape: 128 4 200 200 (20480000)
I0819 09:16:19.622107 24477 net.cpp:165] Memory required for data: 3455318016
I0819 09:16:19.622110 24477 layer_factory.hpp:77] Creating layer cropscore_cropscore_0_split
I0819 09:16:19.622117 24477 net.cpp:100] Creating Layer cropscore_cropscore_0_split
I0819 09:16:19.622119 24477 net.cpp:434] cropscore_cropscore_0_split <- cropscore
I0819 09:16:19.622123 24477 net.cpp:408] cropscore_cropscore_0_split -> cropscore_cropscore_0_split_0
I0819 09:16:19.622128 24477 net.cpp:408] cropscore_cropscore_0_split -> cropscore_cropscore_0_split_1
I0819 09:16:19.622150 24477 net.cpp:150] Setting up cropscore_cropscore_0_split
I0819 09:16:19.622155 24477 net.cpp:157] Top shape: 128 4 200 200 (20480000)
I0819 09:16:19.622164 24477 net.cpp:157] Top shape: 128 4 200 200 (20480000)
I0819 09:16:19.622174 24477 net.cpp:165] Memory required for data: 3619158016
I0819 09:16:19.622177 24477 layer_factory.hpp:77] Creating layer loss
I0819 09:16:19.622184 24477 net.cpp:100] Creating Layer loss
I0819 09:16:19.622186 24477 net.cpp:434] loss <- cropscore_cropscore_0_split_0
I0819 09:16:19.622190 24477 net.cpp:434] loss <- label_data_1_split_0
I0819 09:16:19.622195 24477 net.cpp:408] loss -> loss
I0819 09:16:19.622201 24477 layer_factory.hpp:77] Creating layer loss
I0819 09:16:19.659018 24477 net.cpp:150] Setting up loss
I0819 09:16:19.659045 24477 net.cpp:157] Top shape: (1)
I0819 09:16:19.659049 24477 net.cpp:160]     with loss weight 1
I0819 09:16:19.659066 24477 net.cpp:165] Memory required for data: 3619158020
I0819 09:16:19.659070 24477 layer_factory.hpp:77] Creating layer accuracy
I0819 09:16:19.659087 24477 net.cpp:100] Creating Layer accuracy
I0819 09:16:19.659092 24477 net.cpp:434] accuracy <- cropscore_cropscore_0_split_1
I0819 09:16:19.659098 24477 net.cpp:434] accuracy <- label_data_1_split_1
I0819 09:16:19.659104 24477 net.cpp:408] accuracy -> accuracy
I0819 09:16:19.659113 24477 net.cpp:150] Setting up accuracy
I0819 09:16:19.659117 24477 net.cpp:157] Top shape: (1)
I0819 09:16:19.659121 24477 net.cpp:165] Memory required for data: 3619158024
I0819 09:16:19.659123 24477 net.cpp:228] accuracy does not need backward computation.
I0819 09:16:19.659126 24477 net.cpp:226] loss needs backward computation.
I0819 09:16:19.659129 24477 net.cpp:226] cropscore_cropscore_0_split needs backward computation.
I0819 09:16:19.659133 24477 net.cpp:226] cropscore needs backward computation.
I0819 09:16:19.659137 24477 net.cpp:226] upscore needs backward computation.
I0819 09:16:19.659140 24477 net.cpp:226] score needs backward computation.
I0819 09:16:19.659142 24477 net.cpp:226] conv7_1_relu needs backward computation.
I0819 09:16:19.659145 24477 net.cpp:226] conv7_1_bn_scale needs backward computation.
I0819 09:16:19.659149 24477 net.cpp:226] conv7_1_bn needs backward computation.
I0819 09:16:19.659152 24477 net.cpp:226] conv7_1 needs backward computation.
I0819 09:16:19.659155 24477 net.cpp:226] conv6_1_relu needs backward computation.
I0819 09:16:19.659158 24477 net.cpp:226] conv6_1_bn_scale needs backward computation.
I0819 09:16:19.659160 24477 net.cpp:226] conv6_1_bn needs backward computation.
I0819 09:16:19.659163 24477 net.cpp:226] conv6_1 needs backward computation.
I0819 09:16:19.659167 24477 net.cpp:226] conv5_1_relu needs backward computation.
I0819 09:16:19.659169 24477 net.cpp:226] conv5_1_bn_scale needs backward computation.
I0819 09:16:19.659173 24477 net.cpp:226] conv5_1_bn needs backward computation.
I0819 09:16:19.659175 24477 net.cpp:226] conv5_1 needs backward computation.
I0819 09:16:19.659178 24477 net.cpp:226] pool4 needs backward computation.
I0819 09:16:19.659180 24477 net.cpp:226] conv4_1_relu needs backward computation.
I0819 09:16:19.659183 24477 net.cpp:226] conv4_1_bn_scale needs backward computation.
I0819 09:16:19.659186 24477 net.cpp:226] conv4_1_bn needs backward computation.
I0819 09:16:19.659189 24477 net.cpp:226] conv4_1 needs backward computation.
I0819 09:16:19.659191 24477 net.cpp:226] pool3 needs backward computation.
I0819 09:16:19.659194 24477 net.cpp:226] conv3_1_relu needs backward computation.
I0819 09:16:19.659198 24477 net.cpp:226] conv3_1_bn_scale needs backward computation.
I0819 09:16:19.659200 24477 net.cpp:226] conv3_1_bn needs backward computation.
I0819 09:16:19.659204 24477 net.cpp:226] conv3_1 needs backward computation.
I0819 09:16:19.659206 24477 net.cpp:226] pool2 needs backward computation.
I0819 09:16:19.659209 24477 net.cpp:226] conv2_1_relu needs backward computation.
I0819 09:16:19.659211 24477 net.cpp:226] conv2_1_bn_scale needs backward computation.
I0819 09:16:19.659214 24477 net.cpp:226] conv2_1_bn needs backward computation.
I0819 09:16:19.659217 24477 net.cpp:226] conv2_1 needs backward computation.
I0819 09:16:19.659220 24477 net.cpp:226] pool1 needs backward computation.
I0819 09:16:19.659238 24477 net.cpp:226] conv1_1_relu needs backward computation.
I0819 09:16:19.659241 24477 net.cpp:226] conv1_1_bn_scale needs backward computation.
I0819 09:16:19.659243 24477 net.cpp:226] conv1_1_bn needs backward computation.
I0819 09:16:19.659246 24477 net.cpp:226] conv1_1 needs backward computation.
I0819 09:16:19.659250 24477 net.cpp:228] label_data_1_split does not need backward computation.
I0819 09:16:19.659253 24477 net.cpp:228] image_data_0_split does not need backward computation.
I0819 09:16:19.659256 24477 net.cpp:228] data does not need backward computation.
I0819 09:16:19.659260 24477 net.cpp:270] This network produces output accuracy
I0819 09:16:19.659262 24477 net.cpp:270] This network produces output loss
I0819 09:16:19.659281 24477 net.cpp:283] Network initialization done.
I0819 09:16:19.659853 24477 solver.cpp:181] Creating test net (#0) specified by net file: portrait_train_test_one_stage.prototxt2
I0819 09:16:19.659899 24477 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0819 09:16:19.660048 24477 net.cpp:58] Initializing net from parameters: 
name: "segmentation"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "SegData"
  top: "image"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 200
  }
  data_param {
    source: "/raid/xuehan/segmentation_test_split"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "image"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 50
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv1_1_bn"
  type: "BatchNorm"
  bottom: "conv1_1"
  top: "conv1_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv1_1_bn_scale"
  type: "Scale"
  bottom: "conv1_1_bn"
  top: "conv1_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_1_relu"
  type: "ReLU"
  bottom: "conv1_1_bn"
  top: "conv1_1_bn"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_1_bn"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv2_1_bn"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv2_1_bn_scale"
  type: "Scale"
  bottom: "conv2_1_bn"
  top: "conv2_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1_relu"
  type: "ReLU"
  bottom: "conv2_1_bn"
  top: "conv2_1_bn"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_1_bn"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv3_1_bn"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv3_1_bn_scale"
  type: "Scale"
  bottom: "conv3_1_bn"
  top: "conv3_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1_relu"
  type: "ReLU"
  bottom: "conv3_1_bn"
  top: "conv3_1_bn"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_1_bn"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv4_1_bn"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv4_1_bn_scale"
  type: "Scale"
  bottom: "conv4_1_bn"
  top: "conv4_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1_relu"
  type: "ReLU"
  bottom: "conv4_1_bn"
  top: "conv4_1_bn"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_1_bn"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv5_1_bn"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv5_1_bn_scale"
  type: "Scale"
  bottom: "conv5_1_bn"
  top: "conv5_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_1_relu"
  type: "ReLU"
  bottom: "conv5_1_bn"
  top: "conv5_1_bn"
}
layer {
  name: "conv6_1"
  type: "Convolution"
  bottom: "conv5_1_bn"
  top: "conv6_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv6_1_bn"
  type: "BatchNorm"
  bottom: "conv6_1"
  top: "conv6_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv6_1_bn_scale"
  type: "Scale"
  bottom: "conv6_1_bn"
  top: "conv6_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv6_1_relu"
  type: "ReLU"
  bottom: "conv6_1_bn"
  top: "conv6_1_bn"
}
layer {
  name: "conv7_1"
  type: "Convolution"
  bottom: "conv6_1_bn"
  top: "conv7_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv7_1_bn"
  type: "BatchNorm"
  bottom: "conv7_1"
  top: "conv7_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv7_1_bn_scale"
  type: "Scale"
  bottom: "conv7_1_bn"
  top: "conv7_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv7_1_relu"
  type: "ReLU"
  bottom: "conv7_1_bn"
  top: "conv7_1_bn"
}
layer {
  name: "score"
  type: "Convolution"
  bottom: "conv7_1_bn"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 4
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "upscore"
  type: "Deconvolution"
  bottom: "score"
  top: "upscore"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 4
    bias_term: false
    pad: 0
    kernel_size: 32
    stride: 16
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "cropscore"
  type: "Crop"
  bottom: "upscore"
  bottom: "image"
  top: "cropscore"
  crop_param {
    axis: 2
    offset: 12
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "cropscore"
  bottom: "label"
  top: "loss"
  loss_weight: 1
  loss_param {
    normalize: false
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "cropscore"
  bottom: "label"
  top: "accuracy"
}
I0819 09:16:19.660176 24477 layer_factory.hpp:77] Creating layer data
I0819 09:16:19.660253 24477 net.cpp:100] Creating Layer data
I0819 09:16:19.660270 24477 net.cpp:408] data -> image
I0819 09:16:19.660292 24477 net.cpp:408] data -> label
I0819 09:16:19.661322 24483 db_lmdb.cpp:35] Opened lmdb /raid/xuehan/segmentation_test_split
I0819 09:16:19.661481 24477 seg_data_layer.cpp:38] 200 200 4
I0819 09:16:19.661550 24477 seg_data_layer.cpp:51] output data size: 64,3,200,200
I0819 09:16:19.661595 24477 seg_data_layer.cpp:63] output label size: 64,1,200,200
I0819 09:16:19.724822 24477 net.cpp:150] Setting up data
I0819 09:16:19.724850 24477 net.cpp:157] Top shape: 64 3 200 200 (7680000)
I0819 09:16:19.724856 24477 net.cpp:157] Top shape: 64 1 200 200 (2560000)
I0819 09:16:19.724858 24477 net.cpp:165] Memory required for data: 40960000
I0819 09:16:19.724864 24477 layer_factory.hpp:77] Creating layer image_data_0_split
I0819 09:16:19.724876 24477 net.cpp:100] Creating Layer image_data_0_split
I0819 09:16:19.724879 24477 net.cpp:434] image_data_0_split <- image
I0819 09:16:19.724885 24477 net.cpp:408] image_data_0_split -> image_data_0_split_0
I0819 09:16:19.724895 24477 net.cpp:408] image_data_0_split -> image_data_0_split_1
I0819 09:16:19.731459 24477 net.cpp:150] Setting up image_data_0_split
I0819 09:16:19.731475 24477 net.cpp:157] Top shape: 64 3 200 200 (7680000)
I0819 09:16:19.731479 24477 net.cpp:157] Top shape: 64 3 200 200 (7680000)
I0819 09:16:19.731482 24477 net.cpp:165] Memory required for data: 102400000
I0819 09:16:19.731485 24477 layer_factory.hpp:77] Creating layer label_data_1_split
I0819 09:16:19.731494 24477 net.cpp:100] Creating Layer label_data_1_split
I0819 09:16:19.731498 24477 net.cpp:434] label_data_1_split <- label
I0819 09:16:19.731503 24477 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0819 09:16:19.731508 24477 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0819 09:16:19.731544 24477 net.cpp:150] Setting up label_data_1_split
I0819 09:16:19.731549 24477 net.cpp:157] Top shape: 64 1 200 200 (2560000)
I0819 09:16:19.731552 24477 net.cpp:157] Top shape: 64 1 200 200 (2560000)
I0819 09:16:19.731555 24477 net.cpp:165] Memory required for data: 122880000
I0819 09:16:19.731559 24477 layer_factory.hpp:77] Creating layer conv1_1
I0819 09:16:19.731569 24477 net.cpp:100] Creating Layer conv1_1
I0819 09:16:19.731571 24477 net.cpp:434] conv1_1 <- image_data_0_split_0
I0819 09:16:19.731576 24477 net.cpp:408] conv1_1 -> conv1_1
I0819 09:16:19.731724 24477 net.cpp:150] Setting up conv1_1
I0819 09:16:19.731730 24477 net.cpp:157] Top shape: 64 8 298 298 (45467648)
I0819 09:16:19.731734 24477 net.cpp:165] Memory required for data: 304750592
I0819 09:16:19.731739 24477 layer_factory.hpp:77] Creating layer conv1_1_bn
I0819 09:16:19.731745 24477 net.cpp:100] Creating Layer conv1_1_bn
I0819 09:16:19.731748 24477 net.cpp:434] conv1_1_bn <- conv1_1
I0819 09:16:19.731753 24477 net.cpp:408] conv1_1_bn -> conv1_1_bn
I0819 09:16:19.731953 24477 net.cpp:150] Setting up conv1_1_bn
I0819 09:16:19.731961 24477 net.cpp:157] Top shape: 64 8 298 298 (45467648)
I0819 09:16:19.731962 24477 net.cpp:165] Memory required for data: 486621184
I0819 09:16:19.731971 24477 layer_factory.hpp:77] Creating layer conv1_1_bn_scale
I0819 09:16:19.731978 24477 net.cpp:100] Creating Layer conv1_1_bn_scale
I0819 09:16:19.731981 24477 net.cpp:434] conv1_1_bn_scale <- conv1_1_bn
I0819 09:16:19.731986 24477 net.cpp:395] conv1_1_bn_scale -> conv1_1_bn (in-place)
I0819 09:16:19.732014 24477 layer_factory.hpp:77] Creating layer conv1_1_bn_scale
I0819 09:16:19.732605 24477 net.cpp:150] Setting up conv1_1_bn_scale
I0819 09:16:19.732616 24477 net.cpp:157] Top shape: 64 8 298 298 (45467648)
I0819 09:16:19.732620 24477 net.cpp:165] Memory required for data: 668491776
I0819 09:16:19.732627 24477 layer_factory.hpp:77] Creating layer conv1_1_relu
I0819 09:16:19.732635 24477 net.cpp:100] Creating Layer conv1_1_relu
I0819 09:16:19.732637 24477 net.cpp:434] conv1_1_relu <- conv1_1_bn
I0819 09:16:19.732641 24477 net.cpp:395] conv1_1_relu -> conv1_1_bn (in-place)
I0819 09:16:19.732653 24477 net.cpp:150] Setting up conv1_1_relu
I0819 09:16:19.732664 24477 net.cpp:157] Top shape: 64 8 298 298 (45467648)
I0819 09:16:19.732666 24477 net.cpp:165] Memory required for data: 850362368
I0819 09:16:19.732669 24477 layer_factory.hpp:77] Creating layer pool1
I0819 09:16:19.732674 24477 net.cpp:100] Creating Layer pool1
I0819 09:16:19.732677 24477 net.cpp:434] pool1 <- conv1_1_bn
I0819 09:16:19.732693 24477 net.cpp:408] pool1 -> pool1
I0819 09:16:19.732772 24477 net.cpp:150] Setting up pool1
I0819 09:16:19.732780 24477 net.cpp:157] Top shape: 64 8 149 149 (11366912)
I0819 09:16:19.732784 24477 net.cpp:165] Memory required for data: 895830016
I0819 09:16:19.732786 24477 layer_factory.hpp:77] Creating layer conv2_1
I0819 09:16:19.732794 24477 net.cpp:100] Creating Layer conv2_1
I0819 09:16:19.732796 24477 net.cpp:434] conv2_1 <- pool1
I0819 09:16:19.732801 24477 net.cpp:408] conv2_1 -> conv2_1
I0819 09:16:19.736364 24477 net.cpp:150] Setting up conv2_1
I0819 09:16:19.736382 24477 net.cpp:157] Top shape: 64 16 149 149 (22733824)
I0819 09:16:19.736385 24477 net.cpp:165] Memory required for data: 986765312
I0819 09:16:19.736390 24477 layer_factory.hpp:77] Creating layer conv2_1_bn
I0819 09:16:19.736398 24477 net.cpp:100] Creating Layer conv2_1_bn
I0819 09:16:19.736402 24477 net.cpp:434] conv2_1_bn <- conv2_1
I0819 09:16:19.736407 24477 net.cpp:408] conv2_1_bn -> conv2_1_bn
I0819 09:16:19.736568 24477 net.cpp:150] Setting up conv2_1_bn
I0819 09:16:19.736574 24477 net.cpp:157] Top shape: 64 16 149 149 (22733824)
I0819 09:16:19.736577 24477 net.cpp:165] Memory required for data: 1077700608
I0819 09:16:19.736585 24477 layer_factory.hpp:77] Creating layer conv2_1_bn_scale
I0819 09:16:19.736591 24477 net.cpp:100] Creating Layer conv2_1_bn_scale
I0819 09:16:19.736594 24477 net.cpp:434] conv2_1_bn_scale <- conv2_1_bn
I0819 09:16:19.736599 24477 net.cpp:395] conv2_1_bn_scale -> conv2_1_bn (in-place)
I0819 09:16:19.736631 24477 layer_factory.hpp:77] Creating layer conv2_1_bn_scale
I0819 09:16:19.736742 24477 net.cpp:150] Setting up conv2_1_bn_scale
I0819 09:16:19.736747 24477 net.cpp:157] Top shape: 64 16 149 149 (22733824)
I0819 09:16:19.736749 24477 net.cpp:165] Memory required for data: 1168635904
I0819 09:16:19.736754 24477 layer_factory.hpp:77] Creating layer conv2_1_relu
I0819 09:16:19.736760 24477 net.cpp:100] Creating Layer conv2_1_relu
I0819 09:16:19.736763 24477 net.cpp:434] conv2_1_relu <- conv2_1_bn
I0819 09:16:19.736766 24477 net.cpp:395] conv2_1_relu -> conv2_1_bn (in-place)
I0819 09:16:19.736771 24477 net.cpp:150] Setting up conv2_1_relu
I0819 09:16:19.736775 24477 net.cpp:157] Top shape: 64 16 149 149 (22733824)
I0819 09:16:19.736778 24477 net.cpp:165] Memory required for data: 1259571200
I0819 09:16:19.736780 24477 layer_factory.hpp:77] Creating layer pool2
I0819 09:16:19.736786 24477 net.cpp:100] Creating Layer pool2
I0819 09:16:19.736789 24477 net.cpp:434] pool2 <- conv2_1_bn
I0819 09:16:19.736793 24477 net.cpp:408] pool2 -> pool2
I0819 09:16:19.736822 24477 net.cpp:150] Setting up pool2
I0819 09:16:19.736826 24477 net.cpp:157] Top shape: 64 16 75 75 (5760000)
I0819 09:16:19.736829 24477 net.cpp:165] Memory required for data: 1282611200
I0819 09:16:19.736831 24477 layer_factory.hpp:77] Creating layer conv3_1
I0819 09:16:19.736838 24477 net.cpp:100] Creating Layer conv3_1
I0819 09:16:19.736841 24477 net.cpp:434] conv3_1 <- pool2
I0819 09:16:19.736845 24477 net.cpp:408] conv3_1 -> conv3_1
I0819 09:16:19.737076 24477 net.cpp:150] Setting up conv3_1
I0819 09:16:19.737082 24477 net.cpp:157] Top shape: 64 32 75 75 (11520000)
I0819 09:16:19.737084 24477 net.cpp:165] Memory required for data: 1328691200
I0819 09:16:19.737087 24477 layer_factory.hpp:77] Creating layer conv3_1_bn
I0819 09:16:19.737094 24477 net.cpp:100] Creating Layer conv3_1_bn
I0819 09:16:19.737097 24477 net.cpp:434] conv3_1_bn <- conv3_1
I0819 09:16:19.737102 24477 net.cpp:408] conv3_1_bn -> conv3_1_bn
I0819 09:16:19.737262 24477 net.cpp:150] Setting up conv3_1_bn
I0819 09:16:19.737269 24477 net.cpp:157] Top shape: 64 32 75 75 (11520000)
I0819 09:16:19.737278 24477 net.cpp:165] Memory required for data: 1374771200
I0819 09:16:19.737292 24477 layer_factory.hpp:77] Creating layer conv3_1_bn_scale
I0819 09:16:19.737296 24477 net.cpp:100] Creating Layer conv3_1_bn_scale
I0819 09:16:19.737299 24477 net.cpp:434] conv3_1_bn_scale <- conv3_1_bn
I0819 09:16:19.737303 24477 net.cpp:395] conv3_1_bn_scale -> conv3_1_bn (in-place)
I0819 09:16:19.737334 24477 layer_factory.hpp:77] Creating layer conv3_1_bn_scale
I0819 09:16:19.737419 24477 net.cpp:150] Setting up conv3_1_bn_scale
I0819 09:16:19.737424 24477 net.cpp:157] Top shape: 64 32 75 75 (11520000)
I0819 09:16:19.737427 24477 net.cpp:165] Memory required for data: 1420851200
I0819 09:16:19.737435 24477 layer_factory.hpp:77] Creating layer conv3_1_relu
I0819 09:16:19.737442 24477 net.cpp:100] Creating Layer conv3_1_relu
I0819 09:16:19.737444 24477 net.cpp:434] conv3_1_relu <- conv3_1_bn
I0819 09:16:19.737449 24477 net.cpp:395] conv3_1_relu -> conv3_1_bn (in-place)
I0819 09:16:19.737454 24477 net.cpp:150] Setting up conv3_1_relu
I0819 09:16:19.737457 24477 net.cpp:157] Top shape: 64 32 75 75 (11520000)
I0819 09:16:19.737460 24477 net.cpp:165] Memory required for data: 1466931200
I0819 09:16:19.737463 24477 layer_factory.hpp:77] Creating layer pool3
I0819 09:16:19.737468 24477 net.cpp:100] Creating Layer pool3
I0819 09:16:19.737470 24477 net.cpp:434] pool3 <- conv3_1_bn
I0819 09:16:19.737475 24477 net.cpp:408] pool3 -> pool3
I0819 09:16:19.737503 24477 net.cpp:150] Setting up pool3
I0819 09:16:19.737506 24477 net.cpp:157] Top shape: 64 32 38 38 (2957312)
I0819 09:16:19.737509 24477 net.cpp:165] Memory required for data: 1478760448
I0819 09:16:19.737511 24477 layer_factory.hpp:77] Creating layer conv4_1
I0819 09:16:19.737517 24477 net.cpp:100] Creating Layer conv4_1
I0819 09:16:19.737520 24477 net.cpp:434] conv4_1 <- pool3
I0819 09:16:19.737526 24477 net.cpp:408] conv4_1 -> conv4_1
I0819 09:16:19.738057 24477 net.cpp:150] Setting up conv4_1
I0819 09:16:19.738065 24477 net.cpp:157] Top shape: 64 64 38 38 (5914624)
I0819 09:16:19.738067 24477 net.cpp:165] Memory required for data: 1502418944
I0819 09:16:19.738071 24477 layer_factory.hpp:77] Creating layer conv4_1_bn
I0819 09:16:19.738077 24477 net.cpp:100] Creating Layer conv4_1_bn
I0819 09:16:19.738080 24477 net.cpp:434] conv4_1_bn <- conv4_1
I0819 09:16:19.738085 24477 net.cpp:408] conv4_1_bn -> conv4_1_bn
I0819 09:16:19.738224 24477 net.cpp:150] Setting up conv4_1_bn
I0819 09:16:19.738230 24477 net.cpp:157] Top shape: 64 64 38 38 (5914624)
I0819 09:16:19.738234 24477 net.cpp:165] Memory required for data: 1526077440
I0819 09:16:19.738239 24477 layer_factory.hpp:77] Creating layer conv4_1_bn_scale
I0819 09:16:19.738243 24477 net.cpp:100] Creating Layer conv4_1_bn_scale
I0819 09:16:19.738246 24477 net.cpp:434] conv4_1_bn_scale <- conv4_1_bn
I0819 09:16:19.738250 24477 net.cpp:395] conv4_1_bn_scale -> conv4_1_bn (in-place)
I0819 09:16:19.738277 24477 layer_factory.hpp:77] Creating layer conv4_1_bn_scale
I0819 09:16:19.738363 24477 net.cpp:150] Setting up conv4_1_bn_scale
I0819 09:16:19.738369 24477 net.cpp:157] Top shape: 64 64 38 38 (5914624)
I0819 09:16:19.738371 24477 net.cpp:165] Memory required for data: 1549735936
I0819 09:16:19.738376 24477 layer_factory.hpp:77] Creating layer conv4_1_relu
I0819 09:16:19.738380 24477 net.cpp:100] Creating Layer conv4_1_relu
I0819 09:16:19.738384 24477 net.cpp:434] conv4_1_relu <- conv4_1_bn
I0819 09:16:19.738391 24477 net.cpp:395] conv4_1_relu -> conv4_1_bn (in-place)
I0819 09:16:19.738395 24477 net.cpp:150] Setting up conv4_1_relu
I0819 09:16:19.738399 24477 net.cpp:157] Top shape: 64 64 38 38 (5914624)
I0819 09:16:19.738401 24477 net.cpp:165] Memory required for data: 1573394432
I0819 09:16:19.738404 24477 layer_factory.hpp:77] Creating layer pool4
I0819 09:16:19.738409 24477 net.cpp:100] Creating Layer pool4
I0819 09:16:19.738411 24477 net.cpp:434] pool4 <- conv4_1_bn
I0819 09:16:19.738416 24477 net.cpp:408] pool4 -> pool4
I0819 09:16:19.738442 24477 net.cpp:150] Setting up pool4
I0819 09:16:19.738451 24477 net.cpp:157] Top shape: 64 64 19 19 (1478656)
I0819 09:16:19.738458 24477 net.cpp:165] Memory required for data: 1579309056
I0819 09:16:19.738461 24477 layer_factory.hpp:77] Creating layer conv5_1
I0819 09:16:19.738467 24477 net.cpp:100] Creating Layer conv5_1
I0819 09:16:19.738471 24477 net.cpp:434] conv5_1 <- pool4
I0819 09:16:19.738476 24477 net.cpp:408] conv5_1 -> conv5_1
I0819 09:16:19.739900 24477 net.cpp:150] Setting up conv5_1
I0819 09:16:19.739917 24477 net.cpp:157] Top shape: 64 64 17 17 (1183744)
I0819 09:16:19.739919 24477 net.cpp:165] Memory required for data: 1584044032
I0819 09:16:19.739925 24477 layer_factory.hpp:77] Creating layer conv5_1_bn
I0819 09:16:19.739933 24477 net.cpp:100] Creating Layer conv5_1_bn
I0819 09:16:19.739936 24477 net.cpp:434] conv5_1_bn <- conv5_1
I0819 09:16:19.739943 24477 net.cpp:408] conv5_1_bn -> conv5_1_bn
I0819 09:16:19.740089 24477 net.cpp:150] Setting up conv5_1_bn
I0819 09:16:19.740094 24477 net.cpp:157] Top shape: 64 64 17 17 (1183744)
I0819 09:16:19.740097 24477 net.cpp:165] Memory required for data: 1588779008
I0819 09:16:19.740103 24477 layer_factory.hpp:77] Creating layer conv5_1_bn_scale
I0819 09:16:19.740109 24477 net.cpp:100] Creating Layer conv5_1_bn_scale
I0819 09:16:19.740113 24477 net.cpp:434] conv5_1_bn_scale <- conv5_1_bn
I0819 09:16:19.740115 24477 net.cpp:395] conv5_1_bn_scale -> conv5_1_bn (in-place)
I0819 09:16:19.740144 24477 layer_factory.hpp:77] Creating layer conv5_1_bn_scale
I0819 09:16:19.740232 24477 net.cpp:150] Setting up conv5_1_bn_scale
I0819 09:16:19.740238 24477 net.cpp:157] Top shape: 64 64 17 17 (1183744)
I0819 09:16:19.740241 24477 net.cpp:165] Memory required for data: 1593513984
I0819 09:16:19.740245 24477 layer_factory.hpp:77] Creating layer conv5_1_relu
I0819 09:16:19.740252 24477 net.cpp:100] Creating Layer conv5_1_relu
I0819 09:16:19.740254 24477 net.cpp:434] conv5_1_relu <- conv5_1_bn
I0819 09:16:19.740257 24477 net.cpp:395] conv5_1_relu -> conv5_1_bn (in-place)
I0819 09:16:19.740262 24477 net.cpp:150] Setting up conv5_1_relu
I0819 09:16:19.740265 24477 net.cpp:157] Top shape: 64 64 17 17 (1183744)
I0819 09:16:19.740268 24477 net.cpp:165] Memory required for data: 1598248960
I0819 09:16:19.740270 24477 layer_factory.hpp:77] Creating layer conv6_1
I0819 09:16:19.740278 24477 net.cpp:100] Creating Layer conv6_1
I0819 09:16:19.740281 24477 net.cpp:434] conv6_1 <- conv5_1_bn
I0819 09:16:19.740286 24477 net.cpp:408] conv6_1 -> conv6_1
I0819 09:16:19.741199 24477 net.cpp:150] Setting up conv6_1
I0819 09:16:19.741205 24477 net.cpp:157] Top shape: 64 64 15 15 (921600)
I0819 09:16:19.741209 24477 net.cpp:165] Memory required for data: 1601935360
I0819 09:16:19.741212 24477 layer_factory.hpp:77] Creating layer conv6_1_bn
I0819 09:16:19.741219 24477 net.cpp:100] Creating Layer conv6_1_bn
I0819 09:16:19.741222 24477 net.cpp:434] conv6_1_bn <- conv6_1
I0819 09:16:19.741226 24477 net.cpp:408] conv6_1_bn -> conv6_1_bn
I0819 09:16:19.741369 24477 net.cpp:150] Setting up conv6_1_bn
I0819 09:16:19.741374 24477 net.cpp:157] Top shape: 64 64 15 15 (921600)
I0819 09:16:19.741377 24477 net.cpp:165] Memory required for data: 1605621760
I0819 09:16:19.741389 24477 layer_factory.hpp:77] Creating layer conv6_1_bn_scale
I0819 09:16:19.741395 24477 net.cpp:100] Creating Layer conv6_1_bn_scale
I0819 09:16:19.741397 24477 net.cpp:434] conv6_1_bn_scale <- conv6_1_bn
I0819 09:16:19.741401 24477 net.cpp:395] conv6_1_bn_scale -> conv6_1_bn (in-place)
I0819 09:16:19.741430 24477 layer_factory.hpp:77] Creating layer conv6_1_bn_scale
I0819 09:16:19.741509 24477 net.cpp:150] Setting up conv6_1_bn_scale
I0819 09:16:19.741514 24477 net.cpp:157] Top shape: 64 64 15 15 (921600)
I0819 09:16:19.741518 24477 net.cpp:165] Memory required for data: 1609308160
I0819 09:16:19.741521 24477 layer_factory.hpp:77] Creating layer conv6_1_relu
I0819 09:16:19.741528 24477 net.cpp:100] Creating Layer conv6_1_relu
I0819 09:16:19.741530 24477 net.cpp:434] conv6_1_relu <- conv6_1_bn
I0819 09:16:19.741534 24477 net.cpp:395] conv6_1_relu -> conv6_1_bn (in-place)
I0819 09:16:19.741546 24477 net.cpp:150] Setting up conv6_1_relu
I0819 09:16:19.741557 24477 net.cpp:157] Top shape: 64 64 15 15 (921600)
I0819 09:16:19.741560 24477 net.cpp:165] Memory required for data: 1612994560
I0819 09:16:19.741562 24477 layer_factory.hpp:77] Creating layer conv7_1
I0819 09:16:19.741569 24477 net.cpp:100] Creating Layer conv7_1
I0819 09:16:19.741571 24477 net.cpp:434] conv7_1 <- conv6_1_bn
I0819 09:16:19.741577 24477 net.cpp:408] conv7_1 -> conv7_1
I0819 09:16:19.743306 24477 net.cpp:150] Setting up conv7_1
I0819 09:16:19.743320 24477 net.cpp:157] Top shape: 64 128 13 13 (1384448)
I0819 09:16:19.743324 24477 net.cpp:165] Memory required for data: 1618532352
I0819 09:16:19.743329 24477 layer_factory.hpp:77] Creating layer conv7_1_bn
I0819 09:16:19.743340 24477 net.cpp:100] Creating Layer conv7_1_bn
I0819 09:16:19.743343 24477 net.cpp:434] conv7_1_bn <- conv7_1
I0819 09:16:19.743348 24477 net.cpp:408] conv7_1_bn -> conv7_1_bn
I0819 09:16:19.743490 24477 net.cpp:150] Setting up conv7_1_bn
I0819 09:16:19.743495 24477 net.cpp:157] Top shape: 64 128 13 13 (1384448)
I0819 09:16:19.743497 24477 net.cpp:165] Memory required for data: 1624070144
I0819 09:16:19.743504 24477 layer_factory.hpp:77] Creating layer conv7_1_bn_scale
I0819 09:16:19.743508 24477 net.cpp:100] Creating Layer conv7_1_bn_scale
I0819 09:16:19.743511 24477 net.cpp:434] conv7_1_bn_scale <- conv7_1_bn
I0819 09:16:19.743516 24477 net.cpp:395] conv7_1_bn_scale -> conv7_1_bn (in-place)
I0819 09:16:19.743544 24477 layer_factory.hpp:77] Creating layer conv7_1_bn_scale
I0819 09:16:19.743619 24477 net.cpp:150] Setting up conv7_1_bn_scale
I0819 09:16:19.743625 24477 net.cpp:157] Top shape: 64 128 13 13 (1384448)
I0819 09:16:19.743628 24477 net.cpp:165] Memory required for data: 1629607936
I0819 09:16:19.743633 24477 layer_factory.hpp:77] Creating layer conv7_1_relu
I0819 09:16:19.743638 24477 net.cpp:100] Creating Layer conv7_1_relu
I0819 09:16:19.743640 24477 net.cpp:434] conv7_1_relu <- conv7_1_bn
I0819 09:16:19.743644 24477 net.cpp:395] conv7_1_relu -> conv7_1_bn (in-place)
I0819 09:16:19.743649 24477 net.cpp:150] Setting up conv7_1_relu
I0819 09:16:19.743651 24477 net.cpp:157] Top shape: 64 128 13 13 (1384448)
I0819 09:16:19.743654 24477 net.cpp:165] Memory required for data: 1635145728
I0819 09:16:19.743656 24477 layer_factory.hpp:77] Creating layer score
I0819 09:16:19.743665 24477 net.cpp:100] Creating Layer score
I0819 09:16:19.743669 24477 net.cpp:434] score <- conv7_1_bn
I0819 09:16:19.743674 24477 net.cpp:408] score -> score
I0819 09:16:19.743857 24477 net.cpp:150] Setting up score
I0819 09:16:19.743862 24477 net.cpp:157] Top shape: 64 4 13 13 (43264)
I0819 09:16:19.743865 24477 net.cpp:165] Memory required for data: 1635318784
I0819 09:16:19.743870 24477 layer_factory.hpp:77] Creating layer upscore
I0819 09:16:19.743877 24477 net.cpp:100] Creating Layer upscore
I0819 09:16:19.743880 24477 net.cpp:434] upscore <- score
I0819 09:16:19.743885 24477 net.cpp:408] upscore -> upscore
I0819 09:16:19.744369 24477 net.cpp:150] Setting up upscore
I0819 09:16:19.744374 24477 net.cpp:157] Top shape: 64 4 224 224 (12845056)
I0819 09:16:19.744377 24477 net.cpp:165] Memory required for data: 1686699008
I0819 09:16:19.744380 24477 layer_factory.hpp:77] Creating layer cropscore
I0819 09:16:19.744387 24477 net.cpp:100] Creating Layer cropscore
I0819 09:16:19.744390 24477 net.cpp:434] cropscore <- upscore
I0819 09:16:19.744393 24477 net.cpp:434] cropscore <- image_data_0_split_1
I0819 09:16:19.744398 24477 net.cpp:408] cropscore -> cropscore
I0819 09:16:19.744415 24477 net.cpp:150] Setting up cropscore
I0819 09:16:19.744420 24477 net.cpp:157] Top shape: 64 4 200 200 (10240000)
I0819 09:16:19.744422 24477 net.cpp:165] Memory required for data: 1727659008
I0819 09:16:19.744424 24477 layer_factory.hpp:77] Creating layer cropscore_cropscore_0_split
I0819 09:16:19.744429 24477 net.cpp:100] Creating Layer cropscore_cropscore_0_split
I0819 09:16:19.744432 24477 net.cpp:434] cropscore_cropscore_0_split <- cropscore
I0819 09:16:19.744437 24477 net.cpp:408] cropscore_cropscore_0_split -> cropscore_cropscore_0_split_0
I0819 09:16:19.744449 24477 net.cpp:408] cropscore_cropscore_0_split -> cropscore_cropscore_0_split_1
I0819 09:16:19.744482 24477 net.cpp:150] Setting up cropscore_cropscore_0_split
I0819 09:16:19.744485 24477 net.cpp:157] Top shape: 64 4 200 200 (10240000)
I0819 09:16:19.744489 24477 net.cpp:157] Top shape: 64 4 200 200 (10240000)
I0819 09:16:19.744491 24477 net.cpp:165] Memory required for data: 1809579008
I0819 09:16:19.744494 24477 layer_factory.hpp:77] Creating layer loss
I0819 09:16:19.744500 24477 net.cpp:100] Creating Layer loss
I0819 09:16:19.744503 24477 net.cpp:434] loss <- cropscore_cropscore_0_split_0
I0819 09:16:19.744508 24477 net.cpp:434] loss <- label_data_1_split_0
I0819 09:16:19.744515 24477 net.cpp:408] loss -> loss
I0819 09:16:19.744521 24477 layer_factory.hpp:77] Creating layer loss
I0819 09:16:19.763530 24477 net.cpp:150] Setting up loss
I0819 09:16:19.763563 24477 net.cpp:157] Top shape: (1)
I0819 09:16:19.763566 24477 net.cpp:160]     with loss weight 1
I0819 09:16:19.763576 24477 net.cpp:165] Memory required for data: 1809579012
I0819 09:16:19.763581 24477 layer_factory.hpp:77] Creating layer accuracy
I0819 09:16:19.763589 24477 net.cpp:100] Creating Layer accuracy
I0819 09:16:19.763594 24477 net.cpp:434] accuracy <- cropscore_cropscore_0_split_1
I0819 09:16:19.763602 24477 net.cpp:434] accuracy <- label_data_1_split_1
I0819 09:16:19.763607 24477 net.cpp:408] accuracy -> accuracy
I0819 09:16:19.763615 24477 net.cpp:150] Setting up accuracy
I0819 09:16:19.763619 24477 net.cpp:157] Top shape: (1)
I0819 09:16:19.763622 24477 net.cpp:165] Memory required for data: 1809579016
I0819 09:16:19.763624 24477 net.cpp:228] accuracy does not need backward computation.
I0819 09:16:19.763628 24477 net.cpp:226] loss needs backward computation.
I0819 09:16:19.763630 24477 net.cpp:226] cropscore_cropscore_0_split needs backward computation.
I0819 09:16:19.763633 24477 net.cpp:226] cropscore needs backward computation.
I0819 09:16:19.763636 24477 net.cpp:226] upscore needs backward computation.
I0819 09:16:19.763639 24477 net.cpp:226] score needs backward computation.
I0819 09:16:19.763643 24477 net.cpp:226] conv7_1_relu needs backward computation.
I0819 09:16:19.763645 24477 net.cpp:226] conv7_1_bn_scale needs backward computation.
I0819 09:16:19.763648 24477 net.cpp:226] conv7_1_bn needs backward computation.
I0819 09:16:19.763651 24477 net.cpp:226] conv7_1 needs backward computation.
I0819 09:16:19.763654 24477 net.cpp:226] conv6_1_relu needs backward computation.
I0819 09:16:19.763658 24477 net.cpp:226] conv6_1_bn_scale needs backward computation.
I0819 09:16:19.763659 24477 net.cpp:226] conv6_1_bn needs backward computation.
I0819 09:16:19.763662 24477 net.cpp:226] conv6_1 needs backward computation.
I0819 09:16:19.763665 24477 net.cpp:226] conv5_1_relu needs backward computation.
I0819 09:16:19.763669 24477 net.cpp:226] conv5_1_bn_scale needs backward computation.
I0819 09:16:19.763670 24477 net.cpp:226] conv5_1_bn needs backward computation.
I0819 09:16:19.763674 24477 net.cpp:226] conv5_1 needs backward computation.
I0819 09:16:19.763676 24477 net.cpp:226] pool4 needs backward computation.
I0819 09:16:19.763679 24477 net.cpp:226] conv4_1_relu needs backward computation.
I0819 09:16:19.763682 24477 net.cpp:226] conv4_1_bn_scale needs backward computation.
I0819 09:16:19.763684 24477 net.cpp:226] conv4_1_bn needs backward computation.
I0819 09:16:19.763687 24477 net.cpp:226] conv4_1 needs backward computation.
I0819 09:16:19.763691 24477 net.cpp:226] pool3 needs backward computation.
I0819 09:16:19.763694 24477 net.cpp:226] conv3_1_relu needs backward computation.
I0819 09:16:19.763696 24477 net.cpp:226] conv3_1_bn_scale needs backward computation.
I0819 09:16:19.763700 24477 net.cpp:226] conv3_1_bn needs backward computation.
I0819 09:16:19.763702 24477 net.cpp:226] conv3_1 needs backward computation.
I0819 09:16:19.763705 24477 net.cpp:226] pool2 needs backward computation.
I0819 09:16:19.763708 24477 net.cpp:226] conv2_1_relu needs backward computation.
I0819 09:16:19.763720 24477 net.cpp:226] conv2_1_bn_scale needs backward computation.
I0819 09:16:19.763730 24477 net.cpp:226] conv2_1_bn needs backward computation.
I0819 09:16:19.763732 24477 net.cpp:226] conv2_1 needs backward computation.
I0819 09:16:19.763736 24477 net.cpp:226] pool1 needs backward computation.
I0819 09:16:19.763739 24477 net.cpp:226] conv1_1_relu needs backward computation.
I0819 09:16:19.763742 24477 net.cpp:226] conv1_1_bn_scale needs backward computation.
I0819 09:16:19.763744 24477 net.cpp:226] conv1_1_bn needs backward computation.
I0819 09:16:19.763747 24477 net.cpp:226] conv1_1 needs backward computation.
I0819 09:16:19.763751 24477 net.cpp:228] label_data_1_split does not need backward computation.
I0819 09:16:19.763754 24477 net.cpp:228] image_data_0_split does not need backward computation.
I0819 09:16:19.763757 24477 net.cpp:228] data does not need backward computation.
I0819 09:16:19.763761 24477 net.cpp:270] This network produces output accuracy
I0819 09:16:19.763763 24477 net.cpp:270] This network produces output loss
I0819 09:16:19.763782 24477 net.cpp:283] Network initialization done.
I0819 09:16:19.763896 24477 solver.cpp:60] Solver scaffolding done.
I0819 09:16:19.764976 24477 caffe.cpp:251] Starting Optimization
I0819 09:16:19.764983 24477 solver.cpp:279] Solving segmentation
I0819 09:16:19.764986 24477 solver.cpp:280] Learning Rate Policy: step
I0819 09:16:19.766116 24477 solver.cpp:337] Iteration 0, Testing net (#0)
I0819 09:16:26.491838 24477 solver.cpp:454] Snapshotting to binary proto file portrait_one_stage_iter_0.caffemodel
I0819 09:16:26.495056 24477 sgd_solver.cpp:273] Snapshotting solver state to binary proto file portrait_one_stage_iter_0.solverstate
I0819 09:16:27.516723 24477 solver.cpp:404]     Test net output #0: accuracy = 0.251015
I0819 09:16:27.516760 24477 solver.cpp:404]     Test net output #1: loss = 2.61655e+06 (* 1 = 2.61655e+06 loss)
I0819 09:16:29.192263 24477 solver.cpp:228] Iteration 0, loss = 55452.1
I0819 09:16:29.192294 24477 solver.cpp:244]     Train net output #0: accuracy = 0.251135
I0819 09:16:29.192303 24477 solver.cpp:244]     Train net output #1: loss = 55452.1 (* 1 = 55452.1 loss)
I0819 09:16:29.192314 24477 sgd_solver.cpp:106] Iteration 0, lr = 1e-05
I0819 09:17:54.054316 24477 solver.cpp:228] Iteration 50, loss = 39931.8
I0819 09:17:54.054380 24477 solver.cpp:244]     Train net output #0: accuracy = 0.509075
I0819 09:17:54.054390 24477 solver.cpp:244]     Train net output #1: loss = 39931.8 (* 1 = 39931.8 loss)
I0819 09:17:54.054396 24477 sgd_solver.cpp:106] Iteration 50, lr = 1e-05
I0819 09:19:18.820610 24477 solver.cpp:228] Iteration 100, loss = 24516.3
I0819 09:19:18.820701 24477 solver.cpp:244]     Train net output #0: accuracy = 0.812174
I0819 09:19:18.820713 24477 solver.cpp:244]     Train net output #1: loss = 24516.3 (* 1 = 24516.3 loss)
I0819 09:19:18.820719 24477 sgd_solver.cpp:106] Iteration 100, lr = 1e-05
I0819 09:20:43.708411 24477 solver.cpp:228] Iteration 150, loss = 28732.6
I0819 09:20:43.708503 24477 solver.cpp:244]     Train net output #0: accuracy = 0.69766
I0819 09:20:43.708513 24477 solver.cpp:244]     Train net output #1: loss = 28732.6 (* 1 = 28732.6 loss)
I0819 09:20:43.708520 24477 sgd_solver.cpp:106] Iteration 150, lr = 1e-05
I0819 09:22:07.275971 24477 solver.cpp:337] Iteration 200, Testing net (#0)
I0819 09:22:14.765992 24477 solver.cpp:404]     Test net output #0: accuracy = 0.579536
I0819 09:22:14.766031 24477 solver.cpp:404]     Test net output #1: loss = 60028.8 (* 1 = 60028.8 loss)
I0819 09:22:16.151942 24477 solver.cpp:228] Iteration 200, loss = 20453.7
I0819 09:22:16.151976 24477 solver.cpp:244]     Train net output #0: accuracy = 0.824507
I0819 09:22:16.151984 24477 solver.cpp:244]     Train net output #1: loss = 20453.7 (* 1 = 20453.7 loss)
I0819 09:22:16.151991 24477 sgd_solver.cpp:106] Iteration 200, lr = 1e-05
I0819 09:23:41.153921 24477 solver.cpp:228] Iteration 250, loss = 22275.4
I0819 09:23:41.154042 24477 solver.cpp:244]     Train net output #0: accuracy = 0.743281
I0819 09:23:41.154053 24477 solver.cpp:244]     Train net output #1: loss = 22275.4 (* 1 = 22275.4 loss)
I0819 09:23:41.154063 24477 sgd_solver.cpp:106] Iteration 250, lr = 1e-05
I0819 09:25:06.202082 24477 solver.cpp:228] Iteration 300, loss = 18208
I0819 09:25:06.202178 24477 solver.cpp:244]     Train net output #0: accuracy = 0.833878
I0819 09:25:06.202188 24477 solver.cpp:244]     Train net output #1: loss = 18208 (* 1 = 18208 loss)
I0819 09:25:06.202194 24477 sgd_solver.cpp:106] Iteration 300, lr = 1e-05
I0819 09:26:31.293709 24477 solver.cpp:228] Iteration 350, loss = 20998.6
I0819 09:26:31.293802 24477 solver.cpp:244]     Train net output #0: accuracy = 0.78662
I0819 09:26:31.293813 24477 solver.cpp:244]     Train net output #1: loss = 20998.6 (* 1 = 20998.6 loss)
I0819 09:26:31.293820 24477 sgd_solver.cpp:106] Iteration 350, lr = 1e-05
I0819 09:27:54.942178 24477 solver.cpp:337] Iteration 400, Testing net (#0)
I0819 09:28:02.418325 24477 solver.cpp:404]     Test net output #0: accuracy = 0.728496
I0819 09:28:02.418361 24477 solver.cpp:404]     Test net output #1: loss = 31154.3 (* 1 = 31154.3 loss)
I0819 09:28:03.813525 24477 solver.cpp:228] Iteration 400, loss = 20103.9
I0819 09:28:03.813560 24477 solver.cpp:244]     Train net output #0: accuracy = 0.792857
I0819 09:28:03.813568 24477 solver.cpp:244]     Train net output #1: loss = 20103.9 (* 1 = 20103.9 loss)
I0819 09:28:03.813575 24477 sgd_solver.cpp:106] Iteration 400, lr = 1e-05
I0819 09:29:28.884996 24477 solver.cpp:228] Iteration 450, loss = 20035
I0819 09:29:28.885088 24477 solver.cpp:244]     Train net output #0: accuracy = 0.769758
I0819 09:29:28.885099 24477 solver.cpp:244]     Train net output #1: loss = 20035 (* 1 = 20035 loss)
I0819 09:29:28.885105 24477 sgd_solver.cpp:106] Iteration 450, lr = 1e-05
I0819 09:30:54.087466 24477 solver.cpp:228] Iteration 500, loss = 24382.3
I0819 09:30:54.087534 24477 solver.cpp:244]     Train net output #0: accuracy = 0.757233
I0819 09:30:54.087544 24477 solver.cpp:244]     Train net output #1: loss = 24382.3 (* 1 = 24382.3 loss)
I0819 09:30:54.087551 24477 sgd_solver.cpp:106] Iteration 500, lr = 1e-05
I0819 09:32:19.274442 24477 solver.cpp:228] Iteration 550, loss = 14975.4
I0819 09:32:19.274533 24477 solver.cpp:244]     Train net output #0: accuracy = 0.853272
I0819 09:32:19.274544 24477 solver.cpp:244]     Train net output #1: loss = 14975.4 (* 1 = 14975.4 loss)
I0819 09:32:19.274551 24477 sgd_solver.cpp:106] Iteration 550, lr = 1e-05
I0819 09:33:42.985397 24477 solver.cpp:337] Iteration 600, Testing net (#0)
I0819 09:33:50.465392 24477 solver.cpp:404]     Test net output #0: accuracy = 0.682626
I0819 09:33:50.465432 24477 solver.cpp:404]     Test net output #1: loss = 38359.8 (* 1 = 38359.8 loss)
I0819 09:33:51.858808 24477 solver.cpp:228] Iteration 600, loss = 18942.6
I0819 09:33:51.858839 24477 solver.cpp:244]     Train net output #0: accuracy = 0.817952
I0819 09:33:51.858849 24477 solver.cpp:244]     Train net output #1: loss = 18942.6 (* 1 = 18942.6 loss)
I0819 09:33:51.858855 24477 sgd_solver.cpp:106] Iteration 600, lr = 1e-05
I0819 09:35:17.032280 24477 solver.cpp:228] Iteration 650, loss = 14363.1
I0819 09:35:17.032371 24477 solver.cpp:244]     Train net output #0: accuracy = 0.861397
I0819 09:35:17.032382 24477 solver.cpp:244]     Train net output #1: loss = 14363.1 (* 1 = 14363.1 loss)
I0819 09:35:17.032388 24477 sgd_solver.cpp:106] Iteration 650, lr = 1e-05
I0819 09:36:42.216111 24477 solver.cpp:228] Iteration 700, loss = 13282
I0819 09:36:42.216184 24477 solver.cpp:244]     Train net output #0: accuracy = 0.871953
I0819 09:36:42.216195 24477 solver.cpp:244]     Train net output #1: loss = 13282 (* 1 = 13282 loss)
I0819 09:36:42.216202 24477 sgd_solver.cpp:106] Iteration 700, lr = 1e-05
I0819 09:38:07.325975 24477 solver.cpp:228] Iteration 750, loss = 16033.2
I0819 09:38:07.326067 24477 solver.cpp:244]     Train net output #0: accuracy = 0.851498
I0819 09:38:07.326078 24477 solver.cpp:244]     Train net output #1: loss = 16033.2 (* 1 = 16033.2 loss)
I0819 09:38:07.326084 24477 sgd_solver.cpp:106] Iteration 750, lr = 1e-05
I0819 09:39:31.031033 24477 solver.cpp:337] Iteration 800, Testing net (#0)
I0819 09:39:38.555704 24477 solver.cpp:404]     Test net output #0: accuracy = 0.68174
I0819 09:39:38.555742 24477 solver.cpp:404]     Test net output #1: loss = 35121 (* 1 = 35121 loss)
I0819 09:39:39.945039 24477 solver.cpp:228] Iteration 800, loss = 15035.7
I0819 09:39:39.945072 24477 solver.cpp:244]     Train net output #0: accuracy = 0.849794
I0819 09:39:39.945080 24477 solver.cpp:244]     Train net output #1: loss = 15035.7 (* 1 = 15035.7 loss)
I0819 09:39:39.945087 24477 sgd_solver.cpp:106] Iteration 800, lr = 1e-05
I0819 09:41:05.086271 24477 solver.cpp:228] Iteration 850, loss = 15907.7
I0819 09:41:05.086364 24477 solver.cpp:244]     Train net output #0: accuracy = 0.834743
I0819 09:41:05.086375 24477 solver.cpp:244]     Train net output #1: loss = 15907.7 (* 1 = 15907.7 loss)
I0819 09:41:05.086381 24477 sgd_solver.cpp:106] Iteration 850, lr = 1e-05
I0819 09:42:30.190572 24477 solver.cpp:228] Iteration 900, loss = 11332.8
I0819 09:42:30.190663 24477 solver.cpp:244]     Train net output #0: accuracy = 0.891125
I0819 09:42:30.190675 24477 solver.cpp:244]     Train net output #1: loss = 11332.8 (* 1 = 11332.8 loss)
I0819 09:42:30.190681 24477 sgd_solver.cpp:106] Iteration 900, lr = 1e-05
I0819 09:43:55.261026 24477 solver.cpp:228] Iteration 950, loss = 14495
I0819 09:43:55.261116 24477 solver.cpp:244]     Train net output #0: accuracy = 0.855293
I0819 09:43:55.261126 24477 solver.cpp:244]     Train net output #1: loss = 14495 (* 1 = 14495 loss)
I0819 09:43:55.261132 24477 sgd_solver.cpp:106] Iteration 950, lr = 1e-05
I0819 09:45:19.031558 24477 solver.cpp:337] Iteration 1000, Testing net (#0)
I0819 09:45:26.509279 24477 solver.cpp:404]     Test net output #0: accuracy = 0.713896
I0819 09:45:26.509318 24477 solver.cpp:404]     Test net output #1: loss = 30317.9 (* 1 = 30317.9 loss)
I0819 09:45:27.901285 24477 solver.cpp:228] Iteration 1000, loss = 8856.35
I0819 09:45:27.901319 24477 solver.cpp:244]     Train net output #0: accuracy = 0.91605
I0819 09:45:27.901327 24477 solver.cpp:244]     Train net output #1: loss = 8856.35 (* 1 = 8856.35 loss)
I0819 09:45:27.901334 24477 sgd_solver.cpp:106] Iteration 1000, lr = 1e-05
I0819 09:46:53.278079 24477 solver.cpp:228] Iteration 1050, loss = 13217.2
I0819 09:46:53.278167 24477 solver.cpp:244]     Train net output #0: accuracy = 0.875243
I0819 09:46:53.278178 24477 solver.cpp:244]     Train net output #1: loss = 13217.2 (* 1 = 13217.2 loss)
I0819 09:46:53.278185 24477 sgd_solver.cpp:106] Iteration 1050, lr = 1e-05
I0819 09:48:18.727824 24477 solver.cpp:228] Iteration 1100, loss = 11406.7
I0819 09:48:18.727910 24477 solver.cpp:244]     Train net output #0: accuracy = 0.88998
I0819 09:48:18.727921 24477 solver.cpp:244]     Train net output #1: loss = 11406.7 (* 1 = 11406.7 loss)
I0819 09:48:18.727927 24477 sgd_solver.cpp:106] Iteration 1100, lr = 1e-05
I0819 09:49:44.179209 24477 solver.cpp:228] Iteration 1150, loss = 9644.45
I0819 09:49:44.179291 24477 solver.cpp:244]     Train net output #0: accuracy = 0.909786
I0819 09:49:44.179301 24477 solver.cpp:244]     Train net output #1: loss = 9644.45 (* 1 = 9644.45 loss)
I0819 09:49:44.179307 24477 sgd_solver.cpp:106] Iteration 1150, lr = 1e-05
I0819 09:51:08.272322 24477 solver.cpp:337] Iteration 1200, Testing net (#0)
I0819 09:51:15.742527 24477 solver.cpp:404]     Test net output #0: accuracy = 0.608872
I0819 09:51:15.742565 24477 solver.cpp:404]     Test net output #1: loss = 43708.2 (* 1 = 43708.2 loss)
I0819 09:51:17.141101 24477 solver.cpp:228] Iteration 1200, loss = 10984.5
I0819 09:51:17.141134 24477 solver.cpp:244]     Train net output #0: accuracy = 0.891926
I0819 09:51:17.141142 24477 solver.cpp:244]     Train net output #1: loss = 10984.5 (* 1 = 10984.5 loss)
I0819 09:51:17.141149 24477 sgd_solver.cpp:106] Iteration 1200, lr = 1e-05
I0819 09:52:42.589828 24477 solver.cpp:228] Iteration 1250, loss = 8420.03
I0819 09:52:42.589901 24477 solver.cpp:244]     Train net output #0: accuracy = 0.919885
I0819 09:52:42.589912 24477 solver.cpp:244]     Train net output #1: loss = 8420.03 (* 1 = 8420.03 loss)
I0819 09:52:42.589927 24477 sgd_solver.cpp:106] Iteration 1250, lr = 1e-05
I0819 09:54:08.486857 24477 solver.cpp:228] Iteration 1300, loss = 10450.7
I0819 09:54:08.486959 24477 solver.cpp:244]     Train net output #0: accuracy = 0.896812
I0819 09:54:08.486971 24477 solver.cpp:244]     Train net output #1: loss = 10450.7 (* 1 = 10450.7 loss)
I0819 09:54:08.486979 24477 sgd_solver.cpp:106] Iteration 1300, lr = 1e-05
I0819 09:55:34.759476 24477 solver.cpp:228] Iteration 1350, loss = 7292.85
I0819 09:55:34.759560 24477 solver.cpp:244]     Train net output #0: accuracy = 0.929294
I0819 09:55:34.759572 24477 solver.cpp:244]     Train net output #1: loss = 7292.85 (* 1 = 7292.85 loss)
I0819 09:55:34.759579 24477 sgd_solver.cpp:106] Iteration 1350, lr = 1e-05
I0819 09:56:58.915541 24477 solver.cpp:337] Iteration 1400, Testing net (#0)
I0819 09:57:06.393635 24477 solver.cpp:404]     Test net output #0: accuracy = 0.657542
I0819 09:57:06.393674 24477 solver.cpp:404]     Test net output #1: loss = 37275.5 (* 1 = 37275.5 loss)
I0819 09:57:07.795586 24477 solver.cpp:228] Iteration 1400, loss = 11436.9
I0819 09:57:07.795617 24477 solver.cpp:244]     Train net output #0: accuracy = 0.882513
I0819 09:57:07.795626 24477 solver.cpp:244]     Train net output #1: loss = 11436.9 (* 1 = 11436.9 loss)
I0819 09:57:07.795632 24477 sgd_solver.cpp:106] Iteration 1400, lr = 1e-05
I0819 09:58:33.217972 24477 solver.cpp:228] Iteration 1450, loss = 6779.38
I0819 09:58:33.218017 24477 solver.cpp:244]     Train net output #0: accuracy = 0.935488
I0819 09:58:33.218027 24477 solver.cpp:244]     Train net output #1: loss = 6779.38 (* 1 = 6779.38 loss)
I0819 09:58:33.218034 24477 sgd_solver.cpp:106] Iteration 1450, lr = 1e-05
I0819 09:59:58.657335 24477 solver.cpp:228] Iteration 1500, loss = 10151.2
I0819 09:59:58.657407 24477 solver.cpp:244]     Train net output #0: accuracy = 0.901584
I0819 09:59:58.657416 24477 solver.cpp:244]     Train net output #1: loss = 10151.2 (* 1 = 10151.2 loss)
I0819 09:59:58.657423 24477 sgd_solver.cpp:106] Iteration 1500, lr = 1e-05
I0819 10:01:24.046983 24477 solver.cpp:228] Iteration 1550, loss = 11863.3
I0819 10:01:24.047052 24477 solver.cpp:244]     Train net output #0: accuracy = 0.886674
I0819 10:01:24.047063 24477 solver.cpp:244]     Train net output #1: loss = 11863.3 (* 1 = 11863.3 loss)
I0819 10:01:24.047070 24477 sgd_solver.cpp:106] Iteration 1550, lr = 1e-05
I0819 10:02:48.040143 24477 solver.cpp:337] Iteration 1600, Testing net (#0)
I0819 10:02:55.529160 24477 solver.cpp:404]     Test net output #0: accuracy = 0.735897
I0819 10:02:55.529201 24477 solver.cpp:404]     Test net output #1: loss = 27473.5 (* 1 = 27473.5 loss)
I0819 10:02:56.919404 24477 solver.cpp:228] Iteration 1600, loss = 7787.66
I0819 10:02:56.919437 24477 solver.cpp:244]     Train net output #0: accuracy = 0.926497
I0819 10:02:56.919446 24477 solver.cpp:244]     Train net output #1: loss = 7787.66 (* 1 = 7787.66 loss)
I0819 10:02:56.919452 24477 sgd_solver.cpp:106] Iteration 1600, lr = 1e-05
I0819 10:04:22.278479 24477 solver.cpp:228] Iteration 1650, loss = 7848.24
I0819 10:04:22.278550 24477 solver.cpp:244]     Train net output #0: accuracy = 0.922647
I0819 10:04:22.278560 24477 solver.cpp:244]     Train net output #1: loss = 7848.24 (* 1 = 7848.24 loss)
I0819 10:04:22.278568 24477 sgd_solver.cpp:106] Iteration 1650, lr = 1e-05
I0819 10:05:47.650144 24477 solver.cpp:228] Iteration 1700, loss = 6287.3
I0819 10:05:47.650235 24477 solver.cpp:244]     Train net output #0: accuracy = 0.941116
I0819 10:05:47.650246 24477 solver.cpp:244]     Train net output #1: loss = 6287.3 (* 1 = 6287.3 loss)
I0819 10:05:47.650252 24477 sgd_solver.cpp:106] Iteration 1700, lr = 1e-05
I0819 10:07:12.997233 24477 solver.cpp:228] Iteration 1750, loss = 8536.11
I0819 10:07:12.997305 24477 solver.cpp:244]     Train net output #0: accuracy = 0.915258
I0819 10:07:12.997315 24477 solver.cpp:244]     Train net output #1: loss = 8536.11 (* 1 = 8536.11 loss)
I0819 10:07:12.997321 24477 sgd_solver.cpp:106] Iteration 1750, lr = 1e-05
I0819 10:08:36.943395 24477 solver.cpp:337] Iteration 1800, Testing net (#0)
I0819 10:08:44.409708 24477 solver.cpp:404]     Test net output #0: accuracy = 0.698009
I0819 10:08:44.409747 24477 solver.cpp:404]     Test net output #1: loss = 31810.1 (* 1 = 31810.1 loss)
I0819 10:08:45.801645 24477 solver.cpp:228] Iteration 1800, loss = 5171.15
I0819 10:08:45.801677 24477 solver.cpp:244]     Train net output #0: accuracy = 0.949884
I0819 10:08:45.801687 24477 solver.cpp:244]     Train net output #1: loss = 5171.15 (* 1 = 5171.15 loss)
I0819 10:08:45.801693 24477 sgd_solver.cpp:106] Iteration 1800, lr = 1e-05
I0819 10:10:11.160694 24477 solver.cpp:228] Iteration 1850, loss = 10931.4
I0819 10:10:11.160771 24477 solver.cpp:244]     Train net output #0: accuracy = 0.890715
I0819 10:10:11.160781 24477 solver.cpp:244]     Train net output #1: loss = 10931.4 (* 1 = 10931.4 loss)
I0819 10:10:11.160789 24477 sgd_solver.cpp:106] Iteration 1850, lr = 1e-05
I0819 10:11:36.475826 24477 solver.cpp:228] Iteration 1900, loss = 9757.75
I0819 10:11:36.475896 24477 solver.cpp:244]     Train net output #0: accuracy = 0.903974
I0819 10:11:36.475908 24477 solver.cpp:244]     Train net output #1: loss = 9757.75 (* 1 = 9757.75 loss)
I0819 10:11:36.475914 24477 sgd_solver.cpp:106] Iteration 1900, lr = 1e-05
I0819 10:13:01.873518 24477 solver.cpp:228] Iteration 1950, loss = 6154.32
I0819 10:13:01.873564 24477 solver.cpp:244]     Train net output #0: accuracy = 0.942699
I0819 10:13:01.873574 24477 solver.cpp:244]     Train net output #1: loss = 6154.32 (* 1 = 6154.32 loss)
I0819 10:13:01.873580 24477 sgd_solver.cpp:106] Iteration 1950, lr = 1e-05
I0819 10:14:25.849762 24477 solver.cpp:454] Snapshotting to binary proto file portrait_one_stage_iter_2000.caffemodel
I0819 10:14:25.852391 24477 sgd_solver.cpp:273] Snapshotting solver state to binary proto file portrait_one_stage_iter_2000.solverstate
I0819 10:14:25.853368 24477 solver.cpp:337] Iteration 2000, Testing net (#0)
I0819 10:14:33.348631 24477 solver.cpp:404]     Test net output #0: accuracy = 0.830558
I0819 10:14:33.348670 24477 solver.cpp:404]     Test net output #1: loss = 18351.3 (* 1 = 18351.3 loss)
I0819 10:14:34.746374 24477 solver.cpp:228] Iteration 2000, loss = 11083.3
I0819 10:14:34.746407 24477 solver.cpp:244]     Train net output #0: accuracy = 0.889128
I0819 10:14:34.746417 24477 solver.cpp:244]     Train net output #1: loss = 11083.3 (* 1 = 11083.3 loss)
I0819 10:14:34.746423 24477 sgd_solver.cpp:106] Iteration 2000, lr = 1e-06
I0819 10:16:00.116956 24477 solver.cpp:228] Iteration 2050, loss = 6060.93
I0819 10:16:00.117050 24477 solver.cpp:244]     Train net output #0: accuracy = 0.942211
I0819 10:16:00.117060 24477 solver.cpp:244]     Train net output #1: loss = 6060.93 (* 1 = 6060.93 loss)
I0819 10:16:00.117068 24477 sgd_solver.cpp:106] Iteration 2050, lr = 1e-06
I0819 10:17:25.513842 24477 solver.cpp:228] Iteration 2100, loss = 9055.31
I0819 10:17:25.513932 24477 solver.cpp:244]     Train net output #0: accuracy = 0.91571
I0819 10:17:25.513943 24477 solver.cpp:244]     Train net output #1: loss = 9055.31 (* 1 = 9055.31 loss)
I0819 10:17:25.513949 24477 sgd_solver.cpp:106] Iteration 2100, lr = 1e-06
I0819 10:18:50.893307 24477 solver.cpp:228] Iteration 2150, loss = 4693.13
I0819 10:18:50.893396 24477 solver.cpp:244]     Train net output #0: accuracy = 0.955143
I0819 10:18:50.893407 24477 solver.cpp:244]     Train net output #1: loss = 4693.13 (* 1 = 4693.13 loss)
I0819 10:18:50.893414 24477 sgd_solver.cpp:106] Iteration 2150, lr = 1e-06
I0819 10:20:14.902434 24477 solver.cpp:337] Iteration 2200, Testing net (#0)
I0819 10:20:22.368003 24477 solver.cpp:404]     Test net output #0: accuracy = 0.84905
I0819 10:20:22.368044 24477 solver.cpp:404]     Test net output #1: loss = 15701 (* 1 = 15701 loss)
I0819 10:20:23.772220 24477 solver.cpp:228] Iteration 2200, loss = 8556.42
I0819 10:20:23.772253 24477 solver.cpp:244]     Train net output #0: accuracy = 0.917002
I0819 10:20:23.772261 24477 solver.cpp:244]     Train net output #1: loss = 8556.42 (* 1 = 8556.42 loss)
I0819 10:20:23.772267 24477 sgd_solver.cpp:106] Iteration 2200, lr = 1e-06
I0819 10:21:49.120395 24477 solver.cpp:228] Iteration 2250, loss = 6194.19
I0819 10:21:49.120503 24477 solver.cpp:244]     Train net output #0: accuracy = 0.938856
I0819 10:21:49.120515 24477 solver.cpp:244]     Train net output #1: loss = 6194.19 (* 1 = 6194.19 loss)
I0819 10:21:49.120522 24477 sgd_solver.cpp:106] Iteration 2250, lr = 1e-06
I0819 10:23:18.079563 24477 solver.cpp:228] Iteration 2300, loss = 5385.17
I0819 10:23:18.079648 24477 solver.cpp:244]     Train net output #0: accuracy = 0.948485
I0819 10:23:18.079658 24477 solver.cpp:244]     Train net output #1: loss = 5385.17 (* 1 = 5385.17 loss)
I0819 10:23:18.079665 24477 sgd_solver.cpp:106] Iteration 2300, lr = 1e-06
I0819 10:24:49.772702 24477 solver.cpp:228] Iteration 2350, loss = 9503.5
I0819 10:24:49.772800 24477 solver.cpp:244]     Train net output #0: accuracy = 0.905454
I0819 10:24:49.772812 24477 solver.cpp:244]     Train net output #1: loss = 9503.5 (* 1 = 9503.5 loss)
I0819 10:24:49.772819 24477 sgd_solver.cpp:106] Iteration 2350, lr = 1e-06
I0819 10:26:13.727704 24477 solver.cpp:337] Iteration 2400, Testing net (#0)
I0819 10:26:21.195727 24477 solver.cpp:404]     Test net output #0: accuracy = 0.869248
I0819 10:26:21.195766 24477 solver.cpp:404]     Test net output #1: loss = 13560.1 (* 1 = 13560.1 loss)
I0819 10:26:22.587322 24477 solver.cpp:228] Iteration 2400, loss = 5247.28
I0819 10:26:22.587353 24477 solver.cpp:244]     Train net output #0: accuracy = 0.948253
I0819 10:26:22.587363 24477 solver.cpp:244]     Train net output #1: loss = 5247.28 (* 1 = 5247.28 loss)
I0819 10:26:22.587368 24477 sgd_solver.cpp:106] Iteration 2400, lr = 1e-06
I0819 10:27:47.930553 24477 solver.cpp:228] Iteration 2450, loss = 10470.1
I0819 10:27:47.930629 24477 solver.cpp:244]     Train net output #0: accuracy = 0.90003
I0819 10:27:47.930639 24477 solver.cpp:244]     Train net output #1: loss = 10470.1 (* 1 = 10470.1 loss)
I0819 10:27:47.930646 24477 sgd_solver.cpp:106] Iteration 2450, lr = 1e-06
I0819 10:29:13.233145 24477 solver.cpp:228] Iteration 2500, loss = 5910.58
I0819 10:29:13.233234 24477 solver.cpp:244]     Train net output #0: accuracy = 0.942872
I0819 10:29:13.233245 24477 solver.cpp:244]     Train net output #1: loss = 5910.58 (* 1 = 5910.58 loss)
I0819 10:29:13.233252 24477 sgd_solver.cpp:106] Iteration 2500, lr = 1e-06
I0819 10:30:38.579208 24477 solver.cpp:228] Iteration 2550, loss = 7276.61
I0819 10:30:38.579291 24477 solver.cpp:244]     Train net output #0: accuracy = 0.929747
I0819 10:30:38.579303 24477 solver.cpp:244]     Train net output #1: loss = 7276.61 (* 1 = 7276.61 loss)
I0819 10:30:38.579309 24477 sgd_solver.cpp:106] Iteration 2550, lr = 1e-06
I0819 10:32:02.508646 24477 solver.cpp:337] Iteration 2600, Testing net (#0)
I0819 10:32:09.982970 24477 solver.cpp:404]     Test net output #0: accuracy = 0.888311
I0819 10:32:09.983008 24477 solver.cpp:404]     Test net output #1: loss = 11768.2 (* 1 = 11768.2 loss)
I0819 10:32:11.373934 24477 solver.cpp:228] Iteration 2600, loss = 5034.87
I0819 10:32:11.373965 24477 solver.cpp:244]     Train net output #0: accuracy = 0.952766
I0819 10:32:11.373973 24477 solver.cpp:244]     Train net output #1: loss = 5034.87 (* 1 = 5034.87 loss)
I0819 10:32:11.373980 24477 sgd_solver.cpp:106] Iteration 2600, lr = 1e-06
I0819 10:33:36.770964 24477 solver.cpp:228] Iteration 2650, loss = 7415.05
I0819 10:33:36.771054 24477 solver.cpp:244]     Train net output #0: accuracy = 0.927656
I0819 10:33:36.771064 24477 solver.cpp:244]     Train net output #1: loss = 7415.05 (* 1 = 7415.05 loss)
I0819 10:33:36.771071 24477 sgd_solver.cpp:106] Iteration 2650, lr = 1e-06
I0819 10:35:02.104065 24477 solver.cpp:228] Iteration 2700, loss = 7912.11
I0819 10:35:02.104146 24477 solver.cpp:244]     Train net output #0: accuracy = 0.921085
I0819 10:35:02.104156 24477 solver.cpp:244]     Train net output #1: loss = 7912.11 (* 1 = 7912.11 loss)
I0819 10:35:02.104163 24477 sgd_solver.cpp:106] Iteration 2700, lr = 1e-06
I0819 10:36:27.448770 24477 solver.cpp:228] Iteration 2750, loss = 5241.82
I0819 10:36:27.448894 24477 solver.cpp:244]     Train net output #0: accuracy = 0.949136
I0819 10:36:27.448905 24477 solver.cpp:244]     Train net output #1: loss = 5241.82 (* 1 = 5241.82 loss)
I0819 10:36:27.448911 24477 sgd_solver.cpp:106] Iteration 2750, lr = 1e-06
I0819 10:37:51.436875 24477 solver.cpp:337] Iteration 2800, Testing net (#0)
I0819 10:37:58.933779 24477 solver.cpp:404]     Test net output #0: accuracy = 0.897034
I0819 10:37:58.933818 24477 solver.cpp:404]     Test net output #1: loss = 10838.5 (* 1 = 10838.5 loss)
I0819 10:38:00.355522 24477 solver.cpp:228] Iteration 2800, loss = 11226.5
I0819 10:38:00.355551 24477 solver.cpp:244]     Train net output #0: accuracy = 0.889471
I0819 10:38:00.355561 24477 solver.cpp:244]     Train net output #1: loss = 11226.5 (* 1 = 11226.5 loss)
I0819 10:38:00.355566 24477 sgd_solver.cpp:106] Iteration 2800, lr = 1e-06
I0819 10:39:25.776659 24477 solver.cpp:228] Iteration 2850, loss = 5617.17
I0819 10:39:25.776736 24477 solver.cpp:244]     Train net output #0: accuracy = 0.946208
I0819 10:39:25.776748 24477 solver.cpp:244]     Train net output #1: loss = 5617.17 (* 1 = 5617.17 loss)
I0819 10:39:25.776754 24477 sgd_solver.cpp:106] Iteration 2850, lr = 1e-06
I0819 10:40:51.188202 24477 solver.cpp:228] Iteration 2900, loss = 10317.5
I0819 10:40:51.188272 24477 solver.cpp:244]     Train net output #0: accuracy = 0.90218
I0819 10:40:51.188283 24477 solver.cpp:244]     Train net output #1: loss = 10317.5 (* 1 = 10317.5 loss)
I0819 10:40:51.188289 24477 sgd_solver.cpp:106] Iteration 2900, lr = 1e-06
I0819 10:42:16.477254 24477 solver.cpp:228] Iteration 2950, loss = 6340.37
I0819 10:42:16.477344 24477 solver.cpp:244]     Train net output #0: accuracy = 0.939371
I0819 10:42:16.477355 24477 solver.cpp:244]     Train net output #1: loss = 6340.37 (* 1 = 6340.37 loss)
I0819 10:42:16.477361 24477 sgd_solver.cpp:106] Iteration 2950, lr = 1e-06
I0819 10:43:40.419759 24477 solver.cpp:337] Iteration 3000, Testing net (#0)
I0819 10:43:47.894606 24477 solver.cpp:404]     Test net output #0: accuracy = 0.911246
I0819 10:43:47.894645 24477 solver.cpp:404]     Test net output #1: loss = 9476.56 (* 1 = 9476.56 loss)
I0819 10:43:49.293848 24477 solver.cpp:228] Iteration 3000, loss = 6988.9
I0819 10:43:49.293879 24477 solver.cpp:244]     Train net output #0: accuracy = 0.930695
I0819 10:43:49.293887 24477 solver.cpp:244]     Train net output #1: loss = 6988.9 (* 1 = 6988.9 loss)
I0819 10:43:49.293895 24477 sgd_solver.cpp:106] Iteration 3000, lr = 1e-06
I0819 10:45:14.788216 24477 solver.cpp:228] Iteration 3050, loss = 7840.6
I0819 10:45:14.788306 24477 solver.cpp:244]     Train net output #0: accuracy = 0.925948
I0819 10:45:14.788316 24477 solver.cpp:244]     Train net output #1: loss = 7840.6 (* 1 = 7840.6 loss)
I0819 10:45:14.788323 24477 sgd_solver.cpp:106] Iteration 3050, lr = 1e-06
I0819 10:46:40.292625 24477 solver.cpp:228] Iteration 3100, loss = 4688.93
I0819 10:46:40.292697 24477 solver.cpp:244]     Train net output #0: accuracy = 0.954165
I0819 10:46:40.292707 24477 solver.cpp:244]     Train net output #1: loss = 4688.93 (* 1 = 4688.93 loss)
I0819 10:46:40.292713 24477 sgd_solver.cpp:106] Iteration 3100, lr = 1e-06
I0819 10:48:05.728333 24477 solver.cpp:228] Iteration 3150, loss = 7878.71
I0819 10:48:05.728409 24477 solver.cpp:244]     Train net output #0: accuracy = 0.92091
I0819 10:48:05.728418 24477 solver.cpp:244]     Train net output #1: loss = 7878.71 (* 1 = 7878.71 loss)
I0819 10:48:05.728425 24477 sgd_solver.cpp:106] Iteration 3150, lr = 1e-06
I0819 10:49:29.772119 24477 solver.cpp:337] Iteration 3200, Testing net (#0)
I0819 10:49:37.242455 24477 solver.cpp:404]     Test net output #0: accuracy = 0.913371
I0819 10:49:37.242496 24477 solver.cpp:404]     Test net output #1: loss = 9146.47 (* 1 = 9146.47 loss)
I0819 10:49:38.634572 24477 solver.cpp:228] Iteration 3200, loss = 5092.28
I0819 10:49:38.634604 24477 solver.cpp:244]     Train net output #0: accuracy = 0.948942
I0819 10:49:38.634613 24477 solver.cpp:244]     Train net output #1: loss = 5092.28 (* 1 = 5092.28 loss)
I0819 10:49:38.634631 24477 sgd_solver.cpp:106] Iteration 3200, lr = 1e-06
I0819 10:51:03.943328 24477 solver.cpp:228] Iteration 3250, loss = 9224.82
I0819 10:51:03.943425 24477 solver.cpp:244]     Train net output #0: accuracy = 0.909607
I0819 10:51:03.943436 24477 solver.cpp:244]     Train net output #1: loss = 9224.82 (* 1 = 9224.82 loss)
I0819 10:51:03.943442 24477 sgd_solver.cpp:106] Iteration 3250, lr = 1e-06
I0819 10:52:29.259100 24477 solver.cpp:228] Iteration 3300, loss = 5131.62
I0819 10:52:29.259196 24477 solver.cpp:244]     Train net output #0: accuracy = 0.950999
I0819 10:52:29.259207 24477 solver.cpp:244]     Train net output #1: loss = 5131.62 (* 1 = 5131.62 loss)
I0819 10:52:29.259214 24477 sgd_solver.cpp:106] Iteration 3300, lr = 1e-06
I0819 10:53:54.602957 24477 solver.cpp:228] Iteration 3350, loss = 8909.15
I0819 10:53:54.603044 24477 solver.cpp:244]     Train net output #0: accuracy = 0.915248
I0819 10:53:54.603055 24477 solver.cpp:244]     Train net output #1: loss = 8909.15 (* 1 = 8909.15 loss)
I0819 10:53:54.603061 24477 sgd_solver.cpp:106] Iteration 3350, lr = 1e-06
I0819 10:55:18.499929 24477 solver.cpp:337] Iteration 3400, Testing net (#0)
I0819 10:55:25.978394 24477 solver.cpp:404]     Test net output #0: accuracy = 0.919405
I0819 10:55:25.978432 24477 solver.cpp:404]     Test net output #1: loss = 8527.76 (* 1 = 8527.76 loss)
I0819 10:55:27.371156 24477 solver.cpp:228] Iteration 3400, loss = 7347.24
I0819 10:55:27.371188 24477 solver.cpp:244]     Train net output #0: accuracy = 0.929655
I0819 10:55:27.371197 24477 solver.cpp:244]     Train net output #1: loss = 7347.24 (* 1 = 7347.24 loss)
I0819 10:55:27.371203 24477 sgd_solver.cpp:106] Iteration 3400, lr = 1e-06
I0819 10:56:52.692766 24477 solver.cpp:228] Iteration 3450, loss = 5907.49
I0819 10:56:52.692838 24477 solver.cpp:244]     Train net output #0: accuracy = 0.944076
I0819 10:56:52.692849 24477 solver.cpp:244]     Train net output #1: loss = 5907.49 (* 1 = 5907.49 loss)
I0819 10:56:52.692855 24477 sgd_solver.cpp:106] Iteration 3450, lr = 1e-06
I0819 10:58:18.016253 24477 solver.cpp:228] Iteration 3500, loss = 7080.14
I0819 10:58:18.016329 24477 solver.cpp:244]     Train net output #0: accuracy = 0.931496
I0819 10:58:18.016338 24477 solver.cpp:244]     Train net output #1: loss = 7080.14 (* 1 = 7080.14 loss)
I0819 10:58:18.016345 24477 sgd_solver.cpp:106] Iteration 3500, lr = 1e-06
I0819 10:59:43.369496 24477 solver.cpp:228] Iteration 3550, loss = 4914.23
I0819 10:59:43.369572 24477 solver.cpp:244]     Train net output #0: accuracy = 0.952596
I0819 10:59:43.369583 24477 solver.cpp:244]     Train net output #1: loss = 4914.23 (* 1 = 4914.23 loss)
I0819 10:59:43.369590 24477 sgd_solver.cpp:106] Iteration 3550, lr = 1e-06
I0819 11:01:07.268411 24477 solver.cpp:337] Iteration 3600, Testing net (#0)
I0819 11:01:14.738291 24477 solver.cpp:404]     Test net output #0: accuracy = 0.916144
I0819 11:01:14.738328 24477 solver.cpp:404]     Test net output #1: loss = 8790.9 (* 1 = 8790.9 loss)
I0819 11:01:16.140111 24477 solver.cpp:228] Iteration 3600, loss = 8494.39
I0819 11:01:16.140146 24477 solver.cpp:244]     Train net output #0: accuracy = 0.917074
I0819 11:01:16.140154 24477 solver.cpp:244]     Train net output #1: loss = 8494.39 (* 1 = 8494.39 loss)
I0819 11:01:16.140161 24477 sgd_solver.cpp:106] Iteration 3600, lr = 1e-06
I0819 11:02:41.464131 24477 solver.cpp:228] Iteration 3650, loss = 5383.85
I0819 11:02:41.464223 24477 solver.cpp:244]     Train net output #0: accuracy = 0.945367
I0819 11:02:41.464234 24477 solver.cpp:244]     Train net output #1: loss = 5383.85 (* 1 = 5383.85 loss)
I0819 11:02:41.464241 24477 sgd_solver.cpp:106] Iteration 3650, lr = 1e-06
I0819 11:04:06.809293 24477 solver.cpp:228] Iteration 3700, loss = 8805.03
I0819 11:04:06.809384 24477 solver.cpp:244]     Train net output #0: accuracy = 0.912592
I0819 11:04:06.809396 24477 solver.cpp:244]     Train net output #1: loss = 8805.03 (* 1 = 8805.03 loss)
I0819 11:04:06.809401 24477 sgd_solver.cpp:106] Iteration 3700, lr = 1e-06
I0819 11:05:32.100695 24477 solver.cpp:228] Iteration 3750, loss = 4991.57
I0819 11:05:32.100814 24477 solver.cpp:244]     Train net output #0: accuracy = 0.953985
I0819 11:05:32.100826 24477 solver.cpp:244]     Train net output #1: loss = 4991.57 (* 1 = 4991.57 loss)
I0819 11:05:32.100832 24477 sgd_solver.cpp:106] Iteration 3750, lr = 1e-06
I0819 11:06:56.086092 24477 solver.cpp:337] Iteration 3800, Testing net (#0)
I0819 11:07:03.562446 24477 solver.cpp:404]     Test net output #0: accuracy = 0.919357
I0819 11:07:03.562486 24477 solver.cpp:404]     Test net output #1: loss = 8483.97 (* 1 = 8483.97 loss)
I0819 11:07:04.955032 24477 solver.cpp:228] Iteration 3800, loss = 7466.72
I0819 11:07:04.955065 24477 solver.cpp:244]     Train net output #0: accuracy = 0.928435
I0819 11:07:04.955075 24477 solver.cpp:244]     Train net output #1: loss = 7466.72 (* 1 = 7466.72 loss)
I0819 11:07:04.955080 24477 sgd_solver.cpp:106] Iteration 3800, lr = 1e-06
I0819 11:08:30.254482 24477 solver.cpp:228] Iteration 3850, loss = 9992.88
I0819 11:08:30.254555 24477 solver.cpp:244]     Train net output #0: accuracy = 0.901268
I0819 11:08:30.254566 24477 solver.cpp:244]     Train net output #1: loss = 9992.88 (* 1 = 9992.88 loss)
I0819 11:08:30.254573 24477 sgd_solver.cpp:106] Iteration 3850, lr = 1e-06
I0819 11:09:55.580212 24477 solver.cpp:228] Iteration 3900, loss = 5719.2
I0819 11:09:55.580281 24477 solver.cpp:244]     Train net output #0: accuracy = 0.945596
I0819 11:09:55.580291 24477 solver.cpp:244]     Train net output #1: loss = 5719.2 (* 1 = 5719.2 loss)
I0819 11:09:55.580297 24477 sgd_solver.cpp:106] Iteration 3900, lr = 1e-06
I0819 11:11:20.887421 24477 solver.cpp:228] Iteration 3950, loss = 6771.61
I0819 11:11:20.887492 24477 solver.cpp:244]     Train net output #0: accuracy = 0.934017
I0819 11:11:20.887502 24477 solver.cpp:244]     Train net output #1: loss = 6771.61 (* 1 = 6771.61 loss)
I0819 11:11:20.887509 24477 sgd_solver.cpp:106] Iteration 3950, lr = 1e-06
I0819 11:12:44.814092 24477 solver.cpp:454] Snapshotting to binary proto file portrait_one_stage_iter_4000.caffemodel
I0819 11:12:44.816519 24477 sgd_solver.cpp:273] Snapshotting solver state to binary proto file portrait_one_stage_iter_4000.solverstate
I0819 11:12:44.817436 24477 solver.cpp:337] Iteration 4000, Testing net (#0)
I0819 11:12:52.306983 24477 solver.cpp:404]     Test net output #0: accuracy = 0.922446
I0819 11:12:52.307023 24477 solver.cpp:404]     Test net output #1: loss = 8142.91 (* 1 = 8142.91 loss)
I0819 11:12:53.696100 24477 solver.cpp:228] Iteration 4000, loss = 4643.87
I0819 11:12:53.696132 24477 solver.cpp:244]     Train net output #0: accuracy = 0.95532
I0819 11:12:53.696141 24477 solver.cpp:244]     Train net output #1: loss = 4643.87 (* 1 = 4643.87 loss)
I0819 11:12:53.696147 24477 sgd_solver.cpp:106] Iteration 4000, lr = 1e-07
I0819 11:14:19.054831 24477 solver.cpp:228] Iteration 4050, loss = 7634.01
I0819 11:14:19.054922 24477 solver.cpp:244]     Train net output #0: accuracy = 0.924975
I0819 11:14:19.054934 24477 solver.cpp:244]     Train net output #1: loss = 7634.01 (* 1 = 7634.01 loss)
I0819 11:14:19.054939 24477 sgd_solver.cpp:106] Iteration 4050, lr = 1e-07
I0819 11:15:44.346524 24477 solver.cpp:228] Iteration 4100, loss = 4331.22
I0819 11:15:44.346608 24477 solver.cpp:244]     Train net output #0: accuracy = 0.95842
I0819 11:15:44.346619 24477 solver.cpp:244]     Train net output #1: loss = 4331.22 (* 1 = 4331.22 loss)
I0819 11:15:44.346626 24477 sgd_solver.cpp:106] Iteration 4100, lr = 1e-07
I0819 11:17:09.705116 24477 solver.cpp:228] Iteration 4150, loss = 9127.24
I0819 11:17:09.705207 24477 solver.cpp:244]     Train net output #0: accuracy = 0.911025
I0819 11:17:09.705219 24477 solver.cpp:244]     Train net output #1: loss = 9127.24 (* 1 = 9127.24 loss)
I0819 11:17:09.705224 24477 sgd_solver.cpp:106] Iteration 4150, lr = 1e-07
I0819 11:18:33.604018 24477 solver.cpp:337] Iteration 4200, Testing net (#0)
I0819 11:18:41.081722 24477 solver.cpp:404]     Test net output #0: accuracy = 0.926971
I0819 11:18:41.081763 24477 solver.cpp:404]     Test net output #1: loss = 7695.59 (* 1 = 7695.59 loss)
I0819 11:18:42.483438 24477 solver.cpp:228] Iteration 4200, loss = 8936.89
I0819 11:18:42.483470 24477 solver.cpp:244]     Train net output #0: accuracy = 0.913794
I0819 11:18:42.483479 24477 solver.cpp:244]     Train net output #1: loss = 8936.89 (* 1 = 8936.89 loss)
I0819 11:18:42.483484 24477 sgd_solver.cpp:106] Iteration 4200, lr = 1e-07
I0819 11:20:07.798665 24477 solver.cpp:228] Iteration 4250, loss = 4980.54
I0819 11:20:07.798786 24477 solver.cpp:244]     Train net output #0: accuracy = 0.951559
I0819 11:20:07.798797 24477 solver.cpp:244]     Train net output #1: loss = 4980.54 (* 1 = 4980.54 loss)
I0819 11:20:07.798804 24477 sgd_solver.cpp:106] Iteration 4250, lr = 1e-07
I0819 11:21:33.145386 24477 solver.cpp:228] Iteration 4300, loss = 10457.3
I0819 11:21:33.145462 24477 solver.cpp:244]     Train net output #0: accuracy = 0.898138
I0819 11:21:33.145474 24477 solver.cpp:244]     Train net output #1: loss = 10457.3 (* 1 = 10457.3 loss)
I0819 11:21:33.145481 24477 sgd_solver.cpp:106] Iteration 4300, lr = 1e-07
I0819 11:22:58.546854 24477 solver.cpp:228] Iteration 4350, loss = 5553.81
I0819 11:22:58.546944 24477 solver.cpp:244]     Train net output #0: accuracy = 0.945848
I0819 11:22:58.546954 24477 solver.cpp:244]     Train net output #1: loss = 5553.81 (* 1 = 5553.81 loss)
I0819 11:22:58.546962 24477 sgd_solver.cpp:106] Iteration 4350, lr = 1e-07
I0819 11:24:22.554746 24477 solver.cpp:337] Iteration 4400, Testing net (#0)
I0819 11:24:30.036234 24477 solver.cpp:404]     Test net output #0: accuracy = 0.92574
I0819 11:24:30.036274 24477 solver.cpp:404]     Test net output #1: loss = 7805.2 (* 1 = 7805.2 loss)
I0819 11:24:31.432576 24477 solver.cpp:228] Iteration 4400, loss = 8402.41
I0819 11:24:31.432608 24477 solver.cpp:244]     Train net output #0: accuracy = 0.921348
I0819 11:24:31.432618 24477 solver.cpp:244]     Train net output #1: loss = 8402.41 (* 1 = 8402.41 loss)
I0819 11:24:31.432624 24477 sgd_solver.cpp:106] Iteration 4400, lr = 1e-07
I0819 11:25:56.737004 24477 solver.cpp:228] Iteration 4450, loss = 4185.22
I0819 11:25:56.737095 24477 solver.cpp:244]     Train net output #0: accuracy = 0.959681
I0819 11:25:56.737107 24477 solver.cpp:244]     Train net output #1: loss = 4185.22 (* 1 = 4185.22 loss)
I0819 11:25:56.737113 24477 sgd_solver.cpp:106] Iteration 4450, lr = 1e-07
I0819 11:27:22.092635 24477 solver.cpp:228] Iteration 4500, loss = 7896.44
I0819 11:27:22.092725 24477 solver.cpp:244]     Train net output #0: accuracy = 0.924551
I0819 11:27:22.092736 24477 solver.cpp:244]     Train net output #1: loss = 7896.44 (* 1 = 7896.44 loss)
I0819 11:27:22.092742 24477 sgd_solver.cpp:106] Iteration 4500, lr = 1e-07
I0819 11:28:47.444152 24477 solver.cpp:228] Iteration 4550, loss = 6210.13
I0819 11:28:47.444224 24477 solver.cpp:244]     Train net output #0: accuracy = 0.939307
I0819 11:28:47.444234 24477 solver.cpp:244]     Train net output #1: loss = 6210.13 (* 1 = 6210.13 loss)
I0819 11:28:47.444242 24477 sgd_solver.cpp:106] Iteration 4550, lr = 1e-07
I0819 11:30:11.391268 24477 solver.cpp:337] Iteration 4600, Testing net (#0)
I0819 11:30:18.870355 24477 solver.cpp:404]     Test net output #0: accuracy = 0.92772
I0819 11:30:18.870393 24477 solver.cpp:404]     Test net output #1: loss = 7582.06 (* 1 = 7582.06 loss)
I0819 11:30:20.262298 24477 solver.cpp:228] Iteration 4600, loss = 5036.51
I0819 11:30:20.262331 24477 solver.cpp:244]     Train net output #0: accuracy = 0.951501
I0819 11:30:20.262339 24477 solver.cpp:244]     Train net output #1: loss = 5036.51 (* 1 = 5036.51 loss)
I0819 11:30:20.262346 24477 sgd_solver.cpp:106] Iteration 4600, lr = 1e-07
I0819 11:31:45.596398 24477 solver.cpp:228] Iteration 4650, loss = 8862.94
I0819 11:31:45.596485 24477 solver.cpp:244]     Train net output #0: accuracy = 0.911481
I0819 11:31:45.596496 24477 solver.cpp:244]     Train net output #1: loss = 8862.94 (* 1 = 8862.94 loss)
I0819 11:31:45.596503 24477 sgd_solver.cpp:106] Iteration 4650, lr = 1e-07
I0819 11:33:10.949214 24477 solver.cpp:228] Iteration 4700, loss = 4805.91
I0819 11:33:10.949319 24477 solver.cpp:244]     Train net output #0: accuracy = 0.952523
I0819 11:33:10.949338 24477 solver.cpp:244]     Train net output #1: loss = 4805.91 (* 1 = 4805.91 loss)
I0819 11:33:10.949344 24477 sgd_solver.cpp:106] Iteration 4700, lr = 1e-07
I0819 11:34:36.278440 24477 solver.cpp:228] Iteration 4750, loss = 10215.2
I0819 11:34:36.278533 24477 solver.cpp:244]     Train net output #0: accuracy = 0.904425
I0819 11:34:36.278543 24477 solver.cpp:244]     Train net output #1: loss = 10215.2 (* 1 = 10215.2 loss)
I0819 11:34:36.278549 24477 sgd_solver.cpp:106] Iteration 4750, lr = 1e-07
I0819 11:36:00.213888 24477 solver.cpp:337] Iteration 4800, Testing net (#0)
I0819 11:36:07.695039 24477 solver.cpp:404]     Test net output #0: accuracy = 0.92558
I0819 11:36:07.695078 24477 solver.cpp:404]     Test net output #1: loss = 7772.54 (* 1 = 7772.54 loss)
I0819 11:36:09.086030 24477 solver.cpp:228] Iteration 4800, loss = 5681.94
I0819 11:36:09.086061 24477 solver.cpp:244]     Train net output #0: accuracy = 0.944186
I0819 11:36:09.086071 24477 solver.cpp:244]     Train net output #1: loss = 5681.94 (* 1 = 5681.94 loss)
I0819 11:36:09.086077 24477 sgd_solver.cpp:106] Iteration 4800, lr = 1e-07
I0819 11:37:34.470598 24477 solver.cpp:228] Iteration 4850, loss = 6779.73
I0819 11:37:34.470685 24477 solver.cpp:244]     Train net output #0: accuracy = 0.935193
I0819 11:37:34.470695 24477 solver.cpp:244]     Train net output #1: loss = 6779.73 (* 1 = 6779.73 loss)
I0819 11:37:34.470702 24477 sgd_solver.cpp:106] Iteration 4850, lr = 1e-07
I0819 11:38:59.822734 24477 solver.cpp:228] Iteration 4900, loss = 4365.69
I0819 11:38:59.822824 24477 solver.cpp:244]     Train net output #0: accuracy = 0.958169
I0819 11:38:59.822834 24477 solver.cpp:244]     Train net output #1: loss = 4365.69 (* 1 = 4365.69 loss)
I0819 11:38:59.822840 24477 sgd_solver.cpp:106] Iteration 4900, lr = 1e-07
I0819 11:40:25.227109 24477 solver.cpp:228] Iteration 4950, loss = 6191.31
I0819 11:40:25.227197 24477 solver.cpp:244]     Train net output #0: accuracy = 0.940224
I0819 11:40:25.227208 24477 solver.cpp:244]     Train net output #1: loss = 6191.31 (* 1 = 6191.31 loss)
I0819 11:40:25.227215 24477 sgd_solver.cpp:106] Iteration 4950, lr = 1e-07
I0819 11:41:49.120885 24477 solver.cpp:337] Iteration 5000, Testing net (#0)
I0819 11:41:56.621282 24477 solver.cpp:404]     Test net output #0: accuracy = 0.928067
I0819 11:41:56.621314 24477 solver.cpp:404]     Test net output #1: loss = 7520.91 (* 1 = 7520.91 loss)
I0819 11:41:58.028174 24477 solver.cpp:228] Iteration 5000, loss = 7657.93
I0819 11:41:58.028203 24477 solver.cpp:244]     Train net output #0: accuracy = 0.922203
I0819 11:41:58.028211 24477 solver.cpp:244]     Train net output #1: loss = 7657.93 (* 1 = 7657.93 loss)
I0819 11:41:58.028218 24477 sgd_solver.cpp:106] Iteration 5000, lr = 1e-07
I0819 11:43:23.460049 24477 solver.cpp:228] Iteration 5050, loss = 4698.21
I0819 11:43:23.460122 24477 solver.cpp:244]     Train net output #0: accuracy = 0.955585
I0819 11:43:23.460132 24477 solver.cpp:244]     Train net output #1: loss = 4698.21 (* 1 = 4698.21 loss)
I0819 11:43:23.460139 24477 sgd_solver.cpp:106] Iteration 5050, lr = 1e-07
I0819 11:44:48.836467 24477 solver.cpp:228] Iteration 5100, loss = 10184.6
I0819 11:44:48.836536 24477 solver.cpp:244]     Train net output #0: accuracy = 0.89867
I0819 11:44:48.836546 24477 solver.cpp:244]     Train net output #1: loss = 10184.6 (* 1 = 10184.6 loss)
I0819 11:44:48.836554 24477 sgd_solver.cpp:106] Iteration 5100, lr = 1e-07
I0819 11:46:14.175376 24477 solver.cpp:228] Iteration 5150, loss = 5386.72
I0819 11:46:14.175462 24477 solver.cpp:244]     Train net output #0: accuracy = 0.948563
I0819 11:46:14.175472 24477 solver.cpp:244]     Train net output #1: loss = 5386.72 (* 1 = 5386.72 loss)
I0819 11:46:14.175478 24477 sgd_solver.cpp:106] Iteration 5150, lr = 1e-07
I0819 11:47:38.224535 24477 solver.cpp:337] Iteration 5200, Testing net (#0)
I0819 11:47:45.699584 24477 solver.cpp:404]     Test net output #0: accuracy = 0.929271
I0819 11:47:45.699620 24477 solver.cpp:404]     Test net output #1: loss = 7405.89 (* 1 = 7405.89 loss)
I0819 11:47:47.097343 24477 solver.cpp:228] Iteration 5200, loss = 10389.9
I0819 11:47:47.097373 24477 solver.cpp:244]     Train net output #0: accuracy = 0.902545
I0819 11:47:47.097381 24477 solver.cpp:244]     Train net output #1: loss = 10389.9 (* 1 = 10389.9 loss)
I0819 11:47:47.097388 24477 sgd_solver.cpp:106] Iteration 5200, lr = 1e-07
I0819 11:49:12.445031 24477 solver.cpp:228] Iteration 5250, loss = 6215.78
I0819 11:49:12.445149 24477 solver.cpp:244]     Train net output #0: accuracy = 0.939514
I0819 11:49:12.445161 24477 solver.cpp:244]     Train net output #1: loss = 6215.78 (* 1 = 6215.78 loss)
I0819 11:49:12.445168 24477 sgd_solver.cpp:106] Iteration 5250, lr = 1e-07
I0819 11:50:37.835330 24477 solver.cpp:228] Iteration 5300, loss = 6637.71
I0819 11:50:37.835422 24477 solver.cpp:244]     Train net output #0: accuracy = 0.934681
I0819 11:50:37.835433 24477 solver.cpp:244]     Train net output #1: loss = 6637.71 (* 1 = 6637.71 loss)
I0819 11:50:37.835439 24477 sgd_solver.cpp:106] Iteration 5300, lr = 1e-07
I0819 11:52:03.150271 24477 solver.cpp:228] Iteration 5350, loss = 7698.28
I0819 11:52:03.150363 24477 solver.cpp:244]     Train net output #0: accuracy = 0.9265
I0819 11:52:03.150374 24477 solver.cpp:244]     Train net output #1: loss = 7698.28 (* 1 = 7698.28 loss)
I0819 11:52:03.150382 24477 sgd_solver.cpp:106] Iteration 5350, lr = 1e-07
I0819 11:53:27.115854 24477 solver.cpp:337] Iteration 5400, Testing net (#0)
I0819 11:53:34.592834 24477 solver.cpp:404]     Test net output #0: accuracy = 0.927024
I0819 11:53:34.592875 24477 solver.cpp:404]     Test net output #1: loss = 7624.69 (* 1 = 7624.69 loss)
I0819 11:53:35.981920 24477 solver.cpp:228] Iteration 5400, loss = 4281.57
I0819 11:53:35.981950 24477 solver.cpp:244]     Train net output #0: accuracy = 0.958749
I0819 11:53:35.981959 24477 solver.cpp:244]     Train net output #1: loss = 4281.57 (* 1 = 4281.57 loss)
I0819 11:53:35.981966 24477 sgd_solver.cpp:106] Iteration 5400, lr = 1e-07
I0819 11:55:01.307020 24477 solver.cpp:228] Iteration 5450, loss = 7523.73
I0819 11:55:01.307091 24477 solver.cpp:244]     Train net output #0: accuracy = 0.923707
I0819 11:55:01.307102 24477 solver.cpp:244]     Train net output #1: loss = 7523.73 (* 1 = 7523.73 loss)
I0819 11:55:01.307108 24477 sgd_solver.cpp:106] Iteration 5450, lr = 1e-07
I0819 11:56:26.612452 24477 solver.cpp:228] Iteration 5500, loss = 4895.07
I0819 11:56:26.612538 24477 solver.cpp:244]     Train net output #0: accuracy = 0.951154
I0819 11:56:26.612548 24477 solver.cpp:244]     Train net output #1: loss = 4895.07 (* 1 = 4895.07 loss)
I0819 11:56:26.612555 24477 sgd_solver.cpp:106] Iteration 5500, lr = 1e-07
I0819 11:57:51.955803 24477 solver.cpp:228] Iteration 5550, loss = 9441.81
I0819 11:57:51.955888 24477 solver.cpp:244]     Train net output #0: accuracy = 0.906306
I0819 11:57:51.955899 24477 solver.cpp:244]     Train net output #1: loss = 9441.81 (* 1 = 9441.81 loss)
I0819 11:57:51.955905 24477 sgd_solver.cpp:106] Iteration 5550, lr = 1e-07
I0819 11:59:15.876026 24477 solver.cpp:337] Iteration 5600, Testing net (#0)
I0819 11:59:23.349831 24477 solver.cpp:404]     Test net output #0: accuracy = 0.929145
I0819 11:59:23.349869 24477 solver.cpp:404]     Test net output #1: loss = 7391.97 (* 1 = 7391.97 loss)
I0819 11:59:24.740671 24477 solver.cpp:228] Iteration 5600, loss = 4949.67
I0819 11:59:24.740702 24477 solver.cpp:244]     Train net output #0: accuracy = 0.953355
I0819 11:59:24.740711 24477 solver.cpp:244]     Train net output #1: loss = 4949.67 (* 1 = 4949.67 loss)
I0819 11:59:24.740717 24477 sgd_solver.cpp:106] Iteration 5600, lr = 1e-07
I0819 12:00:50.071955 24477 solver.cpp:228] Iteration 5650, loss = 8554
I0819 12:00:50.072044 24477 solver.cpp:244]     Train net output #0: accuracy = 0.917572
I0819 12:00:50.072055 24477 solver.cpp:244]     Train net output #1: loss = 8554 (* 1 = 8554 loss)
I0819 12:00:50.072062 24477 sgd_solver.cpp:106] Iteration 5650, lr = 1e-07
I0819 12:02:15.369848 24477 solver.cpp:228] Iteration 5700, loss = 8173.86
I0819 12:02:15.369946 24477 solver.cpp:244]     Train net output #0: accuracy = 0.921504
I0819 12:02:15.369959 24477 solver.cpp:244]     Train net output #1: loss = 8173.86 (* 1 = 8173.86 loss)
I0819 12:02:15.369966 24477 sgd_solver.cpp:106] Iteration 5700, lr = 1e-07
I0819 12:03:40.803053 24477 solver.cpp:228] Iteration 5750, loss = 5629.69
I0819 12:03:40.803148 24477 solver.cpp:244]     Train net output #0: accuracy = 0.946148
I0819 12:03:40.803159 24477 solver.cpp:244]     Train net output #1: loss = 5629.69 (* 1 = 5629.69 loss)
I0819 12:03:40.803166 24477 sgd_solver.cpp:106] Iteration 5750, lr = 1e-07
I0819 12:05:04.731410 24477 solver.cpp:337] Iteration 5800, Testing net (#0)
I0819 12:05:12.209573 24477 solver.cpp:404]     Test net output #0: accuracy = 0.927108
I0819 12:05:12.209614 24477 solver.cpp:404]     Test net output #1: loss = 7603.4 (* 1 = 7603.4 loss)
I0819 12:05:13.606708 24477 solver.cpp:228] Iteration 5800, loss = 6628.92
I0819 12:05:13.606739 24477 solver.cpp:244]     Train net output #0: accuracy = 0.935887
I0819 12:05:13.606747 24477 solver.cpp:244]     Train net output #1: loss = 6628.92 (* 1 = 6628.92 loss)
I0819 12:05:13.606755 24477 sgd_solver.cpp:106] Iteration 5800, lr = 1e-07
I0819 12:06:38.989485 24477 solver.cpp:228] Iteration 5850, loss = 4562.34
I0819 12:06:38.989575 24477 solver.cpp:244]     Train net output #0: accuracy = 0.956285
I0819 12:06:38.989586 24477 solver.cpp:244]     Train net output #1: loss = 4562.34 (* 1 = 4562.34 loss)
I0819 12:06:38.989593 24477 sgd_solver.cpp:106] Iteration 5850, lr = 1e-07
I0819 12:08:04.285367 24477 solver.cpp:228] Iteration 5900, loss = 8176.45
I0819 12:08:04.285436 24477 solver.cpp:244]     Train net output #0: accuracy = 0.919954
I0819 12:08:04.285447 24477 solver.cpp:244]     Train net output #1: loss = 8176.45 (* 1 = 8176.45 loss)
I0819 12:08:04.285454 24477 sgd_solver.cpp:106] Iteration 5900, lr = 1e-07
I0819 12:09:29.609488 24477 solver.cpp:228] Iteration 5950, loss = 5076.31
I0819 12:09:29.609561 24477 solver.cpp:244]     Train net output #0: accuracy = 0.949074
I0819 12:09:29.609571 24477 solver.cpp:244]     Train net output #1: loss = 5076.31 (* 1 = 5076.31 loss)
I0819 12:09:29.609577 24477 sgd_solver.cpp:106] Iteration 5950, lr = 1e-07
I0819 12:10:53.661648 24477 solver.cpp:454] Snapshotting to binary proto file portrait_one_stage_iter_6000.caffemodel
I0819 12:10:53.664113 24477 sgd_solver.cpp:273] Snapshotting solver state to binary proto file portrait_one_stage_iter_6000.solverstate
I0819 12:10:53.665045 24477 solver.cpp:337] Iteration 6000, Testing net (#0)
I0819 12:11:01.142803 24477 solver.cpp:404]     Test net output #0: accuracy = 0.928718
I0819 12:11:01.142841 24477 solver.cpp:404]     Test net output #1: loss = 7448.71 (* 1 = 7448.71 loss)
I0819 12:11:02.543148 24477 solver.cpp:228] Iteration 6000, loss = 8274.16
I0819 12:11:02.543179 24477 solver.cpp:244]     Train net output #0: accuracy = 0.918005
I0819 12:11:02.543189 24477 solver.cpp:244]     Train net output #1: loss = 8274.16 (* 1 = 8274.16 loss)
I0819 12:11:02.543195 24477 sgd_solver.cpp:106] Iteration 6000, lr = 1e-08
I0819 12:12:27.553338 24477 solver.cpp:228] Iteration 6050, loss = 4715.06
I0819 12:12:27.553385 24477 solver.cpp:244]     Train net output #0: accuracy = 0.95448
I0819 12:12:27.553395 24477 solver.cpp:244]     Train net output #1: loss = 4715.06 (* 1 = 4715.06 loss)
I0819 12:12:27.553401 24477 sgd_solver.cpp:106] Iteration 6050, lr = 1e-08
I0819 12:13:52.625262 24477 solver.cpp:228] Iteration 6100, loss = 5717.1
I0819 12:13:52.625334 24477 solver.cpp:244]     Train net output #0: accuracy = 0.945516
I0819 12:13:52.625344 24477 solver.cpp:244]     Train net output #1: loss = 5717.1 (* 1 = 5717.1 loss)
I0819 12:13:52.625351 24477 sgd_solver.cpp:106] Iteration 6100, lr = 1e-08
I0819 12:15:17.661149 24477 solver.cpp:228] Iteration 6150, loss = 10501.3
I0819 12:15:17.661240 24477 solver.cpp:244]     Train net output #0: accuracy = 0.896678
I0819 12:15:17.661252 24477 solver.cpp:244]     Train net output #1: loss = 10501.3 (* 1 = 10501.3 loss)
I0819 12:15:17.661257 24477 sgd_solver.cpp:106] Iteration 6150, lr = 1e-08
I0819 12:16:41.304030 24477 solver.cpp:337] Iteration 6200, Testing net (#0)
I0819 12:16:48.771972 24477 solver.cpp:404]     Test net output #0: accuracy = 0.929803
I0819 12:16:48.772012 24477 solver.cpp:404]     Test net output #1: loss = 7326.97 (* 1 = 7326.97 loss)
I0819 12:16:50.157908 24477 solver.cpp:228] Iteration 6200, loss = 5554.97
I0819 12:16:50.157939 24477 solver.cpp:244]     Train net output #0: accuracy = 0.947087
I0819 12:16:50.157948 24477 solver.cpp:244]     Train net output #1: loss = 5554.97 (* 1 = 5554.97 loss)
I0819 12:16:50.157954 24477 sgd_solver.cpp:106] Iteration 6200, lr = 1e-08
I0819 12:18:15.213449 24477 solver.cpp:228] Iteration 6250, loss = 6613.55
I0819 12:18:15.213544 24477 solver.cpp:244]     Train net output #0: accuracy = 0.936037
I0819 12:18:15.213554 24477 solver.cpp:244]     Train net output #1: loss = 6613.55 (* 1 = 6613.55 loss)
I0819 12:18:15.213562 24477 sgd_solver.cpp:106] Iteration 6250, lr = 1e-08
I0819 12:19:40.288040 24477 solver.cpp:228] Iteration 6300, loss = 4592.8
I0819 12:19:40.288113 24477 solver.cpp:244]     Train net output #0: accuracy = 0.956092
I0819 12:19:40.288123 24477 solver.cpp:244]     Train net output #1: loss = 4592.8 (* 1 = 4592.8 loss)
I0819 12:19:40.288130 24477 sgd_solver.cpp:106] Iteration 6300, lr = 1e-08
I0819 12:21:05.380334 24477 solver.cpp:228] Iteration 6350, loss = 7515.16
I0819 12:21:05.380411 24477 solver.cpp:244]     Train net output #0: accuracy = 0.925731
I0819 12:21:05.380421 24477 solver.cpp:244]     Train net output #1: loss = 7515.16 (* 1 = 7515.16 loss)
I0819 12:21:05.380429 24477 sgd_solver.cpp:106] Iteration 6350, lr = 1e-08
I0819 12:22:29.030447 24477 solver.cpp:337] Iteration 6400, Testing net (#0)
I0819 12:22:36.498706 24477 solver.cpp:404]     Test net output #0: accuracy = 0.92669
I0819 12:22:36.498744 24477 solver.cpp:404]     Test net output #1: loss = 7659.52 (* 1 = 7659.52 loss)
I0819 12:22:37.888505 24477 solver.cpp:228] Iteration 6400, loss = 4381.25
I0819 12:22:37.888537 24477 solver.cpp:244]     Train net output #0: accuracy = 0.957607
I0819 12:22:37.888545 24477 solver.cpp:244]     Train net output #1: loss = 4381.25 (* 1 = 4381.25 loss)
I0819 12:22:37.888552 24477 sgd_solver.cpp:106] Iteration 6400, lr = 1e-08
I0819 12:24:02.955610 24477 solver.cpp:228] Iteration 6450, loss = 8507.46
I0819 12:24:02.955656 24477 solver.cpp:244]     Train net output #0: accuracy = 0.917078
I0819 12:24:02.955664 24477 solver.cpp:244]     Train net output #1: loss = 8507.46 (* 1 = 8507.46 loss)
I0819 12:24:02.955672 24477 sgd_solver.cpp:106] Iteration 6450, lr = 1e-08
I0819 12:25:28.011816 24477 solver.cpp:228] Iteration 6500, loss = 8853.83
I0819 12:25:28.011907 24477 solver.cpp:244]     Train net output #0: accuracy = 0.913712
I0819 12:25:28.011919 24477 solver.cpp:244]     Train net output #1: loss = 8853.83 (* 1 = 8853.83 loss)
I0819 12:25:28.011925 24477 sgd_solver.cpp:106] Iteration 6500, lr = 1e-08
I0819 12:26:53.126348 24477 solver.cpp:228] Iteration 6550, loss = 4906.52
I0819 12:26:53.126394 24477 solver.cpp:244]     Train net output #0: accuracy = 0.952285
I0819 12:26:53.126402 24477 solver.cpp:244]     Train net output #1: loss = 4906.52 (* 1 = 4906.52 loss)
I0819 12:26:53.126410 24477 sgd_solver.cpp:106] Iteration 6550, lr = 1e-08
I0819 12:28:16.842839 24477 solver.cpp:337] Iteration 6600, Testing net (#0)
I0819 12:28:24.315472 24477 solver.cpp:404]     Test net output #0: accuracy = 0.929386
I0819 12:28:24.315511 24477 solver.cpp:404]     Test net output #1: loss = 7353.99 (* 1 = 7353.99 loss)
I0819 12:28:25.710398 24477 solver.cpp:228] Iteration 6600, loss = 10165
I0819 12:28:25.710429 24477 solver.cpp:244]     Train net output #0: accuracy = 0.899416
I0819 12:28:25.710438 24477 solver.cpp:244]     Train net output #1: loss = 10165 (* 1 = 10165 loss)
I0819 12:28:25.710444 24477 sgd_solver.cpp:106] Iteration 6600, lr = 1e-08
I0819 12:29:50.802857 24477 solver.cpp:228] Iteration 6650, loss = 5396.58
I0819 12:29:50.802952 24477 solver.cpp:244]     Train net output #0: accuracy = 0.947241
I0819 12:29:50.802965 24477 solver.cpp:244]     Train net output #1: loss = 5396.58 (* 1 = 5396.58 loss)
I0819 12:29:50.802973 24477 sgd_solver.cpp:106] Iteration 6650, lr = 1e-08
I0819 12:31:15.898262 24477 solver.cpp:228] Iteration 6700, loss = 8433.71
I0819 12:31:15.898336 24477 solver.cpp:244]     Train net output #0: accuracy = 0.920769
I0819 12:31:15.898346 24477 solver.cpp:244]     Train net output #1: loss = 8433.71 (* 1 = 8433.71 loss)
I0819 12:31:15.898353 24477 sgd_solver.cpp:106] Iteration 6700, lr = 1e-08
I0819 12:32:40.979949 24477 solver.cpp:228] Iteration 6750, loss = 4261.27
I0819 12:32:40.980021 24477 solver.cpp:244]     Train net output #0: accuracy = 0.958399
I0819 12:32:40.980032 24477 solver.cpp:244]     Train net output #1: loss = 4261.27 (* 1 = 4261.27 loss)
I0819 12:32:40.980039 24477 sgd_solver.cpp:106] Iteration 6750, lr = 1e-08
I0819 12:34:04.660387 24477 solver.cpp:337] Iteration 6800, Testing net (#0)
I0819 12:34:12.132845 24477 solver.cpp:404]     Test net output #0: accuracy = 0.927939
I0819 12:34:12.132884 24477 solver.cpp:404]     Test net output #1: loss = 7516.71 (* 1 = 7516.71 loss)
I0819 12:34:13.530568 24477 solver.cpp:228] Iteration 6800, loss = 7877.62
I0819 12:34:13.530601 24477 solver.cpp:244]     Train net output #0: accuracy = 0.922982
I0819 12:34:13.530608 24477 solver.cpp:244]     Train net output #1: loss = 7877.62 (* 1 = 7877.62 loss)
I0819 12:34:13.530616 24477 sgd_solver.cpp:106] Iteration 6800, lr = 1e-08
I0819 12:35:38.705997 24477 solver.cpp:228] Iteration 6850, loss = 6674.71
I0819 12:35:38.706071 24477 solver.cpp:244]     Train net output #0: accuracy = 0.934111
I0819 12:35:38.706081 24477 solver.cpp:244]     Train net output #1: loss = 6674.71 (* 1 = 6674.71 loss)
I0819 12:35:38.706089 24477 sgd_solver.cpp:106] Iteration 6850, lr = 1e-08
I0819 12:37:03.933137 24477 solver.cpp:228] Iteration 6900, loss = 4860.3
I0819 12:37:03.933213 24477 solver.cpp:244]     Train net output #0: accuracy = 0.952546
I0819 12:37:03.933223 24477 solver.cpp:244]     Train net output #1: loss = 4860.3 (* 1 = 4860.3 loss)
I0819 12:37:03.933230 24477 sgd_solver.cpp:106] Iteration 6900, lr = 1e-08
I0819 12:38:29.131156 24477 solver.cpp:228] Iteration 6950, loss = 8859.94
I0819 12:38:29.131227 24477 solver.cpp:244]     Train net output #0: accuracy = 0.911107
I0819 12:38:29.131238 24477 solver.cpp:244]     Train net output #1: loss = 8859.94 (* 1 = 8859.94 loss)
I0819 12:38:29.131247 24477 sgd_solver.cpp:106] Iteration 6950, lr = 1e-08
I0819 12:39:52.930383 24477 solver.cpp:337] Iteration 7000, Testing net (#0)
I0819 12:40:00.398592 24477 solver.cpp:404]     Test net output #0: accuracy = 0.928889
I0819 12:40:00.398632 24477 solver.cpp:404]     Test net output #1: loss = 7419.27 (* 1 = 7419.27 loss)
I0819 12:40:01.785274 24477 solver.cpp:228] Iteration 7000, loss = 4668.19
I0819 12:40:01.785305 24477 solver.cpp:244]     Train net output #0: accuracy = 0.953669
I0819 12:40:01.785312 24477 solver.cpp:244]     Train net output #1: loss = 4668.19 (* 1 = 4668.19 loss)
I0819 12:40:01.785320 24477 sgd_solver.cpp:106] Iteration 7000, lr = 1e-08
I0819 12:41:26.864226 24477 solver.cpp:228] Iteration 7050, loss = 9238.44
I0819 12:41:26.864313 24477 solver.cpp:244]     Train net output #0: accuracy = 0.912292
I0819 12:41:26.864325 24477 solver.cpp:244]     Train net output #1: loss = 9238.44 (* 1 = 9238.44 loss)
I0819 12:41:26.864331 24477 sgd_solver.cpp:106] Iteration 7050, lr = 1e-08
I0819 12:42:51.966629 24477 solver.cpp:228] Iteration 7100, loss = 5795.42
I0819 12:42:51.966717 24477 solver.cpp:244]     Train net output #0: accuracy = 0.944388
I0819 12:42:51.966728 24477 solver.cpp:244]     Train net output #1: loss = 5795.42 (* 1 = 5795.42 loss)
I0819 12:42:51.966735 24477 sgd_solver.cpp:106] Iteration 7100, lr = 1e-08
I0819 12:44:17.134204 24477 solver.cpp:228] Iteration 7150, loss = 6902.24
I0819 12:44:17.134294 24477 solver.cpp:244]     Train net output #0: accuracy = 0.933704
I0819 12:44:17.134305 24477 solver.cpp:244]     Train net output #1: loss = 6902.24 (* 1 = 6902.24 loss)
I0819 12:44:17.134312 24477 sgd_solver.cpp:106] Iteration 7150, lr = 1e-08
I0819 12:45:40.893543 24477 solver.cpp:337] Iteration 7200, Testing net (#0)
I0819 12:45:48.422818 24477 solver.cpp:404]     Test net output #0: accuracy = 0.930022
I0819 12:45:48.422857 24477 solver.cpp:404]     Test net output #1: loss = 7308.39 (* 1 = 7308.39 loss)
I0819 12:45:49.817311 24477 solver.cpp:228] Iteration 7200, loss = 4493.48
I0819 12:45:49.817344 24477 solver.cpp:244]     Train net output #0: accuracy = 0.956776
I0819 12:45:49.817353 24477 solver.cpp:244]     Train net output #1: loss = 4493.48 (* 1 = 4493.48 loss)
I0819 12:45:49.817360 24477 sgd_solver.cpp:106] Iteration 7200, lr = 1e-08
I0819 12:47:14.989045 24477 solver.cpp:228] Iteration 7250, loss = 5646.43
I0819 12:47:14.989142 24477 solver.cpp:244]     Train net output #0: accuracy = 0.944534
I0819 12:47:14.989152 24477 solver.cpp:244]     Train net output #1: loss = 5646.43 (* 1 = 5646.43 loss)
I0819 12:47:14.989159 24477 sgd_solver.cpp:106] Iteration 7250, lr = 1e-08
I0819 12:48:40.007650 24477 solver.cpp:228] Iteration 7300, loss = 7540.48
I0819 12:48:40.007746 24477 solver.cpp:244]     Train net output #0: accuracy = 0.924195
I0819 12:48:40.007757 24477 solver.cpp:244]     Train net output #1: loss = 7540.48 (* 1 = 7540.48 loss)
I0819 12:48:40.007766 24477 sgd_solver.cpp:106] Iteration 7300, lr = 1e-08
I0819 12:50:05.270839 24477 solver.cpp:228] Iteration 7350, loss = 4863.79
I0819 12:50:05.270927 24477 solver.cpp:244]     Train net output #0: accuracy = 0.953637
I0819 12:50:05.270938 24477 solver.cpp:244]     Train net output #1: loss = 4863.79 (* 1 = 4863.79 loss)
I0819 12:50:05.270946 24477 sgd_solver.cpp:106] Iteration 7350, lr = 1e-08
I0819 12:51:29.092125 24477 solver.cpp:337] Iteration 7400, Testing net (#0)
I0819 12:51:36.561599 24477 solver.cpp:404]     Test net output #0: accuracy = 0.926197
I0819 12:51:36.561637 24477 solver.cpp:404]     Test net output #1: loss = 7698.14 (* 1 = 7698.14 loss)
I0819 12:51:37.957866 24477 solver.cpp:228] Iteration 7400, loss = 9040.63
I0819 12:51:37.957898 24477 solver.cpp:244]     Train net output #0: accuracy = 0.910668
I0819 12:51:37.957906 24477 solver.cpp:244]     Train net output #1: loss = 9040.63 (* 1 = 9040.63 loss)
I0819 12:51:37.957913 24477 sgd_solver.cpp:106] Iteration 7400, lr = 1e-08
I0819 12:53:02.979342 24477 solver.cpp:228] Iteration 7450, loss = 5333.83
I0819 12:53:02.979431 24477 solver.cpp:244]     Train net output #0: accuracy = 0.949033
I0819 12:53:02.979441 24477 solver.cpp:244]     Train net output #1: loss = 5333.83 (* 1 = 5333.83 loss)
I0819 12:53:02.979449 24477 sgd_solver.cpp:106] Iteration 7450, lr = 1e-08
I0819 12:54:28.038213 24477 solver.cpp:228] Iteration 7500, loss = 10763.3
I0819 12:54:28.038301 24477 solver.cpp:244]     Train net output #0: accuracy = 0.899599
I0819 12:54:28.038312 24477 solver.cpp:244]     Train net output #1: loss = 10763.3 (* 1 = 10763.3 loss)
I0819 12:54:28.038319 24477 sgd_solver.cpp:106] Iteration 7500, lr = 1e-08
I0819 12:55:53.077002 24477 solver.cpp:228] Iteration 7550, loss = 6106.39
I0819 12:55:53.077095 24477 solver.cpp:244]     Train net output #0: accuracy = 0.940754
I0819 12:55:53.077106 24477 solver.cpp:244]     Train net output #1: loss = 6106.39 (* 1 = 6106.39 loss)
I0819 12:55:53.077113 24477 sgd_solver.cpp:106] Iteration 7550, lr = 1e-08
I0819 12:57:16.786042 24477 solver.cpp:337] Iteration 7600, Testing net (#0)
I0819 12:57:24.260011 24477 solver.cpp:404]     Test net output #0: accuracy = 0.929409
I0819 12:57:24.260052 24477 solver.cpp:404]     Test net output #1: loss = 7356.58 (* 1 = 7356.58 loss)
I0819 12:57:25.652544 24477 solver.cpp:228] Iteration 7600, loss = 6583.02
I0819 12:57:25.652575 24477 solver.cpp:244]     Train net output #0: accuracy = 0.934897
I0819 12:57:25.652583 24477 solver.cpp:244]     Train net output #1: loss = 6583.02 (* 1 = 6583.02 loss)
I0819 12:57:25.652590 24477 sgd_solver.cpp:106] Iteration 7600, lr = 1e-08
I0819 12:58:50.714310 24477 solver.cpp:228] Iteration 7650, loss = 7452.82
I0819 12:58:50.714423 24477 solver.cpp:244]     Train net output #0: accuracy = 0.928571
I0819 12:58:50.714438 24477 solver.cpp:244]     Train net output #1: loss = 7452.82 (* 1 = 7452.82 loss)
I0819 12:58:50.714445 24477 sgd_solver.cpp:106] Iteration 7650, lr = 1e-08
I0819 13:00:15.833557 24477 solver.cpp:228] Iteration 7700, loss = 4480.38
I0819 13:00:15.833657 24477 solver.cpp:244]     Train net output #0: accuracy = 0.957356
I0819 13:00:15.833668 24477 solver.cpp:244]     Train net output #1: loss = 4480.38 (* 1 = 4480.38 loss)
I0819 13:00:15.833675 24477 sgd_solver.cpp:106] Iteration 7700, lr = 1e-08
I0819 13:01:40.938189 24477 solver.cpp:228] Iteration 7750, loss = 7795.97
I0819 13:01:40.938266 24477 solver.cpp:244]     Train net output #0: accuracy = 0.921285
I0819 13:01:40.938276 24477 solver.cpp:244]     Train net output #1: loss = 7795.97 (* 1 = 7795.97 loss)
I0819 13:01:40.938282 24477 sgd_solver.cpp:106] Iteration 7750, lr = 1e-08
I0819 13:03:04.702054 24477 solver.cpp:337] Iteration 7800, Testing net (#0)
I0819 13:03:12.215543 24477 solver.cpp:404]     Test net output #0: accuracy = 0.928814
I0819 13:03:12.215581 24477 solver.cpp:404]     Test net output #1: loss = 7424.27 (* 1 = 7424.27 loss)
I0819 13:03:13.602524 24477 solver.cpp:228] Iteration 7800, loss = 5001.76
I0819 13:03:13.602556 24477 solver.cpp:244]     Train net output #0: accuracy = 0.950824
I0819 13:03:13.602566 24477 solver.cpp:244]     Train net output #1: loss = 5001.76 (* 1 = 5001.76 loss)
I0819 13:03:13.602572 24477 sgd_solver.cpp:106] Iteration 7800, lr = 1e-08
I0819 13:04:38.661284 24477 solver.cpp:228] Iteration 7850, loss = 9428.4
I0819 13:04:38.661376 24477 solver.cpp:244]     Train net output #0: accuracy = 0.904438
I0819 13:04:38.661387 24477 solver.cpp:244]     Train net output #1: loss = 9428.4 (* 1 = 9428.4 loss)
I0819 13:04:38.661396 24477 sgd_solver.cpp:106] Iteration 7850, lr = 1e-08
I0819 13:06:03.786947 24477 solver.cpp:228] Iteration 7900, loss = 4926.52
I0819 13:06:03.787036 24477 solver.cpp:244]     Train net output #0: accuracy = 0.953807
I0819 13:06:03.787046 24477 solver.cpp:244]     Train net output #1: loss = 4926.52 (* 1 = 4926.52 loss)
I0819 13:06:03.787053 24477 sgd_solver.cpp:106] Iteration 7900, lr = 1e-08
I0819 13:07:28.909442 24477 solver.cpp:228] Iteration 7950, loss = 8835.38
I0819 13:07:28.909515 24477 solver.cpp:244]     Train net output #0: accuracy = 0.913761
I0819 13:07:28.909525 24477 solver.cpp:244]     Train net output #1: loss = 8835.38 (* 1 = 8835.38 loss)
I0819 13:07:28.909533 24477 sgd_solver.cpp:106] Iteration 7950, lr = 1e-08
I0819 13:08:52.569411 24477 solver.cpp:454] Snapshotting to binary proto file portrait_one_stage_iter_8000.caffemodel
I0819 13:08:52.571996 24477 sgd_solver.cpp:273] Snapshotting solver state to binary proto file portrait_one_stage_iter_8000.solverstate
I0819 13:08:53.586287 24477 solver.cpp:317] Iteration 8000, loss = 8187.21
I0819 13:08:53.586323 24477 solver.cpp:337] Iteration 8000, Testing net (#0)
I0819 13:09:01.059383 24477 solver.cpp:404]     Test net output #0: accuracy = 0.928845
I0819 13:09:01.059420 24477 solver.cpp:404]     Test net output #1: loss = 7419.57 (* 1 = 7419.57 loss)
I0819 13:09:01.059425 24477 solver.cpp:322] Optimization Done.
I0819 13:09:01.059429 24477 caffe.cpp:254] Optimization Done.
