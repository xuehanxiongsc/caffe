{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import lmdb\n",
    "import caffe\n",
    "import os\n",
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RED_CHANNEL = 2\n",
    "GREEN_CHANNEL = 1\n",
    "BLUE_CHANNEL = 0\n",
    "TOLERANCE = 10\n",
    "RESIZE_DIM = 128\n",
    "\n",
    "def is_image(file):\n",
    "    if file.endswith(\".jpg\") or file.endswith(\".JPG\") or file.endswith(\".jpeg\") \\\n",
    "    or file.endswith(\".png\") or file.endswith(\".JPEG\"):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def get_image_files(dir):\n",
    "    return [os.path.join(dir, f) for f in os.listdir(dir) if is_image(os.path.join(dir, f))]\n",
    "\n",
    "def red_mask(image):\n",
    "    temp,mask0 = cv2.threshold(image[:,:,RED_CHANNEL],255-TOLERANCE,255,cv2.THRESH_BINARY)\n",
    "    temp,mask1 = cv2.threshold(image[:,:,GREEN_CHANNEL],TOLERANCE,255,cv2.THRESH_BINARY_INV)\n",
    "    temp,mask2 = cv2.threshold(image[:,:,BLUE_CHANNEL],TOLERANCE,255,cv2.THRESH_BINARY_INV)\n",
    "    mask0 = cv2.bitwise_and(mask0,mask1)\n",
    "    mask0 = cv2.bitwise_and(mask0,mask2)\n",
    "    return mask0\n",
    "\n",
    "def green_mask(image):\n",
    "    temp,mask0 = cv2.threshold(image[:,:,GREEN_CHANNEL],255-TOLERANCE,255,cv2.THRESH_BINARY)\n",
    "    temp,mask1 = cv2.threshold(image[:,:,BLUE_CHANNEL],TOLERANCE,255,cv2.THRESH_BINARY_INV)\n",
    "    temp,mask2 = cv2.threshold(image[:,:,RED_CHANNEL],TOLERANCE,255,cv2.THRESH_BINARY_INV)\n",
    "    mask0 = cv2.bitwise_and(mask0,mask1)\n",
    "    mask0 = cv2.bitwise_and(mask0,mask2)\n",
    "    return mask0\n",
    "\n",
    "def blue_mask(image):\n",
    "    temp,mask0 = cv2.threshold(image[:,:,BLUE_CHANNEL],255-TOLERANCE,255,cv2.THRESH_BINARY)\n",
    "    temp,mask1 = cv2.threshold(image[:,:,RED_CHANNEL],TOLERANCE,255,cv2.THRESH_BINARY_INV)\n",
    "    temp,mask2 = cv2.threshold(image[:,:,GREEN_CHANNEL],TOLERANCE,255,cv2.THRESH_BINARY_INV)\n",
    "    mask0 = cv2.bitwise_and(mask0,mask1)\n",
    "    mask0 = cv2.bitwise_and(mask0,mask2)\n",
    "    return mask0\n",
    "\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _gen_label_image(image):\n",
    "    hair_mask = red_mask(image)\n",
    "    face_mask = green_mask(image)\n",
    "    shoulder_mask = blue_mask(image)\n",
    "    label_image = np.zeros_like(image[:,:,0])\n",
    "    label_image[hair_mask==255] = 1\n",
    "    label_image[shoulder_mask==255] = 2\n",
    "    label_image[face_mask==255] = 3\n",
    "    kernel_width = np.maximum(int(label_image.shape[0]/100.0),5)\n",
    "    kernel = np.ones((kernel_width,kernel_width),np.uint8)\n",
    "    label_image = cv2.morphologyEx(label_image, cv2.MORPH_CLOSE, kernel)\n",
    "    return label_image\n",
    "\n",
    "def _resize_image_label(image,label):\n",
    "    height,width = image.shape[:2]\n",
    "    scale = float(RESIZE_DIM) / float(np.minimum(width,height))\n",
    "    resized_image = cv2.resize(image,(0,0),fx=scale,fy=scale)\n",
    "    resized_label = cv2.resize(label,(resized_image.shape[1],resized_image.shape[0]),interpolation=cv2.INTER_NEAREST)\n",
    "    assert resized_image.shape[:2] == resized_label.shape[:2]\n",
    "    assert np.minimum(resized_image.shape[0],resized_image.shape[1]) == RESIZE_DIM\n",
    "    return resized_image,resized_label\n",
    "\n",
    "def _change_background(bgd,image,label):\n",
    "    max_image_dim = np.maximum(image.shape[0],image.shape[1])\n",
    "    min_bgd_dim = np.minimum(bgd.shape[0],bgd.shape[1])\n",
    "    scale = float(max_image_dim)/float(min_bgd_dim)\n",
    "    if scale < 1.0:\n",
    "        resized_bgd = cv2.resize(bgd,None,fx=scale,fy=scale,interpolation=cv2.INTER_AREA)\n",
    "    else:\n",
    "        resized_bgd = cv2.resize(bgd,None,fx=scale,fy=scale)\n",
    "    image_width = image.shape[1]\n",
    "    image_height = image.shape[0]\n",
    "    offset_x = np.random.randint(resized_bgd.shape[1]-image_width+1)\n",
    "    offset_y = np.random.randint(resized_bgd.shape[0]-image_height+1)\n",
    "    crop_bgd = resized_bgd[offset_y:(offset_y+image_height),offset_x:(offset_x+image_width),:]\n",
    "    mask = (label == 0).astype(np.float)\n",
    "    mask = cv2.blur(mask,(5,5))\n",
    "    mask = np.expand_dims(mask,axis=2)\n",
    "    image2 = crop_bgd*mask + (1-mask)*image\n",
    "    return image2.astype(np.uint8)\n",
    "\n",
    "def writeLMDB(image_files, label_files, bgd_files, lmdb_path):\n",
    "    assert len(image_files) == len(label_files)\n",
    "    num_examples = len(image_files)\n",
    "    env = lmdb.open(lmdb_path, map_size=int(1e8))\n",
    "    txn = env.begin(write=True)\n",
    "    write_count = 0\n",
    "    for idx in xrange(num_examples):\n",
    "        img = cv2.imread(image_files[idx])\n",
    "        label_image = cv2.imread(label_files[idx])\n",
    "        label = _gen_label_image(label_image)\n",
    "        resized_image,resized_label = _resize_image_label(img,label)\n",
    "        resized_label = np.expand_dims(resized_label,axis=2)\n",
    "        img4ch = np.concatenate((resized_image, resized_label), axis=2)\n",
    "        datum = caffe.io.array_to_datum(img4ch, label=0)\n",
    "        key = '%07d' % writeCount\n",
    "        txn.put(key, datum.SerializeToString())\n",
    "        write_count = write_count + 1\n",
    "        if(write_count % 1000 == 0):\n",
    "            txn.commit()\n",
    "            txn = env.begin(write=True)\n",
    "            print 'count: %d/ total count: %d' % (write_count,num_examples)\n",
    "    if(write_count % 1000 != 0):\n",
    "        print 'count: %d/ total count: %d' % (write_count,num_examples)\n",
    "        txn.commit()\n",
    "    env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# write training data\n",
    "root_dir = '/Users/xuehan.xiong/Google Drive/datasets/selfies_segmentation'\n",
    "bgd_dir = os.path.join(root_dir,'segmentation_background')\n",
    "bgd_files = get_image_files(bgd_dir)\n",
    "image_dir = os.path.join(root_dir,'train/images')\n",
    "label_dir = os.path.join(root_dir,'train/labels')\n",
    "image_files = get_image_files(image_dir)\n",
    "label_files = get_image_files(label_dir)\n",
    "writeLMDB(image_files, label_files, bgd_files, \n",
    "          os.path.join(root_dir,'portrait_train'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# write validation data\n",
    "image_dir = os.path.join(root_dir,'val/images')\n",
    "label_dir = os.path.join(root_dir,'val/labels')\n",
    "image_files = get_image_files(image_dir)\n",
    "label_files = get_image_files(label_dir)\n",
    "writeLMDB(image_files, label_files, bgd_files, \n",
    "          os.path.join(root_dir,'portrait_val'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
