I0823 08:53:05.962375  7716 caffe.cpp:217] Using GPUs 1
I0823 08:53:05.985349  7716 caffe.cpp:222] GPU 1: GeForce GTX TITAN X
I0823 08:53:06.183115  7716 solver.cpp:48] Initializing solver from parameters: 
test_iter: 15
test_interval: 200
base_lr: 1e-05
display: 50
max_iter: 16000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 1e-06
stepsize: 4000
snapshot: 4000
snapshot_prefix: "portrait_one_stage"
solver_mode: GPU
device_id: 1
net: "portrait_train_test_one_stage.prototxt"
train_state {
  level: 0
  stage: ""
}
I0823 08:53:06.183223  7716 solver.cpp:91] Creating training net from net file: portrait_train_test_one_stage.prototxt
I0823 08:53:06.183953  7716 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0823 08:53:06.184162  7716 net.cpp:58] Initializing net from parameters: 
name: "segmentation"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "SegData"
  top: "image"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 200
  }
  data_param {
    source: "/raid/xuehan/segmentation_train_split"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "image"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 50
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv1_1_bn"
  type: "BatchNorm"
  bottom: "conv1_1"
  top: "conv1_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv1_1_bn_scale"
  type: "Scale"
  bottom: "conv1_1_bn"
  top: "conv1_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_1_relu"
  type: "ReLU"
  bottom: "conv1_1_bn"
  top: "conv1_1_bn"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1_bn"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv1_2_bn"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv1_2_bn_scale"
  type: "Scale"
  bottom: "conv1_2_bn"
  top: "conv1_2_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_2_relu"
  type: "ReLU"
  bottom: "conv1_2_bn"
  top: "conv1_2_bn"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2_bn"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv2_1_bn"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv2_1_bn_scale"
  type: "Scale"
  bottom: "conv2_1_bn"
  top: "conv2_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1_relu"
  type: "ReLU"
  bottom: "conv2_1_bn"
  top: "conv2_1_bn"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1_bn"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv2_2_bn"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv2_2_bn_scale"
  type: "Scale"
  bottom: "conv2_2_bn"
  top: "conv2_2_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_2_relu"
  type: "ReLU"
  bottom: "conv2_2_bn"
  top: "conv2_2_bn"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2_bn"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv3_1_bn"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv3_1_bn_scale"
  type: "Scale"
  bottom: "conv3_1_bn"
  top: "conv3_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1_relu"
  type: "ReLU"
  bottom: "conv3_1_bn"
  top: "conv3_1_bn"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1_bn"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv3_2_bn"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv3_2_bn_scale"
  type: "Scale"
  bottom: "conv3_2_bn"
  top: "conv3_2_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_2_relu"
  type: "ReLU"
  bottom: "conv3_2_bn"
  top: "conv3_2_bn"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_2_bn"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv4_1_bn"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv4_1_bn_scale"
  type: "Scale"
  bottom: "conv4_1_bn"
  top: "conv4_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1_relu"
  type: "ReLU"
  bottom: "conv4_1_bn"
  top: "conv4_1_bn"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1_bn"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv4_2_bn"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv4_2_bn_scale"
  type: "Scale"
  bottom: "conv4_2_bn"
  top: "conv4_2_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_2_relu"
  type: "ReLU"
  bottom: "conv4_2_bn"
  top: "conv4_2_bn"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_2_bn"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv5_1_bn"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv5_1_bn_scale"
  type: "Scale"
  bottom: "conv5_1_bn"
  top: "conv5_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_1_relu"
  type: "ReLU"
  bottom: "conv5_1_bn"
  top: "conv5_1_bn"
}
layer {
  name: "conv6_1"
  type: "Convolution"
  bottom: "conv5_1_bn"
  top: "conv6_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv6_1_bn"
  type: "BatchNorm"
  bottom: "conv6_1"
  top: "conv6_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv6_1_bn_scale"
  type: "Scale"
  bottom: "conv6_1_bn"
  top: "conv6_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv6_1_relu"
  type: "ReLU"
  bottom: "conv6_1_bn"
  top: "conv6_1_bn"
}
layer {
  name: "conv7_1"
  type: "Convolution"
  bottom: "conv6_1_bn"
  top: "conv7_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv7_1_bn"
  type: "BatchNorm"
  bottom: "conv7_1"
  top: "conv7_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv7_1_bn_scale"
  type: "Scale"
  bottom: "conv7_1_bn"
  top: "conv7_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv7_1_relu"
  type: "ReLU"
  bottom: "conv7_1_bn"
  top: "conv7_1_bn"
}
layer {
  name: "score"
  type: "Convolution"
  bottom: "conv7_1_bn"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 4
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "upscore"
  type: "Deconvolution"
  bottom: "score"
  top: "upscore"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 4
    bias_term: false
    pad: 0
    kernel_size: 32
    stride: 16
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "cropscore"
  type: "Crop"
  bottom: "upscore"
  bottom: "image"
  top: "cropscore"
  crop_param {
    axis: 2
    offset: 12
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "cropscore"
  bottom: "label"
  top: "loss"
  loss_weight: 1
  loss_param {
    normalize: false
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "cropscore"
  bottom: "label"
  top: "accuracy"
}
I0823 08:53:06.184345  7716 layer_factory.hpp:77] Creating layer data
I0823 08:53:06.184761  7716 net.cpp:100] Creating Layer data
I0823 08:53:06.184772  7716 net.cpp:408] data -> image
I0823 08:53:06.184788  7716 net.cpp:408] data -> label
I0823 08:53:06.185770  7722 db_lmdb.cpp:35] Opened lmdb /raid/xuehan/segmentation_train_split
I0823 08:53:06.185950  7716 seg_data_layer.cpp:38] 200 200 4
I0823 08:53:06.193222  7716 seg_data_layer.cpp:51] output data size: 64,3,200,200
I0823 08:53:06.193281  7716 seg_data_layer.cpp:63] output label size: 64,1,200,200
I0823 08:53:06.246635  7716 net.cpp:150] Setting up data
I0823 08:53:06.246666  7716 net.cpp:157] Top shape: 64 3 200 200 (7680000)
I0823 08:53:06.246671  7716 net.cpp:157] Top shape: 64 1 200 200 (2560000)
I0823 08:53:06.246675  7716 net.cpp:165] Memory required for data: 40960000
I0823 08:53:06.246685  7716 layer_factory.hpp:77] Creating layer image_data_0_split
I0823 08:53:06.246695  7716 net.cpp:100] Creating Layer image_data_0_split
I0823 08:53:06.246701  7716 net.cpp:434] image_data_0_split <- image
I0823 08:53:06.246711  7716 net.cpp:408] image_data_0_split -> image_data_0_split_0
I0823 08:53:06.246719  7716 net.cpp:408] image_data_0_split -> image_data_0_split_1
I0823 08:53:06.246763  7716 net.cpp:150] Setting up image_data_0_split
I0823 08:53:06.246769  7716 net.cpp:157] Top shape: 64 3 200 200 (7680000)
I0823 08:53:06.246773  7716 net.cpp:157] Top shape: 64 3 200 200 (7680000)
I0823 08:53:06.246775  7716 net.cpp:165] Memory required for data: 102400000
I0823 08:53:06.246785  7716 layer_factory.hpp:77] Creating layer label_data_1_split
I0823 08:53:06.246796  7716 net.cpp:100] Creating Layer label_data_1_split
I0823 08:53:06.246799  7716 net.cpp:434] label_data_1_split <- label
I0823 08:53:06.246805  7716 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0823 08:53:06.246810  7716 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0823 08:53:06.246834  7716 net.cpp:150] Setting up label_data_1_split
I0823 08:53:06.246839  7716 net.cpp:157] Top shape: 64 1 200 200 (2560000)
I0823 08:53:06.246842  7716 net.cpp:157] Top shape: 64 1 200 200 (2560000)
I0823 08:53:06.246845  7716 net.cpp:165] Memory required for data: 122880000
I0823 08:53:06.246847  7716 layer_factory.hpp:77] Creating layer conv1_1
I0823 08:53:06.246861  7716 net.cpp:100] Creating Layer conv1_1
I0823 08:53:06.246865  7716 net.cpp:434] conv1_1 <- image_data_0_split_0
I0823 08:53:06.246870  7716 net.cpp:408] conv1_1 -> conv1_1
I0823 08:53:06.247021  7716 net.cpp:150] Setting up conv1_1
I0823 08:53:06.247027  7716 net.cpp:157] Top shape: 64 8 298 298 (45467648)
I0823 08:53:06.247030  7716 net.cpp:165] Memory required for data: 304750592
I0823 08:53:06.247040  7716 layer_factory.hpp:77] Creating layer conv1_1_bn
I0823 08:53:06.247046  7716 net.cpp:100] Creating Layer conv1_1_bn
I0823 08:53:06.247050  7716 net.cpp:434] conv1_1_bn <- conv1_1
I0823 08:53:06.247053  7716 net.cpp:408] conv1_1_bn -> conv1_1_bn
I0823 08:53:06.247629  7716 net.cpp:150] Setting up conv1_1_bn
I0823 08:53:06.247639  7716 net.cpp:157] Top shape: 64 8 298 298 (45467648)
I0823 08:53:06.247642  7716 net.cpp:165] Memory required for data: 486621184
I0823 08:53:06.247651  7716 layer_factory.hpp:77] Creating layer conv1_1_bn_scale
I0823 08:53:06.247663  7716 net.cpp:100] Creating Layer conv1_1_bn_scale
I0823 08:53:06.247665  7716 net.cpp:434] conv1_1_bn_scale <- conv1_1_bn
I0823 08:53:06.247669  7716 net.cpp:395] conv1_1_bn_scale -> conv1_1_bn (in-place)
I0823 08:53:06.247701  7716 layer_factory.hpp:77] Creating layer conv1_1_bn_scale
I0823 08:53:06.248281  7716 net.cpp:150] Setting up conv1_1_bn_scale
I0823 08:53:06.248291  7716 net.cpp:157] Top shape: 64 8 298 298 (45467648)
I0823 08:53:06.248294  7716 net.cpp:165] Memory required for data: 668491776
I0823 08:53:06.248302  7716 layer_factory.hpp:77] Creating layer conv1_1_relu
I0823 08:53:06.248311  7716 net.cpp:100] Creating Layer conv1_1_relu
I0823 08:53:06.248314  7716 net.cpp:434] conv1_1_relu <- conv1_1_bn
I0823 08:53:06.248318  7716 net.cpp:395] conv1_1_relu -> conv1_1_bn (in-place)
I0823 08:53:06.248323  7716 net.cpp:150] Setting up conv1_1_relu
I0823 08:53:06.248327  7716 net.cpp:157] Top shape: 64 8 298 298 (45467648)
I0823 08:53:06.248330  7716 net.cpp:165] Memory required for data: 850362368
I0823 08:53:06.248333  7716 layer_factory.hpp:77] Creating layer conv1_2
I0823 08:53:06.248342  7716 net.cpp:100] Creating Layer conv1_2
I0823 08:53:06.248344  7716 net.cpp:434] conv1_2 <- conv1_1_bn
I0823 08:53:06.248348  7716 net.cpp:408] conv1_2 -> conv1_2
I0823 08:53:06.252235  7716 net.cpp:150] Setting up conv1_2
I0823 08:53:06.252248  7716 net.cpp:157] Top shape: 64 8 298 298 (45467648)
I0823 08:53:06.252250  7716 net.cpp:165] Memory required for data: 1032232960
I0823 08:53:06.252255  7716 layer_factory.hpp:77] Creating layer conv1_2_bn
I0823 08:53:06.252264  7716 net.cpp:100] Creating Layer conv1_2_bn
I0823 08:53:06.252267  7716 net.cpp:434] conv1_2_bn <- conv1_2
I0823 08:53:06.252272  7716 net.cpp:408] conv1_2_bn -> conv1_2_bn
I0823 08:53:06.252437  7716 net.cpp:150] Setting up conv1_2_bn
I0823 08:53:06.252454  7716 net.cpp:157] Top shape: 64 8 298 298 (45467648)
I0823 08:53:06.252457  7716 net.cpp:165] Memory required for data: 1214103552
I0823 08:53:06.252477  7716 layer_factory.hpp:77] Creating layer conv1_2_bn_scale
I0823 08:53:06.252483  7716 net.cpp:100] Creating Layer conv1_2_bn_scale
I0823 08:53:06.252486  7716 net.cpp:434] conv1_2_bn_scale <- conv1_2_bn
I0823 08:53:06.252490  7716 net.cpp:395] conv1_2_bn_scale -> conv1_2_bn (in-place)
I0823 08:53:06.252519  7716 layer_factory.hpp:77] Creating layer conv1_2_bn_scale
I0823 08:53:06.253068  7716 net.cpp:150] Setting up conv1_2_bn_scale
I0823 08:53:06.253078  7716 net.cpp:157] Top shape: 64 8 298 298 (45467648)
I0823 08:53:06.253082  7716 net.cpp:165] Memory required for data: 1395974144
I0823 08:53:06.253087  7716 layer_factory.hpp:77] Creating layer conv1_2_relu
I0823 08:53:06.253094  7716 net.cpp:100] Creating Layer conv1_2_relu
I0823 08:53:06.253098  7716 net.cpp:434] conv1_2_relu <- conv1_2_bn
I0823 08:53:06.253101  7716 net.cpp:395] conv1_2_relu -> conv1_2_bn (in-place)
I0823 08:53:06.253106  7716 net.cpp:150] Setting up conv1_2_relu
I0823 08:53:06.253110  7716 net.cpp:157] Top shape: 64 8 298 298 (45467648)
I0823 08:53:06.253113  7716 net.cpp:165] Memory required for data: 1577844736
I0823 08:53:06.253116  7716 layer_factory.hpp:77] Creating layer pool1
I0823 08:53:06.253123  7716 net.cpp:100] Creating Layer pool1
I0823 08:53:06.253126  7716 net.cpp:434] pool1 <- conv1_2_bn
I0823 08:53:06.253130  7716 net.cpp:408] pool1 -> pool1
I0823 08:53:06.253165  7716 net.cpp:150] Setting up pool1
I0823 08:53:06.253170  7716 net.cpp:157] Top shape: 64 8 149 149 (11366912)
I0823 08:53:06.253172  7716 net.cpp:165] Memory required for data: 1623312384
I0823 08:53:06.253175  7716 layer_factory.hpp:77] Creating layer conv2_1
I0823 08:53:06.253183  7716 net.cpp:100] Creating Layer conv2_1
I0823 08:53:06.253187  7716 net.cpp:434] conv2_1 <- pool1
I0823 08:53:06.253192  7716 net.cpp:408] conv2_1 -> conv2_1
I0823 08:53:06.253758  7716 net.cpp:150] Setting up conv2_1
I0823 08:53:06.253769  7716 net.cpp:157] Top shape: 64 16 149 149 (22733824)
I0823 08:53:06.253772  7716 net.cpp:165] Memory required for data: 1714247680
I0823 08:53:06.253777  7716 layer_factory.hpp:77] Creating layer conv2_1_bn
I0823 08:53:06.253782  7716 net.cpp:100] Creating Layer conv2_1_bn
I0823 08:53:06.253785  7716 net.cpp:434] conv2_1_bn <- conv2_1
I0823 08:53:06.253792  7716 net.cpp:408] conv2_1_bn -> conv2_1_bn
I0823 08:53:06.254362  7716 net.cpp:150] Setting up conv2_1_bn
I0823 08:53:06.254372  7716 net.cpp:157] Top shape: 64 16 149 149 (22733824)
I0823 08:53:06.254375  7716 net.cpp:165] Memory required for data: 1805182976
I0823 08:53:06.254381  7716 layer_factory.hpp:77] Creating layer conv2_1_bn_scale
I0823 08:53:06.254387  7716 net.cpp:100] Creating Layer conv2_1_bn_scale
I0823 08:53:06.254391  7716 net.cpp:434] conv2_1_bn_scale <- conv2_1_bn
I0823 08:53:06.254395  7716 net.cpp:395] conv2_1_bn_scale -> conv2_1_bn (in-place)
I0823 08:53:06.254426  7716 layer_factory.hpp:77] Creating layer conv2_1_bn_scale
I0823 08:53:06.254513  7716 net.cpp:150] Setting up conv2_1_bn_scale
I0823 08:53:06.254519  7716 net.cpp:157] Top shape: 64 16 149 149 (22733824)
I0823 08:53:06.254523  7716 net.cpp:165] Memory required for data: 1896118272
I0823 08:53:06.254530  7716 layer_factory.hpp:77] Creating layer conv2_1_relu
I0823 08:53:06.254536  7716 net.cpp:100] Creating Layer conv2_1_relu
I0823 08:53:06.254539  7716 net.cpp:434] conv2_1_relu <- conv2_1_bn
I0823 08:53:06.254544  7716 net.cpp:395] conv2_1_relu -> conv2_1_bn (in-place)
I0823 08:53:06.254549  7716 net.cpp:150] Setting up conv2_1_relu
I0823 08:53:06.254552  7716 net.cpp:157] Top shape: 64 16 149 149 (22733824)
I0823 08:53:06.254554  7716 net.cpp:165] Memory required for data: 1987053568
I0823 08:53:06.254557  7716 layer_factory.hpp:77] Creating layer conv2_2
I0823 08:53:06.254570  7716 net.cpp:100] Creating Layer conv2_2
I0823 08:53:06.254572  7716 net.cpp:434] conv2_2 <- conv2_1_bn
I0823 08:53:06.254580  7716 net.cpp:408] conv2_2 -> conv2_2
I0823 08:53:06.254745  7716 net.cpp:150] Setting up conv2_2
I0823 08:53:06.254751  7716 net.cpp:157] Top shape: 64 16 149 149 (22733824)
I0823 08:53:06.254755  7716 net.cpp:165] Memory required for data: 2077988864
I0823 08:53:06.254758  7716 layer_factory.hpp:77] Creating layer conv2_2_bn
I0823 08:53:06.254765  7716 net.cpp:100] Creating Layer conv2_2_bn
I0823 08:53:06.254768  7716 net.cpp:434] conv2_2_bn <- conv2_2
I0823 08:53:06.254772  7716 net.cpp:408] conv2_2_bn -> conv2_2_bn
I0823 08:53:06.254909  7716 net.cpp:150] Setting up conv2_2_bn
I0823 08:53:06.254921  7716 net.cpp:157] Top shape: 64 16 149 149 (22733824)
I0823 08:53:06.254925  7716 net.cpp:165] Memory required for data: 2168924160
I0823 08:53:06.254930  7716 layer_factory.hpp:77] Creating layer conv2_2_bn_scale
I0823 08:53:06.254936  7716 net.cpp:100] Creating Layer conv2_2_bn_scale
I0823 08:53:06.254940  7716 net.cpp:434] conv2_2_bn_scale <- conv2_2_bn
I0823 08:53:06.254943  7716 net.cpp:395] conv2_2_bn_scale -> conv2_2_bn (in-place)
I0823 08:53:06.254971  7716 layer_factory.hpp:77] Creating layer conv2_2_bn_scale
I0823 08:53:06.255058  7716 net.cpp:150] Setting up conv2_2_bn_scale
I0823 08:53:06.255064  7716 net.cpp:157] Top shape: 64 16 149 149 (22733824)
I0823 08:53:06.255066  7716 net.cpp:165] Memory required for data: 2259859456
I0823 08:53:06.255071  7716 layer_factory.hpp:77] Creating layer conv2_2_relu
I0823 08:53:06.255075  7716 net.cpp:100] Creating Layer conv2_2_relu
I0823 08:53:06.255079  7716 net.cpp:434] conv2_2_relu <- conv2_2_bn
I0823 08:53:06.255082  7716 net.cpp:395] conv2_2_relu -> conv2_2_bn (in-place)
I0823 08:53:06.255087  7716 net.cpp:150] Setting up conv2_2_relu
I0823 08:53:06.255090  7716 net.cpp:157] Top shape: 64 16 149 149 (22733824)
I0823 08:53:06.255094  7716 net.cpp:165] Memory required for data: 2350794752
I0823 08:53:06.255096  7716 layer_factory.hpp:77] Creating layer pool2
I0823 08:53:06.255102  7716 net.cpp:100] Creating Layer pool2
I0823 08:53:06.255105  7716 net.cpp:434] pool2 <- conv2_2_bn
I0823 08:53:06.255110  7716 net.cpp:408] pool2 -> pool2
I0823 08:53:06.255136  7716 net.cpp:150] Setting up pool2
I0823 08:53:06.255141  7716 net.cpp:157] Top shape: 64 16 75 75 (5760000)
I0823 08:53:06.255144  7716 net.cpp:165] Memory required for data: 2373834752
I0823 08:53:06.255146  7716 layer_factory.hpp:77] Creating layer conv3_1
I0823 08:53:06.255152  7716 net.cpp:100] Creating Layer conv3_1
I0823 08:53:06.255156  7716 net.cpp:434] conv3_1 <- pool2
I0823 08:53:06.255161  7716 net.cpp:408] conv3_1 -> conv3_1
I0823 08:53:06.255817  7716 net.cpp:150] Setting up conv3_1
I0823 08:53:06.255828  7716 net.cpp:157] Top shape: 64 32 75 75 (11520000)
I0823 08:53:06.255831  7716 net.cpp:165] Memory required for data: 2419914752
I0823 08:53:06.255836  7716 layer_factory.hpp:77] Creating layer conv3_1_bn
I0823 08:53:06.255841  7716 net.cpp:100] Creating Layer conv3_1_bn
I0823 08:53:06.255844  7716 net.cpp:434] conv3_1_bn <- conv3_1
I0823 08:53:06.255848  7716 net.cpp:408] conv3_1_bn -> conv3_1_bn
I0823 08:53:06.255976  7716 net.cpp:150] Setting up conv3_1_bn
I0823 08:53:06.255982  7716 net.cpp:157] Top shape: 64 32 75 75 (11520000)
I0823 08:53:06.255985  7716 net.cpp:165] Memory required for data: 2465994752
I0823 08:53:06.255990  7716 layer_factory.hpp:77] Creating layer conv3_1_bn_scale
I0823 08:53:06.255997  7716 net.cpp:100] Creating Layer conv3_1_bn_scale
I0823 08:53:06.256000  7716 net.cpp:434] conv3_1_bn_scale <- conv3_1_bn
I0823 08:53:06.256005  7716 net.cpp:395] conv3_1_bn_scale -> conv3_1_bn (in-place)
I0823 08:53:06.256036  7716 layer_factory.hpp:77] Creating layer conv3_1_bn_scale
I0823 08:53:06.256114  7716 net.cpp:150] Setting up conv3_1_bn_scale
I0823 08:53:06.256121  7716 net.cpp:157] Top shape: 64 32 75 75 (11520000)
I0823 08:53:06.256124  7716 net.cpp:165] Memory required for data: 2512074752
I0823 08:53:06.256129  7716 layer_factory.hpp:77] Creating layer conv3_1_relu
I0823 08:53:06.256135  7716 net.cpp:100] Creating Layer conv3_1_relu
I0823 08:53:06.256139  7716 net.cpp:434] conv3_1_relu <- conv3_1_bn
I0823 08:53:06.256142  7716 net.cpp:395] conv3_1_relu -> conv3_1_bn (in-place)
I0823 08:53:06.256146  7716 net.cpp:150] Setting up conv3_1_relu
I0823 08:53:06.256150  7716 net.cpp:157] Top shape: 64 32 75 75 (11520000)
I0823 08:53:06.256153  7716 net.cpp:165] Memory required for data: 2558154752
I0823 08:53:06.256156  7716 layer_factory.hpp:77] Creating layer conv3_2
I0823 08:53:06.256163  7716 net.cpp:100] Creating Layer conv3_2
I0823 08:53:06.256166  7716 net.cpp:434] conv3_2 <- conv3_1_bn
I0823 08:53:06.256172  7716 net.cpp:408] conv3_2 -> conv3_2
I0823 08:53:06.256491  7716 net.cpp:150] Setting up conv3_2
I0823 08:53:06.256497  7716 net.cpp:157] Top shape: 64 32 75 75 (11520000)
I0823 08:53:06.256500  7716 net.cpp:165] Memory required for data: 2604234752
I0823 08:53:06.256505  7716 layer_factory.hpp:77] Creating layer conv3_2_bn
I0823 08:53:06.256511  7716 net.cpp:100] Creating Layer conv3_2_bn
I0823 08:53:06.256515  7716 net.cpp:434] conv3_2_bn <- conv3_2
I0823 08:53:06.256518  7716 net.cpp:408] conv3_2_bn -> conv3_2_bn
I0823 08:53:06.256646  7716 net.cpp:150] Setting up conv3_2_bn
I0823 08:53:06.256651  7716 net.cpp:157] Top shape: 64 32 75 75 (11520000)
I0823 08:53:06.256654  7716 net.cpp:165] Memory required for data: 2650314752
I0823 08:53:06.256664  7716 layer_factory.hpp:77] Creating layer conv3_2_bn_scale
I0823 08:53:06.256670  7716 net.cpp:100] Creating Layer conv3_2_bn_scale
I0823 08:53:06.256674  7716 net.cpp:434] conv3_2_bn_scale <- conv3_2_bn
I0823 08:53:06.256677  7716 net.cpp:395] conv3_2_bn_scale -> conv3_2_bn (in-place)
I0823 08:53:06.256705  7716 layer_factory.hpp:77] Creating layer conv3_2_bn_scale
I0823 08:53:06.256780  7716 net.cpp:150] Setting up conv3_2_bn_scale
I0823 08:53:06.256785  7716 net.cpp:157] Top shape: 64 32 75 75 (11520000)
I0823 08:53:06.256788  7716 net.cpp:165] Memory required for data: 2696394752
I0823 08:53:06.256793  7716 layer_factory.hpp:77] Creating layer conv3_2_relu
I0823 08:53:06.256799  7716 net.cpp:100] Creating Layer conv3_2_relu
I0823 08:53:06.256803  7716 net.cpp:434] conv3_2_relu <- conv3_2_bn
I0823 08:53:06.256806  7716 net.cpp:395] conv3_2_relu -> conv3_2_bn (in-place)
I0823 08:53:06.256811  7716 net.cpp:150] Setting up conv3_2_relu
I0823 08:53:06.256815  7716 net.cpp:157] Top shape: 64 32 75 75 (11520000)
I0823 08:53:06.256817  7716 net.cpp:165] Memory required for data: 2742474752
I0823 08:53:06.256820  7716 layer_factory.hpp:77] Creating layer pool3
I0823 08:53:06.256826  7716 net.cpp:100] Creating Layer pool3
I0823 08:53:06.256829  7716 net.cpp:434] pool3 <- conv3_2_bn
I0823 08:53:06.256834  7716 net.cpp:408] pool3 -> pool3
I0823 08:53:06.256860  7716 net.cpp:150] Setting up pool3
I0823 08:53:06.256865  7716 net.cpp:157] Top shape: 64 32 38 38 (2957312)
I0823 08:53:06.256867  7716 net.cpp:165] Memory required for data: 2754304000
I0823 08:53:06.256870  7716 layer_factory.hpp:77] Creating layer conv4_1
I0823 08:53:06.256877  7716 net.cpp:100] Creating Layer conv4_1
I0823 08:53:06.256880  7716 net.cpp:434] conv4_1 <- pool3
I0823 08:53:06.256886  7716 net.cpp:408] conv4_1 -> conv4_1
I0823 08:53:06.257413  7716 net.cpp:150] Setting up conv4_1
I0823 08:53:06.257419  7716 net.cpp:157] Top shape: 64 64 38 38 (5914624)
I0823 08:53:06.257422  7716 net.cpp:165] Memory required for data: 2777962496
I0823 08:53:06.257426  7716 layer_factory.hpp:77] Creating layer conv4_1_bn
I0823 08:53:06.257431  7716 net.cpp:100] Creating Layer conv4_1_bn
I0823 08:53:06.257434  7716 net.cpp:434] conv4_1_bn <- conv4_1
I0823 08:53:06.257438  7716 net.cpp:408] conv4_1_bn -> conv4_1_bn
I0823 08:53:06.257565  7716 net.cpp:150] Setting up conv4_1_bn
I0823 08:53:06.257570  7716 net.cpp:157] Top shape: 64 64 38 38 (5914624)
I0823 08:53:06.257573  7716 net.cpp:165] Memory required for data: 2801620992
I0823 08:53:06.257578  7716 layer_factory.hpp:77] Creating layer conv4_1_bn_scale
I0823 08:53:06.257586  7716 net.cpp:100] Creating Layer conv4_1_bn_scale
I0823 08:53:06.257589  7716 net.cpp:434] conv4_1_bn_scale <- conv4_1_bn
I0823 08:53:06.257596  7716 net.cpp:395] conv4_1_bn_scale -> conv4_1_bn (in-place)
I0823 08:53:06.257622  7716 layer_factory.hpp:77] Creating layer conv4_1_bn_scale
I0823 08:53:06.257701  7716 net.cpp:150] Setting up conv4_1_bn_scale
I0823 08:53:06.257706  7716 net.cpp:157] Top shape: 64 64 38 38 (5914624)
I0823 08:53:06.257709  7716 net.cpp:165] Memory required for data: 2825279488
I0823 08:53:06.257714  7716 layer_factory.hpp:77] Creating layer conv4_1_relu
I0823 08:53:06.257719  7716 net.cpp:100] Creating Layer conv4_1_relu
I0823 08:53:06.257728  7716 net.cpp:434] conv4_1_relu <- conv4_1_bn
I0823 08:53:06.257738  7716 net.cpp:395] conv4_1_relu -> conv4_1_bn (in-place)
I0823 08:53:06.257747  7716 net.cpp:150] Setting up conv4_1_relu
I0823 08:53:06.257752  7716 net.cpp:157] Top shape: 64 64 38 38 (5914624)
I0823 08:53:06.257755  7716 net.cpp:165] Memory required for data: 2848937984
I0823 08:53:06.257757  7716 layer_factory.hpp:77] Creating layer conv4_2
I0823 08:53:06.257764  7716 net.cpp:100] Creating Layer conv4_2
I0823 08:53:06.257766  7716 net.cpp:434] conv4_2 <- conv4_1_bn
I0823 08:53:06.257772  7716 net.cpp:408] conv4_2 -> conv4_2
I0823 08:53:06.258668  7716 net.cpp:150] Setting up conv4_2
I0823 08:53:06.258674  7716 net.cpp:157] Top shape: 64 64 38 38 (5914624)
I0823 08:53:06.258677  7716 net.cpp:165] Memory required for data: 2872596480
I0823 08:53:06.258682  7716 layer_factory.hpp:77] Creating layer conv4_2_bn
I0823 08:53:06.258687  7716 net.cpp:100] Creating Layer conv4_2_bn
I0823 08:53:06.258690  7716 net.cpp:434] conv4_2_bn <- conv4_2
I0823 08:53:06.258694  7716 net.cpp:408] conv4_2_bn -> conv4_2_bn
I0823 08:53:06.258821  7716 net.cpp:150] Setting up conv4_2_bn
I0823 08:53:06.258826  7716 net.cpp:157] Top shape: 64 64 38 38 (5914624)
I0823 08:53:06.258829  7716 net.cpp:165] Memory required for data: 2896254976
I0823 08:53:06.258834  7716 layer_factory.hpp:77] Creating layer conv4_2_bn_scale
I0823 08:53:06.258839  7716 net.cpp:100] Creating Layer conv4_2_bn_scale
I0823 08:53:06.258842  7716 net.cpp:434] conv4_2_bn_scale <- conv4_2_bn
I0823 08:53:06.258847  7716 net.cpp:395] conv4_2_bn_scale -> conv4_2_bn (in-place)
I0823 08:53:06.258874  7716 layer_factory.hpp:77] Creating layer conv4_2_bn_scale
I0823 08:53:06.258949  7716 net.cpp:150] Setting up conv4_2_bn_scale
I0823 08:53:06.258955  7716 net.cpp:157] Top shape: 64 64 38 38 (5914624)
I0823 08:53:06.258956  7716 net.cpp:165] Memory required for data: 2919913472
I0823 08:53:06.258961  7716 layer_factory.hpp:77] Creating layer conv4_2_relu
I0823 08:53:06.258965  7716 net.cpp:100] Creating Layer conv4_2_relu
I0823 08:53:06.258968  7716 net.cpp:434] conv4_2_relu <- conv4_2_bn
I0823 08:53:06.258975  7716 net.cpp:395] conv4_2_relu -> conv4_2_bn (in-place)
I0823 08:53:06.258978  7716 net.cpp:150] Setting up conv4_2_relu
I0823 08:53:06.258982  7716 net.cpp:157] Top shape: 64 64 38 38 (5914624)
I0823 08:53:06.258985  7716 net.cpp:165] Memory required for data: 2943571968
I0823 08:53:06.258988  7716 layer_factory.hpp:77] Creating layer pool4
I0823 08:53:06.258992  7716 net.cpp:100] Creating Layer pool4
I0823 08:53:06.258996  7716 net.cpp:434] pool4 <- conv4_2_bn
I0823 08:53:06.259001  7716 net.cpp:408] pool4 -> pool4
I0823 08:53:06.259026  7716 net.cpp:150] Setting up pool4
I0823 08:53:06.259030  7716 net.cpp:157] Top shape: 64 64 19 19 (1478656)
I0823 08:53:06.259033  7716 net.cpp:165] Memory required for data: 2949486592
I0823 08:53:06.259037  7716 layer_factory.hpp:77] Creating layer conv5_1
I0823 08:53:06.259042  7716 net.cpp:100] Creating Layer conv5_1
I0823 08:53:06.259045  7716 net.cpp:434] conv5_1 <- pool4
I0823 08:53:06.259050  7716 net.cpp:408] conv5_1 -> conv5_1
I0823 08:53:06.259968  7716 net.cpp:150] Setting up conv5_1
I0823 08:53:06.259975  7716 net.cpp:157] Top shape: 64 64 17 17 (1183744)
I0823 08:53:06.259979  7716 net.cpp:165] Memory required for data: 2954221568
I0823 08:53:06.259982  7716 layer_factory.hpp:77] Creating layer conv5_1_bn
I0823 08:53:06.259989  7716 net.cpp:100] Creating Layer conv5_1_bn
I0823 08:53:06.259991  7716 net.cpp:434] conv5_1_bn <- conv5_1
I0823 08:53:06.259995  7716 net.cpp:408] conv5_1_bn -> conv5_1_bn
I0823 08:53:06.260126  7716 net.cpp:150] Setting up conv5_1_bn
I0823 08:53:06.260131  7716 net.cpp:157] Top shape: 64 64 17 17 (1183744)
I0823 08:53:06.260134  7716 net.cpp:165] Memory required for data: 2958956544
I0823 08:53:06.260139  7716 layer_factory.hpp:77] Creating layer conv5_1_bn_scale
I0823 08:53:06.260144  7716 net.cpp:100] Creating Layer conv5_1_bn_scale
I0823 08:53:06.260148  7716 net.cpp:434] conv5_1_bn_scale <- conv5_1_bn
I0823 08:53:06.260151  7716 net.cpp:395] conv5_1_bn_scale -> conv5_1_bn (in-place)
I0823 08:53:06.260185  7716 layer_factory.hpp:77] Creating layer conv5_1_bn_scale
I0823 08:53:06.260288  7716 net.cpp:150] Setting up conv5_1_bn_scale
I0823 08:53:06.260293  7716 net.cpp:157] Top shape: 64 64 17 17 (1183744)
I0823 08:53:06.260296  7716 net.cpp:165] Memory required for data: 2963691520
I0823 08:53:06.260301  7716 layer_factory.hpp:77] Creating layer conv5_1_relu
I0823 08:53:06.260305  7716 net.cpp:100] Creating Layer conv5_1_relu
I0823 08:53:06.260308  7716 net.cpp:434] conv5_1_relu <- conv5_1_bn
I0823 08:53:06.260313  7716 net.cpp:395] conv5_1_relu -> conv5_1_bn (in-place)
I0823 08:53:06.260318  7716 net.cpp:150] Setting up conv5_1_relu
I0823 08:53:06.260321  7716 net.cpp:157] Top shape: 64 64 17 17 (1183744)
I0823 08:53:06.260324  7716 net.cpp:165] Memory required for data: 2968426496
I0823 08:53:06.260327  7716 layer_factory.hpp:77] Creating layer conv6_1
I0823 08:53:06.260334  7716 net.cpp:100] Creating Layer conv6_1
I0823 08:53:06.260337  7716 net.cpp:434] conv6_1 <- conv5_1_bn
I0823 08:53:06.260341  7716 net.cpp:408] conv6_1 -> conv6_1
I0823 08:53:06.261786  7716 net.cpp:150] Setting up conv6_1
I0823 08:53:06.261800  7716 net.cpp:157] Top shape: 64 64 15 15 (921600)
I0823 08:53:06.261802  7716 net.cpp:165] Memory required for data: 2972112896
I0823 08:53:06.261806  7716 layer_factory.hpp:77] Creating layer conv6_1_bn
I0823 08:53:06.261813  7716 net.cpp:100] Creating Layer conv6_1_bn
I0823 08:53:06.261817  7716 net.cpp:434] conv6_1_bn <- conv6_1
I0823 08:53:06.261821  7716 net.cpp:408] conv6_1_bn -> conv6_1_bn
I0823 08:53:06.261956  7716 net.cpp:150] Setting up conv6_1_bn
I0823 08:53:06.261961  7716 net.cpp:157] Top shape: 64 64 15 15 (921600)
I0823 08:53:06.261965  7716 net.cpp:165] Memory required for data: 2975799296
I0823 08:53:06.261970  7716 layer_factory.hpp:77] Creating layer conv6_1_bn_scale
I0823 08:53:06.261976  7716 net.cpp:100] Creating Layer conv6_1_bn_scale
I0823 08:53:06.261978  7716 net.cpp:434] conv6_1_bn_scale <- conv6_1_bn
I0823 08:53:06.261984  7716 net.cpp:395] conv6_1_bn_scale -> conv6_1_bn (in-place)
I0823 08:53:06.262012  7716 layer_factory.hpp:77] Creating layer conv6_1_bn_scale
I0823 08:53:06.262091  7716 net.cpp:150] Setting up conv6_1_bn_scale
I0823 08:53:06.262099  7716 net.cpp:157] Top shape: 64 64 15 15 (921600)
I0823 08:53:06.262100  7716 net.cpp:165] Memory required for data: 2979485696
I0823 08:53:06.262105  7716 layer_factory.hpp:77] Creating layer conv6_1_relu
I0823 08:53:06.262110  7716 net.cpp:100] Creating Layer conv6_1_relu
I0823 08:53:06.262114  7716 net.cpp:434] conv6_1_relu <- conv6_1_bn
I0823 08:53:06.262118  7716 net.cpp:395] conv6_1_relu -> conv6_1_bn (in-place)
I0823 08:53:06.262123  7716 net.cpp:150] Setting up conv6_1_relu
I0823 08:53:06.262127  7716 net.cpp:157] Top shape: 64 64 15 15 (921600)
I0823 08:53:06.262130  7716 net.cpp:165] Memory required for data: 2983172096
I0823 08:53:06.262132  7716 layer_factory.hpp:77] Creating layer conv7_1
I0823 08:53:06.262140  7716 net.cpp:100] Creating Layer conv7_1
I0823 08:53:06.262143  7716 net.cpp:434] conv7_1 <- conv6_1_bn
I0823 08:53:06.262147  7716 net.cpp:408] conv7_1 -> conv7_1
I0823 08:53:06.263898  7716 net.cpp:150] Setting up conv7_1
I0823 08:53:06.263905  7716 net.cpp:157] Top shape: 64 128 13 13 (1384448)
I0823 08:53:06.263907  7716 net.cpp:165] Memory required for data: 2988709888
I0823 08:53:06.263911  7716 layer_factory.hpp:77] Creating layer conv7_1_bn
I0823 08:53:06.263917  7716 net.cpp:100] Creating Layer conv7_1_bn
I0823 08:53:06.263921  7716 net.cpp:434] conv7_1_bn <- conv7_1
I0823 08:53:06.263926  7716 net.cpp:408] conv7_1_bn -> conv7_1_bn
I0823 08:53:06.264048  7716 net.cpp:150] Setting up conv7_1_bn
I0823 08:53:06.264053  7716 net.cpp:157] Top shape: 64 128 13 13 (1384448)
I0823 08:53:06.264056  7716 net.cpp:165] Memory required for data: 2994247680
I0823 08:53:06.264062  7716 layer_factory.hpp:77] Creating layer conv7_1_bn_scale
I0823 08:53:06.264068  7716 net.cpp:100] Creating Layer conv7_1_bn_scale
I0823 08:53:06.264071  7716 net.cpp:434] conv7_1_bn_scale <- conv7_1_bn
I0823 08:53:06.264081  7716 net.cpp:395] conv7_1_bn_scale -> conv7_1_bn (in-place)
I0823 08:53:06.264116  7716 layer_factory.hpp:77] Creating layer conv7_1_bn_scale
I0823 08:53:06.264185  7716 net.cpp:150] Setting up conv7_1_bn_scale
I0823 08:53:06.264190  7716 net.cpp:157] Top shape: 64 128 13 13 (1384448)
I0823 08:53:06.264194  7716 net.cpp:165] Memory required for data: 2999785472
I0823 08:53:06.264209  7716 layer_factory.hpp:77] Creating layer conv7_1_relu
I0823 08:53:06.264215  7716 net.cpp:100] Creating Layer conv7_1_relu
I0823 08:53:06.264219  7716 net.cpp:434] conv7_1_relu <- conv7_1_bn
I0823 08:53:06.264224  7716 net.cpp:395] conv7_1_relu -> conv7_1_bn (in-place)
I0823 08:53:06.264228  7716 net.cpp:150] Setting up conv7_1_relu
I0823 08:53:06.264231  7716 net.cpp:157] Top shape: 64 128 13 13 (1384448)
I0823 08:53:06.264235  7716 net.cpp:165] Memory required for data: 3005323264
I0823 08:53:06.264237  7716 layer_factory.hpp:77] Creating layer score
I0823 08:53:06.264243  7716 net.cpp:100] Creating Layer score
I0823 08:53:06.264246  7716 net.cpp:434] score <- conv7_1_bn
I0823 08:53:06.264251  7716 net.cpp:408] score -> score
I0823 08:53:06.264415  7716 net.cpp:150] Setting up score
I0823 08:53:06.264421  7716 net.cpp:157] Top shape: 64 4 13 13 (43264)
I0823 08:53:06.264425  7716 net.cpp:165] Memory required for data: 3005496320
I0823 08:53:06.264428  7716 layer_factory.hpp:77] Creating layer upscore
I0823 08:53:06.264436  7716 net.cpp:100] Creating Layer upscore
I0823 08:53:06.264439  7716 net.cpp:434] upscore <- score
I0823 08:53:06.264444  7716 net.cpp:408] upscore -> upscore
I0823 08:53:06.264916  7716 net.cpp:150] Setting up upscore
I0823 08:53:06.264922  7716 net.cpp:157] Top shape: 64 4 224 224 (12845056)
I0823 08:53:06.264925  7716 net.cpp:165] Memory required for data: 3056876544
I0823 08:53:06.264930  7716 layer_factory.hpp:77] Creating layer cropscore
I0823 08:53:06.264935  7716 net.cpp:100] Creating Layer cropscore
I0823 08:53:06.264938  7716 net.cpp:434] cropscore <- upscore
I0823 08:53:06.264941  7716 net.cpp:434] cropscore <- image_data_0_split_1
I0823 08:53:06.264945  7716 net.cpp:408] cropscore -> cropscore
I0823 08:53:06.264966  7716 net.cpp:150] Setting up cropscore
I0823 08:53:06.264971  7716 net.cpp:157] Top shape: 64 4 200 200 (10240000)
I0823 08:53:06.264974  7716 net.cpp:165] Memory required for data: 3097836544
I0823 08:53:06.264977  7716 layer_factory.hpp:77] Creating layer cropscore_cropscore_0_split
I0823 08:53:06.264981  7716 net.cpp:100] Creating Layer cropscore_cropscore_0_split
I0823 08:53:06.264984  7716 net.cpp:434] cropscore_cropscore_0_split <- cropscore
I0823 08:53:06.264988  7716 net.cpp:408] cropscore_cropscore_0_split -> cropscore_cropscore_0_split_0
I0823 08:53:06.264993  7716 net.cpp:408] cropscore_cropscore_0_split -> cropscore_cropscore_0_split_1
I0823 08:53:06.265017  7716 net.cpp:150] Setting up cropscore_cropscore_0_split
I0823 08:53:06.265022  7716 net.cpp:157] Top shape: 64 4 200 200 (10240000)
I0823 08:53:06.265025  7716 net.cpp:157] Top shape: 64 4 200 200 (10240000)
I0823 08:53:06.265028  7716 net.cpp:165] Memory required for data: 3179756544
I0823 08:53:06.265031  7716 layer_factory.hpp:77] Creating layer loss
I0823 08:53:06.265036  7716 net.cpp:100] Creating Layer loss
I0823 08:53:06.265039  7716 net.cpp:434] loss <- cropscore_cropscore_0_split_0
I0823 08:53:06.265043  7716 net.cpp:434] loss <- label_data_1_split_0
I0823 08:53:06.265048  7716 net.cpp:408] loss -> loss
I0823 08:53:06.265055  7716 layer_factory.hpp:77] Creating layer loss
I0823 08:53:06.283537  7716 net.cpp:150] Setting up loss
I0823 08:53:06.283565  7716 net.cpp:157] Top shape: (1)
I0823 08:53:06.283567  7716 net.cpp:160]     with loss weight 1
I0823 08:53:06.283584  7716 net.cpp:165] Memory required for data: 3179756548
I0823 08:53:06.283588  7716 layer_factory.hpp:77] Creating layer accuracy
I0823 08:53:06.283607  7716 net.cpp:100] Creating Layer accuracy
I0823 08:53:06.283612  7716 net.cpp:434] accuracy <- cropscore_cropscore_0_split_1
I0823 08:53:06.283617  7716 net.cpp:434] accuracy <- label_data_1_split_1
I0823 08:53:06.283630  7716 net.cpp:408] accuracy -> accuracy
I0823 08:53:06.283646  7716 net.cpp:150] Setting up accuracy
I0823 08:53:06.283653  7716 net.cpp:157] Top shape: (1)
I0823 08:53:06.283655  7716 net.cpp:165] Memory required for data: 3179756552
I0823 08:53:06.283658  7716 net.cpp:228] accuracy does not need backward computation.
I0823 08:53:06.283661  7716 net.cpp:226] loss needs backward computation.
I0823 08:53:06.283665  7716 net.cpp:226] cropscore_cropscore_0_split needs backward computation.
I0823 08:53:06.283668  7716 net.cpp:226] cropscore needs backward computation.
I0823 08:53:06.283673  7716 net.cpp:226] upscore needs backward computation.
I0823 08:53:06.283675  7716 net.cpp:226] score needs backward computation.
I0823 08:53:06.283679  7716 net.cpp:226] conv7_1_relu needs backward computation.
I0823 08:53:06.283681  7716 net.cpp:226] conv7_1_bn_scale needs backward computation.
I0823 08:53:06.283684  7716 net.cpp:226] conv7_1_bn needs backward computation.
I0823 08:53:06.283687  7716 net.cpp:226] conv7_1 needs backward computation.
I0823 08:53:06.283690  7716 net.cpp:226] conv6_1_relu needs backward computation.
I0823 08:53:06.283694  7716 net.cpp:226] conv6_1_bn_scale needs backward computation.
I0823 08:53:06.283696  7716 net.cpp:226] conv6_1_bn needs backward computation.
I0823 08:53:06.283699  7716 net.cpp:226] conv6_1 needs backward computation.
I0823 08:53:06.283702  7716 net.cpp:226] conv5_1_relu needs backward computation.
I0823 08:53:06.283705  7716 net.cpp:226] conv5_1_bn_scale needs backward computation.
I0823 08:53:06.283707  7716 net.cpp:226] conv5_1_bn needs backward computation.
I0823 08:53:06.283710  7716 net.cpp:226] conv5_1 needs backward computation.
I0823 08:53:06.283715  7716 net.cpp:226] pool4 needs backward computation.
I0823 08:53:06.283717  7716 net.cpp:226] conv4_2_relu needs backward computation.
I0823 08:53:06.283720  7716 net.cpp:226] conv4_2_bn_scale needs backward computation.
I0823 08:53:06.283722  7716 net.cpp:226] conv4_2_bn needs backward computation.
I0823 08:53:06.283725  7716 net.cpp:226] conv4_2 needs backward computation.
I0823 08:53:06.283728  7716 net.cpp:226] conv4_1_relu needs backward computation.
I0823 08:53:06.283731  7716 net.cpp:226] conv4_1_bn_scale needs backward computation.
I0823 08:53:06.283733  7716 net.cpp:226] conv4_1_bn needs backward computation.
I0823 08:53:06.283736  7716 net.cpp:226] conv4_1 needs backward computation.
I0823 08:53:06.283740  7716 net.cpp:226] pool3 needs backward computation.
I0823 08:53:06.283743  7716 net.cpp:226] conv3_2_relu needs backward computation.
I0823 08:53:06.283746  7716 net.cpp:226] conv3_2_bn_scale needs backward computation.
I0823 08:53:06.283748  7716 net.cpp:226] conv3_2_bn needs backward computation.
I0823 08:53:06.283751  7716 net.cpp:226] conv3_2 needs backward computation.
I0823 08:53:06.283754  7716 net.cpp:226] conv3_1_relu needs backward computation.
I0823 08:53:06.283757  7716 net.cpp:226] conv3_1_bn_scale needs backward computation.
I0823 08:53:06.283759  7716 net.cpp:226] conv3_1_bn needs backward computation.
I0823 08:53:06.283762  7716 net.cpp:226] conv3_1 needs backward computation.
I0823 08:53:06.283766  7716 net.cpp:226] pool2 needs backward computation.
I0823 08:53:06.283768  7716 net.cpp:226] conv2_2_relu needs backward computation.
I0823 08:53:06.283771  7716 net.cpp:226] conv2_2_bn_scale needs backward computation.
I0823 08:53:06.283774  7716 net.cpp:226] conv2_2_bn needs backward computation.
I0823 08:53:06.283777  7716 net.cpp:226] conv2_2 needs backward computation.
I0823 08:53:06.283781  7716 net.cpp:226] conv2_1_relu needs backward computation.
I0823 08:53:06.283783  7716 net.cpp:226] conv2_1_bn_scale needs backward computation.
I0823 08:53:06.283787  7716 net.cpp:226] conv2_1_bn needs backward computation.
I0823 08:53:06.283788  7716 net.cpp:226] conv2_1 needs backward computation.
I0823 08:53:06.283792  7716 net.cpp:226] pool1 needs backward computation.
I0823 08:53:06.283794  7716 net.cpp:226] conv1_2_relu needs backward computation.
I0823 08:53:06.283797  7716 net.cpp:226] conv1_2_bn_scale needs backward computation.
I0823 08:53:06.283807  7716 net.cpp:226] conv1_2_bn needs backward computation.
I0823 08:53:06.283809  7716 net.cpp:226] conv1_2 needs backward computation.
I0823 08:53:06.283812  7716 net.cpp:226] conv1_1_relu needs backward computation.
I0823 08:53:06.283815  7716 net.cpp:226] conv1_1_bn_scale needs backward computation.
I0823 08:53:06.283818  7716 net.cpp:226] conv1_1_bn needs backward computation.
I0823 08:53:06.283820  7716 net.cpp:226] conv1_1 needs backward computation.
I0823 08:53:06.283824  7716 net.cpp:228] label_data_1_split does not need backward computation.
I0823 08:53:06.283828  7716 net.cpp:228] image_data_0_split does not need backward computation.
I0823 08:53:06.283830  7716 net.cpp:228] data does not need backward computation.
I0823 08:53:06.283833  7716 net.cpp:270] This network produces output accuracy
I0823 08:53:06.283836  7716 net.cpp:270] This network produces output loss
I0823 08:53:06.283870  7716 net.cpp:283] Network initialization done.
I0823 08:53:06.284670  7716 solver.cpp:181] Creating test net (#0) specified by net file: portrait_train_test_one_stage.prototxt
I0823 08:53:06.284721  7716 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0823 08:53:06.284922  7716 net.cpp:58] Initializing net from parameters: 
name: "segmentation"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "SegData"
  top: "image"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 200
  }
  data_param {
    source: "/raid/xuehan/segmentation_test_split"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "image"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 50
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv1_1_bn"
  type: "BatchNorm"
  bottom: "conv1_1"
  top: "conv1_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv1_1_bn_scale"
  type: "Scale"
  bottom: "conv1_1_bn"
  top: "conv1_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_1_relu"
  type: "ReLU"
  bottom: "conv1_1_bn"
  top: "conv1_1_bn"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1_bn"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv1_2_bn"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv1_2_bn_scale"
  type: "Scale"
  bottom: "conv1_2_bn"
  top: "conv1_2_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_2_relu"
  type: "ReLU"
  bottom: "conv1_2_bn"
  top: "conv1_2_bn"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2_bn"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv2_1_bn"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv2_1_bn_scale"
  type: "Scale"
  bottom: "conv2_1_bn"
  top: "conv2_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1_relu"
  type: "ReLU"
  bottom: "conv2_1_bn"
  top: "conv2_1_bn"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1_bn"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv2_2_bn"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv2_2_bn_scale"
  type: "Scale"
  bottom: "conv2_2_bn"
  top: "conv2_2_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_2_relu"
  type: "ReLU"
  bottom: "conv2_2_bn"
  top: "conv2_2_bn"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2_bn"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv3_1_bn"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv3_1_bn_scale"
  type: "Scale"
  bottom: "conv3_1_bn"
  top: "conv3_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1_relu"
  type: "ReLU"
  bottom: "conv3_1_bn"
  top: "conv3_1_bn"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1_bn"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv3_2_bn"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv3_2_bn_scale"
  type: "Scale"
  bottom: "conv3_2_bn"
  top: "conv3_2_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_2_relu"
  type: "ReLU"
  bottom: "conv3_2_bn"
  top: "conv3_2_bn"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_2_bn"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv4_1_bn"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv4_1_bn_scale"
  type: "Scale"
  bottom: "conv4_1_bn"
  top: "conv4_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1_relu"
  type: "ReLU"
  bottom: "conv4_1_bn"
  top: "conv4_1_bn"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1_bn"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv4_2_bn"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv4_2_bn_scale"
  type: "Scale"
  bottom: "conv4_2_bn"
  top: "conv4_2_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_2_relu"
  type: "ReLU"
  bottom: "conv4_2_bn"
  top: "conv4_2_bn"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_2_bn"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv5_1_bn"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv5_1_bn_scale"
  type: "Scale"
  bottom: "conv5_1_bn"
  top: "conv5_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_1_relu"
  type: "ReLU"
  bottom: "conv5_1_bn"
  top: "conv5_1_bn"
}
layer {
  name: "conv6_1"
  type: "Convolution"
  bottom: "conv5_1_bn"
  top: "conv6_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv6_1_bn"
  type: "BatchNorm"
  bottom: "conv6_1"
  top: "conv6_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv6_1_bn_scale"
  type: "Scale"
  bottom: "conv6_1_bn"
  top: "conv6_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv6_1_relu"
  type: "ReLU"
  bottom: "conv6_1_bn"
  top: "conv6_1_bn"
}
layer {
  name: "conv7_1"
  type: "Convolution"
  bottom: "conv6_1_bn"
  top: "conv7_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv7_1_bn"
  type: "BatchNorm"
  bottom: "conv7_1"
  top: "conv7_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv7_1_bn_scale"
  type: "Scale"
  bottom: "conv7_1_bn"
  top: "conv7_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv7_1_relu"
  type: "ReLU"
  bottom: "conv7_1_bn"
  top: "conv7_1_bn"
}
layer {
  name: "score"
  type: "Convolution"
  bottom: "conv7_1_bn"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 4
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "upscore"
  type: "Deconvolution"
  bottom: "score"
  top: "upscore"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 4
    bias_term: false
    pad: 0
    kernel_size: 32
    stride: 16
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "cropscore"
  type: "Crop"
  bottom: "upscore"
  bottom: "image"
  top: "cropscore"
  crop_param {
    axis: 2
    offset: 12
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "cropscore"
  bottom: "label"
  top: "loss"
  loss_weight: 1
  loss_param {
    normalize: false
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "cropscore"
  bottom: "label"
  top: "accuracy"
}
I0823 08:53:06.285071  7716 layer_factory.hpp:77] Creating layer data
I0823 08:53:06.285161  7716 net.cpp:100] Creating Layer data
I0823 08:53:06.285172  7716 net.cpp:408] data -> image
I0823 08:53:06.285179  7716 net.cpp:408] data -> label
I0823 08:53:06.286250  7724 db_lmdb.cpp:35] Opened lmdb /raid/xuehan/segmentation_test_split
I0823 08:53:06.286418  7716 seg_data_layer.cpp:38] 200 200 4
I0823 08:53:06.286495  7716 seg_data_layer.cpp:51] output data size: 64,3,200,200
I0823 08:53:06.286541  7716 seg_data_layer.cpp:63] output label size: 64,1,200,200
I0823 08:53:06.344702  7716 net.cpp:150] Setting up data
I0823 08:53:06.344732  7716 net.cpp:157] Top shape: 64 3 200 200 (7680000)
I0823 08:53:06.344739  7716 net.cpp:157] Top shape: 64 1 200 200 (2560000)
I0823 08:53:06.344743  7716 net.cpp:165] Memory required for data: 40960000
I0823 08:53:06.344748  7716 layer_factory.hpp:77] Creating layer image_data_0_split
I0823 08:53:06.344759  7716 net.cpp:100] Creating Layer image_data_0_split
I0823 08:53:06.344763  7716 net.cpp:434] image_data_0_split <- image
I0823 08:53:06.344776  7716 net.cpp:408] image_data_0_split -> image_data_0_split_0
I0823 08:53:06.344794  7716 net.cpp:408] image_data_0_split -> image_data_0_split_1
I0823 08:53:06.344846  7716 net.cpp:150] Setting up image_data_0_split
I0823 08:53:06.344851  7716 net.cpp:157] Top shape: 64 3 200 200 (7680000)
I0823 08:53:06.344856  7716 net.cpp:157] Top shape: 64 3 200 200 (7680000)
I0823 08:53:06.344858  7716 net.cpp:165] Memory required for data: 102400000
I0823 08:53:06.344861  7716 layer_factory.hpp:77] Creating layer label_data_1_split
I0823 08:53:06.344866  7716 net.cpp:100] Creating Layer label_data_1_split
I0823 08:53:06.344869  7716 net.cpp:434] label_data_1_split <- label
I0823 08:53:06.344874  7716 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0823 08:53:06.344879  7716 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0823 08:53:06.344904  7716 net.cpp:150] Setting up label_data_1_split
I0823 08:53:06.344909  7716 net.cpp:157] Top shape: 64 1 200 200 (2560000)
I0823 08:53:06.344913  7716 net.cpp:157] Top shape: 64 1 200 200 (2560000)
I0823 08:53:06.344915  7716 net.cpp:165] Memory required for data: 122880000
I0823 08:53:06.344918  7716 layer_factory.hpp:77] Creating layer conv1_1
I0823 08:53:06.344933  7716 net.cpp:100] Creating Layer conv1_1
I0823 08:53:06.344936  7716 net.cpp:434] conv1_1 <- image_data_0_split_0
I0823 08:53:06.344940  7716 net.cpp:408] conv1_1 -> conv1_1
I0823 08:53:06.345087  7716 net.cpp:150] Setting up conv1_1
I0823 08:53:06.345093  7716 net.cpp:157] Top shape: 64 8 298 298 (45467648)
I0823 08:53:06.345095  7716 net.cpp:165] Memory required for data: 304750592
I0823 08:53:06.345101  7716 layer_factory.hpp:77] Creating layer conv1_1_bn
I0823 08:53:06.345108  7716 net.cpp:100] Creating Layer conv1_1_bn
I0823 08:53:06.345111  7716 net.cpp:434] conv1_1_bn <- conv1_1
I0823 08:53:06.345116  7716 net.cpp:408] conv1_1_bn -> conv1_1_bn
I0823 08:53:06.345741  7716 net.cpp:150] Setting up conv1_1_bn
I0823 08:53:06.345752  7716 net.cpp:157] Top shape: 64 8 298 298 (45467648)
I0823 08:53:06.345755  7716 net.cpp:165] Memory required for data: 486621184
I0823 08:53:06.345764  7716 layer_factory.hpp:77] Creating layer conv1_1_bn_scale
I0823 08:53:06.345773  7716 net.cpp:100] Creating Layer conv1_1_bn_scale
I0823 08:53:06.345777  7716 net.cpp:434] conv1_1_bn_scale <- conv1_1_bn
I0823 08:53:06.345780  7716 net.cpp:395] conv1_1_bn_scale -> conv1_1_bn (in-place)
I0823 08:53:06.345815  7716 layer_factory.hpp:77] Creating layer conv1_1_bn_scale
I0823 08:53:06.349860  7716 net.cpp:150] Setting up conv1_1_bn_scale
I0823 08:53:06.349875  7716 net.cpp:157] Top shape: 64 8 298 298 (45467648)
I0823 08:53:06.349879  7716 net.cpp:165] Memory required for data: 668491776
I0823 08:53:06.349889  7716 layer_factory.hpp:77] Creating layer conv1_1_relu
I0823 08:53:06.349897  7716 net.cpp:100] Creating Layer conv1_1_relu
I0823 08:53:06.349900  7716 net.cpp:434] conv1_1_relu <- conv1_1_bn
I0823 08:53:06.349905  7716 net.cpp:395] conv1_1_relu -> conv1_1_bn (in-place)
I0823 08:53:06.349912  7716 net.cpp:150] Setting up conv1_1_relu
I0823 08:53:06.349915  7716 net.cpp:157] Top shape: 64 8 298 298 (45467648)
I0823 08:53:06.349918  7716 net.cpp:165] Memory required for data: 850362368
I0823 08:53:06.349921  7716 layer_factory.hpp:77] Creating layer conv1_2
I0823 08:53:06.349930  7716 net.cpp:100] Creating Layer conv1_2
I0823 08:53:06.349932  7716 net.cpp:434] conv1_2 <- conv1_1_bn
I0823 08:53:06.349937  7716 net.cpp:408] conv1_2 -> conv1_2
I0823 08:53:06.350090  7716 net.cpp:150] Setting up conv1_2
I0823 08:53:06.350097  7716 net.cpp:157] Top shape: 64 8 298 298 (45467648)
I0823 08:53:06.350100  7716 net.cpp:165] Memory required for data: 1032232960
I0823 08:53:06.350105  7716 layer_factory.hpp:77] Creating layer conv1_2_bn
I0823 08:53:06.350111  7716 net.cpp:100] Creating Layer conv1_2_bn
I0823 08:53:06.350114  7716 net.cpp:434] conv1_2_bn <- conv1_2
I0823 08:53:06.350118  7716 net.cpp:408] conv1_2_bn -> conv1_2_bn
I0823 08:53:06.350298  7716 net.cpp:150] Setting up conv1_2_bn
I0823 08:53:06.350309  7716 net.cpp:157] Top shape: 64 8 298 298 (45467648)
I0823 08:53:06.350317  7716 net.cpp:165] Memory required for data: 1214103552
I0823 08:53:06.350327  7716 layer_factory.hpp:77] Creating layer conv1_2_bn_scale
I0823 08:53:06.350333  7716 net.cpp:100] Creating Layer conv1_2_bn_scale
I0823 08:53:06.350337  7716 net.cpp:434] conv1_2_bn_scale <- conv1_2_bn
I0823 08:53:06.350342  7716 net.cpp:395] conv1_2_bn_scale -> conv1_2_bn (in-place)
I0823 08:53:06.350374  7716 layer_factory.hpp:77] Creating layer conv1_2_bn_scale
I0823 08:53:06.350946  7716 net.cpp:150] Setting up conv1_2_bn_scale
I0823 08:53:06.350958  7716 net.cpp:157] Top shape: 64 8 298 298 (45467648)
I0823 08:53:06.350961  7716 net.cpp:165] Memory required for data: 1395974144
I0823 08:53:06.350966  7716 layer_factory.hpp:77] Creating layer conv1_2_relu
I0823 08:53:06.350972  7716 net.cpp:100] Creating Layer conv1_2_relu
I0823 08:53:06.350975  7716 net.cpp:434] conv1_2_relu <- conv1_2_bn
I0823 08:53:06.350980  7716 net.cpp:395] conv1_2_relu -> conv1_2_bn (in-place)
I0823 08:53:06.350986  7716 net.cpp:150] Setting up conv1_2_relu
I0823 08:53:06.350988  7716 net.cpp:157] Top shape: 64 8 298 298 (45467648)
I0823 08:53:06.350991  7716 net.cpp:165] Memory required for data: 1577844736
I0823 08:53:06.350994  7716 layer_factory.hpp:77] Creating layer pool1
I0823 08:53:06.351001  7716 net.cpp:100] Creating Layer pool1
I0823 08:53:06.351004  7716 net.cpp:434] pool1 <- conv1_2_bn
I0823 08:53:06.351009  7716 net.cpp:408] pool1 -> pool1
I0823 08:53:06.351042  7716 net.cpp:150] Setting up pool1
I0823 08:53:06.351047  7716 net.cpp:157] Top shape: 64 8 149 149 (11366912)
I0823 08:53:06.351049  7716 net.cpp:165] Memory required for data: 1623312384
I0823 08:53:06.351052  7716 layer_factory.hpp:77] Creating layer conv2_1
I0823 08:53:06.351059  7716 net.cpp:100] Creating Layer conv2_1
I0823 08:53:06.351063  7716 net.cpp:434] conv2_1 <- pool1
I0823 08:53:06.351068  7716 net.cpp:408] conv2_1 -> conv2_1
I0823 08:53:06.351225  7716 net.cpp:150] Setting up conv2_1
I0823 08:53:06.351232  7716 net.cpp:157] Top shape: 64 16 149 149 (22733824)
I0823 08:53:06.351233  7716 net.cpp:165] Memory required for data: 1714247680
I0823 08:53:06.351238  7716 layer_factory.hpp:77] Creating layer conv2_1_bn
I0823 08:53:06.351244  7716 net.cpp:100] Creating Layer conv2_1_bn
I0823 08:53:06.351248  7716 net.cpp:434] conv2_1_bn <- conv2_1
I0823 08:53:06.351253  7716 net.cpp:408] conv2_1_bn -> conv2_1_bn
I0823 08:53:06.351408  7716 net.cpp:150] Setting up conv2_1_bn
I0823 08:53:06.351414  7716 net.cpp:157] Top shape: 64 16 149 149 (22733824)
I0823 08:53:06.351416  7716 net.cpp:165] Memory required for data: 1805182976
I0823 08:53:06.351423  7716 layer_factory.hpp:77] Creating layer conv2_1_bn_scale
I0823 08:53:06.351428  7716 net.cpp:100] Creating Layer conv2_1_bn_scale
I0823 08:53:06.351430  7716 net.cpp:434] conv2_1_bn_scale <- conv2_1_bn
I0823 08:53:06.351434  7716 net.cpp:395] conv2_1_bn_scale -> conv2_1_bn (in-place)
I0823 08:53:06.351464  7716 layer_factory.hpp:77] Creating layer conv2_1_bn_scale
I0823 08:53:06.351574  7716 net.cpp:150] Setting up conv2_1_bn_scale
I0823 08:53:06.351583  7716 net.cpp:157] Top shape: 64 16 149 149 (22733824)
I0823 08:53:06.351584  7716 net.cpp:165] Memory required for data: 1896118272
I0823 08:53:06.351593  7716 layer_factory.hpp:77] Creating layer conv2_1_relu
I0823 08:53:06.351598  7716 net.cpp:100] Creating Layer conv2_1_relu
I0823 08:53:06.351600  7716 net.cpp:434] conv2_1_relu <- conv2_1_bn
I0823 08:53:06.351606  7716 net.cpp:395] conv2_1_relu -> conv2_1_bn (in-place)
I0823 08:53:06.351611  7716 net.cpp:150] Setting up conv2_1_relu
I0823 08:53:06.351615  7716 net.cpp:157] Top shape: 64 16 149 149 (22733824)
I0823 08:53:06.351619  7716 net.cpp:165] Memory required for data: 1987053568
I0823 08:53:06.351621  7716 layer_factory.hpp:77] Creating layer conv2_2
I0823 08:53:06.351629  7716 net.cpp:100] Creating Layer conv2_2
I0823 08:53:06.351632  7716 net.cpp:434] conv2_2 <- conv2_1_bn
I0823 08:53:06.351637  7716 net.cpp:408] conv2_2 -> conv2_2
I0823 08:53:06.351821  7716 net.cpp:150] Setting up conv2_2
I0823 08:53:06.351833  7716 net.cpp:157] Top shape: 64 16 149 149 (22733824)
I0823 08:53:06.351836  7716 net.cpp:165] Memory required for data: 2077988864
I0823 08:53:06.351840  7716 layer_factory.hpp:77] Creating layer conv2_2_bn
I0823 08:53:06.351845  7716 net.cpp:100] Creating Layer conv2_2_bn
I0823 08:53:06.351848  7716 net.cpp:434] conv2_2_bn <- conv2_2
I0823 08:53:06.351855  7716 net.cpp:408] conv2_2_bn -> conv2_2_bn
I0823 08:53:06.352012  7716 net.cpp:150] Setting up conv2_2_bn
I0823 08:53:06.352017  7716 net.cpp:157] Top shape: 64 16 149 149 (22733824)
I0823 08:53:06.352020  7716 net.cpp:165] Memory required for data: 2168924160
I0823 08:53:06.352026  7716 layer_factory.hpp:77] Creating layer conv2_2_bn_scale
I0823 08:53:06.352031  7716 net.cpp:100] Creating Layer conv2_2_bn_scale
I0823 08:53:06.352035  7716 net.cpp:434] conv2_2_bn_scale <- conv2_2_bn
I0823 08:53:06.352038  7716 net.cpp:395] conv2_2_bn_scale -> conv2_2_bn (in-place)
I0823 08:53:06.352068  7716 layer_factory.hpp:77] Creating layer conv2_2_bn_scale
I0823 08:53:06.352175  7716 net.cpp:150] Setting up conv2_2_bn_scale
I0823 08:53:06.352181  7716 net.cpp:157] Top shape: 64 16 149 149 (22733824)
I0823 08:53:06.352183  7716 net.cpp:165] Memory required for data: 2259859456
I0823 08:53:06.352188  7716 layer_factory.hpp:77] Creating layer conv2_2_relu
I0823 08:53:06.352195  7716 net.cpp:100] Creating Layer conv2_2_relu
I0823 08:53:06.352198  7716 net.cpp:434] conv2_2_relu <- conv2_2_bn
I0823 08:53:06.352201  7716 net.cpp:395] conv2_2_relu -> conv2_2_bn (in-place)
I0823 08:53:06.352206  7716 net.cpp:150] Setting up conv2_2_relu
I0823 08:53:06.352210  7716 net.cpp:157] Top shape: 64 16 149 149 (22733824)
I0823 08:53:06.352212  7716 net.cpp:165] Memory required for data: 2350794752
I0823 08:53:06.352216  7716 layer_factory.hpp:77] Creating layer pool2
I0823 08:53:06.352221  7716 net.cpp:100] Creating Layer pool2
I0823 08:53:06.352223  7716 net.cpp:434] pool2 <- conv2_2_bn
I0823 08:53:06.352228  7716 net.cpp:408] pool2 -> pool2
I0823 08:53:06.352255  7716 net.cpp:150] Setting up pool2
I0823 08:53:06.352260  7716 net.cpp:157] Top shape: 64 16 75 75 (5760000)
I0823 08:53:06.352263  7716 net.cpp:165] Memory required for data: 2373834752
I0823 08:53:06.352267  7716 layer_factory.hpp:77] Creating layer conv3_1
I0823 08:53:06.352273  7716 net.cpp:100] Creating Layer conv3_1
I0823 08:53:06.352277  7716 net.cpp:434] conv3_1 <- pool2
I0823 08:53:06.352282  7716 net.cpp:408] conv3_1 -> conv3_1
I0823 08:53:06.352507  7716 net.cpp:150] Setting up conv3_1
I0823 08:53:06.352514  7716 net.cpp:157] Top shape: 64 32 75 75 (11520000)
I0823 08:53:06.352517  7716 net.cpp:165] Memory required for data: 2419914752
I0823 08:53:06.352521  7716 layer_factory.hpp:77] Creating layer conv3_1_bn
I0823 08:53:06.352526  7716 net.cpp:100] Creating Layer conv3_1_bn
I0823 08:53:06.352530  7716 net.cpp:434] conv3_1_bn <- conv3_1
I0823 08:53:06.352535  7716 net.cpp:408] conv3_1_bn -> conv3_1_bn
I0823 08:53:06.352677  7716 net.cpp:150] Setting up conv3_1_bn
I0823 08:53:06.352684  7716 net.cpp:157] Top shape: 64 32 75 75 (11520000)
I0823 08:53:06.352686  7716 net.cpp:165] Memory required for data: 2465994752
I0823 08:53:06.352692  7716 layer_factory.hpp:77] Creating layer conv3_1_bn_scale
I0823 08:53:06.352701  7716 net.cpp:100] Creating Layer conv3_1_bn_scale
I0823 08:53:06.352705  7716 net.cpp:434] conv3_1_bn_scale <- conv3_1_bn
I0823 08:53:06.352708  7716 net.cpp:395] conv3_1_bn_scale -> conv3_1_bn (in-place)
I0823 08:53:06.352737  7716 layer_factory.hpp:77] Creating layer conv3_1_bn_scale
I0823 08:53:06.352828  7716 net.cpp:150] Setting up conv3_1_bn_scale
I0823 08:53:06.352833  7716 net.cpp:157] Top shape: 64 32 75 75 (11520000)
I0823 08:53:06.352835  7716 net.cpp:165] Memory required for data: 2512074752
I0823 08:53:06.352840  7716 layer_factory.hpp:77] Creating layer conv3_1_relu
I0823 08:53:06.352845  7716 net.cpp:100] Creating Layer conv3_1_relu
I0823 08:53:06.352849  7716 net.cpp:434] conv3_1_relu <- conv3_1_bn
I0823 08:53:06.352854  7716 net.cpp:395] conv3_1_relu -> conv3_1_bn (in-place)
I0823 08:53:06.352865  7716 net.cpp:150] Setting up conv3_1_relu
I0823 08:53:06.352869  7716 net.cpp:157] Top shape: 64 32 75 75 (11520000)
I0823 08:53:06.352872  7716 net.cpp:165] Memory required for data: 2558154752
I0823 08:53:06.352874  7716 layer_factory.hpp:77] Creating layer conv3_2
I0823 08:53:06.352882  7716 net.cpp:100] Creating Layer conv3_2
I0823 08:53:06.352885  7716 net.cpp:434] conv3_2 <- conv3_1_bn
I0823 08:53:06.352890  7716 net.cpp:408] conv3_2 -> conv3_2
I0823 08:53:06.353215  7716 net.cpp:150] Setting up conv3_2
I0823 08:53:06.353221  7716 net.cpp:157] Top shape: 64 32 75 75 (11520000)
I0823 08:53:06.353224  7716 net.cpp:165] Memory required for data: 2604234752
I0823 08:53:06.353229  7716 layer_factory.hpp:77] Creating layer conv3_2_bn
I0823 08:53:06.353233  7716 net.cpp:100] Creating Layer conv3_2_bn
I0823 08:53:06.353236  7716 net.cpp:434] conv3_2_bn <- conv3_2
I0823 08:53:06.353240  7716 net.cpp:408] conv3_2_bn -> conv3_2_bn
I0823 08:53:06.353384  7716 net.cpp:150] Setting up conv3_2_bn
I0823 08:53:06.353389  7716 net.cpp:157] Top shape: 64 32 75 75 (11520000)
I0823 08:53:06.353391  7716 net.cpp:165] Memory required for data: 2650314752
I0823 08:53:06.353401  7716 layer_factory.hpp:77] Creating layer conv3_2_bn_scale
I0823 08:53:06.353407  7716 net.cpp:100] Creating Layer conv3_2_bn_scale
I0823 08:53:06.353410  7716 net.cpp:434] conv3_2_bn_scale <- conv3_2_bn
I0823 08:53:06.353415  7716 net.cpp:395] conv3_2_bn_scale -> conv3_2_bn (in-place)
I0823 08:53:06.353446  7716 layer_factory.hpp:77] Creating layer conv3_2_bn_scale
I0823 08:53:06.353533  7716 net.cpp:150] Setting up conv3_2_bn_scale
I0823 08:53:06.353538  7716 net.cpp:157] Top shape: 64 32 75 75 (11520000)
I0823 08:53:06.353540  7716 net.cpp:165] Memory required for data: 2696394752
I0823 08:53:06.353545  7716 layer_factory.hpp:77] Creating layer conv3_2_relu
I0823 08:53:06.353551  7716 net.cpp:100] Creating Layer conv3_2_relu
I0823 08:53:06.353554  7716 net.cpp:434] conv3_2_relu <- conv3_2_bn
I0823 08:53:06.353559  7716 net.cpp:395] conv3_2_relu -> conv3_2_bn (in-place)
I0823 08:53:06.353562  7716 net.cpp:150] Setting up conv3_2_relu
I0823 08:53:06.353566  7716 net.cpp:157] Top shape: 64 32 75 75 (11520000)
I0823 08:53:06.353569  7716 net.cpp:165] Memory required for data: 2742474752
I0823 08:53:06.353572  7716 layer_factory.hpp:77] Creating layer pool3
I0823 08:53:06.353576  7716 net.cpp:100] Creating Layer pool3
I0823 08:53:06.353579  7716 net.cpp:434] pool3 <- conv3_2_bn
I0823 08:53:06.353585  7716 net.cpp:408] pool3 -> pool3
I0823 08:53:06.353612  7716 net.cpp:150] Setting up pool3
I0823 08:53:06.353617  7716 net.cpp:157] Top shape: 64 32 38 38 (2957312)
I0823 08:53:06.353621  7716 net.cpp:165] Memory required for data: 2754304000
I0823 08:53:06.353623  7716 layer_factory.hpp:77] Creating layer conv4_1
I0823 08:53:06.353633  7716 net.cpp:100] Creating Layer conv4_1
I0823 08:53:06.353637  7716 net.cpp:434] conv4_1 <- pool3
I0823 08:53:06.353641  7716 net.cpp:408] conv4_1 -> conv4_1
I0823 08:53:06.354185  7716 net.cpp:150] Setting up conv4_1
I0823 08:53:06.354194  7716 net.cpp:157] Top shape: 64 64 38 38 (5914624)
I0823 08:53:06.354197  7716 net.cpp:165] Memory required for data: 2777962496
I0823 08:53:06.354202  7716 layer_factory.hpp:77] Creating layer conv4_1_bn
I0823 08:53:06.354207  7716 net.cpp:100] Creating Layer conv4_1_bn
I0823 08:53:06.354210  7716 net.cpp:434] conv4_1_bn <- conv4_1
I0823 08:53:06.354215  7716 net.cpp:408] conv4_1_bn -> conv4_1_bn
I0823 08:53:06.354372  7716 net.cpp:150] Setting up conv4_1_bn
I0823 08:53:06.354378  7716 net.cpp:157] Top shape: 64 64 38 38 (5914624)
I0823 08:53:06.354382  7716 net.cpp:165] Memory required for data: 2801620992
I0823 08:53:06.354387  7716 layer_factory.hpp:77] Creating layer conv4_1_bn_scale
I0823 08:53:06.354396  7716 net.cpp:100] Creating Layer conv4_1_bn_scale
I0823 08:53:06.354400  7716 net.cpp:434] conv4_1_bn_scale <- conv4_1_bn
I0823 08:53:06.354404  7716 net.cpp:395] conv4_1_bn_scale -> conv4_1_bn (in-place)
I0823 08:53:06.354440  7716 layer_factory.hpp:77] Creating layer conv4_1_bn_scale
I0823 08:53:06.354533  7716 net.cpp:150] Setting up conv4_1_bn_scale
I0823 08:53:06.354540  7716 net.cpp:157] Top shape: 64 64 38 38 (5914624)
I0823 08:53:06.354543  7716 net.cpp:165] Memory required for data: 2825279488
I0823 08:53:06.354548  7716 layer_factory.hpp:77] Creating layer conv4_1_relu
I0823 08:53:06.354552  7716 net.cpp:100] Creating Layer conv4_1_relu
I0823 08:53:06.354557  7716 net.cpp:434] conv4_1_relu <- conv4_1_bn
I0823 08:53:06.354559  7716 net.cpp:395] conv4_1_relu -> conv4_1_bn (in-place)
I0823 08:53:06.354564  7716 net.cpp:150] Setting up conv4_1_relu
I0823 08:53:06.354568  7716 net.cpp:157] Top shape: 64 64 38 38 (5914624)
I0823 08:53:06.354571  7716 net.cpp:165] Memory required for data: 2848937984
I0823 08:53:06.354573  7716 layer_factory.hpp:77] Creating layer conv4_2
I0823 08:53:06.354581  7716 net.cpp:100] Creating Layer conv4_2
I0823 08:53:06.354585  7716 net.cpp:434] conv4_2 <- conv4_1_bn
I0823 08:53:06.354589  7716 net.cpp:408] conv4_2 -> conv4_2
I0823 08:53:06.355499  7716 net.cpp:150] Setting up conv4_2
I0823 08:53:06.355505  7716 net.cpp:157] Top shape: 64 64 38 38 (5914624)
I0823 08:53:06.355509  7716 net.cpp:165] Memory required for data: 2872596480
I0823 08:53:06.355512  7716 layer_factory.hpp:77] Creating layer conv4_2_bn
I0823 08:53:06.355517  7716 net.cpp:100] Creating Layer conv4_2_bn
I0823 08:53:06.355520  7716 net.cpp:434] conv4_2_bn <- conv4_2
I0823 08:53:06.355525  7716 net.cpp:408] conv4_2_bn -> conv4_2_bn
I0823 08:53:06.355674  7716 net.cpp:150] Setting up conv4_2_bn
I0823 08:53:06.355680  7716 net.cpp:157] Top shape: 64 64 38 38 (5914624)
I0823 08:53:06.355684  7716 net.cpp:165] Memory required for data: 2896254976
I0823 08:53:06.355690  7716 layer_factory.hpp:77] Creating layer conv4_2_bn_scale
I0823 08:53:06.355695  7716 net.cpp:100] Creating Layer conv4_2_bn_scale
I0823 08:53:06.355698  7716 net.cpp:434] conv4_2_bn_scale <- conv4_2_bn
I0823 08:53:06.355702  7716 net.cpp:395] conv4_2_bn_scale -> conv4_2_bn (in-place)
I0823 08:53:06.355731  7716 layer_factory.hpp:77] Creating layer conv4_2_bn_scale
I0823 08:53:06.355815  7716 net.cpp:150] Setting up conv4_2_bn_scale
I0823 08:53:06.355820  7716 net.cpp:157] Top shape: 64 64 38 38 (5914624)
I0823 08:53:06.355823  7716 net.cpp:165] Memory required for data: 2919913472
I0823 08:53:06.355829  7716 layer_factory.hpp:77] Creating layer conv4_2_relu
I0823 08:53:06.355834  7716 net.cpp:100] Creating Layer conv4_2_relu
I0823 08:53:06.355837  7716 net.cpp:434] conv4_2_relu <- conv4_2_bn
I0823 08:53:06.355840  7716 net.cpp:395] conv4_2_relu -> conv4_2_bn (in-place)
I0823 08:53:06.355845  7716 net.cpp:150] Setting up conv4_2_relu
I0823 08:53:06.355849  7716 net.cpp:157] Top shape: 64 64 38 38 (5914624)
I0823 08:53:06.355851  7716 net.cpp:165] Memory required for data: 2943571968
I0823 08:53:06.355854  7716 layer_factory.hpp:77] Creating layer pool4
I0823 08:53:06.355860  7716 net.cpp:100] Creating Layer pool4
I0823 08:53:06.355864  7716 net.cpp:434] pool4 <- conv4_2_bn
I0823 08:53:06.355867  7716 net.cpp:408] pool4 -> pool4
I0823 08:53:06.355895  7716 net.cpp:150] Setting up pool4
I0823 08:53:06.355900  7716 net.cpp:157] Top shape: 64 64 19 19 (1478656)
I0823 08:53:06.355902  7716 net.cpp:165] Memory required for data: 2949486592
I0823 08:53:06.355906  7716 layer_factory.hpp:77] Creating layer conv5_1
I0823 08:53:06.355912  7716 net.cpp:100] Creating Layer conv5_1
I0823 08:53:06.355916  7716 net.cpp:434] conv5_1 <- pool4
I0823 08:53:06.355919  7716 net.cpp:408] conv5_1 -> conv5_1
I0823 08:53:06.357318  7716 net.cpp:150] Setting up conv5_1
I0823 08:53:06.357331  7716 net.cpp:157] Top shape: 64 64 17 17 (1183744)
I0823 08:53:06.357333  7716 net.cpp:165] Memory required for data: 2954221568
I0823 08:53:06.357337  7716 layer_factory.hpp:77] Creating layer conv5_1_bn
I0823 08:53:06.357343  7716 net.cpp:100] Creating Layer conv5_1_bn
I0823 08:53:06.357347  7716 net.cpp:434] conv5_1_bn <- conv5_1
I0823 08:53:06.357353  7716 net.cpp:408] conv5_1_bn -> conv5_1_bn
I0823 08:53:06.357511  7716 net.cpp:150] Setting up conv5_1_bn
I0823 08:53:06.357523  7716 net.cpp:157] Top shape: 64 64 17 17 (1183744)
I0823 08:53:06.357527  7716 net.cpp:165] Memory required for data: 2958956544
I0823 08:53:06.357532  7716 layer_factory.hpp:77] Creating layer conv5_1_bn_scale
I0823 08:53:06.357537  7716 net.cpp:100] Creating Layer conv5_1_bn_scale
I0823 08:53:06.357542  7716 net.cpp:434] conv5_1_bn_scale <- conv5_1_bn
I0823 08:53:06.357545  7716 net.cpp:395] conv5_1_bn_scale -> conv5_1_bn (in-place)
I0823 08:53:06.357578  7716 layer_factory.hpp:77] Creating layer conv5_1_bn_scale
I0823 08:53:06.357661  7716 net.cpp:150] Setting up conv5_1_bn_scale
I0823 08:53:06.357667  7716 net.cpp:157] Top shape: 64 64 17 17 (1183744)
I0823 08:53:06.357671  7716 net.cpp:165] Memory required for data: 2963691520
I0823 08:53:06.357676  7716 layer_factory.hpp:77] Creating layer conv5_1_relu
I0823 08:53:06.357681  7716 net.cpp:100] Creating Layer conv5_1_relu
I0823 08:53:06.357683  7716 net.cpp:434] conv5_1_relu <- conv5_1_bn
I0823 08:53:06.357686  7716 net.cpp:395] conv5_1_relu -> conv5_1_bn (in-place)
I0823 08:53:06.357692  7716 net.cpp:150] Setting up conv5_1_relu
I0823 08:53:06.357695  7716 net.cpp:157] Top shape: 64 64 17 17 (1183744)
I0823 08:53:06.357697  7716 net.cpp:165] Memory required for data: 2968426496
I0823 08:53:06.357700  7716 layer_factory.hpp:77] Creating layer conv6_1
I0823 08:53:06.357708  7716 net.cpp:100] Creating Layer conv6_1
I0823 08:53:06.357712  7716 net.cpp:434] conv6_1 <- conv5_1_bn
I0823 08:53:06.357717  7716 net.cpp:408] conv6_1 -> conv6_1
I0823 08:53:06.358635  7716 net.cpp:150] Setting up conv6_1
I0823 08:53:06.358644  7716 net.cpp:157] Top shape: 64 64 15 15 (921600)
I0823 08:53:06.358646  7716 net.cpp:165] Memory required for data: 2972112896
I0823 08:53:06.358650  7716 layer_factory.hpp:77] Creating layer conv6_1_bn
I0823 08:53:06.358654  7716 net.cpp:100] Creating Layer conv6_1_bn
I0823 08:53:06.358659  7716 net.cpp:434] conv6_1_bn <- conv6_1
I0823 08:53:06.358662  7716 net.cpp:408] conv6_1_bn -> conv6_1_bn
I0823 08:53:06.358806  7716 net.cpp:150] Setting up conv6_1_bn
I0823 08:53:06.358813  7716 net.cpp:157] Top shape: 64 64 15 15 (921600)
I0823 08:53:06.358814  7716 net.cpp:165] Memory required for data: 2975799296
I0823 08:53:06.358820  7716 layer_factory.hpp:77] Creating layer conv6_1_bn_scale
I0823 08:53:06.358826  7716 net.cpp:100] Creating Layer conv6_1_bn_scale
I0823 08:53:06.358830  7716 net.cpp:434] conv6_1_bn_scale <- conv6_1_bn
I0823 08:53:06.358834  7716 net.cpp:395] conv6_1_bn_scale -> conv6_1_bn (in-place)
I0823 08:53:06.358863  7716 layer_factory.hpp:77] Creating layer conv6_1_bn_scale
I0823 08:53:06.358945  7716 net.cpp:150] Setting up conv6_1_bn_scale
I0823 08:53:06.358952  7716 net.cpp:157] Top shape: 64 64 15 15 (921600)
I0823 08:53:06.358954  7716 net.cpp:165] Memory required for data: 2979485696
I0823 08:53:06.358959  7716 layer_factory.hpp:77] Creating layer conv6_1_relu
I0823 08:53:06.358966  7716 net.cpp:100] Creating Layer conv6_1_relu
I0823 08:53:06.358970  7716 net.cpp:434] conv6_1_relu <- conv6_1_bn
I0823 08:53:06.358974  7716 net.cpp:395] conv6_1_relu -> conv6_1_bn (in-place)
I0823 08:53:06.358978  7716 net.cpp:150] Setting up conv6_1_relu
I0823 08:53:06.358983  7716 net.cpp:157] Top shape: 64 64 15 15 (921600)
I0823 08:53:06.358985  7716 net.cpp:165] Memory required for data: 2983172096
I0823 08:53:06.358989  7716 layer_factory.hpp:77] Creating layer conv7_1
I0823 08:53:06.358995  7716 net.cpp:100] Creating Layer conv7_1
I0823 08:53:06.358999  7716 net.cpp:434] conv7_1 <- conv6_1_bn
I0823 08:53:06.359004  7716 net.cpp:408] conv7_1 -> conv7_1
I0823 08:53:06.360702  7716 net.cpp:150] Setting up conv7_1
I0823 08:53:06.360709  7716 net.cpp:157] Top shape: 64 128 13 13 (1384448)
I0823 08:53:06.360713  7716 net.cpp:165] Memory required for data: 2988709888
I0823 08:53:06.360716  7716 layer_factory.hpp:77] Creating layer conv7_1_bn
I0823 08:53:06.360723  7716 net.cpp:100] Creating Layer conv7_1_bn
I0823 08:53:06.360725  7716 net.cpp:434] conv7_1_bn <- conv7_1
I0823 08:53:06.360734  7716 net.cpp:408] conv7_1_bn -> conv7_1_bn
I0823 08:53:06.360877  7716 net.cpp:150] Setting up conv7_1_bn
I0823 08:53:06.360883  7716 net.cpp:157] Top shape: 64 128 13 13 (1384448)
I0823 08:53:06.360887  7716 net.cpp:165] Memory required for data: 2994247680
I0823 08:53:06.360891  7716 layer_factory.hpp:77] Creating layer conv7_1_bn_scale
I0823 08:53:06.360896  7716 net.cpp:100] Creating Layer conv7_1_bn_scale
I0823 08:53:06.360900  7716 net.cpp:434] conv7_1_bn_scale <- conv7_1_bn
I0823 08:53:06.360904  7716 net.cpp:395] conv7_1_bn_scale -> conv7_1_bn (in-place)
I0823 08:53:06.360934  7716 layer_factory.hpp:77] Creating layer conv7_1_bn_scale
I0823 08:53:06.361008  7716 net.cpp:150] Setting up conv7_1_bn_scale
I0823 08:53:06.361013  7716 net.cpp:157] Top shape: 64 128 13 13 (1384448)
I0823 08:53:06.361016  7716 net.cpp:165] Memory required for data: 2999785472
I0823 08:53:06.361030  7716 layer_factory.hpp:77] Creating layer conv7_1_relu
I0823 08:53:06.361037  7716 net.cpp:100] Creating Layer conv7_1_relu
I0823 08:53:06.361040  7716 net.cpp:434] conv7_1_relu <- conv7_1_bn
I0823 08:53:06.361044  7716 net.cpp:395] conv7_1_relu -> conv7_1_bn (in-place)
I0823 08:53:06.361049  7716 net.cpp:150] Setting up conv7_1_relu
I0823 08:53:06.361053  7716 net.cpp:157] Top shape: 64 128 13 13 (1384448)
I0823 08:53:06.361057  7716 net.cpp:165] Memory required for data: 3005323264
I0823 08:53:06.361058  7716 layer_factory.hpp:77] Creating layer score
I0823 08:53:06.361066  7716 net.cpp:100] Creating Layer score
I0823 08:53:06.361069  7716 net.cpp:434] score <- conv7_1_bn
I0823 08:53:06.361074  7716 net.cpp:408] score -> score
I0823 08:53:06.361251  7716 net.cpp:150] Setting up score
I0823 08:53:06.361258  7716 net.cpp:157] Top shape: 64 4 13 13 (43264)
I0823 08:53:06.361261  7716 net.cpp:165] Memory required for data: 3005496320
I0823 08:53:06.361265  7716 layer_factory.hpp:77] Creating layer upscore
I0823 08:53:06.361274  7716 net.cpp:100] Creating Layer upscore
I0823 08:53:06.361277  7716 net.cpp:434] upscore <- score
I0823 08:53:06.361282  7716 net.cpp:408] upscore -> upscore
I0823 08:53:06.361788  7716 net.cpp:150] Setting up upscore
I0823 08:53:06.361796  7716 net.cpp:157] Top shape: 64 4 224 224 (12845056)
I0823 08:53:06.361799  7716 net.cpp:165] Memory required for data: 3056876544
I0823 08:53:06.361804  7716 layer_factory.hpp:77] Creating layer cropscore
I0823 08:53:06.361809  7716 net.cpp:100] Creating Layer cropscore
I0823 08:53:06.361812  7716 net.cpp:434] cropscore <- upscore
I0823 08:53:06.361816  7716 net.cpp:434] cropscore <- image_data_0_split_1
I0823 08:53:06.361821  7716 net.cpp:408] cropscore -> cropscore
I0823 08:53:06.361841  7716 net.cpp:150] Setting up cropscore
I0823 08:53:06.361845  7716 net.cpp:157] Top shape: 64 4 200 200 (10240000)
I0823 08:53:06.361848  7716 net.cpp:165] Memory required for data: 3097836544
I0823 08:53:06.361851  7716 layer_factory.hpp:77] Creating layer cropscore_cropscore_0_split
I0823 08:53:06.361855  7716 net.cpp:100] Creating Layer cropscore_cropscore_0_split
I0823 08:53:06.361858  7716 net.cpp:434] cropscore_cropscore_0_split <- cropscore
I0823 08:53:06.361862  7716 net.cpp:408] cropscore_cropscore_0_split -> cropscore_cropscore_0_split_0
I0823 08:53:06.361868  7716 net.cpp:408] cropscore_cropscore_0_split -> cropscore_cropscore_0_split_1
I0823 08:53:06.361894  7716 net.cpp:150] Setting up cropscore_cropscore_0_split
I0823 08:53:06.361899  7716 net.cpp:157] Top shape: 64 4 200 200 (10240000)
I0823 08:53:06.361902  7716 net.cpp:157] Top shape: 64 4 200 200 (10240000)
I0823 08:53:06.361906  7716 net.cpp:165] Memory required for data: 3179756544
I0823 08:53:06.361908  7716 layer_factory.hpp:77] Creating layer loss
I0823 08:53:06.361914  7716 net.cpp:100] Creating Layer loss
I0823 08:53:06.361918  7716 net.cpp:434] loss <- cropscore_cropscore_0_split_0
I0823 08:53:06.361922  7716 net.cpp:434] loss <- label_data_1_split_0
I0823 08:53:06.361925  7716 net.cpp:408] loss -> loss
I0823 08:53:06.361932  7716 layer_factory.hpp:77] Creating layer loss
I0823 08:53:06.380427  7716 net.cpp:150] Setting up loss
I0823 08:53:06.380462  7716 net.cpp:157] Top shape: (1)
I0823 08:53:06.380475  7716 net.cpp:160]     with loss weight 1
I0823 08:53:06.380484  7716 net.cpp:165] Memory required for data: 3179756548
I0823 08:53:06.380489  7716 layer_factory.hpp:77] Creating layer accuracy
I0823 08:53:06.380499  7716 net.cpp:100] Creating Layer accuracy
I0823 08:53:06.380504  7716 net.cpp:434] accuracy <- cropscore_cropscore_0_split_1
I0823 08:53:06.380511  7716 net.cpp:434] accuracy <- label_data_1_split_1
I0823 08:53:06.380516  7716 net.cpp:408] accuracy -> accuracy
I0823 08:53:06.380523  7716 net.cpp:150] Setting up accuracy
I0823 08:53:06.380528  7716 net.cpp:157] Top shape: (1)
I0823 08:53:06.380530  7716 net.cpp:165] Memory required for data: 3179756552
I0823 08:53:06.380533  7716 net.cpp:228] accuracy does not need backward computation.
I0823 08:53:06.380537  7716 net.cpp:226] loss needs backward computation.
I0823 08:53:06.380540  7716 net.cpp:226] cropscore_cropscore_0_split needs backward computation.
I0823 08:53:06.380544  7716 net.cpp:226] cropscore needs backward computation.
I0823 08:53:06.380548  7716 net.cpp:226] upscore needs backward computation.
I0823 08:53:06.380550  7716 net.cpp:226] score needs backward computation.
I0823 08:53:06.380554  7716 net.cpp:226] conv7_1_relu needs backward computation.
I0823 08:53:06.380558  7716 net.cpp:226] conv7_1_bn_scale needs backward computation.
I0823 08:53:06.380559  7716 net.cpp:226] conv7_1_bn needs backward computation.
I0823 08:53:06.380563  7716 net.cpp:226] conv7_1 needs backward computation.
I0823 08:53:06.380566  7716 net.cpp:226] conv6_1_relu needs backward computation.
I0823 08:53:06.380568  7716 net.cpp:226] conv6_1_bn_scale needs backward computation.
I0823 08:53:06.380571  7716 net.cpp:226] conv6_1_bn needs backward computation.
I0823 08:53:06.380574  7716 net.cpp:226] conv6_1 needs backward computation.
I0823 08:53:06.380578  7716 net.cpp:226] conv5_1_relu needs backward computation.
I0823 08:53:06.380580  7716 net.cpp:226] conv5_1_bn_scale needs backward computation.
I0823 08:53:06.380584  7716 net.cpp:226] conv5_1_bn needs backward computation.
I0823 08:53:06.380586  7716 net.cpp:226] conv5_1 needs backward computation.
I0823 08:53:06.380589  7716 net.cpp:226] pool4 needs backward computation.
I0823 08:53:06.380592  7716 net.cpp:226] conv4_2_relu needs backward computation.
I0823 08:53:06.380595  7716 net.cpp:226] conv4_2_bn_scale needs backward computation.
I0823 08:53:06.380599  7716 net.cpp:226] conv4_2_bn needs backward computation.
I0823 08:53:06.380601  7716 net.cpp:226] conv4_2 needs backward computation.
I0823 08:53:06.380604  7716 net.cpp:226] conv4_1_relu needs backward computation.
I0823 08:53:06.380607  7716 net.cpp:226] conv4_1_bn_scale needs backward computation.
I0823 08:53:06.380610  7716 net.cpp:226] conv4_1_bn needs backward computation.
I0823 08:53:06.380612  7716 net.cpp:226] conv4_1 needs backward computation.
I0823 08:53:06.380615  7716 net.cpp:226] pool3 needs backward computation.
I0823 08:53:06.380620  7716 net.cpp:226] conv3_2_relu needs backward computation.
I0823 08:53:06.380621  7716 net.cpp:226] conv3_2_bn_scale needs backward computation.
I0823 08:53:06.380625  7716 net.cpp:226] conv3_2_bn needs backward computation.
I0823 08:53:06.380627  7716 net.cpp:226] conv3_2 needs backward computation.
I0823 08:53:06.380630  7716 net.cpp:226] conv3_1_relu needs backward computation.
I0823 08:53:06.380633  7716 net.cpp:226] conv3_1_bn_scale needs backward computation.
I0823 08:53:06.380636  7716 net.cpp:226] conv3_1_bn needs backward computation.
I0823 08:53:06.380640  7716 net.cpp:226] conv3_1 needs backward computation.
I0823 08:53:06.380642  7716 net.cpp:226] pool2 needs backward computation.
I0823 08:53:06.380645  7716 net.cpp:226] conv2_2_relu needs backward computation.
I0823 08:53:06.380648  7716 net.cpp:226] conv2_2_bn_scale needs backward computation.
I0823 08:53:06.380651  7716 net.cpp:226] conv2_2_bn needs backward computation.
I0823 08:53:06.380655  7716 net.cpp:226] conv2_2 needs backward computation.
I0823 08:53:06.380661  7716 net.cpp:226] conv2_1_relu needs backward computation.
I0823 08:53:06.380666  7716 net.cpp:226] conv2_1_bn_scale needs backward computation.
I0823 08:53:06.380669  7716 net.cpp:226] conv2_1_bn needs backward computation.
I0823 08:53:06.380672  7716 net.cpp:226] conv2_1 needs backward computation.
I0823 08:53:06.380676  7716 net.cpp:226] pool1 needs backward computation.
I0823 08:53:06.380678  7716 net.cpp:226] conv1_2_relu needs backward computation.
I0823 08:53:06.380681  7716 net.cpp:226] conv1_2_bn_scale needs backward computation.
I0823 08:53:06.380684  7716 net.cpp:226] conv1_2_bn needs backward computation.
I0823 08:53:06.380687  7716 net.cpp:226] conv1_2 needs backward computation.
I0823 08:53:06.380691  7716 net.cpp:226] conv1_1_relu needs backward computation.
I0823 08:53:06.380693  7716 net.cpp:226] conv1_1_bn_scale needs backward computation.
I0823 08:53:06.380697  7716 net.cpp:226] conv1_1_bn needs backward computation.
I0823 08:53:06.380700  7716 net.cpp:226] conv1_1 needs backward computation.
I0823 08:53:06.380704  7716 net.cpp:228] label_data_1_split does not need backward computation.
I0823 08:53:06.380707  7716 net.cpp:228] image_data_0_split does not need backward computation.
I0823 08:53:06.380712  7716 net.cpp:228] data does not need backward computation.
I0823 08:53:06.380713  7716 net.cpp:270] This network produces output accuracy
I0823 08:53:06.380717  7716 net.cpp:270] This network produces output loss
I0823 08:53:06.380740  7716 net.cpp:283] Network initialization done.
I0823 08:53:06.380878  7716 solver.cpp:60] Solver scaffolding done.
I0823 08:53:06.382565  7716 caffe.cpp:251] Starting Optimization
I0823 08:53:06.382572  7716 solver.cpp:279] Solving segmentation
I0823 08:53:06.382575  7716 solver.cpp:280] Learning Rate Policy: step
I0823 08:53:06.383971  7716 solver.cpp:337] Iteration 0, Testing net (#0)
I0823 08:53:10.466223  7716 solver.cpp:454] Snapshotting to binary proto file portrait_one_stage_iter_0.caffemodel
I0823 08:53:10.470325  7716 sgd_solver.cpp:273] Snapshotting solver state to binary proto file portrait_one_stage_iter_0.solverstate
I0823 08:53:15.101763  7716 solver.cpp:404]     Test net output #0: accuracy = 0.24239
I0823 08:53:15.101804  7716 solver.cpp:404]     Test net output #1: loss = 2.64668e+06 (* 1 = 2.64668e+06 loss)
I0823 08:53:16.319752  7716 solver.cpp:228] Iteration 0, loss = 55454.2
I0823 08:53:16.319787  7716 solver.cpp:244]     Train net output #0: accuracy = 0.242698
I0823 08:53:16.319794  7716 solver.cpp:244]     Train net output #1: loss = 55454.2 (* 1 = 55454.2 loss)
I0823 08:53:16.319806  7716 sgd_solver.cpp:106] Iteration 0, lr = 1e-05
I0823 08:54:17.629462  7716 solver.cpp:228] Iteration 50, loss = 33564.9
I0823 08:54:17.629531  7716 solver.cpp:244]     Train net output #0: accuracy = 0.593973
I0823 08:54:17.629542  7716 solver.cpp:244]     Train net output #1: loss = 33564.9 (* 1 = 33564.9 loss)
I0823 08:54:17.629549  7716 sgd_solver.cpp:106] Iteration 50, lr = 1e-05
I0823 08:55:19.600363  7716 solver.cpp:228] Iteration 100, loss = 38706
I0823 08:55:19.600456  7716 solver.cpp:244]     Train net output #0: accuracy = 0.605796
I0823 08:55:19.600467  7716 solver.cpp:244]     Train net output #1: loss = 38706 (* 1 = 38706 loss)
I0823 08:55:19.600476  7716 sgd_solver.cpp:106] Iteration 100, lr = 1e-05
I0823 08:56:21.812680  7716 solver.cpp:228] Iteration 150, loss = 27737.7
I0823 08:56:21.812739  7716 solver.cpp:244]     Train net output #0: accuracy = 0.768746
I0823 08:56:21.812750  7716 solver.cpp:244]     Train net output #1: loss = 27737.7 (* 1 = 27737.7 loss)
I0823 08:56:21.812757  7716 sgd_solver.cpp:106] Iteration 150, lr = 1e-05
I0823 08:57:23.082217  7716 solver.cpp:337] Iteration 200, Testing net (#0)
I0823 08:57:31.525570  7716 solver.cpp:404]     Test net output #0: accuracy = 0.509186
I0823 08:57:31.525611  7716 solver.cpp:404]     Test net output #1: loss = 61580.3 (* 1 = 61580.3 loss)
I0823 08:57:32.425809  7716 solver.cpp:228] Iteration 200, loss = 23446.4
I0823 08:57:32.425838  7716 solver.cpp:244]     Train net output #0: accuracy = 0.808522
I0823 08:57:32.425856  7716 solver.cpp:244]     Train net output #1: loss = 23446.4 (* 1 = 23446.4 loss)
I0823 08:57:32.425863  7716 sgd_solver.cpp:106] Iteration 200, lr = 1e-05
I0823 08:58:34.769243  7716 solver.cpp:228] Iteration 250, loss = 27578.7
I0823 08:58:34.769333  7716 solver.cpp:244]     Train net output #0: accuracy = 0.736001
I0823 08:58:34.769345  7716 solver.cpp:244]     Train net output #1: loss = 27578.7 (* 1 = 27578.7 loss)
I0823 08:58:34.769352  7716 sgd_solver.cpp:106] Iteration 250, lr = 1e-05
I0823 08:59:37.121003  7716 solver.cpp:228] Iteration 300, loss = 29263.4
I0823 08:59:37.121073  7716 solver.cpp:244]     Train net output #0: accuracy = 0.704713
I0823 08:59:37.121084  7716 solver.cpp:244]     Train net output #1: loss = 29263.4 (* 1 = 29263.4 loss)
I0823 08:59:37.121091  7716 sgd_solver.cpp:106] Iteration 300, lr = 1e-05
I0823 09:00:39.455503  7716 solver.cpp:228] Iteration 350, loss = 22623.5
I0823 09:00:39.455565  7716 solver.cpp:244]     Train net output #0: accuracy = 0.790552
I0823 09:00:39.455577  7716 solver.cpp:244]     Train net output #1: loss = 22623.5 (* 1 = 22623.5 loss)
I0823 09:00:39.455585  7716 sgd_solver.cpp:106] Iteration 350, lr = 1e-05
I0823 09:01:40.861699  7716 solver.cpp:337] Iteration 400, Testing net (#0)
I0823 09:01:49.258155  7716 solver.cpp:404]     Test net output #0: accuracy = 0.603372
I0823 09:01:49.258198  7716 solver.cpp:404]     Test net output #1: loss = 108331 (* 1 = 108331 loss)
I0823 09:01:50.159461  7716 solver.cpp:228] Iteration 400, loss = 22247.8
I0823 09:01:50.159493  7716 solver.cpp:244]     Train net output #0: accuracy = 0.797851
I0823 09:01:50.159503  7716 solver.cpp:244]     Train net output #1: loss = 22247.8 (* 1 = 22247.8 loss)
I0823 09:01:50.159509  7716 sgd_solver.cpp:106] Iteration 400, lr = 1e-05
I0823 09:02:52.460036  7716 solver.cpp:228] Iteration 450, loss = 25414
I0823 09:02:52.460125  7716 solver.cpp:244]     Train net output #0: accuracy = 0.739961
I0823 09:02:52.460136  7716 solver.cpp:244]     Train net output #1: loss = 25414 (* 1 = 25414 loss)
I0823 09:02:52.460144  7716 sgd_solver.cpp:106] Iteration 450, lr = 1e-05
I0823 09:03:54.796691  7716 solver.cpp:228] Iteration 500, loss = 20825.1
I0823 09:03:54.796749  7716 solver.cpp:244]     Train net output #0: accuracy = 0.802776
I0823 09:03:54.796761  7716 solver.cpp:244]     Train net output #1: loss = 20825.1 (* 1 = 20825.1 loss)
I0823 09:03:54.796767  7716 sgd_solver.cpp:106] Iteration 500, lr = 1e-05
I0823 09:04:57.105209  7716 solver.cpp:228] Iteration 550, loss = 32326.3
I0823 09:04:57.105269  7716 solver.cpp:244]     Train net output #0: accuracy = 0.686735
I0823 09:04:57.105280  7716 solver.cpp:244]     Train net output #1: loss = 32326.3 (* 1 = 32326.3 loss)
I0823 09:04:57.105288  7716 sgd_solver.cpp:106] Iteration 550, lr = 1e-05
I0823 09:05:58.604079  7716 solver.cpp:337] Iteration 600, Testing net (#0)
I0823 09:06:07.003597  7716 solver.cpp:404]     Test net output #0: accuracy = 0.599474
I0823 09:06:07.003638  7716 solver.cpp:404]     Test net output #1: loss = 78703.9 (* 1 = 78703.9 loss)
I0823 09:06:07.903728  7716 solver.cpp:228] Iteration 600, loss = 19873.4
I0823 09:06:07.903762  7716 solver.cpp:244]     Train net output #0: accuracy = 0.823748
I0823 09:06:07.903771  7716 solver.cpp:244]     Train net output #1: loss = 19873.4 (* 1 = 19873.4 loss)
I0823 09:06:07.903779  7716 sgd_solver.cpp:106] Iteration 600, lr = 1e-05
I0823 09:07:10.193557  7716 solver.cpp:228] Iteration 650, loss = 18894.7
I0823 09:07:10.193617  7716 solver.cpp:244]     Train net output #0: accuracy = 0.807432
I0823 09:07:10.193629  7716 solver.cpp:244]     Train net output #1: loss = 18894.7 (* 1 = 18894.7 loss)
I0823 09:07:10.193634  7716 sgd_solver.cpp:106] Iteration 650, lr = 1e-05
I0823 09:08:12.553675  7716 solver.cpp:228] Iteration 700, loss = 18820.7
I0823 09:08:12.553725  7716 solver.cpp:244]     Train net output #0: accuracy = 0.82745
I0823 09:08:12.553735  7716 solver.cpp:244]     Train net output #1: loss = 18820.7 (* 1 = 18820.7 loss)
I0823 09:08:12.553741  7716 sgd_solver.cpp:106] Iteration 700, lr = 1e-05
I0823 09:09:14.833705  7716 solver.cpp:228] Iteration 750, loss = 22821.7
I0823 09:09:14.833807  7716 solver.cpp:244]     Train net output #0: accuracy = 0.746966
I0823 09:09:14.833819  7716 solver.cpp:244]     Train net output #1: loss = 22821.7 (* 1 = 22821.7 loss)
I0823 09:09:14.833827  7716 sgd_solver.cpp:106] Iteration 750, lr = 1e-05
I0823 09:10:16.290825  7716 solver.cpp:337] Iteration 800, Testing net (#0)
I0823 09:10:24.713121  7716 solver.cpp:404]     Test net output #0: accuracy = 0.687911
I0823 09:10:24.713162  7716 solver.cpp:404]     Test net output #1: loss = 66768.7 (* 1 = 66768.7 loss)
I0823 09:10:25.615897  7716 solver.cpp:228] Iteration 800, loss = 26537.2
I0823 09:10:25.615931  7716 solver.cpp:244]     Train net output #0: accuracy = 0.73986
I0823 09:10:25.615941  7716 solver.cpp:244]     Train net output #1: loss = 26537.2 (* 1 = 26537.2 loss)
I0823 09:10:25.615947  7716 sgd_solver.cpp:106] Iteration 800, lr = 1e-05
I0823 09:11:27.918263  7716 solver.cpp:228] Iteration 850, loss = 18883
I0823 09:11:27.918311  7716 solver.cpp:244]     Train net output #0: accuracy = 0.824049
I0823 09:11:27.918321  7716 solver.cpp:244]     Train net output #1: loss = 18883 (* 1 = 18883 loss)
I0823 09:11:27.918328  7716 sgd_solver.cpp:106] Iteration 850, lr = 1e-05
I0823 09:12:30.243197  7716 solver.cpp:228] Iteration 900, loss = 21400.4
I0823 09:12:30.243245  7716 solver.cpp:244]     Train net output #0: accuracy = 0.771254
I0823 09:12:30.243254  7716 solver.cpp:244]     Train net output #1: loss = 21400.4 (* 1 = 21400.4 loss)
I0823 09:12:30.243262  7716 sgd_solver.cpp:106] Iteration 900, lr = 1e-05
I0823 09:13:32.582839  7716 solver.cpp:228] Iteration 950, loss = 16954.2
I0823 09:13:32.582885  7716 solver.cpp:244]     Train net output #0: accuracy = 0.83782
I0823 09:13:32.582895  7716 solver.cpp:244]     Train net output #1: loss = 16954.2 (* 1 = 16954.2 loss)
I0823 09:13:32.582901  7716 sgd_solver.cpp:106] Iteration 950, lr = 1e-05
I0823 09:14:33.963513  7716 solver.cpp:337] Iteration 1000, Testing net (#0)
I0823 09:14:42.385520  7716 solver.cpp:404]     Test net output #0: accuracy = 0.779443
I0823 09:14:42.385561  7716 solver.cpp:404]     Test net output #1: loss = 31099.5 (* 1 = 31099.5 loss)
I0823 09:14:43.288527  7716 solver.cpp:228] Iteration 1000, loss = 25824.6
I0823 09:14:43.288563  7716 solver.cpp:244]     Train net output #0: accuracy = 0.75163
I0823 09:14:43.288571  7716 solver.cpp:244]     Train net output #1: loss = 25824.6 (* 1 = 25824.6 loss)
I0823 09:14:43.288578  7716 sgd_solver.cpp:106] Iteration 1000, lr = 1e-05
I0823 09:15:45.623924  7716 solver.cpp:228] Iteration 1050, loss = 13676.2
I0823 09:15:45.624008  7716 solver.cpp:244]     Train net output #0: accuracy = 0.875927
I0823 09:15:45.624019  7716 solver.cpp:244]     Train net output #1: loss = 13676.2 (* 1 = 13676.2 loss)
I0823 09:15:45.624027  7716 sgd_solver.cpp:106] Iteration 1050, lr = 1e-05
I0823 09:16:47.880942  7716 solver.cpp:228] Iteration 1100, loss = 16701.5
I0823 09:16:47.881016  7716 solver.cpp:244]     Train net output #0: accuracy = 0.841817
I0823 09:16:47.881026  7716 solver.cpp:244]     Train net output #1: loss = 16701.5 (* 1 = 16701.5 loss)
I0823 09:16:47.881033  7716 sgd_solver.cpp:106] Iteration 1100, lr = 1e-05
I0823 09:17:50.411989  7716 solver.cpp:228] Iteration 1150, loss = 29022.8
I0823 09:17:50.412077  7716 solver.cpp:244]     Train net output #0: accuracy = 0.695977
I0823 09:17:50.412088  7716 solver.cpp:244]     Train net output #1: loss = 29022.8 (* 1 = 29022.8 loss)
I0823 09:17:50.412096  7716 sgd_solver.cpp:106] Iteration 1150, lr = 1e-05
I0823 09:18:51.964433  7716 solver.cpp:337] Iteration 1200, Testing net (#0)
I0823 09:19:00.440562  7716 solver.cpp:404]     Test net output #0: accuracy = 0.586621
I0823 09:19:00.440604  7716 solver.cpp:404]     Test net output #1: loss = 50294.4 (* 1 = 50294.4 loss)
I0823 09:19:01.347131  7716 solver.cpp:228] Iteration 1200, loss = 19925.8
I0823 09:19:01.347165  7716 solver.cpp:244]     Train net output #0: accuracy = 0.80536
I0823 09:19:01.347184  7716 solver.cpp:244]     Train net output #1: loss = 19925.8 (* 1 = 19925.8 loss)
I0823 09:19:01.347192  7716 sgd_solver.cpp:106] Iteration 1200, lr = 1e-05
I0823 09:20:03.857271  7716 solver.cpp:228] Iteration 1250, loss = 22481.9
I0823 09:20:03.857370  7716 solver.cpp:244]     Train net output #0: accuracy = 0.774709
I0823 09:20:03.857383  7716 solver.cpp:244]     Train net output #1: loss = 22481.9 (* 1 = 22481.9 loss)
I0823 09:20:03.857389  7716 sgd_solver.cpp:106] Iteration 1250, lr = 1e-05
I0823 09:21:06.360308  7716 solver.cpp:228] Iteration 1300, loss = 15524.2
I0823 09:21:06.360393  7716 solver.cpp:244]     Train net output #0: accuracy = 0.859585
I0823 09:21:06.360404  7716 solver.cpp:244]     Train net output #1: loss = 15524.2 (* 1 = 15524.2 loss)
I0823 09:21:06.360410  7716 sgd_solver.cpp:106] Iteration 1300, lr = 1e-05
I0823 09:22:08.865901  7716 solver.cpp:228] Iteration 1350, loss = 16934.4
I0823 09:22:08.865978  7716 solver.cpp:244]     Train net output #0: accuracy = 0.834382
I0823 09:22:08.865988  7716 solver.cpp:244]     Train net output #1: loss = 16934.4 (* 1 = 16934.4 loss)
I0823 09:22:08.865995  7716 sgd_solver.cpp:106] Iteration 1350, lr = 1e-05
I0823 09:23:10.459883  7716 solver.cpp:337] Iteration 1400, Testing net (#0)
I0823 09:23:18.912736  7716 solver.cpp:404]     Test net output #0: accuracy = 0.577255
I0823 09:23:18.912776  7716 solver.cpp:404]     Test net output #1: loss = 78251.6 (* 1 = 78251.6 loss)
I0823 09:23:19.820180  7716 solver.cpp:228] Iteration 1400, loss = 14702
I0823 09:23:19.820214  7716 solver.cpp:244]     Train net output #0: accuracy = 0.861552
I0823 09:23:19.820222  7716 solver.cpp:244]     Train net output #1: loss = 14702 (* 1 = 14702 loss)
I0823 09:23:19.820230  7716 sgd_solver.cpp:106] Iteration 1400, lr = 1e-05
I0823 09:24:22.315423  7716 solver.cpp:228] Iteration 1450, loss = 20047.3
I0823 09:24:22.315501  7716 solver.cpp:244]     Train net output #0: accuracy = 0.804226
I0823 09:24:22.315512  7716 solver.cpp:244]     Train net output #1: loss = 20047.3 (* 1 = 20047.3 loss)
I0823 09:24:22.315520  7716 sgd_solver.cpp:106] Iteration 1450, lr = 1e-05
I0823 09:25:24.843166  7716 solver.cpp:228] Iteration 1500, loss = 14225.2
I0823 09:25:24.843261  7716 solver.cpp:244]     Train net output #0: accuracy = 0.863898
I0823 09:25:24.843272  7716 solver.cpp:244]     Train net output #1: loss = 14225.2 (* 1 = 14225.2 loss)
I0823 09:25:24.843279  7716 sgd_solver.cpp:106] Iteration 1500, lr = 1e-05
I0823 09:26:27.325362  7716 solver.cpp:228] Iteration 1550, loss = 13154.5
I0823 09:26:27.325409  7716 solver.cpp:244]     Train net output #0: accuracy = 0.879956
I0823 09:26:27.325419  7716 solver.cpp:244]     Train net output #1: loss = 13154.5 (* 1 = 13154.5 loss)
I0823 09:26:27.325425  7716 sgd_solver.cpp:106] Iteration 1550, lr = 1e-05
I0823 09:27:28.943109  7716 solver.cpp:337] Iteration 1600, Testing net (#0)
I0823 09:27:37.438026  7716 solver.cpp:404]     Test net output #0: accuracy = 0.723377
I0823 09:27:37.438066  7716 solver.cpp:404]     Test net output #1: loss = 29225.6 (* 1 = 29225.6 loss)
I0823 09:27:38.343789  7716 solver.cpp:228] Iteration 1600, loss = 20653.5
I0823 09:27:38.343822  7716 solver.cpp:244]     Train net output #0: accuracy = 0.79522
I0823 09:27:38.343832  7716 solver.cpp:244]     Train net output #1: loss = 20653.5 (* 1 = 20653.5 loss)
I0823 09:27:38.343839  7716 sgd_solver.cpp:106] Iteration 1600, lr = 1e-05
I0823 09:28:40.810592  7716 solver.cpp:228] Iteration 1650, loss = 18006.9
I0823 09:28:40.810667  7716 solver.cpp:244]     Train net output #0: accuracy = 0.832022
I0823 09:28:40.810678  7716 solver.cpp:244]     Train net output #1: loss = 18006.9 (* 1 = 18006.9 loss)
I0823 09:28:40.810684  7716 sgd_solver.cpp:106] Iteration 1650, lr = 1e-05
I0823 09:29:43.305611  7716 solver.cpp:228] Iteration 1700, loss = 18912
I0823 09:29:43.305703  7716 solver.cpp:244]     Train net output #0: accuracy = 0.811246
I0823 09:29:43.305713  7716 solver.cpp:244]     Train net output #1: loss = 18912 (* 1 = 18912 loss)
I0823 09:29:43.305724  7716 sgd_solver.cpp:106] Iteration 1700, lr = 1e-05
I0823 09:30:45.813882  7716 solver.cpp:228] Iteration 1750, loss = 13069.6
I0823 09:30:45.813956  7716 solver.cpp:244]     Train net output #0: accuracy = 0.873261
I0823 09:30:45.813967  7716 solver.cpp:244]     Train net output #1: loss = 13069.6 (* 1 = 13069.6 loss)
I0823 09:30:45.813974  7716 sgd_solver.cpp:106] Iteration 1750, lr = 1e-05
I0823 09:31:47.415246  7716 solver.cpp:337] Iteration 1800, Testing net (#0)
I0823 09:31:55.899360  7716 solver.cpp:404]     Test net output #0: accuracy = 0.566468
I0823 09:31:55.899401  7716 solver.cpp:404]     Test net output #1: loss = 44405.9 (* 1 = 44405.9 loss)
I0823 09:31:56.805660  7716 solver.cpp:228] Iteration 1800, loss = 13260
I0823 09:31:56.805691  7716 solver.cpp:244]     Train net output #0: accuracy = 0.874991
I0823 09:31:56.805701  7716 solver.cpp:244]     Train net output #1: loss = 13260 (* 1 = 13260 loss)
I0823 09:31:56.805707  7716 sgd_solver.cpp:106] Iteration 1800, lr = 1e-05
I0823 09:32:59.337273  7716 solver.cpp:228] Iteration 1850, loss = 10865.6
I0823 09:32:59.337350  7716 solver.cpp:244]     Train net output #0: accuracy = 0.898613
I0823 09:32:59.337362  7716 solver.cpp:244]     Train net output #1: loss = 10865.6 (* 1 = 10865.6 loss)
I0823 09:32:59.337368  7716 sgd_solver.cpp:106] Iteration 1850, lr = 1e-05
I0823 09:34:01.813673  7716 solver.cpp:228] Iteration 1900, loss = 16556
I0823 09:34:01.813748  7716 solver.cpp:244]     Train net output #0: accuracy = 0.839782
I0823 09:34:01.813758  7716 solver.cpp:244]     Train net output #1: loss = 16556 (* 1 = 16556 loss)
I0823 09:34:01.813766  7716 sgd_solver.cpp:106] Iteration 1900, lr = 1e-05
I0823 09:35:04.344074  7716 solver.cpp:228] Iteration 1950, loss = 21922.8
I0823 09:35:04.344166  7716 solver.cpp:244]     Train net output #0: accuracy = 0.802121
I0823 09:35:04.344177  7716 solver.cpp:244]     Train net output #1: loss = 21922.8 (* 1 = 21922.8 loss)
I0823 09:35:04.344183  7716 sgd_solver.cpp:106] Iteration 1950, lr = 1e-05
I0823 09:36:05.938536  7716 solver.cpp:337] Iteration 2000, Testing net (#0)
I0823 09:36:14.401926  7716 solver.cpp:404]     Test net output #0: accuracy = 0.449428
I0823 09:36:14.401965  7716 solver.cpp:404]     Test net output #1: loss = 60238.6 (* 1 = 60238.6 loss)
I0823 09:36:15.306367  7716 solver.cpp:228] Iteration 2000, loss = 10550.7
I0823 09:36:15.306401  7716 solver.cpp:244]     Train net output #0: accuracy = 0.902352
I0823 09:36:15.306409  7716 solver.cpp:244]     Train net output #1: loss = 10550.7 (* 1 = 10550.7 loss)
I0823 09:36:15.306416  7716 sgd_solver.cpp:106] Iteration 2000, lr = 1e-05
I0823 09:37:17.862915  7716 solver.cpp:228] Iteration 2050, loss = 15039.5
I0823 09:37:17.862993  7716 solver.cpp:244]     Train net output #0: accuracy = 0.855522
I0823 09:37:17.863003  7716 solver.cpp:244]     Train net output #1: loss = 15039.5 (* 1 = 15039.5 loss)
I0823 09:37:17.863010  7716 sgd_solver.cpp:106] Iteration 2050, lr = 1e-05
I0823 09:38:20.346338  7716 solver.cpp:228] Iteration 2100, loss = 15142.2
I0823 09:38:20.346413  7716 solver.cpp:244]     Train net output #0: accuracy = 0.857355
I0823 09:38:20.346424  7716 solver.cpp:244]     Train net output #1: loss = 15142.2 (* 1 = 15142.2 loss)
I0823 09:38:20.346431  7716 sgd_solver.cpp:106] Iteration 2100, lr = 1e-05
I0823 09:39:22.872092  7716 solver.cpp:228] Iteration 2150, loss = 14549.2
I0823 09:39:22.872140  7716 solver.cpp:244]     Train net output #0: accuracy = 0.850894
I0823 09:39:22.872150  7716 solver.cpp:244]     Train net output #1: loss = 14549.2 (* 1 = 14549.2 loss)
I0823 09:39:22.872158  7716 sgd_solver.cpp:106] Iteration 2150, lr = 1e-05
I0823 09:40:24.478626  7716 solver.cpp:337] Iteration 2200, Testing net (#0)
I0823 09:40:32.922049  7716 solver.cpp:404]     Test net output #0: accuracy = 0.686373
I0823 09:40:32.922089  7716 solver.cpp:404]     Test net output #1: loss = 35001.6 (* 1 = 35001.6 loss)
I0823 09:40:33.825956  7716 solver.cpp:228] Iteration 2200, loss = 12298.7
I0823 09:40:33.825990  7716 solver.cpp:244]     Train net output #0: accuracy = 0.879521
I0823 09:40:33.826009  7716 solver.cpp:244]     Train net output #1: loss = 12298.7 (* 1 = 12298.7 loss)
I0823 09:40:33.826016  7716 sgd_solver.cpp:106] Iteration 2200, lr = 1e-05
I0823 09:41:36.359262  7716 solver.cpp:228] Iteration 2250, loss = 9906.82
I0823 09:41:36.359351  7716 solver.cpp:244]     Train net output #0: accuracy = 0.910212
I0823 09:41:36.359364  7716 solver.cpp:244]     Train net output #1: loss = 9906.82 (* 1 = 9906.82 loss)
I0823 09:41:36.359370  7716 sgd_solver.cpp:106] Iteration 2250, lr = 1e-05
I0823 09:42:38.894062  7716 solver.cpp:228] Iteration 2300, loss = 14233.9
I0823 09:42:38.894140  7716 solver.cpp:244]     Train net output #0: accuracy = 0.8689
I0823 09:42:38.894150  7716 solver.cpp:244]     Train net output #1: loss = 14233.9 (* 1 = 14233.9 loss)
I0823 09:42:38.894157  7716 sgd_solver.cpp:106] Iteration 2300, lr = 1e-05
I0823 09:43:41.386148  7716 solver.cpp:228] Iteration 2350, loss = 15432.4
I0823 09:43:41.386224  7716 solver.cpp:244]     Train net output #0: accuracy = 0.846096
I0823 09:43:41.386234  7716 solver.cpp:244]     Train net output #1: loss = 15432.4 (* 1 = 15432.4 loss)
I0823 09:43:41.386240  7716 sgd_solver.cpp:106] Iteration 2350, lr = 1e-05
I0823 09:44:43.007151  7716 solver.cpp:337] Iteration 2400, Testing net (#0)
I0823 09:44:51.423728  7716 solver.cpp:404]     Test net output #0: accuracy = 0.684326
I0823 09:44:51.423769  7716 solver.cpp:404]     Test net output #1: loss = 33077.2 (* 1 = 33077.2 loss)
I0823 09:44:52.329989  7716 solver.cpp:228] Iteration 2400, loss = 14126.1
I0823 09:44:52.330024  7716 solver.cpp:244]     Train net output #0: accuracy = 0.862273
I0823 09:44:52.330034  7716 solver.cpp:244]     Train net output #1: loss = 14126.1 (* 1 = 14126.1 loss)
I0823 09:44:52.330040  7716 sgd_solver.cpp:106] Iteration 2400, lr = 1e-05
I0823 09:45:54.818363  7716 solver.cpp:228] Iteration 2450, loss = 7851.28
I0823 09:45:54.818454  7716 solver.cpp:244]     Train net output #0: accuracy = 0.925823
I0823 09:45:54.818464  7716 solver.cpp:244]     Train net output #1: loss = 7851.28 (* 1 = 7851.28 loss)
I0823 09:45:54.818471  7716 sgd_solver.cpp:106] Iteration 2450, lr = 1e-05
I0823 09:46:57.358777  7716 solver.cpp:228] Iteration 2500, loss = 10400.2
I0823 09:46:57.358851  7716 solver.cpp:244]     Train net output #0: accuracy = 0.902174
I0823 09:46:57.358861  7716 solver.cpp:244]     Train net output #1: loss = 10400.2 (* 1 = 10400.2 loss)
I0823 09:46:57.358868  7716 sgd_solver.cpp:106] Iteration 2500, lr = 1e-05
I0823 09:47:59.838495  7716 solver.cpp:228] Iteration 2550, loss = 12180
I0823 09:47:59.838590  7716 solver.cpp:244]     Train net output #0: accuracy = 0.884065
I0823 09:47:59.838601  7716 solver.cpp:244]     Train net output #1: loss = 12180 (* 1 = 12180 loss)
I0823 09:47:59.838608  7716 sgd_solver.cpp:106] Iteration 2550, lr = 1e-05
I0823 09:49:01.434880  7716 solver.cpp:337] Iteration 2600, Testing net (#0)
I0823 09:49:09.903225  7716 solver.cpp:404]     Test net output #0: accuracy = 0.705931
I0823 09:49:09.903266  7716 solver.cpp:404]     Test net output #1: loss = 30584.3 (* 1 = 30584.3 loss)
I0823 09:49:10.811956  7716 solver.cpp:228] Iteration 2600, loss = 11666
I0823 09:49:10.811991  7716 solver.cpp:244]     Train net output #0: accuracy = 0.88568
I0823 09:49:10.812000  7716 solver.cpp:244]     Train net output #1: loss = 11666 (* 1 = 11666 loss)
I0823 09:49:10.812007  7716 sgd_solver.cpp:106] Iteration 2600, lr = 1e-05
I0823 09:50:13.298303  7716 solver.cpp:228] Iteration 2650, loss = 13058.1
I0823 09:50:13.298369  7716 solver.cpp:244]     Train net output #0: accuracy = 0.870893
I0823 09:50:13.298380  7716 solver.cpp:244]     Train net output #1: loss = 13058.1 (* 1 = 13058.1 loss)
I0823 09:50:13.298388  7716 sgd_solver.cpp:106] Iteration 2650, lr = 1e-05
I0823 09:51:15.866338  7716 solver.cpp:228] Iteration 2700, loss = 8822.66
I0823 09:51:15.866381  7716 solver.cpp:244]     Train net output #0: accuracy = 0.916194
I0823 09:51:15.866391  7716 solver.cpp:244]     Train net output #1: loss = 8822.66 (* 1 = 8822.66 loss)
I0823 09:51:15.866399  7716 sgd_solver.cpp:106] Iteration 2700, lr = 1e-05
I0823 09:52:18.382123  7716 solver.cpp:228] Iteration 2750, loss = 11339
I0823 09:52:18.382195  7716 solver.cpp:244]     Train net output #0: accuracy = 0.893971
I0823 09:52:18.382206  7716 solver.cpp:244]     Train net output #1: loss = 11339 (* 1 = 11339 loss)
I0823 09:52:18.382213  7716 sgd_solver.cpp:106] Iteration 2750, lr = 1e-05
I0823 09:53:19.979336  7716 solver.cpp:337] Iteration 2800, Testing net (#0)
I0823 09:53:28.432117  7716 solver.cpp:404]     Test net output #0: accuracy = 0.693447
I0823 09:53:28.432158  7716 solver.cpp:404]     Test net output #1: loss = 36030 (* 1 = 36030 loss)
I0823 09:53:29.342108  7716 solver.cpp:228] Iteration 2800, loss = 13991
I0823 09:53:29.342139  7716 solver.cpp:244]     Train net output #0: accuracy = 0.856264
I0823 09:53:29.342149  7716 solver.cpp:244]     Train net output #1: loss = 13991 (* 1 = 13991 loss)
I0823 09:53:29.342155  7716 sgd_solver.cpp:106] Iteration 2800, lr = 1e-05
I0823 09:54:31.900795  7716 solver.cpp:228] Iteration 2850, loss = 9920.11
I0823 09:54:31.900845  7716 solver.cpp:244]     Train net output #0: accuracy = 0.904266
I0823 09:54:31.900856  7716 solver.cpp:244]     Train net output #1: loss = 9920.11 (* 1 = 9920.11 loss)
I0823 09:54:31.900861  7716 sgd_solver.cpp:106] Iteration 2850, lr = 1e-05
I0823 09:55:34.422055  7716 solver.cpp:228] Iteration 2900, loss = 7308.78
I0823 09:55:34.422147  7716 solver.cpp:244]     Train net output #0: accuracy = 0.932232
I0823 09:55:34.422158  7716 solver.cpp:244]     Train net output #1: loss = 7308.78 (* 1 = 7308.78 loss)
I0823 09:55:34.422163  7716 sgd_solver.cpp:106] Iteration 2900, lr = 1e-05
I0823 09:56:36.986982  7716 solver.cpp:228] Iteration 2950, loss = 9187.08
I0823 09:56:36.987058  7716 solver.cpp:244]     Train net output #0: accuracy = 0.914416
I0823 09:56:36.987068  7716 solver.cpp:244]     Train net output #1: loss = 9187.08 (* 1 = 9187.08 loss)
I0823 09:56:36.987076  7716 sgd_solver.cpp:106] Iteration 2950, lr = 1e-05
I0823 09:57:38.570464  7716 solver.cpp:337] Iteration 3000, Testing net (#0)
I0823 09:57:47.007302  7716 solver.cpp:404]     Test net output #0: accuracy = 0.762446
I0823 09:57:47.007344  7716 solver.cpp:404]     Test net output #1: loss = 28325.3 (* 1 = 28325.3 loss)
I0823 09:57:47.914871  7716 solver.cpp:228] Iteration 3000, loss = 12405.2
I0823 09:57:47.914906  7716 solver.cpp:244]     Train net output #0: accuracy = 0.876404
I0823 09:57:47.914914  7716 solver.cpp:244]     Train net output #1: loss = 12405.2 (* 1 = 12405.2 loss)
I0823 09:57:47.914921  7716 sgd_solver.cpp:106] Iteration 3000, lr = 1e-05
I0823 09:58:50.438607  7716 solver.cpp:228] Iteration 3050, loss = 11310.5
I0823 09:58:50.438683  7716 solver.cpp:244]     Train net output #0: accuracy = 0.893296
I0823 09:58:50.438693  7716 solver.cpp:244]     Train net output #1: loss = 11310.5 (* 1 = 11310.5 loss)
I0823 09:58:50.438699  7716 sgd_solver.cpp:106] Iteration 3050, lr = 1e-05
I0823 09:59:52.967561  7716 solver.cpp:228] Iteration 3100, loss = 14506.7
I0823 09:59:52.967653  7716 solver.cpp:244]     Train net output #0: accuracy = 0.859797
I0823 09:59:52.967664  7716 solver.cpp:244]     Train net output #1: loss = 14506.7 (* 1 = 14506.7 loss)
I0823 09:59:52.967671  7716 sgd_solver.cpp:106] Iteration 3100, lr = 1e-05
I0823 10:00:55.501829  7716 solver.cpp:228] Iteration 3150, loss = 7296.41
I0823 10:00:55.501904  7716 solver.cpp:244]     Train net output #0: accuracy = 0.929136
I0823 10:00:55.501914  7716 solver.cpp:244]     Train net output #1: loss = 7296.41 (* 1 = 7296.41 loss)
I0823 10:00:55.501921  7716 sgd_solver.cpp:106] Iteration 3150, lr = 1e-05
I0823 10:01:57.144804  7716 solver.cpp:337] Iteration 3200, Testing net (#0)
I0823 10:02:05.570348  7716 solver.cpp:404]     Test net output #0: accuracy = 0.764385
I0823 10:02:05.570389  7716 solver.cpp:404]     Test net output #1: loss = 29167.2 (* 1 = 29167.2 loss)
I0823 10:02:06.474949  7716 solver.cpp:228] Iteration 3200, loss = 9001.69
I0823 10:02:06.474982  7716 solver.cpp:244]     Train net output #0: accuracy = 0.914171
I0823 10:02:06.475000  7716 solver.cpp:244]     Train net output #1: loss = 9001.69 (* 1 = 9001.69 loss)
I0823 10:02:06.475008  7716 sgd_solver.cpp:106] Iteration 3200, lr = 1e-05
I0823 10:03:08.991857  7716 solver.cpp:228] Iteration 3250, loss = 11505.3
I0823 10:03:08.991958  7716 solver.cpp:244]     Train net output #0: accuracy = 0.880905
I0823 10:03:08.991971  7716 solver.cpp:244]     Train net output #1: loss = 11505.3 (* 1 = 11505.3 loss)
I0823 10:03:08.991976  7716 sgd_solver.cpp:106] Iteration 3250, lr = 1e-05
I0823 10:04:11.528082  7716 solver.cpp:228] Iteration 3300, loss = 9282.91
I0823 10:04:11.528162  7716 solver.cpp:244]     Train net output #0: accuracy = 0.908604
I0823 10:04:11.528172  7716 solver.cpp:244]     Train net output #1: loss = 9282.91 (* 1 = 9282.91 loss)
I0823 10:04:11.528178  7716 sgd_solver.cpp:106] Iteration 3300, lr = 1e-05
I0823 10:05:14.047716  7716 solver.cpp:228] Iteration 3350, loss = 5958.29
I0823 10:05:14.047806  7716 solver.cpp:244]     Train net output #0: accuracy = 0.944611
I0823 10:05:14.047817  7716 solver.cpp:244]     Train net output #1: loss = 5958.29 (* 1 = 5958.29 loss)
I0823 10:05:14.047824  7716 sgd_solver.cpp:106] Iteration 3350, lr = 1e-05
I0823 10:06:15.711478  7716 solver.cpp:337] Iteration 3400, Testing net (#0)
I0823 10:06:24.264691  7716 solver.cpp:404]     Test net output #0: accuracy = 0.774166
I0823 10:06:24.264731  7716 solver.cpp:404]     Test net output #1: loss = 26994.6 (* 1 = 26994.6 loss)
I0823 10:06:25.168244  7716 solver.cpp:228] Iteration 3400, loss = 6543.71
I0823 10:06:25.168278  7716 solver.cpp:244]     Train net output #0: accuracy = 0.938065
I0823 10:06:25.168287  7716 solver.cpp:244]     Train net output #1: loss = 6543.71 (* 1 = 6543.71 loss)
I0823 10:06:25.168294  7716 sgd_solver.cpp:106] Iteration 3400, lr = 1e-05
I0823 10:07:27.666241  7716 solver.cpp:228] Iteration 3450, loss = 7540.5
I0823 10:07:27.666317  7716 solver.cpp:244]     Train net output #0: accuracy = 0.929243
I0823 10:07:27.666328  7716 solver.cpp:244]     Train net output #1: loss = 7540.5 (* 1 = 7540.5 loss)
I0823 10:07:27.666335  7716 sgd_solver.cpp:106] Iteration 3450, lr = 1e-05
I0823 10:08:30.198818  7716 solver.cpp:228] Iteration 3500, loss = 9070.55
I0823 10:08:30.198894  7716 solver.cpp:244]     Train net output #0: accuracy = 0.910421
I0823 10:08:30.198904  7716 solver.cpp:244]     Train net output #1: loss = 9070.55 (* 1 = 9070.55 loss)
I0823 10:08:30.198911  7716 sgd_solver.cpp:106] Iteration 3500, lr = 1e-05
I0823 10:09:32.693078  7716 solver.cpp:228] Iteration 3550, loss = 12937.5
I0823 10:09:32.693151  7716 solver.cpp:244]     Train net output #0: accuracy = 0.871961
I0823 10:09:32.693162  7716 solver.cpp:244]     Train net output #1: loss = 12937.5 (* 1 = 12937.5 loss)
I0823 10:09:32.693168  7716 sgd_solver.cpp:106] Iteration 3550, lr = 1e-05
I0823 10:10:34.325379  7716 solver.cpp:337] Iteration 3600, Testing net (#0)
I0823 10:10:42.711035  7716 solver.cpp:404]     Test net output #0: accuracy = 0.582251
I0823 10:10:42.711076  7716 solver.cpp:404]     Test net output #1: loss = 67403.4 (* 1 = 67403.4 loss)
I0823 10:10:43.616068  7716 solver.cpp:228] Iteration 3600, loss = 5982.65
I0823 10:10:43.616101  7716 solver.cpp:244]     Train net output #0: accuracy = 0.943253
I0823 10:10:43.616111  7716 solver.cpp:244]     Train net output #1: loss = 5982.65 (* 1 = 5982.65 loss)
I0823 10:10:43.616117  7716 sgd_solver.cpp:106] Iteration 3600, lr = 1e-05
I0823 10:11:46.161073  7716 solver.cpp:228] Iteration 3650, loss = 8578.62
I0823 10:11:46.161160  7716 solver.cpp:244]     Train net output #0: accuracy = 0.916894
I0823 10:11:46.161171  7716 solver.cpp:244]     Train net output #1: loss = 8578.62 (* 1 = 8578.62 loss)
I0823 10:11:46.161178  7716 sgd_solver.cpp:106] Iteration 3650, lr = 1e-05
I0823 10:12:48.709905  7716 solver.cpp:228] Iteration 3700, loss = 12235.3
I0823 10:12:48.709978  7716 solver.cpp:244]     Train net output #0: accuracy = 0.874896
I0823 10:12:48.709988  7716 solver.cpp:244]     Train net output #1: loss = 12235.3 (* 1 = 12235.3 loss)
I0823 10:12:48.710003  7716 sgd_solver.cpp:106] Iteration 3700, lr = 1e-05
I0823 10:13:51.245100  7716 solver.cpp:228] Iteration 3750, loss = 8228.75
I0823 10:13:51.245208  7716 solver.cpp:244]     Train net output #0: accuracy = 0.91926
I0823 10:13:51.245219  7716 solver.cpp:244]     Train net output #1: loss = 8228.75 (* 1 = 8228.75 loss)
I0823 10:13:51.245226  7716 sgd_solver.cpp:106] Iteration 3750, lr = 1e-05
I0823 10:14:52.846320  7716 solver.cpp:337] Iteration 3800, Testing net (#0)
I0823 10:15:01.226972  7716 solver.cpp:404]     Test net output #0: accuracy = 0.641069
I0823 10:15:01.227012  7716 solver.cpp:404]     Test net output #1: loss = 55470.4 (* 1 = 55470.4 loss)
I0823 10:15:02.133147  7716 solver.cpp:228] Iteration 3800, loss = 12044.2
I0823 10:15:02.133177  7716 solver.cpp:244]     Train net output #0: accuracy = 0.884123
I0823 10:15:02.133188  7716 solver.cpp:244]     Train net output #1: loss = 12044.2 (* 1 = 12044.2 loss)
I0823 10:15:02.133193  7716 sgd_solver.cpp:106] Iteration 3800, lr = 1e-05
I0823 10:16:04.688668  7716 solver.cpp:228] Iteration 3850, loss = 7164.94
I0823 10:16:04.688760  7716 solver.cpp:244]     Train net output #0: accuracy = 0.933724
I0823 10:16:04.688771  7716 solver.cpp:244]     Train net output #1: loss = 7164.94 (* 1 = 7164.94 loss)
I0823 10:16:04.688778  7716 sgd_solver.cpp:106] Iteration 3850, lr = 1e-05
I0823 10:17:07.210439  7716 solver.cpp:228] Iteration 3900, loss = 7122.21
I0823 10:17:07.210525  7716 solver.cpp:244]     Train net output #0: accuracy = 0.929968
I0823 10:17:07.210536  7716 solver.cpp:244]     Train net output #1: loss = 7122.21 (* 1 = 7122.21 loss)
I0823 10:17:07.210542  7716 sgd_solver.cpp:106] Iteration 3900, lr = 1e-05
I0823 10:18:09.778681  7716 solver.cpp:228] Iteration 3950, loss = 9176.82
I0823 10:18:09.778774  7716 solver.cpp:244]     Train net output #0: accuracy = 0.909875
I0823 10:18:09.778785  7716 solver.cpp:244]     Train net output #1: loss = 9176.82 (* 1 = 9176.82 loss)
I0823 10:18:09.778792  7716 sgd_solver.cpp:106] Iteration 3950, lr = 1e-05
I0823 10:19:11.369740  7716 solver.cpp:454] Snapshotting to binary proto file portrait_one_stage_iter_4000.caffemodel
I0823 10:19:11.373152  7716 sgd_solver.cpp:273] Snapshotting solver state to binary proto file portrait_one_stage_iter_4000.solverstate
I0823 10:19:11.374404  7716 solver.cpp:337] Iteration 4000, Testing net (#0)
I0823 10:19:19.770555  7716 solver.cpp:404]     Test net output #0: accuracy = 0.700543
I0823 10:19:19.770596  7716 solver.cpp:404]     Test net output #1: loss = 38935.5 (* 1 = 38935.5 loss)
I0823 10:19:20.677475  7716 solver.cpp:228] Iteration 4000, loss = 12644.1
I0823 10:19:20.677510  7716 solver.cpp:244]     Train net output #0: accuracy = 0.873136
I0823 10:19:20.677518  7716 solver.cpp:244]     Train net output #1: loss = 12644.1 (* 1 = 12644.1 loss)
I0823 10:19:20.677526  7716 sgd_solver.cpp:106] Iteration 4000, lr = 1e-06
I0823 10:20:23.247071  7716 solver.cpp:228] Iteration 4050, loss = 6128.03
I0823 10:20:23.247166  7716 solver.cpp:244]     Train net output #0: accuracy = 0.941191
I0823 10:20:23.247177  7716 solver.cpp:244]     Train net output #1: loss = 6128.03 (* 1 = 6128.03 loss)
I0823 10:20:23.247184  7716 sgd_solver.cpp:106] Iteration 4050, lr = 1e-06
I0823 10:21:25.817692  7716 solver.cpp:228] Iteration 4100, loss = 6888.91
I0823 10:21:25.817775  7716 solver.cpp:244]     Train net output #0: accuracy = 0.936267
I0823 10:21:25.817785  7716 solver.cpp:244]     Train net output #1: loss = 6888.91 (* 1 = 6888.91 loss)
I0823 10:21:25.817792  7716 sgd_solver.cpp:106] Iteration 4100, lr = 1e-06
I0823 10:22:28.396194  7716 solver.cpp:228] Iteration 4150, loss = 11585.3
I0823 10:22:28.396267  7716 solver.cpp:244]     Train net output #0: accuracy = 0.886479
I0823 10:22:28.396278  7716 solver.cpp:244]     Train net output #1: loss = 11585.3 (* 1 = 11585.3 loss)
I0823 10:22:28.396284  7716 sgd_solver.cpp:106] Iteration 4150, lr = 1e-06
I0823 10:23:30.053063  7716 solver.cpp:337] Iteration 4200, Testing net (#0)
I0823 10:23:38.473263  7716 solver.cpp:404]     Test net output #0: accuracy = 0.77892
I0823 10:23:38.473310  7716 solver.cpp:404]     Test net output #1: loss = 25521.6 (* 1 = 25521.6 loss)
I0823 10:23:39.380554  7716 solver.cpp:228] Iteration 4200, loss = 9039.11
I0823 10:23:39.380586  7716 solver.cpp:244]     Train net output #0: accuracy = 0.914167
I0823 10:23:39.380595  7716 solver.cpp:244]     Train net output #1: loss = 9039.11 (* 1 = 9039.11 loss)
I0823 10:23:39.380602  7716 sgd_solver.cpp:106] Iteration 4200, lr = 1e-06
I0823 10:24:41.929415  7716 solver.cpp:228] Iteration 4250, loss = 11368.7
I0823 10:24:41.929477  7716 solver.cpp:244]     Train net output #0: accuracy = 0.891484
I0823 10:24:41.929488  7716 solver.cpp:244]     Train net output #1: loss = 11368.7 (* 1 = 11368.7 loss)
I0823 10:24:41.929496  7716 sgd_solver.cpp:106] Iteration 4250, lr = 1e-06
I0823 10:25:44.538127  7716 solver.cpp:228] Iteration 4300, loss = 5701.63
I0823 10:25:44.538215  7716 solver.cpp:244]     Train net output #0: accuracy = 0.945586
I0823 10:25:44.538225  7716 solver.cpp:244]     Train net output #1: loss = 5701.63 (* 1 = 5701.63 loss)
I0823 10:25:44.538233  7716 sgd_solver.cpp:106] Iteration 4300, lr = 1e-06
I0823 10:26:47.126713  7716 solver.cpp:228] Iteration 4350, loss = 6284.86
I0823 10:26:47.126760  7716 solver.cpp:244]     Train net output #0: accuracy = 0.939392
I0823 10:26:47.126770  7716 solver.cpp:244]     Train net output #1: loss = 6284.86 (* 1 = 6284.86 loss)
I0823 10:26:47.126775  7716 sgd_solver.cpp:106] Iteration 4350, lr = 1e-06
I0823 10:27:48.810798  7716 solver.cpp:337] Iteration 4400, Testing net (#0)
I0823 10:27:57.249909  7716 solver.cpp:404]     Test net output #0: accuracy = 0.772246
I0823 10:27:57.249949  7716 solver.cpp:404]     Test net output #1: loss = 26964.1 (* 1 = 26964.1 loss)
I0823 10:27:58.160090  7716 solver.cpp:228] Iteration 4400, loss = 8903.78
I0823 10:27:58.160123  7716 solver.cpp:244]     Train net output #0: accuracy = 0.914348
I0823 10:27:58.160132  7716 solver.cpp:244]     Train net output #1: loss = 8903.78 (* 1 = 8903.78 loss)
I0823 10:27:58.160140  7716 sgd_solver.cpp:106] Iteration 4400, lr = 1e-06
I0823 10:29:00.715096  7716 solver.cpp:228] Iteration 4450, loss = 12304.6
I0823 10:29:00.715188  7716 solver.cpp:244]     Train net output #0: accuracy = 0.880672
I0823 10:29:00.715198  7716 solver.cpp:244]     Train net output #1: loss = 12304.6 (* 1 = 12304.6 loss)
I0823 10:29:00.715205  7716 sgd_solver.cpp:106] Iteration 4450, lr = 1e-06
I0823 10:30:03.256788  7716 solver.cpp:228] Iteration 4500, loss = 5523.91
I0823 10:30:03.256860  7716 solver.cpp:244]     Train net output #0: accuracy = 0.945659
I0823 10:30:03.256871  7716 solver.cpp:244]     Train net output #1: loss = 5523.91 (* 1 = 5523.91 loss)
I0823 10:30:03.256877  7716 sgd_solver.cpp:106] Iteration 4500, lr = 1e-06
I0823 10:31:05.834458  7716 solver.cpp:228] Iteration 4550, loss = 6137.8
I0823 10:31:05.834532  7716 solver.cpp:244]     Train net output #0: accuracy = 0.942387
I0823 10:31:05.834542  7716 solver.cpp:244]     Train net output #1: loss = 6137.8 (* 1 = 6137.8 loss)
I0823 10:31:05.834549  7716 sgd_solver.cpp:106] Iteration 4550, lr = 1e-06
I0823 10:32:07.492287  7716 solver.cpp:337] Iteration 4600, Testing net (#0)
I0823 10:32:15.918702  7716 solver.cpp:404]     Test net output #0: accuracy = 0.79616
I0823 10:32:15.918740  7716 solver.cpp:404]     Test net output #1: loss = 23587 (* 1 = 23587 loss)
I0823 10:32:16.823621  7716 solver.cpp:228] Iteration 4600, loss = 6055.6
I0823 10:32:16.823657  7716 solver.cpp:244]     Train net output #0: accuracy = 0.943098
I0823 10:32:16.823665  7716 solver.cpp:244]     Train net output #1: loss = 6055.6 (* 1 = 6055.6 loss)
I0823 10:32:16.823671  7716 sgd_solver.cpp:106] Iteration 4600, lr = 1e-06
I0823 10:33:19.378754  7716 solver.cpp:228] Iteration 4650, loss = 8212.03
I0823 10:33:19.378821  7716 solver.cpp:244]     Train net output #0: accuracy = 0.925213
I0823 10:33:19.378832  7716 solver.cpp:244]     Train net output #1: loss = 8212.03 (* 1 = 8212.03 loss)
I0823 10:33:19.378839  7716 sgd_solver.cpp:106] Iteration 4650, lr = 1e-06
I0823 10:34:21.905563  7716 solver.cpp:228] Iteration 4700, loss = 9952.3
I0823 10:34:21.905666  7716 solver.cpp:244]     Train net output #0: accuracy = 0.900936
I0823 10:34:21.905678  7716 solver.cpp:244]     Train net output #1: loss = 9952.3 (* 1 = 9952.3 loss)
I0823 10:34:21.905685  7716 sgd_solver.cpp:106] Iteration 4700, lr = 1e-06
I0823 10:35:24.497730  7716 solver.cpp:228] Iteration 4750, loss = 4765.57
I0823 10:35:24.497826  7716 solver.cpp:244]     Train net output #0: accuracy = 0.953572
I0823 10:35:24.497838  7716 solver.cpp:244]     Train net output #1: loss = 4765.57 (* 1 = 4765.57 loss)
I0823 10:35:24.497844  7716 sgd_solver.cpp:106] Iteration 4750, lr = 1e-06
I0823 10:36:26.147085  7716 solver.cpp:337] Iteration 4800, Testing net (#0)
I0823 10:36:34.581954  7716 solver.cpp:404]     Test net output #0: accuracy = 0.816297
I0823 10:36:34.581992  7716 solver.cpp:404]     Test net output #1: loss = 20894.3 (* 1 = 20894.3 loss)
I0823 10:36:35.486124  7716 solver.cpp:228] Iteration 4800, loss = 6016.76
I0823 10:36:35.486158  7716 solver.cpp:244]     Train net output #0: accuracy = 0.942015
I0823 10:36:35.486167  7716 solver.cpp:244]     Train net output #1: loss = 6016.76 (* 1 = 6016.76 loss)
I0823 10:36:35.486174  7716 sgd_solver.cpp:106] Iteration 4800, lr = 1e-06
I0823 10:37:38.071182  7716 solver.cpp:228] Iteration 4850, loss = 8896.46
I0823 10:37:38.071228  7716 solver.cpp:244]     Train net output #0: accuracy = 0.9144
I0823 10:37:38.071239  7716 solver.cpp:244]     Train net output #1: loss = 8896.46 (* 1 = 8896.46 loss)
I0823 10:37:38.071246  7716 sgd_solver.cpp:106] Iteration 4850, lr = 1e-06
I0823 10:38:40.584578  7716 solver.cpp:228] Iteration 4900, loss = 11868.1
I0823 10:38:40.584672  7716 solver.cpp:244]     Train net output #0: accuracy = 0.886423
I0823 10:38:40.584683  7716 solver.cpp:244]     Train net output #1: loss = 11868.1 (* 1 = 11868.1 loss)
I0823 10:38:40.584689  7716 sgd_solver.cpp:106] Iteration 4900, lr = 1e-06
I0823 10:39:43.137409  7716 solver.cpp:228] Iteration 4950, loss = 7713.05
I0823 10:39:43.137481  7716 solver.cpp:244]     Train net output #0: accuracy = 0.924953
I0823 10:39:43.137492  7716 solver.cpp:244]     Train net output #1: loss = 7713.05 (* 1 = 7713.05 loss)
I0823 10:39:43.137500  7716 sgd_solver.cpp:106] Iteration 4950, lr = 1e-06
I0823 10:40:44.782577  7716 solver.cpp:337] Iteration 5000, Testing net (#0)
I0823 10:40:53.240537  7716 solver.cpp:404]     Test net output #0: accuracy = 0.833431
I0823 10:40:53.240576  7716 solver.cpp:404]     Test net output #1: loss = 18381.7 (* 1 = 18381.7 loss)
I0823 10:40:54.145344  7716 solver.cpp:228] Iteration 5000, loss = 6070.69
I0823 10:40:54.145375  7716 solver.cpp:244]     Train net output #0: accuracy = 0.940224
I0823 10:40:54.145383  7716 solver.cpp:244]     Train net output #1: loss = 6070.69 (* 1 = 6070.69 loss)
I0823 10:40:54.145390  7716 sgd_solver.cpp:106] Iteration 5000, lr = 1e-06
I0823 10:41:56.721595  7716 solver.cpp:228] Iteration 5050, loss = 5753.62
I0823 10:41:56.721683  7716 solver.cpp:244]     Train net output #0: accuracy = 0.943718
I0823 10:41:56.721695  7716 solver.cpp:244]     Train net output #1: loss = 5753.62 (* 1 = 5753.62 loss)
I0823 10:41:56.721703  7716 sgd_solver.cpp:106] Iteration 5050, lr = 1e-06
I0823 10:42:59.291934  7716 solver.cpp:228] Iteration 5100, loss = 7412.08
I0823 10:42:59.292032  7716 solver.cpp:244]     Train net output #0: accuracy = 0.929715
I0823 10:42:59.292042  7716 solver.cpp:244]     Train net output #1: loss = 7412.08 (* 1 = 7412.08 loss)
I0823 10:42:59.292048  7716 sgd_solver.cpp:106] Iteration 5100, lr = 1e-06
I0823 10:44:01.826099  7716 solver.cpp:228] Iteration 5150, loss = 10587
I0823 10:44:01.826174  7716 solver.cpp:244]     Train net output #0: accuracy = 0.896579
I0823 10:44:01.826184  7716 solver.cpp:244]     Train net output #1: loss = 10587 (* 1 = 10587 loss)
I0823 10:44:01.826191  7716 sgd_solver.cpp:106] Iteration 5150, lr = 1e-06
I0823 10:45:03.488068  7716 solver.cpp:337] Iteration 5200, Testing net (#0)
I0823 10:45:11.928731  7716 solver.cpp:404]     Test net output #0: accuracy = 0.829249
I0823 10:45:11.928781  7716 solver.cpp:404]     Test net output #1: loss = 18981.7 (* 1 = 18981.7 loss)
I0823 10:45:12.832778  7716 solver.cpp:228] Iteration 5200, loss = 5638.77
I0823 10:45:12.832810  7716 solver.cpp:244]     Train net output #0: accuracy = 0.94897
I0823 10:45:12.832819  7716 solver.cpp:244]     Train net output #1: loss = 5638.77 (* 1 = 5638.77 loss)
I0823 10:45:12.832826  7716 sgd_solver.cpp:106] Iteration 5200, lr = 1e-06
I0823 10:46:15.377017  7716 solver.cpp:228] Iteration 5250, loss = 5114.89
I0823 10:46:15.377097  7716 solver.cpp:244]     Train net output #0: accuracy = 0.94982
I0823 10:46:15.377107  7716 solver.cpp:244]     Train net output #1: loss = 5114.89 (* 1 = 5114.89 loss)
I0823 10:46:15.377115  7716 sgd_solver.cpp:106] Iteration 5250, lr = 1e-06
I0823 10:47:17.969092  7716 solver.cpp:228] Iteration 5300, loss = 9039.82
I0823 10:47:17.969138  7716 solver.cpp:244]     Train net output #0: accuracy = 0.913518
I0823 10:47:17.969148  7716 solver.cpp:244]     Train net output #1: loss = 9039.82 (* 1 = 9039.82 loss)
I0823 10:47:17.969154  7716 sgd_solver.cpp:106] Iteration 5300, lr = 1e-06
I0823 10:48:20.498344  7716 solver.cpp:228] Iteration 5350, loss = 10946.1
I0823 10:48:20.498390  7716 solver.cpp:244]     Train net output #0: accuracy = 0.898914
I0823 10:48:20.498400  7716 solver.cpp:244]     Train net output #1: loss = 10946.1 (* 1 = 10946.1 loss)
I0823 10:48:20.498406  7716 sgd_solver.cpp:106] Iteration 5350, lr = 1e-06
I0823 10:49:22.153681  7716 solver.cpp:337] Iteration 5400, Testing net (#0)
I0823 10:49:30.592996  7716 solver.cpp:404]     Test net output #0: accuracy = 0.832788
I0823 10:49:30.593036  7716 solver.cpp:404]     Test net output #1: loss = 18661.2 (* 1 = 18661.2 loss)
I0823 10:49:31.502609  7716 solver.cpp:228] Iteration 5400, loss = 8289.06
I0823 10:49:31.502642  7716 solver.cpp:244]     Train net output #0: accuracy = 0.920999
I0823 10:49:31.502651  7716 solver.cpp:244]     Train net output #1: loss = 8289.06 (* 1 = 8289.06 loss)
I0823 10:49:31.502657  7716 sgd_solver.cpp:106] Iteration 5400, lr = 1e-06
I0823 10:50:34.041520  7716 solver.cpp:228] Iteration 5450, loss = 6726.84
I0823 10:50:34.041590  7716 solver.cpp:244]     Train net output #0: accuracy = 0.933538
I0823 10:50:34.041600  7716 solver.cpp:244]     Train net output #1: loss = 6726.84 (* 1 = 6726.84 loss)
I0823 10:50:34.041607  7716 sgd_solver.cpp:106] Iteration 5450, lr = 1e-06
I0823 10:51:36.623865  7716 solver.cpp:228] Iteration 5500, loss = 5462.73
I0823 10:51:36.623909  7716 solver.cpp:244]     Train net output #0: accuracy = 0.945981
I0823 10:51:36.623919  7716 solver.cpp:244]     Train net output #1: loss = 5462.73 (* 1 = 5462.73 loss)
I0823 10:51:36.623925  7716 sgd_solver.cpp:106] Iteration 5500, lr = 1e-06
I0823 10:52:39.184638  7716 solver.cpp:228] Iteration 5550, loss = 7441.59
I0823 10:52:39.184687  7716 solver.cpp:244]     Train net output #0: accuracy = 0.928702
I0823 10:52:39.184700  7716 solver.cpp:244]     Train net output #1: loss = 7441.59 (* 1 = 7441.59 loss)
I0823 10:52:39.184707  7716 sgd_solver.cpp:106] Iteration 5550, lr = 1e-06
I0823 10:53:40.837203  7716 solver.cpp:337] Iteration 5600, Testing net (#0)
I0823 10:53:49.274121  7716 solver.cpp:404]     Test net output #0: accuracy = 0.848279
I0823 10:53:49.274163  7716 solver.cpp:404]     Test net output #1: loss = 16477.8 (* 1 = 16477.8 loss)
I0823 10:53:50.183651  7716 solver.cpp:228] Iteration 5600, loss = 12525.1
I0823 10:53:50.183686  7716 solver.cpp:244]     Train net output #0: accuracy = 0.877403
I0823 10:53:50.183694  7716 solver.cpp:244]     Train net output #1: loss = 12525.1 (* 1 = 12525.1 loss)
I0823 10:53:50.183701  7716 sgd_solver.cpp:106] Iteration 5600, lr = 1e-06
I0823 10:54:52.757086  7716 solver.cpp:228] Iteration 5650, loss = 4485.48
I0823 10:54:52.757164  7716 solver.cpp:244]     Train net output #0: accuracy = 0.955763
I0823 10:54:52.757174  7716 solver.cpp:244]     Train net output #1: loss = 4485.48 (* 1 = 4485.48 loss)
I0823 10:54:52.757180  7716 sgd_solver.cpp:106] Iteration 5650, lr = 1e-06
I0823 10:55:55.303514  7716 solver.cpp:228] Iteration 5700, loss = 5466.38
I0823 10:55:55.303635  7716 solver.cpp:244]     Train net output #0: accuracy = 0.948484
I0823 10:55:55.303647  7716 solver.cpp:244]     Train net output #1: loss = 5466.38 (* 1 = 5466.38 loss)
I0823 10:55:55.303654  7716 sgd_solver.cpp:106] Iteration 5700, lr = 1e-06
I0823 10:56:57.900135  7716 solver.cpp:228] Iteration 5750, loss = 5068.06
I0823 10:56:57.900213  7716 solver.cpp:244]     Train net output #0: accuracy = 0.949993
I0823 10:56:57.900223  7716 solver.cpp:244]     Train net output #1: loss = 5068.06 (* 1 = 5068.06 loss)
I0823 10:56:57.900230  7716 sgd_solver.cpp:106] Iteration 5750, lr = 1e-06
I0823 10:57:59.528749  7716 solver.cpp:337] Iteration 5800, Testing net (#0)
I0823 10:58:07.974105  7716 solver.cpp:404]     Test net output #0: accuracy = 0.85648
I0823 10:58:07.974146  7716 solver.cpp:404]     Test net output #1: loss = 15271.5 (* 1 = 15271.5 loss)
I0823 10:58:08.881775  7716 solver.cpp:228] Iteration 5800, loss = 9380.72
I0823 10:58:08.881811  7716 solver.cpp:244]     Train net output #0: accuracy = 0.907073
I0823 10:58:08.881821  7716 solver.cpp:244]     Train net output #1: loss = 9380.72 (* 1 = 9380.72 loss)
I0823 10:58:08.881827  7716 sgd_solver.cpp:106] Iteration 5800, lr = 1e-06
I0823 10:59:11.433969  7716 solver.cpp:228] Iteration 5850, loss = 8179.4
I0823 10:59:11.434056  7716 solver.cpp:244]     Train net output #0: accuracy = 0.917561
I0823 10:59:11.434067  7716 solver.cpp:244]     Train net output #1: loss = 8179.4 (* 1 = 8179.4 loss)
I0823 10:59:11.434073  7716 sgd_solver.cpp:106] Iteration 5850, lr = 1e-06
I0823 11:00:14.004959  7716 solver.cpp:228] Iteration 5900, loss = 7447.12
I0823 11:00:14.005033  7716 solver.cpp:244]     Train net output #0: accuracy = 0.932007
I0823 11:00:14.005044  7716 solver.cpp:244]     Train net output #1: loss = 7447.12 (* 1 = 7447.12 loss)
I0823 11:00:14.005050  7716 sgd_solver.cpp:106] Iteration 5900, lr = 1e-06
I0823 11:01:16.584023  7716 solver.cpp:228] Iteration 5950, loss = 5042.94
I0823 11:01:16.584098  7716 solver.cpp:244]     Train net output #0: accuracy = 0.951678
I0823 11:01:16.584108  7716 solver.cpp:244]     Train net output #1: loss = 5042.94 (* 1 = 5042.94 loss)
I0823 11:01:16.584115  7716 sgd_solver.cpp:106] Iteration 5950, lr = 1e-06
I0823 11:02:18.280772  7716 solver.cpp:337] Iteration 6000, Testing net (#0)
I0823 11:02:26.752106  7716 solver.cpp:404]     Test net output #0: accuracy = 0.885979
I0823 11:02:26.752147  7716 solver.cpp:404]     Test net output #1: loss = 11833.7 (* 1 = 11833.7 loss)
I0823 11:02:27.660675  7716 solver.cpp:228] Iteration 6000, loss = 7166.54
I0823 11:02:27.660708  7716 solver.cpp:244]     Train net output #0: accuracy = 0.92947
I0823 11:02:27.660717  7716 solver.cpp:244]     Train net output #1: loss = 7166.54 (* 1 = 7166.54 loss)
I0823 11:02:27.660724  7716 sgd_solver.cpp:106] Iteration 6000, lr = 1e-06
I0823 11:03:30.208847  7716 solver.cpp:228] Iteration 6050, loss = 10191.5
I0823 11:03:30.208895  7716 solver.cpp:244]     Train net output #0: accuracy = 0.899121
I0823 11:03:30.208904  7716 solver.cpp:244]     Train net output #1: loss = 10191.5 (* 1 = 10191.5 loss)
I0823 11:03:30.208911  7716 sgd_solver.cpp:106] Iteration 6050, lr = 1e-06
I0823 11:04:32.784281  7716 solver.cpp:228] Iteration 6100, loss = 7496.01
I0823 11:04:32.784360  7716 solver.cpp:244]     Train net output #0: accuracy = 0.929805
I0823 11:04:32.784373  7716 solver.cpp:244]     Train net output #1: loss = 7496.01 (* 1 = 7496.01 loss)
I0823 11:04:32.784379  7716 sgd_solver.cpp:106] Iteration 6100, lr = 1e-06
I0823 11:05:35.350366  7716 solver.cpp:228] Iteration 6150, loss = 5968.11
I0823 11:05:35.350451  7716 solver.cpp:244]     Train net output #0: accuracy = 0.941959
I0823 11:05:35.350461  7716 solver.cpp:244]     Train net output #1: loss = 5968.11 (* 1 = 5968.11 loss)
I0823 11:05:35.350468  7716 sgd_solver.cpp:106] Iteration 6150, lr = 1e-06
I0823 11:06:37.071146  7716 solver.cpp:337] Iteration 6200, Testing net (#0)
I0823 11:06:45.518518  7716 solver.cpp:404]     Test net output #0: accuracy = 0.886059
I0823 11:06:45.518568  7716 solver.cpp:404]     Test net output #1: loss = 11845.3 (* 1 = 11845.3 loss)
I0823 11:06:46.421859  7716 solver.cpp:228] Iteration 6200, loss = 5031.63
I0823 11:06:46.421890  7716 solver.cpp:244]     Train net output #0: accuracy = 0.951198
I0823 11:06:46.421900  7716 solver.cpp:244]     Train net output #1: loss = 5031.63 (* 1 = 5031.63 loss)
I0823 11:06:46.421906  7716 sgd_solver.cpp:106] Iteration 6200, lr = 1e-06
I0823 11:07:48.943392  7716 solver.cpp:228] Iteration 6250, loss = 12003.1
I0823 11:07:48.943444  7716 solver.cpp:244]     Train net output #0: accuracy = 0.888806
I0823 11:07:48.943454  7716 solver.cpp:244]     Train net output #1: loss = 12003.1 (* 1 = 12003.1 loss)
I0823 11:07:48.943459  7716 sgd_solver.cpp:106] Iteration 6250, lr = 1e-06
I0823 11:08:51.500322  7716 solver.cpp:228] Iteration 6300, loss = 8641.48
I0823 11:08:51.500417  7716 solver.cpp:244]     Train net output #0: accuracy = 0.91505
I0823 11:08:51.500428  7716 solver.cpp:244]     Train net output #1: loss = 8641.48 (* 1 = 8641.48 loss)
I0823 11:08:51.500434  7716 sgd_solver.cpp:106] Iteration 6300, lr = 1e-06
I0823 11:09:54.026626  7716 solver.cpp:228] Iteration 6350, loss = 7106.6
I0823 11:09:54.026715  7716 solver.cpp:244]     Train net output #0: accuracy = 0.932835
I0823 11:09:54.026726  7716 solver.cpp:244]     Train net output #1: loss = 7106.6 (* 1 = 7106.6 loss)
I0823 11:09:54.026733  7716 sgd_solver.cpp:106] Iteration 6350, lr = 1e-06
I0823 11:10:55.686106  7716 solver.cpp:337] Iteration 6400, Testing net (#0)
I0823 11:11:04.125756  7716 solver.cpp:404]     Test net output #0: accuracy = 0.880165
I0823 11:11:04.125794  7716 solver.cpp:404]     Test net output #1: loss = 12536.4 (* 1 = 12536.4 loss)
I0823 11:11:05.031014  7716 solver.cpp:228] Iteration 6400, loss = 5139.67
I0823 11:11:05.031050  7716 solver.cpp:244]     Train net output #0: accuracy = 0.947033
I0823 11:11:05.031059  7716 solver.cpp:244]     Train net output #1: loss = 5139.67 (* 1 = 5139.67 loss)
I0823 11:11:05.031066  7716 sgd_solver.cpp:106] Iteration 6400, lr = 1e-06
I0823 11:12:07.607908  7716 solver.cpp:228] Iteration 6450, loss = 6713.97
I0823 11:12:07.608000  7716 solver.cpp:244]     Train net output #0: accuracy = 0.932386
I0823 11:12:07.608011  7716 solver.cpp:244]     Train net output #1: loss = 6713.97 (* 1 = 6713.97 loss)
I0823 11:12:07.608016  7716 sgd_solver.cpp:106] Iteration 6450, lr = 1e-06
I0823 11:13:10.158174  7716 solver.cpp:228] Iteration 6500, loss = 9141.05
I0823 11:13:10.158246  7716 solver.cpp:244]     Train net output #0: accuracy = 0.912764
I0823 11:13:10.158257  7716 solver.cpp:244]     Train net output #1: loss = 9141.05 (* 1 = 9141.05 loss)
I0823 11:13:10.158263  7716 sgd_solver.cpp:106] Iteration 6500, lr = 1e-06
I0823 11:14:12.712131  7716 solver.cpp:228] Iteration 6550, loss = 8486.15
I0823 11:14:12.712177  7716 solver.cpp:244]     Train net output #0: accuracy = 0.920251
I0823 11:14:12.712187  7716 solver.cpp:244]     Train net output #1: loss = 8486.15 (* 1 = 8486.15 loss)
I0823 11:14:12.712193  7716 sgd_solver.cpp:106] Iteration 6550, lr = 1e-06
I0823 11:15:14.374351  7716 solver.cpp:337] Iteration 6600, Testing net (#0)
I0823 11:15:22.821074  7716 solver.cpp:404]     Test net output #0: accuracy = 0.901573
I0823 11:15:22.821115  7716 solver.cpp:404]     Test net output #1: loss = 10170 (* 1 = 10170 loss)
I0823 11:15:23.726092  7716 solver.cpp:228] Iteration 6600, loss = 5739.93
I0823 11:15:23.726127  7716 solver.cpp:244]     Train net output #0: accuracy = 0.945693
I0823 11:15:23.726136  7716 solver.cpp:244]     Train net output #1: loss = 5739.93 (* 1 = 5739.93 loss)
I0823 11:15:23.726143  7716 sgd_solver.cpp:106] Iteration 6600, lr = 1e-06
I0823 11:16:26.314193  7716 solver.cpp:228] Iteration 6650, loss = 5215.06
I0823 11:16:26.314239  7716 solver.cpp:244]     Train net output #0: accuracy = 0.950547
I0823 11:16:26.314249  7716 solver.cpp:244]     Train net output #1: loss = 5215.06 (* 1 = 5215.06 loss)
I0823 11:16:26.314255  7716 sgd_solver.cpp:106] Iteration 6650, lr = 1e-06
I0823 11:17:28.852270  7716 solver.cpp:228] Iteration 6700, loss = 9469.51
I0823 11:17:28.852392  7716 solver.cpp:244]     Train net output #0: accuracy = 0.909563
I0823 11:17:28.852403  7716 solver.cpp:244]     Train net output #1: loss = 9469.51 (* 1 = 9469.51 loss)
I0823 11:17:28.852411  7716 sgd_solver.cpp:106] Iteration 6700, lr = 1e-06
I0823 11:18:31.415561  7716 solver.cpp:228] Iteration 6750, loss = 7401.66
I0823 11:18:31.415611  7716 solver.cpp:244]     Train net output #0: accuracy = 0.925659
I0823 11:18:31.415622  7716 solver.cpp:244]     Train net output #1: loss = 7401.66 (* 1 = 7401.66 loss)
I0823 11:18:31.415628  7716 sgd_solver.cpp:106] Iteration 6750, lr = 1e-06
I0823 11:19:33.047860  7716 solver.cpp:337] Iteration 6800, Testing net (#0)
I0823 11:19:41.504703  7716 solver.cpp:404]     Test net output #0: accuracy = 0.904094
I0823 11:19:41.504741  7716 solver.cpp:404]     Test net output #1: loss = 9908.23 (* 1 = 9908.23 loss)
I0823 11:19:42.409286  7716 solver.cpp:228] Iteration 6800, loss = 6646.24
I0823 11:19:42.409318  7716 solver.cpp:244]     Train net output #0: accuracy = 0.934418
I0823 11:19:42.409328  7716 solver.cpp:244]     Train net output #1: loss = 6646.24 (* 1 = 6646.24 loss)
I0823 11:19:42.409334  7716 sgd_solver.cpp:106] Iteration 6800, lr = 1e-06
I0823 11:20:44.976408  7716 solver.cpp:228] Iteration 6850, loss = 5052.71
I0823 11:20:44.976480  7716 solver.cpp:244]     Train net output #0: accuracy = 0.949446
I0823 11:20:44.976491  7716 solver.cpp:244]     Train net output #1: loss = 5052.71 (* 1 = 5052.71 loss)
I0823 11:20:44.976497  7716 sgd_solver.cpp:106] Iteration 6850, lr = 1e-06
I0823 11:21:47.541406  7716 solver.cpp:228] Iteration 6900, loss = 6832.32
I0823 11:21:47.541478  7716 solver.cpp:244]     Train net output #0: accuracy = 0.936041
I0823 11:21:47.541488  7716 solver.cpp:244]     Train net output #1: loss = 6832.32 (* 1 = 6832.32 loss)
I0823 11:21:47.541496  7716 sgd_solver.cpp:106] Iteration 6900, lr = 1e-06
I0823 11:22:50.092849  7716 solver.cpp:228] Iteration 6950, loss = 9855.81
I0823 11:22:50.092942  7716 solver.cpp:244]     Train net output #0: accuracy = 0.904174
I0823 11:22:50.092953  7716 solver.cpp:244]     Train net output #1: loss = 9855.81 (* 1 = 9855.81 loss)
I0823 11:22:50.092959  7716 sgd_solver.cpp:106] Iteration 6950, lr = 1e-06
I0823 11:23:51.744578  7716 solver.cpp:337] Iteration 7000, Testing net (#0)
I0823 11:24:00.205258  7716 solver.cpp:404]     Test net output #0: accuracy = 0.915235
I0823 11:24:00.205294  7716 solver.cpp:404]     Test net output #1: loss = 8778.09 (* 1 = 8778.09 loss)
I0823 11:24:01.112968  7716 solver.cpp:228] Iteration 7000, loss = 7728.86
I0823 11:24:01.113000  7716 solver.cpp:244]     Train net output #0: accuracy = 0.92522
I0823 11:24:01.113010  7716 solver.cpp:244]     Train net output #1: loss = 7728.86 (* 1 = 7728.86 loss)
I0823 11:24:01.113016  7716 sgd_solver.cpp:106] Iteration 7000, lr = 1e-06
I0823 11:25:03.648071  7716 solver.cpp:228] Iteration 7050, loss = 5090.66
I0823 11:25:03.648160  7716 solver.cpp:244]     Train net output #0: accuracy = 0.951016
I0823 11:25:03.648171  7716 solver.cpp:244]     Train net output #1: loss = 5090.66 (* 1 = 5090.66 loss)
I0823 11:25:03.648178  7716 sgd_solver.cpp:106] Iteration 7050, lr = 1e-06
I0823 11:26:06.268467  7716 solver.cpp:228] Iteration 7100, loss = 4606.01
I0823 11:26:06.268543  7716 solver.cpp:244]     Train net output #0: accuracy = 0.956466
I0823 11:26:06.268553  7716 solver.cpp:244]     Train net output #1: loss = 4606.01 (* 1 = 4606.01 loss)
I0823 11:26:06.268559  7716 sgd_solver.cpp:106] Iteration 7100, lr = 1e-06
I0823 11:27:08.818003  7716 solver.cpp:228] Iteration 7150, loss = 9020.03
I0823 11:27:08.818053  7716 solver.cpp:244]     Train net output #0: accuracy = 0.913952
I0823 11:27:08.818063  7716 solver.cpp:244]     Train net output #1: loss = 9020.03 (* 1 = 9020.03 loss)
I0823 11:27:08.818068  7716 sgd_solver.cpp:106] Iteration 7150, lr = 1e-06
I0823 11:28:10.485604  7716 solver.cpp:337] Iteration 7200, Testing net (#0)
I0823 11:28:19.048282  7716 solver.cpp:404]     Test net output #0: accuracy = 0.915761
I0823 11:28:19.048323  7716 solver.cpp:404]     Test net output #1: loss = 8781.29 (* 1 = 8781.29 loss)
I0823 11:28:19.957995  7716 solver.cpp:228] Iteration 7200, loss = 8105.13
I0823 11:28:19.958029  7716 solver.cpp:244]     Train net output #0: accuracy = 0.920469
I0823 11:28:19.958037  7716 solver.cpp:244]     Train net output #1: loss = 8105.13 (* 1 = 8105.13 loss)
I0823 11:28:19.958044  7716 sgd_solver.cpp:106] Iteration 7200, lr = 1e-06
I0823 11:29:22.482635  7716 solver.cpp:228] Iteration 7250, loss = 10077.7
I0823 11:29:22.482687  7716 solver.cpp:244]     Train net output #0: accuracy = 0.903105
I0823 11:29:22.482697  7716 solver.cpp:244]     Train net output #1: loss = 10077.7 (* 1 = 10077.7 loss)
I0823 11:29:22.482704  7716 sgd_solver.cpp:106] Iteration 7250, lr = 1e-06
I0823 11:30:25.060101  7716 solver.cpp:228] Iteration 7300, loss = 5574.51
I0823 11:30:25.060149  7716 solver.cpp:244]     Train net output #0: accuracy = 0.943993
I0823 11:30:25.060159  7716 solver.cpp:244]     Train net output #1: loss = 5574.51 (* 1 = 5574.51 loss)
I0823 11:30:25.060166  7716 sgd_solver.cpp:106] Iteration 7300, lr = 1e-06
I0823 11:31:27.643076  7716 solver.cpp:228] Iteration 7350, loss = 5116.71
I0823 11:31:27.643122  7716 solver.cpp:244]     Train net output #0: accuracy = 0.949283
I0823 11:31:27.643132  7716 solver.cpp:244]     Train net output #1: loss = 5116.71 (* 1 = 5116.71 loss)
I0823 11:31:27.643138  7716 sgd_solver.cpp:106] Iteration 7350, lr = 1e-06
I0823 11:32:29.284054  7716 solver.cpp:337] Iteration 7400, Testing net (#0)
I0823 11:32:37.729676  7716 solver.cpp:404]     Test net output #0: accuracy = 0.910008
I0823 11:32:37.729714  7716 solver.cpp:404]     Test net output #1: loss = 9381.87 (* 1 = 9381.87 loss)
I0823 11:32:38.638475  7716 solver.cpp:228] Iteration 7400, loss = 9938.5
I0823 11:32:38.638509  7716 solver.cpp:244]     Train net output #0: accuracy = 0.900428
I0823 11:32:38.638517  7716 solver.cpp:244]     Train net output #1: loss = 9938.5 (* 1 = 9938.5 loss)
I0823 11:32:38.638525  7716 sgd_solver.cpp:106] Iteration 7400, lr = 1e-06
I0823 11:33:41.187044  7716 solver.cpp:228] Iteration 7450, loss = 6397.13
I0823 11:33:41.187090  7716 solver.cpp:244]     Train net output #0: accuracy = 0.93753
I0823 11:33:41.187100  7716 solver.cpp:244]     Train net output #1: loss = 6397.13 (* 1 = 6397.13 loss)
I0823 11:33:41.187108  7716 sgd_solver.cpp:106] Iteration 7450, lr = 1e-06
I0823 11:34:43.724498  7716 solver.cpp:228] Iteration 7500, loss = 5077.54
I0823 11:34:43.724577  7716 solver.cpp:244]     Train net output #0: accuracy = 0.950787
I0823 11:34:43.724587  7716 solver.cpp:244]     Train net output #1: loss = 5077.54 (* 1 = 5077.54 loss)
I0823 11:34:43.724594  7716 sgd_solver.cpp:106] Iteration 7500, lr = 1e-06
I0823 11:35:46.331939  7716 solver.cpp:228] Iteration 7550, loss = 5140.37
I0823 11:35:46.332031  7716 solver.cpp:244]     Train net output #0: accuracy = 0.949993
I0823 11:35:46.332041  7716 solver.cpp:244]     Train net output #1: loss = 5140.37 (* 1 = 5140.37 loss)
I0823 11:35:46.332048  7716 sgd_solver.cpp:106] Iteration 7550, lr = 1e-06
I0823 11:36:47.968582  7716 solver.cpp:337] Iteration 7600, Testing net (#0)
I0823 11:36:56.419384  7716 solver.cpp:404]     Test net output #0: accuracy = 0.911475
I0823 11:36:56.419425  7716 solver.cpp:404]     Test net output #1: loss = 9095.27 (* 1 = 9095.27 loss)
I0823 11:36:57.326236  7716 solver.cpp:228] Iteration 7600, loss = 9424.74
I0823 11:36:57.326269  7716 solver.cpp:244]     Train net output #0: accuracy = 0.909439
I0823 11:36:57.326279  7716 solver.cpp:244]     Train net output #1: loss = 9424.74 (* 1 = 9424.74 loss)
I0823 11:36:57.326287  7716 sgd_solver.cpp:106] Iteration 7600, lr = 1e-06
I0823 11:37:59.920227  7716 solver.cpp:228] Iteration 7650, loss = 8440.77
I0823 11:37:59.920302  7716 solver.cpp:244]     Train net output #0: accuracy = 0.917368
I0823 11:37:59.920313  7716 solver.cpp:244]     Train net output #1: loss = 8440.77 (* 1 = 8440.77 loss)
I0823 11:37:59.920328  7716 sgd_solver.cpp:106] Iteration 7650, lr = 1e-06
I0823 11:39:02.486179  7716 solver.cpp:228] Iteration 7700, loss = 10523.5
I0823 11:39:02.486277  7716 solver.cpp:244]     Train net output #0: accuracy = 0.897206
I0823 11:39:02.486289  7716 solver.cpp:244]     Train net output #1: loss = 10523.5 (* 1 = 10523.5 loss)
I0823 11:39:02.486295  7716 sgd_solver.cpp:106] Iteration 7700, lr = 1e-06
I0823 11:40:05.094146  7716 solver.cpp:228] Iteration 7750, loss = 4944.71
I0823 11:40:05.094197  7716 solver.cpp:244]     Train net output #0: accuracy = 0.95093
I0823 11:40:05.094207  7716 solver.cpp:244]     Train net output #1: loss = 4944.71 (* 1 = 4944.71 loss)
I0823 11:40:05.094213  7716 sgd_solver.cpp:106] Iteration 7750, lr = 1e-06
I0823 11:41:06.752380  7716 solver.cpp:337] Iteration 7800, Testing net (#0)
I0823 11:41:15.210096  7716 solver.cpp:404]     Test net output #0: accuracy = 0.91187
I0823 11:41:15.210137  7716 solver.cpp:404]     Test net output #1: loss = 9124.96 (* 1 = 9124.96 loss)
I0823 11:41:16.114490  7716 solver.cpp:228] Iteration 7800, loss = 5671.84
I0823 11:41:16.114521  7716 solver.cpp:244]     Train net output #0: accuracy = 0.944909
I0823 11:41:16.114529  7716 solver.cpp:244]     Train net output #1: loss = 5671.84 (* 1 = 5671.84 loss)
I0823 11:41:16.114537  7716 sgd_solver.cpp:106] Iteration 7800, lr = 1e-06
I0823 11:42:18.726624  7716 solver.cpp:228] Iteration 7850, loss = 8819.08
I0823 11:42:18.726670  7716 solver.cpp:244]     Train net output #0: accuracy = 0.911224
I0823 11:42:18.726681  7716 solver.cpp:244]     Train net output #1: loss = 8819.08 (* 1 = 8819.08 loss)
I0823 11:42:18.726687  7716 sgd_solver.cpp:106] Iteration 7850, lr = 1e-06
I0823 11:43:21.308354  7716 solver.cpp:228] Iteration 7900, loss = 6684.75
I0823 11:43:21.308400  7716 solver.cpp:244]     Train net output #0: accuracy = 0.933661
I0823 11:43:21.308410  7716 solver.cpp:244]     Train net output #1: loss = 6684.75 (* 1 = 6684.75 loss)
I0823 11:43:21.308418  7716 sgd_solver.cpp:106] Iteration 7900, lr = 1e-06
I0823 11:44:23.847890  7716 solver.cpp:228] Iteration 7950, loss = 4800.99
I0823 11:44:23.847939  7716 solver.cpp:244]     Train net output #0: accuracy = 0.95239
I0823 11:44:23.847949  7716 solver.cpp:244]     Train net output #1: loss = 4800.99 (* 1 = 4800.99 loss)
I0823 11:44:23.847956  7716 sgd_solver.cpp:106] Iteration 7950, lr = 1e-06
I0823 11:45:25.544544  7716 solver.cpp:454] Snapshotting to binary proto file portrait_one_stage_iter_8000.caffemodel
I0823 11:45:25.547857  7716 sgd_solver.cpp:273] Snapshotting solver state to binary proto file portrait_one_stage_iter_8000.solverstate
I0823 11:45:25.549101  7716 solver.cpp:337] Iteration 8000, Testing net (#0)
I0823 11:45:34.001504  7716 solver.cpp:404]     Test net output #0: accuracy = 0.917616
I0823 11:45:34.001541  7716 solver.cpp:404]     Test net output #1: loss = 8523.58 (* 1 = 8523.58 loss)
I0823 11:45:34.905210  7716 solver.cpp:228] Iteration 8000, loss = 4374.25
I0823 11:45:34.905246  7716 solver.cpp:244]     Train net output #0: accuracy = 0.957104
I0823 11:45:34.905254  7716 solver.cpp:244]     Train net output #1: loss = 4374.25 (* 1 = 4374.25 loss)
I0823 11:45:34.905261  7716 sgd_solver.cpp:106] Iteration 8000, lr = 1e-07
I0823 11:46:37.421135  7716 solver.cpp:228] Iteration 8050, loss = 4667.68
I0823 11:46:37.421213  7716 solver.cpp:244]     Train net output #0: accuracy = 0.953924
I0823 11:46:37.421224  7716 solver.cpp:244]     Train net output #1: loss = 4667.68 (* 1 = 4667.68 loss)
I0823 11:46:37.421231  7716 sgd_solver.cpp:106] Iteration 8050, lr = 1e-07
I0823 11:47:40.025894  7716 solver.cpp:228] Iteration 8100, loss = 8072.65
I0823 11:47:40.025980  7716 solver.cpp:244]     Train net output #0: accuracy = 0.920768
I0823 11:47:40.025990  7716 solver.cpp:244]     Train net output #1: loss = 8072.65 (* 1 = 8072.65 loss)
I0823 11:47:40.025997  7716 sgd_solver.cpp:106] Iteration 8100, lr = 1e-07
I0823 11:48:42.524962  7716 solver.cpp:228] Iteration 8150, loss = 11000.4
I0823 11:48:42.525082  7716 solver.cpp:244]     Train net output #0: accuracy = 0.893346
I0823 11:48:42.525097  7716 solver.cpp:244]     Train net output #1: loss = 11000.4 (* 1 = 11000.4 loss)
I0823 11:48:42.525105  7716 sgd_solver.cpp:106] Iteration 8150, lr = 1e-07
I0823 11:49:44.173468  7716 solver.cpp:337] Iteration 8200, Testing net (#0)
I0823 11:49:52.631085  7716 solver.cpp:404]     Test net output #0: accuracy = 0.923138
I0823 11:49:52.631125  7716 solver.cpp:404]     Test net output #1: loss = 8054.86 (* 1 = 8054.86 loss)
I0823 11:49:53.536782  7716 solver.cpp:228] Iteration 8200, loss = 4293.72
I0823 11:49:53.536816  7716 solver.cpp:244]     Train net output #0: accuracy = 0.958516
I0823 11:49:53.536825  7716 solver.cpp:244]     Train net output #1: loss = 4293.72 (* 1 = 4293.72 loss)
I0823 11:49:53.536833  7716 sgd_solver.cpp:106] Iteration 8200, lr = 1e-07
I0823 11:50:56.066582  7716 solver.cpp:228] Iteration 8250, loss = 6005.24
I0823 11:50:56.066675  7716 solver.cpp:244]     Train net output #0: accuracy = 0.942687
I0823 11:50:56.066686  7716 solver.cpp:244]     Train net output #1: loss = 6005.24 (* 1 = 6005.24 loss)
I0823 11:50:56.066694  7716 sgd_solver.cpp:106] Iteration 8250, lr = 1e-07
I0823 11:51:58.613920  7716 solver.cpp:228] Iteration 8300, loss = 9275.26
I0823 11:51:58.614001  7716 solver.cpp:244]     Train net output #0: accuracy = 0.907204
I0823 11:51:58.614012  7716 solver.cpp:244]     Train net output #1: loss = 9275.26 (* 1 = 9275.26 loss)
I0823 11:51:58.614018  7716 sgd_solver.cpp:106] Iteration 8300, lr = 1e-07
I0823 11:53:01.136823  7716 solver.cpp:228] Iteration 8350, loss = 6806.33
I0823 11:53:01.136896  7716 solver.cpp:244]     Train net output #0: accuracy = 0.935784
I0823 11:53:01.136907  7716 solver.cpp:244]     Train net output #1: loss = 6806.33 (* 1 = 6806.33 loss)
I0823 11:53:01.136914  7716 sgd_solver.cpp:106] Iteration 8350, lr = 1e-07
I0823 11:54:02.735834  7716 solver.cpp:337] Iteration 8400, Testing net (#0)
I0823 11:54:11.190529  7716 solver.cpp:404]     Test net output #0: accuracy = 0.921824
I0823 11:54:11.190569  7716 solver.cpp:404]     Test net output #1: loss = 8171.55 (* 1 = 8171.55 loss)
I0823 11:54:12.099637  7716 solver.cpp:228] Iteration 8400, loss = 8793.09
I0823 11:54:12.099671  7716 solver.cpp:244]     Train net output #0: accuracy = 0.913901
I0823 11:54:12.099680  7716 solver.cpp:244]     Train net output #1: loss = 8793.09 (* 1 = 8793.09 loss)
I0823 11:54:12.099687  7716 sgd_solver.cpp:106] Iteration 8400, lr = 1e-07
I0823 11:55:14.655302  7716 solver.cpp:228] Iteration 8450, loss = 4756.54
I0823 11:55:14.655395  7716 solver.cpp:244]     Train net output #0: accuracy = 0.953577
I0823 11:55:14.655405  7716 solver.cpp:244]     Train net output #1: loss = 4756.54 (* 1 = 4756.54 loss)
I0823 11:55:14.655412  7716 sgd_solver.cpp:106] Iteration 8450, lr = 1e-07
I0823 11:56:17.195452  7716 solver.cpp:228] Iteration 8500, loss = 5477.52
I0823 11:56:17.195499  7716 solver.cpp:244]     Train net output #0: accuracy = 0.947469
I0823 11:56:17.195508  7716 solver.cpp:244]     Train net output #1: loss = 5477.52 (* 1 = 5477.52 loss)
I0823 11:56:17.195515  7716 sgd_solver.cpp:106] Iteration 8500, lr = 1e-07
I0823 11:57:19.745216  7716 solver.cpp:228] Iteration 8550, loss = 7835.76
I0823 11:57:19.745290  7716 solver.cpp:244]     Train net output #0: accuracy = 0.923601
I0823 11:57:19.745301  7716 solver.cpp:244]     Train net output #1: loss = 7835.76 (* 1 = 7835.76 loss)
I0823 11:57:19.745307  7716 sgd_solver.cpp:106] Iteration 8550, lr = 1e-07
I0823 11:58:21.330870  7716 solver.cpp:337] Iteration 8600, Testing net (#0)
I0823 11:58:29.787870  7716 solver.cpp:404]     Test net output #0: accuracy = 0.926087
I0823 11:58:29.787914  7716 solver.cpp:404]     Test net output #1: loss = 7740.15 (* 1 = 7740.15 loss)
I0823 11:58:30.696104  7716 solver.cpp:228] Iteration 8600, loss = 11017.2
I0823 11:58:30.696136  7716 solver.cpp:244]     Train net output #0: accuracy = 0.889518
I0823 11:58:30.696146  7716 solver.cpp:244]     Train net output #1: loss = 11017.2 (* 1 = 11017.2 loss)
I0823 11:58:30.696152  7716 sgd_solver.cpp:106] Iteration 8600, lr = 1e-07
I0823 11:59:33.231847  7716 solver.cpp:228] Iteration 8650, loss = 4347.19
I0823 11:59:33.231919  7716 solver.cpp:244]     Train net output #0: accuracy = 0.957771
I0823 11:59:33.231930  7716 solver.cpp:244]     Train net output #1: loss = 4347.19 (* 1 = 4347.19 loss)
I0823 11:59:33.231936  7716 sgd_solver.cpp:106] Iteration 8650, lr = 1e-07
I0823 12:00:35.773947  7716 solver.cpp:228] Iteration 8700, loss = 6123.02
I0823 12:00:35.774046  7716 solver.cpp:244]     Train net output #0: accuracy = 0.941895
I0823 12:00:35.774057  7716 solver.cpp:244]     Train net output #1: loss = 6123.02 (* 1 = 6123.02 loss)
I0823 12:00:35.774063  7716 sgd_solver.cpp:106] Iteration 8700, lr = 1e-07
I0823 12:01:38.325057  7716 solver.cpp:228] Iteration 8750, loss = 8845.39
I0823 12:01:38.325134  7716 solver.cpp:244]     Train net output #0: accuracy = 0.917297
I0823 12:01:38.325144  7716 solver.cpp:244]     Train net output #1: loss = 8845.39 (* 1 = 8845.39 loss)
I0823 12:01:38.325150  7716 sgd_solver.cpp:106] Iteration 8750, lr = 1e-07
I0823 12:02:39.937876  7716 solver.cpp:337] Iteration 8800, Testing net (#0)
I0823 12:02:48.392030  7716 solver.cpp:404]     Test net output #0: accuracy = 0.925842
I0823 12:02:48.392071  7716 solver.cpp:404]     Test net output #1: loss = 7748.22 (* 1 = 7748.22 loss)
I0823 12:02:49.299362  7716 solver.cpp:228] Iteration 8800, loss = 8300.26
I0823 12:02:49.299394  7716 solver.cpp:244]     Train net output #0: accuracy = 0.919277
I0823 12:02:49.299403  7716 solver.cpp:244]     Train net output #1: loss = 8300.26 (* 1 = 8300.26 loss)
I0823 12:02:49.299410  7716 sgd_solver.cpp:106] Iteration 8800, lr = 1e-07
I0823 12:03:51.820559  7716 solver.cpp:228] Iteration 8850, loss = 10187
I0823 12:03:51.820605  7716 solver.cpp:244]     Train net output #0: accuracy = 0.903972
I0823 12:03:51.820616  7716 solver.cpp:244]     Train net output #1: loss = 10187 (* 1 = 10187 loss)
I0823 12:03:51.820623  7716 sgd_solver.cpp:106] Iteration 8850, lr = 1e-07
I0823 12:04:54.396111  7716 solver.cpp:228] Iteration 8900, loss = 4829.63
I0823 12:04:54.396199  7716 solver.cpp:244]     Train net output #0: accuracy = 0.954031
I0823 12:04:54.396210  7716 solver.cpp:244]     Train net output #1: loss = 4829.63 (* 1 = 4829.63 loss)
I0823 12:04:54.396217  7716 sgd_solver.cpp:106] Iteration 8900, lr = 1e-07
I0823 12:05:56.937309  7716 solver.cpp:228] Iteration 8950, loss = 5056.48
I0823 12:05:56.937403  7716 solver.cpp:244]     Train net output #0: accuracy = 0.949889
I0823 12:05:56.937414  7716 solver.cpp:244]     Train net output #1: loss = 5056.48 (* 1 = 5056.48 loss)
I0823 12:05:56.937422  7716 sgd_solver.cpp:106] Iteration 8950, lr = 1e-07
I0823 12:06:58.595682  7716 solver.cpp:337] Iteration 9000, Testing net (#0)
I0823 12:07:07.049540  7716 solver.cpp:404]     Test net output #0: accuracy = 0.924394
I0823 12:07:07.049579  7716 solver.cpp:404]     Test net output #1: loss = 7840.93 (* 1 = 7840.93 loss)
I0823 12:07:07.959564  7716 solver.cpp:228] Iteration 9000, loss = 8047.03
I0823 12:07:07.959599  7716 solver.cpp:244]     Train net output #0: accuracy = 0.923421
I0823 12:07:07.959607  7716 solver.cpp:244]     Train net output #1: loss = 8047.03 (* 1 = 8047.03 loss)
I0823 12:07:07.959614  7716 sgd_solver.cpp:106] Iteration 9000, lr = 1e-07
I0823 12:08:10.442776  7716 solver.cpp:228] Iteration 9050, loss = 10545.8
I0823 12:08:10.442823  7716 solver.cpp:244]     Train net output #0: accuracy = 0.895479
I0823 12:08:10.442833  7716 solver.cpp:244]     Train net output #1: loss = 10545.8 (* 1 = 10545.8 loss)
I0823 12:08:10.442839  7716 sgd_solver.cpp:106] Iteration 9050, lr = 1e-07
I0823 12:09:12.991991  7716 solver.cpp:228] Iteration 9100, loss = 5364.47
I0823 12:09:12.992065  7716 solver.cpp:244]     Train net output #0: accuracy = 0.948933
I0823 12:09:12.992075  7716 solver.cpp:244]     Train net output #1: loss = 5364.47 (* 1 = 5364.47 loss)
I0823 12:09:12.992082  7716 sgd_solver.cpp:106] Iteration 9100, lr = 1e-07
I0823 12:10:15.520957  7716 solver.cpp:228] Iteration 9150, loss = 5348.04
I0823 12:10:15.521055  7716 solver.cpp:244]     Train net output #0: accuracy = 0.946627
I0823 12:10:15.521070  7716 solver.cpp:244]     Train net output #1: loss = 5348.04 (* 1 = 5348.04 loss)
I0823 12:10:15.521076  7716 sgd_solver.cpp:106] Iteration 9150, lr = 1e-07
I0823 12:11:17.177829  7716 solver.cpp:337] Iteration 9200, Testing net (#0)
I0823 12:11:25.630336  7716 solver.cpp:404]     Test net output #0: accuracy = 0.926199
I0823 12:11:25.630375  7716 solver.cpp:404]     Test net output #1: loss = 7682.89 (* 1 = 7682.89 loss)
I0823 12:11:26.535480  7716 solver.cpp:228] Iteration 9200, loss = 5238.16
I0823 12:11:26.535514  7716 solver.cpp:244]     Train net output #0: accuracy = 0.948056
I0823 12:11:26.535523  7716 solver.cpp:244]     Train net output #1: loss = 5238.16 (* 1 = 5238.16 loss)
I0823 12:11:26.535529  7716 sgd_solver.cpp:106] Iteration 9200, lr = 1e-07
I0823 12:12:29.054412  7716 solver.cpp:228] Iteration 9250, loss = 7556.32
I0823 12:12:29.054503  7716 solver.cpp:244]     Train net output #0: accuracy = 0.928773
I0823 12:12:29.054514  7716 solver.cpp:244]     Train net output #1: loss = 7556.32 (* 1 = 7556.32 loss)
I0823 12:12:29.054520  7716 sgd_solver.cpp:106] Iteration 9250, lr = 1e-07
I0823 12:13:31.567605  7716 solver.cpp:228] Iteration 9300, loss = 8761.73
I0823 12:13:31.567652  7716 solver.cpp:244]     Train net output #0: accuracy = 0.911108
I0823 12:13:31.567662  7716 solver.cpp:244]     Train net output #1: loss = 8761.73 (* 1 = 8761.73 loss)
I0823 12:13:31.567668  7716 sgd_solver.cpp:106] Iteration 9300, lr = 1e-07
I0823 12:14:34.113270  7716 solver.cpp:228] Iteration 9350, loss = 4209.42
I0823 12:14:34.113315  7716 solver.cpp:244]     Train net output #0: accuracy = 0.959926
I0823 12:14:34.113325  7716 solver.cpp:244]     Train net output #1: loss = 4209.42 (* 1 = 4209.42 loss)
I0823 12:14:34.113332  7716 sgd_solver.cpp:106] Iteration 9350, lr = 1e-07
I0823 12:15:35.731119  7716 solver.cpp:337] Iteration 9400, Testing net (#0)
I0823 12:15:44.192560  7716 solver.cpp:404]     Test net output #0: accuracy = 0.921173
I0823 12:15:44.192600  7716 solver.cpp:404]     Test net output #1: loss = 8158.02 (* 1 = 8158.02 loss)
I0823 12:15:45.097223  7716 solver.cpp:228] Iteration 9400, loss = 5481.26
I0823 12:15:45.097257  7716 solver.cpp:244]     Train net output #0: accuracy = 0.946769
I0823 12:15:45.097266  7716 solver.cpp:244]     Train net output #1: loss = 5481.26 (* 1 = 5481.26 loss)
I0823 12:15:45.097273  7716 sgd_solver.cpp:106] Iteration 9400, lr = 1e-07
I0823 12:16:47.672854  7716 solver.cpp:228] Iteration 9450, loss = 8352.98
I0823 12:16:47.672930  7716 solver.cpp:244]     Train net output #0: accuracy = 0.916832
I0823 12:16:47.672941  7716 solver.cpp:244]     Train net output #1: loss = 8352.98 (* 1 = 8352.98 loss)
I0823 12:16:47.672947  7716 sgd_solver.cpp:106] Iteration 9450, lr = 1e-07
I0823 12:17:50.202273  7716 solver.cpp:228] Iteration 9500, loss = 10463.8
I0823 12:17:50.202365  7716 solver.cpp:244]     Train net output #0: accuracy = 0.899746
I0823 12:17:50.202376  7716 solver.cpp:244]     Train net output #1: loss = 10463.8 (* 1 = 10463.8 loss)
I0823 12:17:50.202383  7716 sgd_solver.cpp:106] Iteration 9500, lr = 1e-07
I0823 12:18:52.747750  7716 solver.cpp:228] Iteration 9550, loss = 7983.92
I0823 12:18:52.747797  7716 solver.cpp:244]     Train net output #0: accuracy = 0.920584
I0823 12:18:52.747807  7716 solver.cpp:244]     Train net output #1: loss = 7983.92 (* 1 = 7983.92 loss)
I0823 12:18:52.747812  7716 sgd_solver.cpp:106] Iteration 9550, lr = 1e-07
I0823 12:19:54.374379  7716 solver.cpp:337] Iteration 9600, Testing net (#0)
I0823 12:20:02.828812  7716 solver.cpp:404]     Test net output #0: accuracy = 0.924958
I0823 12:20:02.828852  7716 solver.cpp:404]     Test net output #1: loss = 7790.17 (* 1 = 7790.17 loss)
I0823 12:20:03.733511  7716 solver.cpp:228] Iteration 9600, loss = 5550.83
I0823 12:20:03.733546  7716 solver.cpp:244]     Train net output #0: accuracy = 0.944248
I0823 12:20:03.733556  7716 solver.cpp:244]     Train net output #1: loss = 5550.83 (* 1 = 5550.83 loss)
I0823 12:20:03.733561  7716 sgd_solver.cpp:106] Iteration 9600, lr = 1e-07
I0823 12:21:06.283828  7716 solver.cpp:228] Iteration 9650, loss = 4793.42
I0823 12:21:06.283921  7716 solver.cpp:244]     Train net output #0: accuracy = 0.954562
I0823 12:21:06.283932  7716 solver.cpp:244]     Train net output #1: loss = 4793.42 (* 1 = 4793.42 loss)
I0823 12:21:06.283938  7716 sgd_solver.cpp:106] Iteration 9650, lr = 1e-07
I0823 12:22:08.863631  7716 solver.cpp:228] Iteration 9700, loss = 7115.78
I0823 12:22:08.863694  7716 solver.cpp:244]     Train net output #0: accuracy = 0.933004
I0823 12:22:08.863705  7716 solver.cpp:244]     Train net output #1: loss = 7115.78 (* 1 = 7115.78 loss)
I0823 12:22:08.863711  7716 sgd_solver.cpp:106] Iteration 9700, lr = 1e-07
I0823 12:23:11.420025  7716 solver.cpp:228] Iteration 9750, loss = 9647.6
I0823 12:23:11.420071  7716 solver.cpp:244]     Train net output #0: accuracy = 0.905981
I0823 12:23:11.420081  7716 solver.cpp:244]     Train net output #1: loss = 9647.6 (* 1 = 9647.6 loss)
I0823 12:23:11.420087  7716 sgd_solver.cpp:106] Iteration 9750, lr = 1e-07
I0823 12:24:13.093551  7716 solver.cpp:337] Iteration 9800, Testing net (#0)
I0823 12:24:21.547718  7716 solver.cpp:404]     Test net output #0: accuracy = 0.924856
I0823 12:24:21.547760  7716 solver.cpp:404]     Test net output #1: loss = 7792.24 (* 1 = 7792.24 loss)
I0823 12:24:22.452081  7716 solver.cpp:228] Iteration 9800, loss = 5277.62
I0823 12:24:22.452114  7716 solver.cpp:244]     Train net output #0: accuracy = 0.951619
I0823 12:24:22.452124  7716 solver.cpp:244]     Train net output #1: loss = 5277.62 (* 1 = 5277.62 loss)
I0823 12:24:22.452131  7716 sgd_solver.cpp:106] Iteration 9800, lr = 1e-07
I0823 12:25:24.981027  7716 solver.cpp:228] Iteration 9850, loss = 4905.93
I0823 12:25:24.981122  7716 solver.cpp:244]     Train net output #0: accuracy = 0.951494
I0823 12:25:24.981132  7716 solver.cpp:244]     Train net output #1: loss = 4905.93 (* 1 = 4905.93 loss)
I0823 12:25:24.981138  7716 sgd_solver.cpp:106] Iteration 9850, lr = 1e-07
I0823 12:26:27.556654  7716 solver.cpp:228] Iteration 9900, loss = 8055.82
I0823 12:26:27.556746  7716 solver.cpp:244]     Train net output #0: accuracy = 0.923345
I0823 12:26:27.556756  7716 solver.cpp:244]     Train net output #1: loss = 8055.82 (* 1 = 8055.82 loss)
I0823 12:26:27.556763  7716 sgd_solver.cpp:106] Iteration 9900, lr = 1e-07
I0823 12:27:30.049248  7716 solver.cpp:228] Iteration 9950, loss = 10389.6
I0823 12:27:30.049322  7716 solver.cpp:244]     Train net output #0: accuracy = 0.904657
I0823 12:27:30.049334  7716 solver.cpp:244]     Train net output #1: loss = 10389.6 (* 1 = 10389.6 loss)
I0823 12:27:30.049340  7716 sgd_solver.cpp:106] Iteration 9950, lr = 1e-07
I0823 12:28:31.686862  7716 solver.cpp:337] Iteration 10000, Testing net (#0)
I0823 12:28:40.139822  7716 solver.cpp:404]     Test net output #0: accuracy = 0.923948
I0823 12:28:40.139863  7716 solver.cpp:404]     Test net output #1: loss = 7855.89 (* 1 = 7855.89 loss)
I0823 12:28:41.050253  7716 solver.cpp:228] Iteration 10000, loss = 8047.56
I0823 12:28:41.050288  7716 solver.cpp:244]     Train net output #0: accuracy = 0.922039
I0823 12:28:41.050298  7716 solver.cpp:244]     Train net output #1: loss = 8047.56 (* 1 = 8047.56 loss)
I0823 12:28:41.050305  7716 sgd_solver.cpp:106] Iteration 10000, lr = 1e-07
I0823 12:29:43.564045  7716 solver.cpp:228] Iteration 10050, loss = 6319.49
I0823 12:29:43.564102  7716 solver.cpp:244]     Train net output #0: accuracy = 0.93761
I0823 12:29:43.564112  7716 solver.cpp:244]     Train net output #1: loss = 6319.49 (* 1 = 6319.49 loss)
I0823 12:29:43.564119  7716 sgd_solver.cpp:106] Iteration 10050, lr = 1e-07
I0823 12:30:46.112169  7716 solver.cpp:228] Iteration 10100, loss = 5041.17
I0823 12:30:46.112216  7716 solver.cpp:244]     Train net output #0: accuracy = 0.951449
I0823 12:30:46.112229  7716 solver.cpp:244]     Train net output #1: loss = 5041.17 (* 1 = 5041.17 loss)
I0823 12:30:46.112236  7716 sgd_solver.cpp:106] Iteration 10100, lr = 1e-07
I0823 12:31:48.697722  7716 solver.cpp:228] Iteration 10150, loss = 7313.67
I0823 12:31:48.697830  7716 solver.cpp:244]     Train net output #0: accuracy = 0.929255
I0823 12:31:48.697842  7716 solver.cpp:244]     Train net output #1: loss = 7313.67 (* 1 = 7313.67 loss)
I0823 12:31:48.697849  7716 sgd_solver.cpp:106] Iteration 10150, lr = 1e-07
I0823 12:32:50.354702  7716 solver.cpp:337] Iteration 10200, Testing net (#0)
I0823 12:32:58.835829  7716 solver.cpp:404]     Test net output #0: accuracy = 0.925509
I0823 12:32:58.835870  7716 solver.cpp:404]     Test net output #1: loss = 7725.43 (* 1 = 7725.43 loss)
I0823 12:32:59.745363  7716 solver.cpp:228] Iteration 10200, loss = 11365.5
I0823 12:32:59.745398  7716 solver.cpp:244]     Train net output #0: accuracy = 0.887286
I0823 12:32:59.745406  7716 solver.cpp:244]     Train net output #1: loss = 11365.5 (* 1 = 11365.5 loss)
I0823 12:32:59.745414  7716 sgd_solver.cpp:106] Iteration 10200, lr = 1e-07
I0823 12:34:02.310703  7716 solver.cpp:228] Iteration 10250, loss = 4353.87
I0823 12:34:02.310775  7716 solver.cpp:244]     Train net output #0: accuracy = 0.956783
I0823 12:34:02.310786  7716 solver.cpp:244]     Train net output #1: loss = 4353.87 (* 1 = 4353.87 loss)
I0823 12:34:02.310792  7716 sgd_solver.cpp:106] Iteration 10250, lr = 1e-07
I0823 12:35:04.840044  7716 solver.cpp:228] Iteration 10300, loss = 5624.93
I0823 12:35:04.840136  7716 solver.cpp:244]     Train net output #0: accuracy = 0.947756
I0823 12:35:04.840147  7716 solver.cpp:244]     Train net output #1: loss = 5624.93 (* 1 = 5624.93 loss)
I0823 12:35:04.840153  7716 sgd_solver.cpp:106] Iteration 10300, lr = 1e-07
I0823 12:36:07.438041  7716 solver.cpp:228] Iteration 10350, loss = 4717.83
I0823 12:36:07.438114  7716 solver.cpp:244]     Train net output #0: accuracy = 0.95355
I0823 12:36:07.438124  7716 solver.cpp:244]     Train net output #1: loss = 4717.83 (* 1 = 4717.83 loss)
I0823 12:36:07.438130  7716 sgd_solver.cpp:106] Iteration 10350, lr = 1e-07
I0823 12:37:09.031394  7716 solver.cpp:337] Iteration 10400, Testing net (#0)
I0823 12:37:17.486382  7716 solver.cpp:404]     Test net output #0: accuracy = 0.920376
I0823 12:37:17.486421  7716 solver.cpp:404]     Test net output #1: loss = 8213.66 (* 1 = 8213.66 loss)
I0823 12:37:18.393836  7716 solver.cpp:228] Iteration 10400, loss = 9771.52
I0823 12:37:18.393870  7716 solver.cpp:244]     Train net output #0: accuracy = 0.90488
I0823 12:37:18.393879  7716 solver.cpp:244]     Train net output #1: loss = 9771.52 (* 1 = 9771.52 loss)
I0823 12:37:18.393887  7716 sgd_solver.cpp:106] Iteration 10400, lr = 1e-07
I0823 12:38:20.936491  7716 solver.cpp:228] Iteration 10450, loss = 8104.53
I0823 12:38:20.936571  7716 solver.cpp:244]     Train net output #0: accuracy = 0.918097
I0823 12:38:20.936583  7716 solver.cpp:244]     Train net output #1: loss = 8104.53 (* 1 = 8104.53 loss)
I0823 12:38:20.936589  7716 sgd_solver.cpp:106] Iteration 10450, lr = 1e-07
I0823 12:39:23.455304  7716 solver.cpp:228] Iteration 10500, loss = 6083.29
I0823 12:39:23.455394  7716 solver.cpp:244]     Train net output #0: accuracy = 0.940048
I0823 12:39:23.455404  7716 solver.cpp:244]     Train net output #1: loss = 6083.29 (* 1 = 6083.29 loss)
I0823 12:39:23.455411  7716 sgd_solver.cpp:106] Iteration 10500, lr = 1e-07
I0823 12:40:26.048099  7716 solver.cpp:228] Iteration 10550, loss = 5163.44
I0823 12:40:26.048190  7716 solver.cpp:244]     Train net output #0: accuracy = 0.950182
I0823 12:40:26.048202  7716 solver.cpp:244]     Train net output #1: loss = 5163.44 (* 1 = 5163.44 loss)
I0823 12:40:26.048208  7716 sgd_solver.cpp:106] Iteration 10550, lr = 1e-07
I0823 12:41:27.682721  7716 solver.cpp:337] Iteration 10600, Testing net (#0)
I0823 12:41:36.150413  7716 solver.cpp:404]     Test net output #0: accuracy = 0.923548
I0823 12:41:36.150454  7716 solver.cpp:404]     Test net output #1: loss = 7907.06 (* 1 = 7907.06 loss)
I0823 12:41:37.058063  7716 solver.cpp:228] Iteration 10600, loss = 6938.21
I0823 12:41:37.058096  7716 solver.cpp:244]     Train net output #0: accuracy = 0.933038
I0823 12:41:37.058106  7716 solver.cpp:244]     Train net output #1: loss = 6938.21 (* 1 = 6938.21 loss)
I0823 12:41:37.058122  7716 sgd_solver.cpp:106] Iteration 10600, lr = 1e-07
I0823 12:42:39.600168  7716 solver.cpp:228] Iteration 10650, loss = 9078
I0823 12:42:39.600266  7716 solver.cpp:244]     Train net output #0: accuracy = 0.910529
I0823 12:42:39.600277  7716 solver.cpp:244]     Train net output #1: loss = 9078 (* 1 = 9078 loss)
I0823 12:42:39.600284  7716 sgd_solver.cpp:106] Iteration 10650, lr = 1e-07
I0823 12:43:42.138679  7716 solver.cpp:228] Iteration 10700, loss = 7966.95
I0823 12:43:42.138756  7716 solver.cpp:244]     Train net output #0: accuracy = 0.925246
I0823 12:43:42.138768  7716 solver.cpp:244]     Train net output #1: loss = 7966.95 (* 1 = 7966.95 loss)
I0823 12:43:42.138775  7716 sgd_solver.cpp:106] Iteration 10700, lr = 1e-07
I0823 12:44:44.690201  7716 solver.cpp:228] Iteration 10750, loss = 5674.34
I0823 12:44:44.690273  7716 solver.cpp:244]     Train net output #0: accuracy = 0.944311
I0823 12:44:44.690284  7716 solver.cpp:244]     Train net output #1: loss = 5674.34 (* 1 = 5674.34 loss)
I0823 12:44:44.690290  7716 sgd_solver.cpp:106] Iteration 10750, lr = 1e-07
I0823 12:45:46.378806  7716 solver.cpp:337] Iteration 10800, Testing net (#0)
I0823 12:45:54.843201  7716 solver.cpp:404]     Test net output #0: accuracy = 0.924146
I0823 12:45:54.843242  7716 solver.cpp:404]     Test net output #1: loss = 7852.85 (* 1 = 7852.85 loss)
I0823 12:45:55.747807  7716 solver.cpp:228] Iteration 10800, loss = 4328.13
I0823 12:45:55.747840  7716 solver.cpp:244]     Train net output #0: accuracy = 0.958657
I0823 12:45:55.747849  7716 solver.cpp:244]     Train net output #1: loss = 4328.13 (* 1 = 4328.13 loss)
I0823 12:45:55.747856  7716 sgd_solver.cpp:106] Iteration 10800, lr = 1e-07
I0823 12:46:58.292336  7716 solver.cpp:228] Iteration 10850, loss = 11056.9
I0823 12:46:58.292430  7716 solver.cpp:244]     Train net output #0: accuracy = 0.90083
I0823 12:46:58.292441  7716 solver.cpp:244]     Train net output #1: loss = 11056.9 (* 1 = 11056.9 loss)
I0823 12:46:58.292448  7716 sgd_solver.cpp:106] Iteration 10850, lr = 1e-07
I0823 12:48:00.879844  7716 solver.cpp:228] Iteration 10900, loss = 8463.1
I0823 12:48:00.879937  7716 solver.cpp:244]     Train net output #0: accuracy = 0.917363
I0823 12:48:00.879948  7716 solver.cpp:244]     Train net output #1: loss = 8463.1 (* 1 = 8463.1 loss)
I0823 12:48:00.879956  7716 sgd_solver.cpp:106] Iteration 10900, lr = 1e-07
I0823 12:49:03.422636  7716 solver.cpp:228] Iteration 10950, loss = 6585.82
I0823 12:49:03.422722  7716 solver.cpp:244]     Train net output #0: accuracy = 0.9359
I0823 12:49:03.422734  7716 solver.cpp:244]     Train net output #1: loss = 6585.82 (* 1 = 6585.82 loss)
I0823 12:49:03.422740  7716 sgd_solver.cpp:106] Iteration 10950, lr = 1e-07
I0823 12:50:05.114585  7716 solver.cpp:337] Iteration 11000, Testing net (#0)
I0823 12:50:13.682874  7716 solver.cpp:404]     Test net output #0: accuracy = 0.924285
I0823 12:50:13.682916  7716 solver.cpp:404]     Test net output #1: loss = 7819.84 (* 1 = 7819.84 loss)
I0823 12:50:14.588662  7716 solver.cpp:228] Iteration 11000, loss = 5088.76
I0823 12:50:14.588696  7716 solver.cpp:244]     Train net output #0: accuracy = 0.948767
I0823 12:50:14.588706  7716 solver.cpp:244]     Train net output #1: loss = 5088.76 (* 1 = 5088.76 loss)
I0823 12:50:14.588712  7716 sgd_solver.cpp:106] Iteration 11000, lr = 1e-07
I0823 12:51:17.128629  7716 solver.cpp:228] Iteration 11050, loss = 7139.14
I0823 12:51:17.128702  7716 solver.cpp:244]     Train net output #0: accuracy = 0.93047
I0823 12:51:17.128712  7716 solver.cpp:244]     Train net output #1: loss = 7139.14 (* 1 = 7139.14 loss)
I0823 12:51:17.128720  7716 sgd_solver.cpp:106] Iteration 11050, lr = 1e-07
I0823 12:52:19.682932  7716 solver.cpp:228] Iteration 11100, loss = 9576.1
I0823 12:52:19.683007  7716 solver.cpp:244]     Train net output #0: accuracy = 0.905491
I0823 12:52:19.683018  7716 solver.cpp:244]     Train net output #1: loss = 9576.1 (* 1 = 9576.1 loss)
I0823 12:52:19.683025  7716 sgd_solver.cpp:106] Iteration 11100, lr = 1e-07
I0823 12:53:22.234751  7716 solver.cpp:228] Iteration 11150, loss = 6710.18
I0823 12:53:22.234827  7716 solver.cpp:244]     Train net output #0: accuracy = 0.935273
I0823 12:53:22.234838  7716 solver.cpp:244]     Train net output #1: loss = 6710.18 (* 1 = 6710.18 loss)
I0823 12:53:22.234844  7716 sgd_solver.cpp:106] Iteration 11150, lr = 1e-07
I0823 12:54:23.892665  7716 solver.cpp:337] Iteration 11200, Testing net (#0)
I0823 12:54:32.380024  7716 solver.cpp:404]     Test net output #0: accuracy = 0.924989
I0823 12:54:32.380065  7716 solver.cpp:404]     Test net output #1: loss = 7766.01 (* 1 = 7766.01 loss)
I0823 12:54:33.285423  7716 solver.cpp:228] Iteration 11200, loss = 5314.13
I0823 12:54:33.285455  7716 solver.cpp:244]     Train net output #0: accuracy = 0.949009
I0823 12:54:33.285465  7716 solver.cpp:244]     Train net output #1: loss = 5314.13 (* 1 = 5314.13 loss)
I0823 12:54:33.285471  7716 sgd_solver.cpp:106] Iteration 11200, lr = 1e-07
I0823 12:55:35.880816  7716 solver.cpp:228] Iteration 11250, loss = 5051.84
I0823 12:55:35.880913  7716 solver.cpp:244]     Train net output #0: accuracy = 0.952685
I0823 12:55:35.880923  7716 solver.cpp:244]     Train net output #1: loss = 5051.84 (* 1 = 5051.84 loss)
I0823 12:55:35.880929  7716 sgd_solver.cpp:106] Iteration 11250, lr = 1e-07
I0823 12:56:38.420439  7716 solver.cpp:228] Iteration 11300, loss = 8939.06
I0823 12:56:38.420512  7716 solver.cpp:244]     Train net output #0: accuracy = 0.913909
I0823 12:56:38.420523  7716 solver.cpp:244]     Train net output #1: loss = 8939.06 (* 1 = 8939.06 loss)
I0823 12:56:38.420531  7716 sgd_solver.cpp:106] Iteration 11300, lr = 1e-07
I0823 12:57:40.981354  7716 solver.cpp:228] Iteration 11350, loss = 7522.64
I0823 12:57:40.981431  7716 solver.cpp:244]     Train net output #0: accuracy = 0.924299
I0823 12:57:40.981441  7716 solver.cpp:244]     Train net output #1: loss = 7522.64 (* 1 = 7522.64 loss)
I0823 12:57:40.981448  7716 sgd_solver.cpp:106] Iteration 11350, lr = 1e-07
I0823 12:58:42.604717  7716 solver.cpp:337] Iteration 11400, Testing net (#0)
I0823 12:58:51.058656  7716 solver.cpp:404]     Test net output #0: accuracy = 0.920363
I0823 12:58:51.058697  7716 solver.cpp:404]     Test net output #1: loss = 8219.81 (* 1 = 8219.81 loss)
I0823 12:58:51.963126  7716 solver.cpp:228] Iteration 11400, loss = 6138.15
I0823 12:58:51.963161  7716 solver.cpp:244]     Train net output #0: accuracy = 0.938765
I0823 12:58:51.963171  7716 solver.cpp:244]     Train net output #1: loss = 6138.15 (* 1 = 6138.15 loss)
I0823 12:58:51.963177  7716 sgd_solver.cpp:106] Iteration 11400, lr = 1e-07
I0823 12:59:54.522778  7716 solver.cpp:228] Iteration 11450, loss = 5326.85
I0823 12:59:54.522871  7716 solver.cpp:244]     Train net output #0: accuracy = 0.949036
I0823 12:59:54.522881  7716 solver.cpp:244]     Train net output #1: loss = 5326.85 (* 1 = 5326.85 loss)
I0823 12:59:54.522887  7716 sgd_solver.cpp:106] Iteration 11450, lr = 1e-07
I0823 13:00:57.110501  7716 solver.cpp:228] Iteration 11500, loss = 6792.46
I0823 13:00:57.110589  7716 solver.cpp:244]     Train net output #0: accuracy = 0.935979
I0823 13:00:57.110599  7716 solver.cpp:244]     Train net output #1: loss = 6792.46 (* 1 = 6792.46 loss)
I0823 13:00:57.110606  7716 sgd_solver.cpp:106] Iteration 11500, lr = 1e-07
I0823 13:01:59.698447  7716 solver.cpp:228] Iteration 11550, loss = 10215.6
I0823 13:01:59.698523  7716 solver.cpp:244]     Train net output #0: accuracy = 0.897322
I0823 13:01:59.698534  7716 solver.cpp:244]     Train net output #1: loss = 10215.6 (* 1 = 10215.6 loss)
I0823 13:01:59.698540  7716 sgd_solver.cpp:106] Iteration 11550, lr = 1e-07
I0823 13:03:01.355409  7716 solver.cpp:337] Iteration 11600, Testing net (#0)
I0823 13:03:09.807726  7716 solver.cpp:404]     Test net output #0: accuracy = 0.922542
I0823 13:03:09.807767  7716 solver.cpp:404]     Test net output #1: loss = 8001.82 (* 1 = 8001.82 loss)
I0823 13:03:10.715822  7716 solver.cpp:228] Iteration 11600, loss = 6879.54
I0823 13:03:10.715857  7716 solver.cpp:244]     Train net output #0: accuracy = 0.932777
I0823 13:03:10.715865  7716 solver.cpp:244]     Train net output #1: loss = 6879.54 (* 1 = 6879.54 loss)
I0823 13:03:10.715881  7716 sgd_solver.cpp:106] Iteration 11600, lr = 1e-07
I0823 13:04:13.257133  7716 solver.cpp:228] Iteration 11650, loss = 5030.26
I0823 13:04:13.257254  7716 solver.cpp:244]     Train net output #0: accuracy = 0.951963
I0823 13:04:13.257266  7716 solver.cpp:244]     Train net output #1: loss = 5030.26 (* 1 = 5030.26 loss)
I0823 13:04:13.257272  7716 sgd_solver.cpp:106] Iteration 11650, lr = 1e-07
I0823 13:05:15.859803  7716 solver.cpp:228] Iteration 11700, loss = 4645.56
I0823 13:05:15.859899  7716 solver.cpp:244]     Train net output #0: accuracy = 0.954113
I0823 13:05:15.859910  7716 solver.cpp:244]     Train net output #1: loss = 4645.56 (* 1 = 4645.56 loss)
I0823 13:05:15.859917  7716 sgd_solver.cpp:106] Iteration 11700, lr = 1e-07
I0823 13:06:18.399407  7716 solver.cpp:228] Iteration 11750, loss = 9437.75
I0823 13:06:18.399453  7716 solver.cpp:244]     Train net output #0: accuracy = 0.909823
I0823 13:06:18.399463  7716 solver.cpp:244]     Train net output #1: loss = 9437.75 (* 1 = 9437.75 loss)
I0823 13:06:18.399471  7716 sgd_solver.cpp:106] Iteration 11750, lr = 1e-07
I0823 13:07:20.065255  7716 solver.cpp:337] Iteration 11800, Testing net (#0)
I0823 13:07:28.531437  7716 solver.cpp:404]     Test net output #0: accuracy = 0.924258
I0823 13:07:28.531476  7716 solver.cpp:404]     Test net output #1: loss = 7831 (* 1 = 7831 loss)
I0823 13:07:29.440981  7716 solver.cpp:228] Iteration 11800, loss = 8664.27
I0823 13:07:29.441015  7716 solver.cpp:244]     Train net output #0: accuracy = 0.914266
I0823 13:07:29.441025  7716 solver.cpp:244]     Train net output #1: loss = 8664.27 (* 1 = 8664.27 loss)
I0823 13:07:29.441031  7716 sgd_solver.cpp:106] Iteration 11800, lr = 1e-07
I0823 13:08:31.958385  7716 solver.cpp:228] Iteration 11850, loss = 10130.5
I0823 13:08:31.958478  7716 solver.cpp:244]     Train net output #0: accuracy = 0.904897
I0823 13:08:31.958489  7716 solver.cpp:244]     Train net output #1: loss = 10130.5 (* 1 = 10130.5 loss)
I0823 13:08:31.958497  7716 sgd_solver.cpp:106] Iteration 11850, lr = 1e-07
I0823 13:09:34.519197  7716 solver.cpp:228] Iteration 11900, loss = 5256.77
I0823 13:09:34.519244  7716 solver.cpp:244]     Train net output #0: accuracy = 0.947845
I0823 13:09:34.519253  7716 solver.cpp:244]     Train net output #1: loss = 5256.77 (* 1 = 5256.77 loss)
I0823 13:09:34.519260  7716 sgd_solver.cpp:106] Iteration 11900, lr = 1e-07
I0823 13:10:37.079111  7716 solver.cpp:228] Iteration 11950, loss = 4837.11
I0823 13:10:37.079192  7716 solver.cpp:244]     Train net output #0: accuracy = 0.951989
I0823 13:10:37.079205  7716 solver.cpp:244]     Train net output #1: loss = 4837.11 (* 1 = 4837.11 loss)
I0823 13:10:37.079210  7716 sgd_solver.cpp:106] Iteration 11950, lr = 1e-07
I0823 13:11:38.786897  7716 solver.cpp:454] Snapshotting to binary proto file portrait_one_stage_iter_12000.caffemodel
I0823 13:11:38.790192  7716 sgd_solver.cpp:273] Snapshotting solver state to binary proto file portrait_one_stage_iter_12000.solverstate
I0823 13:11:38.791442  7716 solver.cpp:337] Iteration 12000, Testing net (#0)
I0823 13:11:47.241641  7716 solver.cpp:404]     Test net output #0: accuracy = 0.925104
I0823 13:11:47.241681  7716 solver.cpp:404]     Test net output #1: loss = 7734.63 (* 1 = 7734.63 loss)
I0823 13:11:48.150856  7716 solver.cpp:228] Iteration 12000, loss = 8792.1
I0823 13:11:48.150890  7716 solver.cpp:244]     Train net output #0: accuracy = 0.910723
I0823 13:11:48.150900  7716 solver.cpp:244]     Train net output #1: loss = 8792.1 (* 1 = 8792.1 loss)
I0823 13:11:48.150908  7716 sgd_solver.cpp:106] Iteration 12000, lr = 1e-08
I0823 13:12:50.695727  7716 solver.cpp:228] Iteration 12050, loss = 6338.32
I0823 13:12:50.695823  7716 solver.cpp:244]     Train net output #0: accuracy = 0.939051
I0823 13:12:50.695834  7716 solver.cpp:244]     Train net output #1: loss = 6338.32 (* 1 = 6338.32 loss)
I0823 13:12:50.695842  7716 sgd_solver.cpp:106] Iteration 12050, lr = 1e-08
I0823 13:13:53.234846  7716 solver.cpp:228] Iteration 12100, loss = 5021.56
I0823 13:13:53.234953  7716 solver.cpp:244]     Train net output #0: accuracy = 0.950808
I0823 13:13:53.234966  7716 solver.cpp:244]     Train net output #1: loss = 5021.56 (* 1 = 5021.56 loss)
I0823 13:13:53.234972  7716 sgd_solver.cpp:106] Iteration 12100, lr = 1e-08
I0823 13:14:55.819857  7716 solver.cpp:228] Iteration 12150, loss = 4562.88
I0823 13:14:55.819908  7716 solver.cpp:244]     Train net output #0: accuracy = 0.956088
I0823 13:14:55.819918  7716 solver.cpp:244]     Train net output #1: loss = 4562.88 (* 1 = 4562.88 loss)
I0823 13:14:55.819926  7716 sgd_solver.cpp:106] Iteration 12150, lr = 1e-08
I0823 13:15:57.457674  7716 solver.cpp:337] Iteration 12200, Testing net (#0)
I0823 13:16:05.910815  7716 solver.cpp:404]     Test net output #0: accuracy = 0.924174
I0823 13:16:05.910867  7716 solver.cpp:404]     Test net output #1: loss = 7832.34 (* 1 = 7832.34 loss)
I0823 13:16:06.827105  7716 solver.cpp:228] Iteration 12200, loss = 7460.83
I0823 13:16:06.827142  7716 solver.cpp:244]     Train net output #0: accuracy = 0.927447
I0823 13:16:06.827150  7716 solver.cpp:244]     Train net output #1: loss = 7460.83 (* 1 = 7460.83 loss)
I0823 13:16:06.827158  7716 sgd_solver.cpp:106] Iteration 12200, lr = 1e-08
I0823 13:17:09.384567  7716 solver.cpp:228] Iteration 12250, loss = 7681.27
I0823 13:17:09.384657  7716 solver.cpp:244]     Train net output #0: accuracy = 0.923944
I0823 13:17:09.384668  7716 solver.cpp:244]     Train net output #1: loss = 7681.27 (* 1 = 7681.27 loss)
I0823 13:17:09.384675  7716 sgd_solver.cpp:106] Iteration 12250, lr = 1e-08
I0823 13:18:11.954422  7716 solver.cpp:228] Iteration 12300, loss = 10283.2
I0823 13:18:11.954509  7716 solver.cpp:244]     Train net output #0: accuracy = 0.900597
I0823 13:18:11.954519  7716 solver.cpp:244]     Train net output #1: loss = 10283.2 (* 1 = 10283.2 loss)
I0823 13:18:11.954527  7716 sgd_solver.cpp:106] Iteration 12300, lr = 1e-08
I0823 13:19:15.151154  7716 solver.cpp:228] Iteration 12350, loss = 4708.12
I0823 13:19:15.151231  7716 solver.cpp:244]     Train net output #0: accuracy = 0.953415
I0823 13:19:15.151242  7716 solver.cpp:244]     Train net output #1: loss = 4708.12 (* 1 = 4708.12 loss)
I0823 13:19:15.151249  7716 sgd_solver.cpp:106] Iteration 12350, lr = 1e-08
I0823 13:20:16.930905  7716 solver.cpp:337] Iteration 12400, Testing net (#0)
I0823 13:20:25.441972  7716 solver.cpp:404]     Test net output #0: accuracy = 0.919219
I0823 13:20:25.442010  7716 solver.cpp:404]     Test net output #1: loss = 8321.26 (* 1 = 8321.26 loss)
I0823 13:20:26.349042  7716 solver.cpp:228] Iteration 12400, loss = 5648.98
I0823 13:20:26.349074  7716 solver.cpp:244]     Train net output #0: accuracy = 0.946671
I0823 13:20:26.349084  7716 solver.cpp:244]     Train net output #1: loss = 5648.98 (* 1 = 5648.98 loss)
I0823 13:20:26.349102  7716 sgd_solver.cpp:106] Iteration 12400, lr = 1e-08
I0823 13:21:28.980937  7716 solver.cpp:228] Iteration 12450, loss = 8701.5
I0823 13:21:28.981009  7716 solver.cpp:244]     Train net output #0: accuracy = 0.912305
I0823 13:21:28.981020  7716 solver.cpp:244]     Train net output #1: loss = 8701.5 (* 1 = 8701.5 loss)
I0823 13:21:28.981029  7716 sgd_solver.cpp:106] Iteration 12450, lr = 1e-08
I0823 13:22:31.646291  7716 solver.cpp:228] Iteration 12500, loss = 6522.85
I0823 13:22:31.646384  7716 solver.cpp:244]     Train net output #0: accuracy = 0.936939
I0823 13:22:31.646395  7716 solver.cpp:244]     Train net output #1: loss = 6522.85 (* 1 = 6522.85 loss)
I0823 13:22:31.646404  7716 sgd_solver.cpp:106] Iteration 12500, lr = 1e-08
I0823 13:23:34.257652  7716 solver.cpp:228] Iteration 12550, loss = 5010.64
I0823 13:23:34.257731  7716 solver.cpp:244]     Train net output #0: accuracy = 0.952238
I0823 13:23:34.257743  7716 solver.cpp:244]     Train net output #1: loss = 5010.64 (* 1 = 5010.64 loss)
I0823 13:23:34.257750  7716 sgd_solver.cpp:106] Iteration 12550, lr = 1e-08
I0823 13:24:35.998433  7716 solver.cpp:337] Iteration 12600, Testing net (#0)
I0823 13:24:44.484726  7716 solver.cpp:404]     Test net output #0: accuracy = 0.92209
I0823 13:24:44.484776  7716 solver.cpp:404]     Test net output #1: loss = 8048.19 (* 1 = 8048.19 loss)
I0823 13:24:45.390935  7716 solver.cpp:228] Iteration 12600, loss = 4938.88
I0823 13:24:45.390966  7716 solver.cpp:244]     Train net output #0: accuracy = 0.953834
I0823 13:24:45.390975  7716 solver.cpp:244]     Train net output #1: loss = 4938.88 (* 1 = 4938.88 loss)
I0823 13:24:45.390982  7716 sgd_solver.cpp:106] Iteration 12600, lr = 1e-08
I0823 13:25:48.180948  7716 solver.cpp:228] Iteration 12650, loss = 4589.44
I0823 13:25:48.181046  7716 solver.cpp:244]     Train net output #0: accuracy = 0.955836
I0823 13:25:48.181057  7716 solver.cpp:244]     Train net output #1: loss = 4589.44 (* 1 = 4589.44 loss)
I0823 13:25:48.181066  7716 sgd_solver.cpp:106] Iteration 12650, lr = 1e-08
I0823 13:26:51.016435  7716 solver.cpp:228] Iteration 12700, loss = 8059.42
I0823 13:26:51.016530  7716 solver.cpp:244]     Train net output #0: accuracy = 0.919759
I0823 13:26:51.016541  7716 solver.cpp:244]     Train net output #1: loss = 8059.42 (* 1 = 8059.42 loss)
I0823 13:26:51.016548  7716 sgd_solver.cpp:106] Iteration 12700, lr = 1e-08
I0823 13:27:53.719537  7716 solver.cpp:228] Iteration 12750, loss = 11206.2
I0823 13:27:53.719614  7716 solver.cpp:244]     Train net output #0: accuracy = 0.890484
I0823 13:27:53.719625  7716 solver.cpp:244]     Train net output #1: loss = 11206.2 (* 1 = 11206.2 loss)
I0823 13:27:53.719632  7716 sgd_solver.cpp:106] Iteration 12750, lr = 1e-08
I0823 13:28:55.551718  7716 solver.cpp:337] Iteration 12800, Testing net (#0)
I0823 13:29:04.065587  7716 solver.cpp:404]     Test net output #0: accuracy = 0.924452
I0823 13:29:04.065625  7716 solver.cpp:404]     Test net output #1: loss = 7807.12 (* 1 = 7807.12 loss)
I0823 13:29:04.972386  7716 solver.cpp:228] Iteration 12800, loss = 4555.94
I0823 13:29:04.972415  7716 solver.cpp:244]     Train net output #0: accuracy = 0.95555
I0823 13:29:04.972424  7716 solver.cpp:244]     Train net output #1: loss = 4555.94 (* 1 = 4555.94 loss)
I0823 13:29:04.972432  7716 sgd_solver.cpp:106] Iteration 12800, lr = 1e-08
I0823 13:30:07.696768  7716 solver.cpp:228] Iteration 12850, loss = 5303.84
I0823 13:30:07.696864  7716 solver.cpp:244]     Train net output #0: accuracy = 0.948765
I0823 13:30:07.696876  7716 solver.cpp:244]     Train net output #1: loss = 5303.84 (* 1 = 5303.84 loss)
I0823 13:30:07.696882  7716 sgd_solver.cpp:106] Iteration 12850, lr = 1e-08
I0823 13:31:10.567445  7716 solver.cpp:228] Iteration 12900, loss = 9568.1
I0823 13:31:10.567517  7716 solver.cpp:244]     Train net output #0: accuracy = 0.906548
I0823 13:31:10.567528  7716 solver.cpp:244]     Train net output #1: loss = 9568.1 (* 1 = 9568.1 loss)
I0823 13:31:10.567536  7716 sgd_solver.cpp:106] Iteration 12900, lr = 1e-08
I0823 13:32:13.249867  7716 solver.cpp:228] Iteration 12950, loss = 6854.91
I0823 13:32:13.249912  7716 solver.cpp:244]     Train net output #0: accuracy = 0.934555
I0823 13:32:13.249922  7716 solver.cpp:244]     Train net output #1: loss = 6854.91 (* 1 = 6854.91 loss)
I0823 13:32:13.249929  7716 sgd_solver.cpp:106] Iteration 12950, lr = 1e-08
I0823 13:33:14.980550  7716 solver.cpp:337] Iteration 13000, Testing net (#0)
I0823 13:33:23.507190  7716 solver.cpp:404]     Test net output #0: accuracy = 0.924951
I0823 13:33:23.507228  7716 solver.cpp:404]     Test net output #1: loss = 7749 (* 1 = 7749 loss)
I0823 13:33:24.418455  7716 solver.cpp:228] Iteration 13000, loss = 8612.42
I0823 13:33:24.418486  7716 solver.cpp:244]     Train net output #0: accuracy = 0.915018
I0823 13:33:24.418495  7716 solver.cpp:244]     Train net output #1: loss = 8612.42 (* 1 = 8612.42 loss)
I0823 13:33:24.418503  7716 sgd_solver.cpp:106] Iteration 13000, lr = 1e-08
I0823 13:34:27.059784  7716 solver.cpp:228] Iteration 13050, loss = 4674.8
I0823 13:34:27.059878  7716 solver.cpp:244]     Train net output #0: accuracy = 0.955179
I0823 13:34:27.059890  7716 solver.cpp:244]     Train net output #1: loss = 4674.8 (* 1 = 4674.8 loss)
I0823 13:34:27.059897  7716 sgd_solver.cpp:106] Iteration 13050, lr = 1e-08
I0823 13:35:29.620586  7716 solver.cpp:228] Iteration 13100, loss = 5263.52
I0823 13:35:29.620702  7716 solver.cpp:244]     Train net output #0: accuracy = 0.949388
I0823 13:35:29.620714  7716 solver.cpp:244]     Train net output #1: loss = 5263.52 (* 1 = 5263.52 loss)
I0823 13:35:29.620721  7716 sgd_solver.cpp:106] Iteration 13100, lr = 1e-08
I0823 13:36:32.208153  7716 solver.cpp:228] Iteration 13150, loss = 7559.07
I0823 13:36:32.208235  7716 solver.cpp:244]     Train net output #0: accuracy = 0.92624
I0823 13:36:32.208246  7716 solver.cpp:244]     Train net output #1: loss = 7559.07 (* 1 = 7559.07 loss)
I0823 13:36:32.208253  7716 sgd_solver.cpp:106] Iteration 13150, lr = 1e-08
I0823 13:37:33.836370  7716 solver.cpp:337] Iteration 13200, Testing net (#0)
I0823 13:37:42.294553  7716 solver.cpp:404]     Test net output #0: accuracy = 0.924082
I0823 13:37:42.294591  7716 solver.cpp:404]     Test net output #1: loss = 7841.95 (* 1 = 7841.95 loss)
I0823 13:37:43.203132  7716 solver.cpp:228] Iteration 13200, loss = 10860.9
I0823 13:37:43.203166  7716 solver.cpp:244]     Train net output #0: accuracy = 0.892239
I0823 13:37:43.203176  7716 solver.cpp:244]     Train net output #1: loss = 10860.9 (* 1 = 10860.9 loss)
I0823 13:37:43.203182  7716 sgd_solver.cpp:106] Iteration 13200, lr = 1e-08
I0823 13:38:45.795418  7716 solver.cpp:228] Iteration 13250, loss = 4428.15
I0823 13:38:45.795509  7716 solver.cpp:244]     Train net output #0: accuracy = 0.957689
I0823 13:38:45.795521  7716 solver.cpp:244]     Train net output #1: loss = 4428.15 (* 1 = 4428.15 loss)
I0823 13:38:45.795527  7716 sgd_solver.cpp:106] Iteration 13250, lr = 1e-08
I0823 13:39:48.352303  7716 solver.cpp:228] Iteration 13300, loss = 6006.32
I0823 13:39:48.352397  7716 solver.cpp:244]     Train net output #0: accuracy = 0.944345
I0823 13:39:48.352407  7716 solver.cpp:244]     Train net output #1: loss = 6006.32 (* 1 = 6006.32 loss)
I0823 13:39:48.352416  7716 sgd_solver.cpp:106] Iteration 13300, lr = 1e-08
I0823 13:40:50.960500  7716 solver.cpp:228] Iteration 13350, loss = 7469.06
I0823 13:40:50.960592  7716 solver.cpp:244]     Train net output #0: accuracy = 0.933827
I0823 13:40:50.960603  7716 solver.cpp:244]     Train net output #1: loss = 7469.06 (* 1 = 7469.06 loss)
I0823 13:40:50.960610  7716 sgd_solver.cpp:106] Iteration 13350, lr = 1e-08
I0823 13:41:52.603746  7716 solver.cpp:337] Iteration 13400, Testing net (#0)
I0823 13:42:01.072296  7716 solver.cpp:404]     Test net output #0: accuracy = 0.919236
I0823 13:42:01.072335  7716 solver.cpp:404]     Test net output #1: loss = 8320.68 (* 1 = 8320.68 loss)
I0823 13:42:01.981240  7716 solver.cpp:228] Iteration 13400, loss = 8536.93
I0823 13:42:01.981271  7716 solver.cpp:244]     Train net output #0: accuracy = 0.91698
I0823 13:42:01.981279  7716 solver.cpp:244]     Train net output #1: loss = 8536.93 (* 1 = 8536.93 loss)
I0823 13:42:01.981287  7716 sgd_solver.cpp:106] Iteration 13400, lr = 1e-08
I0823 13:43:04.531672  7716 solver.cpp:228] Iteration 13450, loss = 9917.32
I0823 13:43:04.531759  7716 solver.cpp:244]     Train net output #0: accuracy = 0.903426
I0823 13:43:04.531769  7716 solver.cpp:244]     Train net output #1: loss = 9917.32 (* 1 = 9917.32 loss)
I0823 13:43:04.531776  7716 sgd_solver.cpp:106] Iteration 13450, lr = 1e-08
I0823 13:44:07.141515  7716 solver.cpp:228] Iteration 13500, loss = 4512.47
I0823 13:44:07.141602  7716 solver.cpp:244]     Train net output #0: accuracy = 0.956905
I0823 13:44:07.141613  7716 solver.cpp:244]     Train net output #1: loss = 4512.47 (* 1 = 4512.47 loss)
I0823 13:44:07.141621  7716 sgd_solver.cpp:106] Iteration 13500, lr = 1e-08
I0823 13:45:09.792994  7716 solver.cpp:228] Iteration 13550, loss = 5160.46
I0823 13:45:09.793079  7716 solver.cpp:244]     Train net output #0: accuracy = 0.949367
I0823 13:45:09.793090  7716 solver.cpp:244]     Train net output #1: loss = 5160.46 (* 1 = 5160.46 loss)
I0823 13:45:09.793097  7716 sgd_solver.cpp:106] Iteration 13550, lr = 1e-08
I0823 13:46:11.600730  7716 solver.cpp:337] Iteration 13600, Testing net (#0)
I0823 13:46:20.092593  7716 solver.cpp:404]     Test net output #0: accuracy = 0.921871
I0823 13:46:20.092627  7716 solver.cpp:404]     Test net output #1: loss = 8072.39 (* 1 = 8072.39 loss)
I0823 13:46:21.003034  7716 solver.cpp:228] Iteration 13600, loss = 7730.2
I0823 13:46:21.003062  7716 solver.cpp:244]     Train net output #0: accuracy = 0.92399
I0823 13:46:21.003070  7716 solver.cpp:244]     Train net output #1: loss = 7730.2 (* 1 = 7730.2 loss)
I0823 13:46:21.003077  7716 sgd_solver.cpp:106] Iteration 13600, lr = 1e-08
I0823 13:47:23.556834  7716 solver.cpp:228] Iteration 13650, loss = 10478.2
I0823 13:47:23.556920  7716 solver.cpp:244]     Train net output #0: accuracy = 0.898934
I0823 13:47:23.556931  7716 solver.cpp:244]     Train net output #1: loss = 10478.2 (* 1 = 10478.2 loss)
I0823 13:47:23.556939  7716 sgd_solver.cpp:106] Iteration 13650, lr = 1e-08
I0823 13:48:26.144968  7716 solver.cpp:228] Iteration 13700, loss = 5197.07
I0823 13:48:26.145040  7716 solver.cpp:244]     Train net output #0: accuracy = 0.949945
I0823 13:48:26.145051  7716 solver.cpp:244]     Train net output #1: loss = 5197.07 (* 1 = 5197.07 loss)
I0823 13:48:26.145057  7716 sgd_solver.cpp:106] Iteration 13700, lr = 1e-08
I0823 13:49:28.691370  7716 solver.cpp:228] Iteration 13750, loss = 5235.21
I0823 13:49:28.691460  7716 solver.cpp:244]     Train net output #0: accuracy = 0.949007
I0823 13:49:28.691470  7716 solver.cpp:244]     Train net output #1: loss = 5235.21 (* 1 = 5235.21 loss)
I0823 13:49:28.691478  7716 sgd_solver.cpp:106] Iteration 13750, lr = 1e-08
I0823 13:50:30.348817  7716 solver.cpp:337] Iteration 13800, Testing net (#0)
I0823 13:50:38.803500  7716 solver.cpp:404]     Test net output #0: accuracy = 0.923681
I0823 13:50:38.803544  7716 solver.cpp:404]     Test net output #1: loss = 7881.98 (* 1 = 7881.98 loss)
I0823 13:50:39.708554  7716 solver.cpp:228] Iteration 13800, loss = 5116.93
I0823 13:50:39.708588  7716 solver.cpp:244]     Train net output #0: accuracy = 0.949651
I0823 13:50:39.708596  7716 solver.cpp:244]     Train net output #1: loss = 5116.93 (* 1 = 5116.93 loss)
I0823 13:50:39.708605  7716 sgd_solver.cpp:106] Iteration 13800, lr = 1e-08
I0823 13:51:42.227108  7716 solver.cpp:228] Iteration 13850, loss = 7519.99
I0823 13:51:42.227156  7716 solver.cpp:244]     Train net output #0: accuracy = 0.929693
I0823 13:51:42.227166  7716 solver.cpp:244]     Train net output #1: loss = 7519.99 (* 1 = 7519.99 loss)
I0823 13:51:42.227174  7716 sgd_solver.cpp:106] Iteration 13850, lr = 1e-08
I0823 13:52:44.758221  7716 solver.cpp:228] Iteration 13900, loss = 8975.23
I0823 13:52:44.758318  7716 solver.cpp:244]     Train net output #0: accuracy = 0.909189
I0823 13:52:44.758329  7716 solver.cpp:244]     Train net output #1: loss = 8975.23 (* 1 = 8975.23 loss)
I0823 13:52:44.758337  7716 sgd_solver.cpp:106] Iteration 13900, lr = 1e-08
I0823 13:53:47.308049  7716 solver.cpp:228] Iteration 13950, loss = 4757.97
I0823 13:53:47.308122  7716 solver.cpp:244]     Train net output #0: accuracy = 0.955893
I0823 13:53:47.308133  7716 solver.cpp:244]     Train net output #1: loss = 4757.97 (* 1 = 4757.97 loss)
I0823 13:53:47.308141  7716 sgd_solver.cpp:106] Iteration 13950, lr = 1e-08
I0823 13:54:48.927865  7716 solver.cpp:337] Iteration 14000, Testing net (#0)
I0823 13:54:57.377130  7716 solver.cpp:404]     Test net output #0: accuracy = 0.925539
I0823 13:54:57.377171  7716 solver.cpp:404]     Test net output #1: loss = 7694.44 (* 1 = 7694.44 loss)
I0823 13:54:58.281867  7716 solver.cpp:228] Iteration 14000, loss = 4558.43
I0823 13:54:58.281900  7716 solver.cpp:244]     Train net output #0: accuracy = 0.955216
I0823 13:54:58.281910  7716 solver.cpp:244]     Train net output #1: loss = 4558.43 (* 1 = 4558.43 loss)
I0823 13:54:58.281918  7716 sgd_solver.cpp:106] Iteration 14000, lr = 1e-08
I0823 13:56:00.850479  7716 solver.cpp:228] Iteration 14050, loss = 8112.6
I0823 13:56:00.850572  7716 solver.cpp:244]     Train net output #0: accuracy = 0.919927
I0823 13:56:00.850584  7716 solver.cpp:244]     Train net output #1: loss = 8112.6 (* 1 = 8112.6 loss)
I0823 13:56:00.850602  7716 sgd_solver.cpp:106] Iteration 14050, lr = 1e-08
I0823 13:57:03.372462  7716 solver.cpp:228] Iteration 14100, loss = 9024.07
I0823 13:57:03.372576  7716 solver.cpp:244]     Train net output #0: accuracy = 0.916464
I0823 13:57:03.372587  7716 solver.cpp:244]     Train net output #1: loss = 9024.07 (* 1 = 9024.07 loss)
I0823 13:57:03.372594  7716 sgd_solver.cpp:106] Iteration 14100, lr = 1e-08
I0823 13:58:05.988603  7716 solver.cpp:228] Iteration 14150, loss = 8133.21
I0823 13:58:05.988706  7716 solver.cpp:244]     Train net output #0: accuracy = 0.920218
I0823 13:58:05.988718  7716 solver.cpp:244]     Train net output #1: loss = 8133.21 (* 1 = 8133.21 loss)
I0823 13:58:05.988725  7716 sgd_solver.cpp:106] Iteration 14150, lr = 1e-08
I0823 13:59:07.645098  7716 solver.cpp:337] Iteration 14200, Testing net (#0)
I0823 13:59:16.099777  7716 solver.cpp:404]     Test net output #0: accuracy = 0.923646
I0823 13:59:16.099815  7716 solver.cpp:404]     Test net output #1: loss = 7881.97 (* 1 = 7881.97 loss)
I0823 13:59:17.004439  7716 solver.cpp:228] Iteration 14200, loss = 5459.33
I0823 13:59:17.004473  7716 solver.cpp:244]     Train net output #0: accuracy = 0.946039
I0823 13:59:17.004482  7716 solver.cpp:244]     Train net output #1: loss = 5459.33 (* 1 = 5459.33 loss)
I0823 13:59:17.004489  7716 sgd_solver.cpp:106] Iteration 14200, lr = 1e-08
I0823 14:00:19.575136  7716 solver.cpp:228] Iteration 14250, loss = 5219.74
I0823 14:00:19.575211  7716 solver.cpp:244]     Train net output #0: accuracy = 0.950315
I0823 14:00:19.575220  7716 solver.cpp:244]     Train net output #1: loss = 5219.74 (* 1 = 5219.74 loss)
I0823 14:00:19.575228  7716 sgd_solver.cpp:106] Iteration 14250, lr = 1e-08
I0823 14:01:22.110641  7716 solver.cpp:228] Iteration 14300, loss = 6780.39
I0823 14:01:22.110689  7716 solver.cpp:244]     Train net output #0: accuracy = 0.936323
I0823 14:01:22.110699  7716 solver.cpp:244]     Train net output #1: loss = 6780.39 (* 1 = 6780.39 loss)
I0823 14:01:22.110707  7716 sgd_solver.cpp:106] Iteration 14300, lr = 1e-08
I0823 14:02:24.650806  7716 solver.cpp:228] Iteration 14350, loss = 9838.75
I0823 14:02:24.650882  7716 solver.cpp:244]     Train net output #0: accuracy = 0.903365
I0823 14:02:24.650892  7716 solver.cpp:244]     Train net output #1: loss = 9838.75 (* 1 = 9838.75 loss)
I0823 14:02:24.650899  7716 sgd_solver.cpp:106] Iteration 14350, lr = 1e-08
I0823 14:03:26.340708  7716 solver.cpp:337] Iteration 14400, Testing net (#0)
I0823 14:03:34.795066  7716 solver.cpp:404]     Test net output #0: accuracy = 0.919724
I0823 14:03:34.795109  7716 solver.cpp:404]     Test net output #1: loss = 8272.85 (* 1 = 8272.85 loss)
I0823 14:03:35.699007  7716 solver.cpp:228] Iteration 14400, loss = 5119.71
I0823 14:03:35.699040  7716 solver.cpp:244]     Train net output #0: accuracy = 0.953062
I0823 14:03:35.699050  7716 solver.cpp:244]     Train net output #1: loss = 5119.71 (* 1 = 5119.71 loss)
I0823 14:03:35.699057  7716 sgd_solver.cpp:106] Iteration 14400, lr = 1e-08
I0823 14:04:38.251621  7716 solver.cpp:228] Iteration 14450, loss = 4924.71
I0823 14:04:38.251693  7716 solver.cpp:244]     Train net output #0: accuracy = 0.951072
I0823 14:04:38.251703  7716 solver.cpp:244]     Train net output #1: loss = 4924.71 (* 1 = 4924.71 loss)
I0823 14:04:38.251711  7716 sgd_solver.cpp:106] Iteration 14450, lr = 1e-08
I0823 14:05:40.855068  7716 solver.cpp:228] Iteration 14500, loss = 7187.87
I0823 14:05:40.855167  7716 solver.cpp:244]     Train net output #0: accuracy = 0.931577
I0823 14:05:40.855178  7716 solver.cpp:244]     Train net output #1: loss = 7187.87 (* 1 = 7187.87 loss)
I0823 14:05:40.855186  7716 sgd_solver.cpp:106] Iteration 14500, lr = 1e-08
I0823 14:06:43.369340  7716 solver.cpp:228] Iteration 14550, loss = 9406.19
I0823 14:06:43.369415  7716 solver.cpp:244]     Train net output #0: accuracy = 0.909222
I0823 14:06:43.369426  7716 solver.cpp:244]     Train net output #1: loss = 9406.19 (* 1 = 9406.19 loss)
I0823 14:06:43.369432  7716 sgd_solver.cpp:106] Iteration 14550, lr = 1e-08
I0823 14:07:45.009654  7716 solver.cpp:337] Iteration 14600, Testing net (#0)
I0823 14:07:53.464864  7716 solver.cpp:404]     Test net output #0: accuracy = 0.921659
I0823 14:07:53.464905  7716 solver.cpp:404]     Test net output #1: loss = 8096.04 (* 1 = 8096.04 loss)
I0823 14:07:54.374189  7716 solver.cpp:228] Iteration 14600, loss = 7637.47
I0823 14:07:54.374222  7716 solver.cpp:244]     Train net output #0: accuracy = 0.92545
I0823 14:07:54.374231  7716 solver.cpp:244]     Train net output #1: loss = 7637.47 (* 1 = 7637.47 loss)
I0823 14:07:54.374239  7716 sgd_solver.cpp:106] Iteration 14600, lr = 1e-08
I0823 14:08:56.930198  7716 solver.cpp:228] Iteration 14650, loss = 7042.22
I0823 14:08:56.930284  7716 solver.cpp:244]     Train net output #0: accuracy = 0.932905
I0823 14:08:56.930294  7716 solver.cpp:244]     Train net output #1: loss = 7042.22 (* 1 = 7042.22 loss)
I0823 14:08:56.930301  7716 sgd_solver.cpp:106] Iteration 14650, lr = 1e-08
I0823 14:09:59.540711  7716 solver.cpp:228] Iteration 14700, loss = 4793.69
I0823 14:09:59.540793  7716 solver.cpp:244]     Train net output #0: accuracy = 0.954536
I0823 14:09:59.540804  7716 solver.cpp:244]     Train net output #1: loss = 4793.69 (* 1 = 4793.69 loss)
I0823 14:09:59.540812  7716 sgd_solver.cpp:106] Iteration 14700, lr = 1e-08
I0823 14:11:02.149634  7716 solver.cpp:228] Iteration 14750, loss = 7328.16
I0823 14:11:02.149732  7716 solver.cpp:244]     Train net output #0: accuracy = 0.929303
I0823 14:11:02.149744  7716 solver.cpp:244]     Train net output #1: loss = 7328.16 (* 1 = 7328.16 loss)
I0823 14:11:02.149751  7716 sgd_solver.cpp:106] Iteration 14750, lr = 1e-08
I0823 14:12:03.795522  7716 solver.cpp:337] Iteration 14800, Testing net (#0)
I0823 14:12:12.251085  7716 solver.cpp:404]     Test net output #0: accuracy = 0.922828
I0823 14:12:12.251123  7716 solver.cpp:404]     Test net output #1: loss = 7964.36 (* 1 = 7964.36 loss)
I0823 14:12:13.160552  7716 solver.cpp:228] Iteration 14800, loss = 9470.61
I0823 14:12:13.160585  7716 solver.cpp:244]     Train net output #0: accuracy = 0.904412
I0823 14:12:13.160594  7716 solver.cpp:244]     Train net output #1: loss = 9470.61 (* 1 = 9470.61 loss)
I0823 14:12:13.160603  7716 sgd_solver.cpp:106] Iteration 14800, lr = 1e-08
I0823 14:13:15.718439  7716 solver.cpp:228] Iteration 14850, loss = 4896.89
I0823 14:13:15.718514  7716 solver.cpp:244]     Train net output #0: accuracy = 0.952054
I0823 14:13:15.718524  7716 solver.cpp:244]     Train net output #1: loss = 4896.89 (* 1 = 4896.89 loss)
I0823 14:13:15.718531  7716 sgd_solver.cpp:106] Iteration 14850, lr = 1e-08
I0823 14:14:18.345363  7716 solver.cpp:228] Iteration 14900, loss = 5433.65
I0823 14:14:18.345450  7716 solver.cpp:244]     Train net output #0: accuracy = 0.948704
I0823 14:14:18.345461  7716 solver.cpp:244]     Train net output #1: loss = 5433.65 (* 1 = 5433.65 loss)
I0823 14:14:18.345469  7716 sgd_solver.cpp:106] Iteration 14900, lr = 1e-08
I0823 14:15:20.968935  7716 solver.cpp:228] Iteration 14950, loss = 4215.83
I0823 14:15:20.969033  7716 solver.cpp:244]     Train net output #0: accuracy = 0.957506
I0823 14:15:20.969043  7716 solver.cpp:244]     Train net output #1: loss = 4215.83 (* 1 = 4215.83 loss)
I0823 14:15:20.969050  7716 sgd_solver.cpp:106] Iteration 14950, lr = 1e-08
I0823 14:16:22.647372  7716 solver.cpp:337] Iteration 15000, Testing net (#0)
I0823 14:16:31.098608  7716 solver.cpp:404]     Test net output #0: accuracy = 0.925728
I0823 14:16:31.098645  7716 solver.cpp:404]     Test net output #1: loss = 7695.97 (* 1 = 7695.97 loss)
I0823 14:16:32.006213  7716 solver.cpp:228] Iteration 15000, loss = 11130.9
I0823 14:16:32.006240  7716 solver.cpp:244]     Train net output #0: accuracy = 0.890921
I0823 14:16:32.006249  7716 solver.cpp:244]     Train net output #1: loss = 11130.9 (* 1 = 11130.9 loss)
I0823 14:16:32.006256  7716 sgd_solver.cpp:106] Iteration 15000, lr = 1e-08
I0823 14:17:35.195538  7716 solver.cpp:228] Iteration 15050, loss = 8119.42
I0823 14:17:35.195648  7716 solver.cpp:244]     Train net output #0: accuracy = 0.919674
I0823 14:17:35.195662  7716 solver.cpp:244]     Train net output #1: loss = 8119.42 (* 1 = 8119.42 loss)
I0823 14:17:35.195672  7716 sgd_solver.cpp:106] Iteration 15050, lr = 1e-08
I0823 14:18:38.027685  7716 solver.cpp:228] Iteration 15100, loss = 6208.18
I0823 14:18:38.027783  7716 solver.cpp:244]     Train net output #0: accuracy = 0.940477
I0823 14:18:38.027796  7716 solver.cpp:244]     Train net output #1: loss = 6208.18 (* 1 = 6208.18 loss)
I0823 14:18:38.027803  7716 sgd_solver.cpp:106] Iteration 15100, lr = 1e-08
I0823 14:19:40.599511  7716 solver.cpp:228] Iteration 15150, loss = 5468.17
I0823 14:19:40.599570  7716 solver.cpp:244]     Train net output #0: accuracy = 0.945333
I0823 14:19:40.599581  7716 solver.cpp:244]     Train net output #1: loss = 5468.17 (* 1 = 5468.17 loss)
I0823 14:19:40.599589  7716 sgd_solver.cpp:106] Iteration 15150, lr = 1e-08
I0823 14:20:42.246083  7716 solver.cpp:337] Iteration 15200, Testing net (#0)
I0823 14:20:50.698973  7716 solver.cpp:404]     Test net output #0: accuracy = 0.923044
I0823 14:20:50.699014  7716 solver.cpp:404]     Test net output #1: loss = 7943.99 (* 1 = 7943.99 loss)
I0823 14:20:51.606513  7716 solver.cpp:228] Iteration 15200, loss = 6357.64
I0823 14:20:51.606549  7716 solver.cpp:244]     Train net output #0: accuracy = 0.938752
I0823 14:20:51.606557  7716 solver.cpp:244]     Train net output #1: loss = 6357.64 (* 1 = 6357.64 loss)
I0823 14:20:51.606564  7716 sgd_solver.cpp:106] Iteration 15200, lr = 1e-08
I0823 14:21:54.116616  7716 solver.cpp:228] Iteration 15250, loss = 8956.14
I0823 14:21:54.116659  7716 solver.cpp:244]     Train net output #0: accuracy = 0.911352
I0823 14:21:54.116669  7716 solver.cpp:244]     Train net output #1: loss = 8956.14 (* 1 = 8956.14 loss)
I0823 14:21:54.116677  7716 sgd_solver.cpp:106] Iteration 15250, lr = 1e-08
I0823 14:22:56.674425  7716 solver.cpp:228] Iteration 15300, loss = 8072.31
I0823 14:22:56.674473  7716 solver.cpp:244]     Train net output #0: accuracy = 0.925667
I0823 14:22:56.674482  7716 solver.cpp:244]     Train net output #1: loss = 8072.31 (* 1 = 8072.31 loss)
I0823 14:22:56.674489  7716 sgd_solver.cpp:106] Iteration 15300, lr = 1e-08
I0823 14:23:59.237036  7716 solver.cpp:228] Iteration 15350, loss = 5857.9
I0823 14:23:59.237097  7716 solver.cpp:244]     Train net output #0: accuracy = 0.94348
I0823 14:23:59.237108  7716 solver.cpp:244]     Train net output #1: loss = 5857.9 (* 1 = 5857.9 loss)
I0823 14:23:59.237117  7716 sgd_solver.cpp:106] Iteration 15350, lr = 1e-08
I0823 14:25:00.952973  7716 solver.cpp:337] Iteration 15400, Testing net (#0)
I0823 14:25:09.408588  7716 solver.cpp:404]     Test net output #0: accuracy = 0.921108
I0823 14:25:09.408627  7716 solver.cpp:404]     Test net output #1: loss = 8120.27 (* 1 = 8120.27 loss)
I0823 14:25:10.312624  7716 solver.cpp:228] Iteration 15400, loss = 4407.89
I0823 14:25:10.312651  7716 solver.cpp:244]     Train net output #0: accuracy = 0.957325
I0823 14:25:10.312660  7716 solver.cpp:244]     Train net output #1: loss = 4407.89 (* 1 = 4407.89 loss)
I0823 14:25:10.312669  7716 sgd_solver.cpp:106] Iteration 15400, lr = 1e-08
I0823 14:26:13.173817  7716 solver.cpp:228] Iteration 15450, loss = 10519.5
I0823 14:26:13.173913  7716 solver.cpp:244]     Train net output #0: accuracy = 0.902411
I0823 14:26:13.173925  7716 solver.cpp:244]     Train net output #1: loss = 10519.5 (* 1 = 10519.5 loss)
I0823 14:26:13.173933  7716 sgd_solver.cpp:106] Iteration 15450, lr = 1e-08
I0823 14:27:16.258299  7716 solver.cpp:228] Iteration 15500, loss = 8121.81
I0823 14:27:16.258358  7716 solver.cpp:244]     Train net output #0: accuracy = 0.919748
I0823 14:27:16.258369  7716 solver.cpp:244]     Train net output #1: loss = 8121.81 (* 1 = 8121.81 loss)
I0823 14:27:16.258378  7716 sgd_solver.cpp:106] Iteration 15500, lr = 1e-08
I0823 14:28:18.851230  7716 solver.cpp:228] Iteration 15550, loss = 6482.31
I0823 14:28:18.851357  7716 solver.cpp:244]     Train net output #0: accuracy = 0.935866
I0823 14:28:18.851371  7716 solver.cpp:244]     Train net output #1: loss = 6482.31 (* 1 = 6482.31 loss)
I0823 14:28:18.851389  7716 sgd_solver.cpp:106] Iteration 15550, lr = 1e-08
I0823 14:29:20.567684  7716 solver.cpp:337] Iteration 15600, Testing net (#0)
I0823 14:29:29.043910  7716 solver.cpp:404]     Test net output #0: accuracy = 0.921421
I0823 14:29:29.043949  7716 solver.cpp:404]     Test net output #1: loss = 8144.21 (* 1 = 8144.21 loss)
I0823 14:29:29.949512  7716 solver.cpp:228] Iteration 15600, loss = 5001.95
I0823 14:29:29.949545  7716 solver.cpp:244]     Train net output #0: accuracy = 0.949962
I0823 14:29:29.949554  7716 solver.cpp:244]     Train net output #1: loss = 5001.95 (* 1 = 5001.95 loss)
I0823 14:29:29.949563  7716 sgd_solver.cpp:106] Iteration 15600, lr = 1e-08
I0823 14:30:32.578835  7716 solver.cpp:228] Iteration 15650, loss = 6841.87
I0823 14:30:32.578896  7716 solver.cpp:244]     Train net output #0: accuracy = 0.932021
I0823 14:30:32.578907  7716 solver.cpp:244]     Train net output #1: loss = 6841.87 (* 1 = 6841.87 loss)
I0823 14:30:32.578914  7716 sgd_solver.cpp:106] Iteration 15650, lr = 1e-08
I0823 14:31:35.144902  7716 solver.cpp:228] Iteration 15700, loss = 9208.86
I0823 14:31:35.144996  7716 solver.cpp:244]     Train net output #0: accuracy = 0.908138
I0823 14:31:35.145009  7716 solver.cpp:244]     Train net output #1: loss = 9208.86 (* 1 = 9208.86 loss)
I0823 14:31:35.145016  7716 sgd_solver.cpp:106] Iteration 15700, lr = 1e-08
I0823 14:32:37.705234  7716 solver.cpp:228] Iteration 15750, loss = 7120.58
I0823 14:32:37.705327  7716 solver.cpp:244]     Train net output #0: accuracy = 0.93228
I0823 14:32:37.705339  7716 solver.cpp:244]     Train net output #1: loss = 7120.58 (* 1 = 7120.58 loss)
I0823 14:32:37.705348  7716 sgd_solver.cpp:106] Iteration 15750, lr = 1e-08
I0823 14:33:40.508265  7716 solver.cpp:337] Iteration 15800, Testing net (#0)
I0823 14:33:49.284345  7716 solver.cpp:404]     Test net output #0: accuracy = 0.922716
I0823 14:33:49.284389  7716 solver.cpp:404]     Test net output #1: loss = 7954.52 (* 1 = 7954.52 loss)
I0823 14:33:50.191937  7716 solver.cpp:228] Iteration 15800, loss = 5016.27
I0823 14:33:50.191972  7716 solver.cpp:244]     Train net output #0: accuracy = 0.951467
I0823 14:33:50.191982  7716 solver.cpp:244]     Train net output #1: loss = 5016.27 (* 1 = 5016.27 loss)
I0823 14:33:50.191988  7716 sgd_solver.cpp:106] Iteration 15800, lr = 1e-08
I0823 14:34:52.837736  7716 solver.cpp:228] Iteration 15850, loss = 4779.35
I0823 14:34:52.837803  7716 solver.cpp:244]     Train net output #0: accuracy = 0.955385
I0823 14:34:52.837815  7716 solver.cpp:244]     Train net output #1: loss = 4779.35 (* 1 = 4779.35 loss)
I0823 14:34:52.837822  7716 sgd_solver.cpp:106] Iteration 15850, lr = 1e-08
I0823 14:35:55.410728  7716 solver.cpp:228] Iteration 15900, loss = 9375.88
I0823 14:35:55.410820  7716 solver.cpp:244]     Train net output #0: accuracy = 0.910492
I0823 14:35:55.410830  7716 solver.cpp:244]     Train net output #1: loss = 9375.88 (* 1 = 9375.88 loss)
I0823 14:35:55.410837  7716 sgd_solver.cpp:106] Iteration 15900, lr = 1e-08
I0823 14:36:58.003564  7716 solver.cpp:228] Iteration 15950, loss = 7960.49
I0823 14:36:58.003657  7716 solver.cpp:244]     Train net output #0: accuracy = 0.920739
I0823 14:36:58.003669  7716 solver.cpp:244]     Train net output #1: loss = 7960.49 (* 1 = 7960.49 loss)
I0823 14:36:58.003675  7716 sgd_solver.cpp:106] Iteration 15950, lr = 1e-08
I0823 14:37:59.602208  7716 solver.cpp:454] Snapshotting to binary proto file portrait_one_stage_iter_16000.caffemodel
I0823 14:37:59.605528  7716 sgd_solver.cpp:273] Snapshotting solver state to binary proto file portrait_one_stage_iter_16000.solverstate
I0823 14:38:00.190500  7716 solver.cpp:317] Iteration 16000, loss = 7074.87
I0823 14:38:00.190533  7716 solver.cpp:337] Iteration 16000, Testing net (#0)
I0823 14:38:08.732636  7716 solver.cpp:404]     Test net output #0: accuracy = 0.925755
I0823 14:38:08.732676  7716 solver.cpp:404]     Test net output #1: loss = 7690.89 (* 1 = 7690.89 loss)
I0823 14:38:08.732681  7716 solver.cpp:322] Optimization Done.
I0823 14:38:08.732684  7716 caffe.cpp:254] Optimization Done.
