I0826 17:59:16.437418  5239 caffe.cpp:217] Using GPUs 3
I0826 17:59:16.455106  5239 caffe.cpp:222] GPU 3: GeForce GTX TITAN X
I0826 17:59:16.672641  5239 solver.cpp:48] Initializing solver from parameters: 
test_iter: 15
test_interval: 200
base_lr: 1e-05
display: 50
max_iter: 16000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 1e-05
stepsize: 4000
snapshot: 4000
snapshot_prefix: "portrait_one_stage4"
solver_mode: GPU
device_id: 3
net: "portrait_train_test_one_stage.prototxt4"
train_state {
  level: 0
  stage: ""
}
I0826 17:59:16.672747  5239 solver.cpp:91] Creating training net from net file: portrait_train_test_one_stage.prototxt4
I0826 17:59:16.673311  5239 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0826 17:59:16.673480  5239 net.cpp:58] Initializing net from parameters: 
name: "segmentation"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "SegData"
  top: "image"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 200
  }
  data_param {
    source: "/raid/xuehan/segmentation_train_split"
    batch_size: 128
    backend: LMDB
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "image"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 50
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1_1_bn"
  type: "BatchNorm"
  bottom: "pool1"
  top: "conv1_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv1_1_bn_scale"
  type: "Scale"
  bottom: "conv1_1_bn"
  top: "conv1_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_1_relu"
  type: "ReLU"
  bottom: "conv1_1_bn"
  top: "conv1_1_bn"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv1_1_bn"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_1"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1_bn"
  type: "BatchNorm"
  bottom: "pool2"
  top: "conv2_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv2_1_bn_scale"
  type: "Scale"
  bottom: "conv2_1_bn"
  top: "conv2_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1_relu"
  type: "ReLU"
  bottom: "conv2_1_bn"
  top: "conv2_1_bn"
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv2_1_bn"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_1"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1_bn"
  type: "BatchNorm"
  bottom: "pool3"
  top: "conv3_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv3_1_bn_scale"
  type: "Scale"
  bottom: "conv3_1_bn"
  top: "conv3_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1_relu"
  type: "ReLU"
  bottom: "conv3_1_bn"
  top: "conv3_1_bn"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv3_1_bn"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_1"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1_bn"
  type: "BatchNorm"
  bottom: "pool4"
  top: "conv4_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv4_1_bn_scale"
  type: "Scale"
  bottom: "conv4_1_bn"
  top: "conv4_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1_relu"
  type: "ReLU"
  bottom: "conv4_1_bn"
  top: "conv4_1_bn"
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "conv4_1_bn"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv5_1_bn"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv5_1_bn_scale"
  type: "Scale"
  bottom: "conv5_1_bn"
  top: "conv5_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_1_relu"
  type: "ReLU"
  bottom: "conv5_1_bn"
  top: "conv5_1_bn"
}
layer {
  name: "conv6_1"
  type: "Convolution"
  bottom: "conv5_1_bn"
  top: "conv6_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv6_1_bn"
  type: "BatchNorm"
  bottom: "conv6_1"
  top: "conv6_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv6_1_bn_scale"
  type: "Scale"
  bottom: "conv6_1_bn"
  top: "conv6_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv6_1_relu"
  type: "ReLU"
  bottom: "conv6_1_bn"
  top: "conv6_1_bn"
}
layer {
  name: "conv7_1"
  type: "Convolution"
  bottom: "conv6_1_bn"
  top: "conv7_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv7_1_bn"
  type: "BatchNorm"
  bottom: "conv7_1"
  top: "conv7_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv7_1_bn_scale"
  type: "Scale"
  bottom: "conv7_1_bn"
  top: "conv7_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv7_1_relu"
  type: "ReLU"
  bottom: "conv7_1_bn"
  top: "conv7_1_bn"
}
layer {
  name: "score"
  type: "Convolution"
  bottom: "conv7_1_bn"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 4
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "upscore1"
  type: "Deconvolution"
  bottom: "score"
  top: "upscore1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 4
    bias_term: false
    pad: 0
    kernel_size: 8
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "upscore2"
  type: "Deconvolution"
  bottom: "upscore1"
  top: "upscore2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 4
    bias_term: false
    pad: 0
    kernel_size: 8
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "cropscore"
  type: "Crop"
  bottom: "upscore2"
  bottom: "image"
  top: "cropscore"
  crop_param {
    axis: 2
    offset: 14
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "cropscore"
  bottom: "label"
  top: "loss"
  loss_weight: 1
  loss_param {
    normalize: false
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "cropscore"
  bottom: "label"
  top: "accuracy"
}
I0826 17:59:16.673655  5239 layer_factory.hpp:77] Creating layer data
I0826 17:59:16.674517  5239 net.cpp:100] Creating Layer data
I0826 17:59:16.674535  5239 net.cpp:408] data -> image
I0826 17:59:16.674552  5239 net.cpp:408] data -> label
I0826 17:59:16.675978  5243 db_lmdb.cpp:35] Opened lmdb /raid/xuehan/segmentation_train_split
I0826 17:59:16.676151  5239 seg_data_layer.cpp:38] 200 200 4
I0826 17:59:16.694092  5239 seg_data_layer.cpp:51] output data size: 128,3,200,200
I0826 17:59:16.694152  5239 seg_data_layer.cpp:63] output label size: 128,1,200,200
I0826 17:59:16.798938  5239 net.cpp:150] Setting up data
I0826 17:59:16.798977  5239 net.cpp:157] Top shape: 128 3 200 200 (15360000)
I0826 17:59:16.798986  5239 net.cpp:157] Top shape: 128 1 200 200 (5120000)
I0826 17:59:16.798991  5239 net.cpp:165] Memory required for data: 81920000
I0826 17:59:16.799006  5239 layer_factory.hpp:77] Creating layer image_data_0_split
I0826 17:59:16.799027  5239 net.cpp:100] Creating Layer image_data_0_split
I0826 17:59:16.799036  5239 net.cpp:434] image_data_0_split <- image
I0826 17:59:16.799052  5239 net.cpp:408] image_data_0_split -> image_data_0_split_0
I0826 17:59:16.799064  5239 net.cpp:408] image_data_0_split -> image_data_0_split_1
I0826 17:59:16.799125  5239 net.cpp:150] Setting up image_data_0_split
I0826 17:59:16.799139  5239 net.cpp:157] Top shape: 128 3 200 200 (15360000)
I0826 17:59:16.799145  5239 net.cpp:157] Top shape: 128 3 200 200 (15360000)
I0826 17:59:16.799149  5239 net.cpp:165] Memory required for data: 204800000
I0826 17:59:16.799154  5239 layer_factory.hpp:77] Creating layer label_data_1_split
I0826 17:59:16.799160  5239 net.cpp:100] Creating Layer label_data_1_split
I0826 17:59:16.799161  5239 net.cpp:434] label_data_1_split <- label
I0826 17:59:16.799167  5239 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0826 17:59:16.799172  5239 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0826 17:59:16.799201  5239 net.cpp:150] Setting up label_data_1_split
I0826 17:59:16.799211  5239 net.cpp:157] Top shape: 128 1 200 200 (5120000)
I0826 17:59:16.799216  5239 net.cpp:157] Top shape: 128 1 200 200 (5120000)
I0826 17:59:16.799221  5239 net.cpp:165] Memory required for data: 245760000
I0826 17:59:16.799224  5239 layer_factory.hpp:77] Creating layer conv1_1
I0826 17:59:16.799243  5239 net.cpp:100] Creating Layer conv1_1
I0826 17:59:16.799252  5239 net.cpp:434] conv1_1 <- image_data_0_split_0
I0826 17:59:16.799259  5239 net.cpp:408] conv1_1 -> conv1_1
I0826 17:59:16.799506  5239 net.cpp:150] Setting up conv1_1
I0826 17:59:16.799520  5239 net.cpp:157] Top shape: 128 8 298 298 (90935296)
I0826 17:59:16.799525  5239 net.cpp:165] Memory required for data: 609501184
I0826 17:59:16.799541  5239 layer_factory.hpp:77] Creating layer pool1
I0826 17:59:16.799553  5239 net.cpp:100] Creating Layer pool1
I0826 17:59:16.799561  5239 net.cpp:434] pool1 <- conv1_1
I0826 17:59:16.799566  5239 net.cpp:408] pool1 -> pool1
I0826 17:59:16.799614  5239 net.cpp:150] Setting up pool1
I0826 17:59:16.799624  5239 net.cpp:157] Top shape: 128 8 149 149 (22733824)
I0826 17:59:16.799628  5239 net.cpp:165] Memory required for data: 700436480
I0826 17:59:16.799633  5239 layer_factory.hpp:77] Creating layer conv1_1_bn
I0826 17:59:16.799641  5239 net.cpp:100] Creating Layer conv1_1_bn
I0826 17:59:16.799645  5239 net.cpp:434] conv1_1_bn <- pool1
I0826 17:59:16.799654  5239 net.cpp:408] conv1_1_bn -> conv1_1_bn
I0826 17:59:16.800405  5239 net.cpp:150] Setting up conv1_1_bn
I0826 17:59:16.800420  5239 net.cpp:157] Top shape: 128 8 149 149 (22733824)
I0826 17:59:16.800426  5239 net.cpp:165] Memory required for data: 791371776
I0826 17:59:16.800441  5239 layer_factory.hpp:77] Creating layer conv1_1_bn_scale
I0826 17:59:16.800454  5239 net.cpp:100] Creating Layer conv1_1_bn_scale
I0826 17:59:16.800460  5239 net.cpp:434] conv1_1_bn_scale <- conv1_1_bn
I0826 17:59:16.800469  5239 net.cpp:395] conv1_1_bn_scale -> conv1_1_bn (in-place)
I0826 17:59:16.807031  5239 layer_factory.hpp:77] Creating layer conv1_1_bn_scale
I0826 17:59:16.807153  5239 net.cpp:150] Setting up conv1_1_bn_scale
I0826 17:59:16.807175  5239 net.cpp:157] Top shape: 128 8 149 149 (22733824)
I0826 17:59:16.807178  5239 net.cpp:165] Memory required for data: 882307072
I0826 17:59:16.807188  5239 layer_factory.hpp:77] Creating layer conv1_1_relu
I0826 17:59:16.807193  5239 net.cpp:100] Creating Layer conv1_1_relu
I0826 17:59:16.807198  5239 net.cpp:434] conv1_1_relu <- conv1_1_bn
I0826 17:59:16.807202  5239 net.cpp:395] conv1_1_relu -> conv1_1_bn (in-place)
I0826 17:59:16.807209  5239 net.cpp:150] Setting up conv1_1_relu
I0826 17:59:16.807212  5239 net.cpp:157] Top shape: 128 8 149 149 (22733824)
I0826 17:59:16.807214  5239 net.cpp:165] Memory required for data: 973242368
I0826 17:59:16.807217  5239 layer_factory.hpp:77] Creating layer conv2_1
I0826 17:59:16.807226  5239 net.cpp:100] Creating Layer conv2_1
I0826 17:59:16.807229  5239 net.cpp:434] conv2_1 <- conv1_1_bn
I0826 17:59:16.807234  5239 net.cpp:408] conv2_1 -> conv2_1
I0826 17:59:16.807765  5239 net.cpp:150] Setting up conv2_1
I0826 17:59:16.807775  5239 net.cpp:157] Top shape: 128 16 149 149 (45467648)
I0826 17:59:16.807778  5239 net.cpp:165] Memory required for data: 1155112960
I0826 17:59:16.807782  5239 layer_factory.hpp:77] Creating layer pool2
I0826 17:59:16.807788  5239 net.cpp:100] Creating Layer pool2
I0826 17:59:16.807792  5239 net.cpp:434] pool2 <- conv2_1
I0826 17:59:16.807796  5239 net.cpp:408] pool2 -> pool2
I0826 17:59:16.807821  5239 net.cpp:150] Setting up pool2
I0826 17:59:16.807827  5239 net.cpp:157] Top shape: 128 16 75 75 (11520000)
I0826 17:59:16.807831  5239 net.cpp:165] Memory required for data: 1201192960
I0826 17:59:16.807833  5239 layer_factory.hpp:77] Creating layer conv2_1_bn
I0826 17:59:16.807838  5239 net.cpp:100] Creating Layer conv2_1_bn
I0826 17:59:16.807842  5239 net.cpp:434] conv2_1_bn <- pool2
I0826 17:59:16.807845  5239 net.cpp:408] conv2_1_bn -> conv2_1_bn
I0826 17:59:16.808322  5239 net.cpp:150] Setting up conv2_1_bn
I0826 17:59:16.808332  5239 net.cpp:157] Top shape: 128 16 75 75 (11520000)
I0826 17:59:16.808336  5239 net.cpp:165] Memory required for data: 1247272960
I0826 17:59:16.808343  5239 layer_factory.hpp:77] Creating layer conv2_1_bn_scale
I0826 17:59:16.808349  5239 net.cpp:100] Creating Layer conv2_1_bn_scale
I0826 17:59:16.808353  5239 net.cpp:434] conv2_1_bn_scale <- conv2_1_bn
I0826 17:59:16.808357  5239 net.cpp:395] conv2_1_bn_scale -> conv2_1_bn (in-place)
I0826 17:59:16.808383  5239 layer_factory.hpp:77] Creating layer conv2_1_bn_scale
I0826 17:59:16.808464  5239 net.cpp:150] Setting up conv2_1_bn_scale
I0826 17:59:16.808470  5239 net.cpp:157] Top shape: 128 16 75 75 (11520000)
I0826 17:59:16.808472  5239 net.cpp:165] Memory required for data: 1293352960
I0826 17:59:16.808477  5239 layer_factory.hpp:77] Creating layer conv2_1_relu
I0826 17:59:16.808481  5239 net.cpp:100] Creating Layer conv2_1_relu
I0826 17:59:16.808485  5239 net.cpp:434] conv2_1_relu <- conv2_1_bn
I0826 17:59:16.808488  5239 net.cpp:395] conv2_1_relu -> conv2_1_bn (in-place)
I0826 17:59:16.808492  5239 net.cpp:150] Setting up conv2_1_relu
I0826 17:59:16.808496  5239 net.cpp:157] Top shape: 128 16 75 75 (11520000)
I0826 17:59:16.808498  5239 net.cpp:165] Memory required for data: 1339432960
I0826 17:59:16.808501  5239 layer_factory.hpp:77] Creating layer conv3_1
I0826 17:59:16.808508  5239 net.cpp:100] Creating Layer conv3_1
I0826 17:59:16.808511  5239 net.cpp:434] conv3_1 <- conv2_1_bn
I0826 17:59:16.808516  5239 net.cpp:408] conv3_1 -> conv3_1
I0826 17:59:16.808730  5239 net.cpp:150] Setting up conv3_1
I0826 17:59:16.808737  5239 net.cpp:157] Top shape: 128 32 75 75 (23040000)
I0826 17:59:16.808738  5239 net.cpp:165] Memory required for data: 1431592960
I0826 17:59:16.808743  5239 layer_factory.hpp:77] Creating layer pool3
I0826 17:59:16.808749  5239 net.cpp:100] Creating Layer pool3
I0826 17:59:16.808754  5239 net.cpp:434] pool3 <- conv3_1
I0826 17:59:16.808760  5239 net.cpp:408] pool3 -> pool3
I0826 17:59:16.808794  5239 net.cpp:150] Setting up pool3
I0826 17:59:16.808800  5239 net.cpp:157] Top shape: 128 32 38 38 (5914624)
I0826 17:59:16.808806  5239 net.cpp:165] Memory required for data: 1455251456
I0826 17:59:16.808815  5239 layer_factory.hpp:77] Creating layer conv3_1_bn
I0826 17:59:16.808820  5239 net.cpp:100] Creating Layer conv3_1_bn
I0826 17:59:16.808823  5239 net.cpp:434] conv3_1_bn <- pool3
I0826 17:59:16.808828  5239 net.cpp:408] conv3_1_bn -> conv3_1_bn
I0826 17:59:16.808954  5239 net.cpp:150] Setting up conv3_1_bn
I0826 17:59:16.808960  5239 net.cpp:157] Top shape: 128 32 38 38 (5914624)
I0826 17:59:16.808962  5239 net.cpp:165] Memory required for data: 1478909952
I0826 17:59:16.808969  5239 layer_factory.hpp:77] Creating layer conv3_1_bn_scale
I0826 17:59:16.808975  5239 net.cpp:100] Creating Layer conv3_1_bn_scale
I0826 17:59:16.808979  5239 net.cpp:434] conv3_1_bn_scale <- conv3_1_bn
I0826 17:59:16.808982  5239 net.cpp:395] conv3_1_bn_scale -> conv3_1_bn (in-place)
I0826 17:59:16.809007  5239 layer_factory.hpp:77] Creating layer conv3_1_bn_scale
I0826 17:59:16.809082  5239 net.cpp:150] Setting up conv3_1_bn_scale
I0826 17:59:16.809089  5239 net.cpp:157] Top shape: 128 32 38 38 (5914624)
I0826 17:59:16.809092  5239 net.cpp:165] Memory required for data: 1502568448
I0826 17:59:16.809098  5239 layer_factory.hpp:77] Creating layer conv3_1_relu
I0826 17:59:16.809103  5239 net.cpp:100] Creating Layer conv3_1_relu
I0826 17:59:16.809106  5239 net.cpp:434] conv3_1_relu <- conv3_1_bn
I0826 17:59:16.809110  5239 net.cpp:395] conv3_1_relu -> conv3_1_bn (in-place)
I0826 17:59:16.809114  5239 net.cpp:150] Setting up conv3_1_relu
I0826 17:59:16.809118  5239 net.cpp:157] Top shape: 128 32 38 38 (5914624)
I0826 17:59:16.809120  5239 net.cpp:165] Memory required for data: 1526226944
I0826 17:59:16.809123  5239 layer_factory.hpp:77] Creating layer conv4_1
I0826 17:59:16.809130  5239 net.cpp:100] Creating Layer conv4_1
I0826 17:59:16.809134  5239 net.cpp:434] conv4_1 <- conv3_1_bn
I0826 17:59:16.809137  5239 net.cpp:408] conv4_1 -> conv4_1
I0826 17:59:16.809646  5239 net.cpp:150] Setting up conv4_1
I0826 17:59:16.809653  5239 net.cpp:157] Top shape: 128 64 38 38 (11829248)
I0826 17:59:16.809655  5239 net.cpp:165] Memory required for data: 1573543936
I0826 17:59:16.809659  5239 layer_factory.hpp:77] Creating layer pool4
I0826 17:59:16.809664  5239 net.cpp:100] Creating Layer pool4
I0826 17:59:16.809666  5239 net.cpp:434] pool4 <- conv4_1
I0826 17:59:16.809671  5239 net.cpp:408] pool4 -> pool4
I0826 17:59:16.809695  5239 net.cpp:150] Setting up pool4
I0826 17:59:16.809700  5239 net.cpp:157] Top shape: 128 64 19 19 (2957312)
I0826 17:59:16.809702  5239 net.cpp:165] Memory required for data: 1585373184
I0826 17:59:16.809705  5239 layer_factory.hpp:77] Creating layer conv4_1_bn
I0826 17:59:16.809711  5239 net.cpp:100] Creating Layer conv4_1_bn
I0826 17:59:16.809713  5239 net.cpp:434] conv4_1_bn <- pool4
I0826 17:59:16.809718  5239 net.cpp:408] conv4_1_bn -> conv4_1_bn
I0826 17:59:16.810204  5239 net.cpp:150] Setting up conv4_1_bn
I0826 17:59:16.810214  5239 net.cpp:157] Top shape: 128 64 19 19 (2957312)
I0826 17:59:16.810217  5239 net.cpp:165] Memory required for data: 1597202432
I0826 17:59:16.810223  5239 layer_factory.hpp:77] Creating layer conv4_1_bn_scale
I0826 17:59:16.810231  5239 net.cpp:100] Creating Layer conv4_1_bn_scale
I0826 17:59:16.810235  5239 net.cpp:434] conv4_1_bn_scale <- conv4_1_bn
I0826 17:59:16.810240  5239 net.cpp:395] conv4_1_bn_scale -> conv4_1_bn (in-place)
I0826 17:59:16.810266  5239 layer_factory.hpp:77] Creating layer conv4_1_bn_scale
I0826 17:59:16.810340  5239 net.cpp:150] Setting up conv4_1_bn_scale
I0826 17:59:16.810345  5239 net.cpp:157] Top shape: 128 64 19 19 (2957312)
I0826 17:59:16.810348  5239 net.cpp:165] Memory required for data: 1609031680
I0826 17:59:16.810353  5239 layer_factory.hpp:77] Creating layer conv4_1_relu
I0826 17:59:16.810359  5239 net.cpp:100] Creating Layer conv4_1_relu
I0826 17:59:16.810360  5239 net.cpp:434] conv4_1_relu <- conv4_1_bn
I0826 17:59:16.810364  5239 net.cpp:395] conv4_1_relu -> conv4_1_bn (in-place)
I0826 17:59:16.810379  5239 net.cpp:150] Setting up conv4_1_relu
I0826 17:59:16.810387  5239 net.cpp:157] Top shape: 128 64 19 19 (2957312)
I0826 17:59:16.810395  5239 net.cpp:165] Memory required for data: 1620860928
I0826 17:59:16.810398  5239 layer_factory.hpp:77] Creating layer conv5_1
I0826 17:59:16.810405  5239 net.cpp:100] Creating Layer conv5_1
I0826 17:59:16.810408  5239 net.cpp:434] conv5_1 <- conv4_1_bn
I0826 17:59:16.810413  5239 net.cpp:408] conv5_1 -> conv5_1
I0826 17:59:16.811444  5239 net.cpp:150] Setting up conv5_1
I0826 17:59:16.811455  5239 net.cpp:157] Top shape: 128 64 17 17 (2367488)
I0826 17:59:16.811458  5239 net.cpp:165] Memory required for data: 1630330880
I0826 17:59:16.811465  5239 layer_factory.hpp:77] Creating layer conv5_1_bn
I0826 17:59:16.811473  5239 net.cpp:100] Creating Layer conv5_1_bn
I0826 17:59:16.811478  5239 net.cpp:434] conv5_1_bn <- conv5_1
I0826 17:59:16.811485  5239 net.cpp:408] conv5_1_bn -> conv5_1_bn
I0826 17:59:16.811668  5239 net.cpp:150] Setting up conv5_1_bn
I0826 17:59:16.811676  5239 net.cpp:157] Top shape: 128 64 17 17 (2367488)
I0826 17:59:16.811681  5239 net.cpp:165] Memory required for data: 1639800832
I0826 17:59:16.811689  5239 layer_factory.hpp:77] Creating layer conv5_1_bn_scale
I0826 17:59:16.811697  5239 net.cpp:100] Creating Layer conv5_1_bn_scale
I0826 17:59:16.811702  5239 net.cpp:434] conv5_1_bn_scale <- conv5_1_bn
I0826 17:59:16.811707  5239 net.cpp:395] conv5_1_bn_scale -> conv5_1_bn (in-place)
I0826 17:59:16.811741  5239 layer_factory.hpp:77] Creating layer conv5_1_bn_scale
I0826 17:59:16.811843  5239 net.cpp:150] Setting up conv5_1_bn_scale
I0826 17:59:16.811853  5239 net.cpp:157] Top shape: 128 64 17 17 (2367488)
I0826 17:59:16.811857  5239 net.cpp:165] Memory required for data: 1649270784
I0826 17:59:16.811866  5239 layer_factory.hpp:77] Creating layer conv5_1_relu
I0826 17:59:16.811872  5239 net.cpp:100] Creating Layer conv5_1_relu
I0826 17:59:16.811877  5239 net.cpp:434] conv5_1_relu <- conv5_1_bn
I0826 17:59:16.811882  5239 net.cpp:395] conv5_1_relu -> conv5_1_bn (in-place)
I0826 17:59:16.811888  5239 net.cpp:150] Setting up conv5_1_relu
I0826 17:59:16.811893  5239 net.cpp:157] Top shape: 128 64 17 17 (2367488)
I0826 17:59:16.811897  5239 net.cpp:165] Memory required for data: 1658740736
I0826 17:59:16.811902  5239 layer_factory.hpp:77] Creating layer conv6_1
I0826 17:59:16.811913  5239 net.cpp:100] Creating Layer conv6_1
I0826 17:59:16.811916  5239 net.cpp:434] conv6_1 <- conv5_1_bn
I0826 17:59:16.811924  5239 net.cpp:408] conv6_1 -> conv6_1
I0826 17:59:16.813406  5239 net.cpp:150] Setting up conv6_1
I0826 17:59:16.813416  5239 net.cpp:157] Top shape: 128 64 15 15 (1843200)
I0826 17:59:16.813421  5239 net.cpp:165] Memory required for data: 1666113536
I0826 17:59:16.813426  5239 layer_factory.hpp:77] Creating layer conv6_1_bn
I0826 17:59:16.813433  5239 net.cpp:100] Creating Layer conv6_1_bn
I0826 17:59:16.813437  5239 net.cpp:434] conv6_1_bn <- conv6_1
I0826 17:59:16.813443  5239 net.cpp:408] conv6_1_bn -> conv6_1_bn
I0826 17:59:16.813626  5239 net.cpp:150] Setting up conv6_1_bn
I0826 17:59:16.813633  5239 net.cpp:157] Top shape: 128 64 15 15 (1843200)
I0826 17:59:16.813637  5239 net.cpp:165] Memory required for data: 1673486336
I0826 17:59:16.813657  5239 layer_factory.hpp:77] Creating layer conv6_1_bn_scale
I0826 17:59:16.813665  5239 net.cpp:100] Creating Layer conv6_1_bn_scale
I0826 17:59:16.813670  5239 net.cpp:434] conv6_1_bn_scale <- conv6_1_bn
I0826 17:59:16.813676  5239 net.cpp:395] conv6_1_bn_scale -> conv6_1_bn (in-place)
I0826 17:59:16.813722  5239 layer_factory.hpp:77] Creating layer conv6_1_bn_scale
I0826 17:59:16.813835  5239 net.cpp:150] Setting up conv6_1_bn_scale
I0826 17:59:16.813844  5239 net.cpp:157] Top shape: 128 64 15 15 (1843200)
I0826 17:59:16.813848  5239 net.cpp:165] Memory required for data: 1680859136
I0826 17:59:16.813856  5239 layer_factory.hpp:77] Creating layer conv6_1_relu
I0826 17:59:16.813864  5239 net.cpp:100] Creating Layer conv6_1_relu
I0826 17:59:16.813869  5239 net.cpp:434] conv6_1_relu <- conv6_1_bn
I0826 17:59:16.813875  5239 net.cpp:395] conv6_1_relu -> conv6_1_bn (in-place)
I0826 17:59:16.813889  5239 net.cpp:150] Setting up conv6_1_relu
I0826 17:59:16.813904  5239 net.cpp:157] Top shape: 128 64 15 15 (1843200)
I0826 17:59:16.813907  5239 net.cpp:165] Memory required for data: 1688231936
I0826 17:59:16.813912  5239 layer_factory.hpp:77] Creating layer conv7_1
I0826 17:59:16.813922  5239 net.cpp:100] Creating Layer conv7_1
I0826 17:59:16.813927  5239 net.cpp:434] conv7_1 <- conv6_1_bn
I0826 17:59:16.813933  5239 net.cpp:408] conv7_1 -> conv7_1
I0826 17:59:16.817365  5239 net.cpp:150] Setting up conv7_1
I0826 17:59:16.817397  5239 net.cpp:157] Top shape: 128 128 13 13 (2768896)
I0826 17:59:16.817402  5239 net.cpp:165] Memory required for data: 1699307520
I0826 17:59:16.817412  5239 layer_factory.hpp:77] Creating layer conv7_1_bn
I0826 17:59:16.817430  5239 net.cpp:100] Creating Layer conv7_1_bn
I0826 17:59:16.817436  5239 net.cpp:434] conv7_1_bn <- conv7_1
I0826 17:59:16.817445  5239 net.cpp:408] conv7_1_bn -> conv7_1_bn
I0826 17:59:16.817626  5239 net.cpp:150] Setting up conv7_1_bn
I0826 17:59:16.817634  5239 net.cpp:157] Top shape: 128 128 13 13 (2768896)
I0826 17:59:16.817638  5239 net.cpp:165] Memory required for data: 1710383104
I0826 17:59:16.817648  5239 layer_factory.hpp:77] Creating layer conv7_1_bn_scale
I0826 17:59:16.817656  5239 net.cpp:100] Creating Layer conv7_1_bn_scale
I0826 17:59:16.817661  5239 net.cpp:434] conv7_1_bn_scale <- conv7_1_bn
I0826 17:59:16.817667  5239 net.cpp:395] conv7_1_bn_scale -> conv7_1_bn (in-place)
I0826 17:59:16.817703  5239 layer_factory.hpp:77] Creating layer conv7_1_bn_scale
I0826 17:59:16.817800  5239 net.cpp:150] Setting up conv7_1_bn_scale
I0826 17:59:16.817809  5239 net.cpp:157] Top shape: 128 128 13 13 (2768896)
I0826 17:59:16.817813  5239 net.cpp:165] Memory required for data: 1721458688
I0826 17:59:16.817821  5239 layer_factory.hpp:77] Creating layer conv7_1_relu
I0826 17:59:16.817829  5239 net.cpp:100] Creating Layer conv7_1_relu
I0826 17:59:16.817834  5239 net.cpp:434] conv7_1_relu <- conv7_1_bn
I0826 17:59:16.817839  5239 net.cpp:395] conv7_1_relu -> conv7_1_bn (in-place)
I0826 17:59:16.817847  5239 net.cpp:150] Setting up conv7_1_relu
I0826 17:59:16.817852  5239 net.cpp:157] Top shape: 128 128 13 13 (2768896)
I0826 17:59:16.817857  5239 net.cpp:165] Memory required for data: 1732534272
I0826 17:59:16.817860  5239 layer_factory.hpp:77] Creating layer score
I0826 17:59:16.817873  5239 net.cpp:100] Creating Layer score
I0826 17:59:16.817878  5239 net.cpp:434] score <- conv7_1_bn
I0826 17:59:16.817885  5239 net.cpp:408] score -> score
I0826 17:59:16.818126  5239 net.cpp:150] Setting up score
I0826 17:59:16.818135  5239 net.cpp:157] Top shape: 128 4 13 13 (86528)
I0826 17:59:16.818140  5239 net.cpp:165] Memory required for data: 1732880384
I0826 17:59:16.818147  5239 layer_factory.hpp:77] Creating layer upscore1
I0826 17:59:16.818157  5239 net.cpp:100] Creating Layer upscore1
I0826 17:59:16.818162  5239 net.cpp:434] upscore1 <- score
I0826 17:59:16.818171  5239 net.cpp:408] upscore1 -> upscore1
I0826 17:59:16.818384  5239 net.cpp:150] Setting up upscore1
I0826 17:59:16.818397  5239 net.cpp:157] Top shape: 128 4 56 56 (1605632)
I0826 17:59:16.818403  5239 net.cpp:165] Memory required for data: 1739302912
I0826 17:59:16.818408  5239 layer_factory.hpp:77] Creating layer upscore2
I0826 17:59:16.818418  5239 net.cpp:100] Creating Layer upscore2
I0826 17:59:16.818423  5239 net.cpp:434] upscore2 <- upscore1
I0826 17:59:16.818430  5239 net.cpp:408] upscore2 -> upscore2
I0826 17:59:16.818661  5239 net.cpp:150] Setting up upscore2
I0826 17:59:16.818675  5239 net.cpp:157] Top shape: 128 4 228 228 (26615808)
I0826 17:59:16.818680  5239 net.cpp:165] Memory required for data: 1845766144
I0826 17:59:16.818686  5239 layer_factory.hpp:77] Creating layer cropscore
I0826 17:59:16.818694  5239 net.cpp:100] Creating Layer cropscore
I0826 17:59:16.818701  5239 net.cpp:434] cropscore <- upscore2
I0826 17:59:16.818706  5239 net.cpp:434] cropscore <- image_data_0_split_1
I0826 17:59:16.818714  5239 net.cpp:408] cropscore -> cropscore
I0826 17:59:16.818745  5239 net.cpp:150] Setting up cropscore
I0826 17:59:16.818775  5239 net.cpp:157] Top shape: 128 4 200 200 (20480000)
I0826 17:59:16.818780  5239 net.cpp:165] Memory required for data: 1927686144
I0826 17:59:16.818785  5239 layer_factory.hpp:77] Creating layer cropscore_cropscore_0_split
I0826 17:59:16.818794  5239 net.cpp:100] Creating Layer cropscore_cropscore_0_split
I0826 17:59:16.818799  5239 net.cpp:434] cropscore_cropscore_0_split <- cropscore
I0826 17:59:16.818805  5239 net.cpp:408] cropscore_cropscore_0_split -> cropscore_cropscore_0_split_0
I0826 17:59:16.818814  5239 net.cpp:408] cropscore_cropscore_0_split -> cropscore_cropscore_0_split_1
I0826 17:59:16.818852  5239 net.cpp:150] Setting up cropscore_cropscore_0_split
I0826 17:59:16.818861  5239 net.cpp:157] Top shape: 128 4 200 200 (20480000)
I0826 17:59:16.818867  5239 net.cpp:157] Top shape: 128 4 200 200 (20480000)
I0826 17:59:16.818871  5239 net.cpp:165] Memory required for data: 2091526144
I0826 17:59:16.818876  5239 layer_factory.hpp:77] Creating layer loss
I0826 17:59:16.818886  5239 net.cpp:100] Creating Layer loss
I0826 17:59:16.818892  5239 net.cpp:434] loss <- cropscore_cropscore_0_split_0
I0826 17:59:16.818897  5239 net.cpp:434] loss <- label_data_1_split_0
I0826 17:59:16.818904  5239 net.cpp:408] loss -> loss
I0826 17:59:16.818917  5239 layer_factory.hpp:77] Creating layer loss
I0826 17:59:16.857621  5239 net.cpp:150] Setting up loss
I0826 17:59:16.857656  5239 net.cpp:157] Top shape: (1)
I0826 17:59:16.857658  5239 net.cpp:160]     with loss weight 1
I0826 17:59:16.857676  5239 net.cpp:165] Memory required for data: 2091526148
I0826 17:59:16.857681  5239 layer_factory.hpp:77] Creating layer accuracy
I0826 17:59:16.857697  5239 net.cpp:100] Creating Layer accuracy
I0826 17:59:16.857702  5239 net.cpp:434] accuracy <- cropscore_cropscore_0_split_1
I0826 17:59:16.857707  5239 net.cpp:434] accuracy <- label_data_1_split_1
I0826 17:59:16.857712  5239 net.cpp:408] accuracy -> accuracy
I0826 17:59:16.857720  5239 net.cpp:150] Setting up accuracy
I0826 17:59:16.857724  5239 net.cpp:157] Top shape: (1)
I0826 17:59:16.857728  5239 net.cpp:165] Memory required for data: 2091526152
I0826 17:59:16.857729  5239 net.cpp:228] accuracy does not need backward computation.
I0826 17:59:16.857733  5239 net.cpp:226] loss needs backward computation.
I0826 17:59:16.857736  5239 net.cpp:226] cropscore_cropscore_0_split needs backward computation.
I0826 17:59:16.857739  5239 net.cpp:226] cropscore needs backward computation.
I0826 17:59:16.857743  5239 net.cpp:226] upscore2 needs backward computation.
I0826 17:59:16.857745  5239 net.cpp:226] upscore1 needs backward computation.
I0826 17:59:16.857748  5239 net.cpp:226] score needs backward computation.
I0826 17:59:16.857751  5239 net.cpp:226] conv7_1_relu needs backward computation.
I0826 17:59:16.857754  5239 net.cpp:226] conv7_1_bn_scale needs backward computation.
I0826 17:59:16.857758  5239 net.cpp:226] conv7_1_bn needs backward computation.
I0826 17:59:16.857760  5239 net.cpp:226] conv7_1 needs backward computation.
I0826 17:59:16.857764  5239 net.cpp:226] conv6_1_relu needs backward computation.
I0826 17:59:16.857766  5239 net.cpp:226] conv6_1_bn_scale needs backward computation.
I0826 17:59:16.857769  5239 net.cpp:226] conv6_1_bn needs backward computation.
I0826 17:59:16.857771  5239 net.cpp:226] conv6_1 needs backward computation.
I0826 17:59:16.857774  5239 net.cpp:226] conv5_1_relu needs backward computation.
I0826 17:59:16.857777  5239 net.cpp:226] conv5_1_bn_scale needs backward computation.
I0826 17:59:16.857780  5239 net.cpp:226] conv5_1_bn needs backward computation.
I0826 17:59:16.857782  5239 net.cpp:226] conv5_1 needs backward computation.
I0826 17:59:16.857785  5239 net.cpp:226] conv4_1_relu needs backward computation.
I0826 17:59:16.857789  5239 net.cpp:226] conv4_1_bn_scale needs backward computation.
I0826 17:59:16.857790  5239 net.cpp:226] conv4_1_bn needs backward computation.
I0826 17:59:16.857794  5239 net.cpp:226] pool4 needs backward computation.
I0826 17:59:16.857796  5239 net.cpp:226] conv4_1 needs backward computation.
I0826 17:59:16.857810  5239 net.cpp:226] conv3_1_relu needs backward computation.
I0826 17:59:16.857825  5239 net.cpp:226] conv3_1_bn_scale needs backward computation.
I0826 17:59:16.857828  5239 net.cpp:226] conv3_1_bn needs backward computation.
I0826 17:59:16.857833  5239 net.cpp:226] pool3 needs backward computation.
I0826 17:59:16.857838  5239 net.cpp:226] conv3_1 needs backward computation.
I0826 17:59:16.857843  5239 net.cpp:226] conv2_1_relu needs backward computation.
I0826 17:59:16.857847  5239 net.cpp:226] conv2_1_bn_scale needs backward computation.
I0826 17:59:16.857851  5239 net.cpp:226] conv2_1_bn needs backward computation.
I0826 17:59:16.857856  5239 net.cpp:226] pool2 needs backward computation.
I0826 17:59:16.857859  5239 net.cpp:226] conv2_1 needs backward computation.
I0826 17:59:16.857862  5239 net.cpp:226] conv1_1_relu needs backward computation.
I0826 17:59:16.857866  5239 net.cpp:226] conv1_1_bn_scale needs backward computation.
I0826 17:59:16.857867  5239 net.cpp:226] conv1_1_bn needs backward computation.
I0826 17:59:16.857872  5239 net.cpp:226] pool1 needs backward computation.
I0826 17:59:16.857873  5239 net.cpp:226] conv1_1 needs backward computation.
I0826 17:59:16.857877  5239 net.cpp:228] label_data_1_split does not need backward computation.
I0826 17:59:16.857882  5239 net.cpp:228] image_data_0_split does not need backward computation.
I0826 17:59:16.857887  5239 net.cpp:228] data does not need backward computation.
I0826 17:59:16.857889  5239 net.cpp:270] This network produces output accuracy
I0826 17:59:16.857892  5239 net.cpp:270] This network produces output loss
I0826 17:59:16.857911  5239 net.cpp:283] Network initialization done.
I0826 17:59:16.858716  5239 solver.cpp:181] Creating test net (#0) specified by net file: portrait_train_test_one_stage.prototxt4
I0826 17:59:16.858763  5239 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0826 17:59:16.858919  5239 net.cpp:58] Initializing net from parameters: 
name: "segmentation"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "SegData"
  top: "image"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 200
  }
  data_param {
    source: "/raid/xuehan/segmentation_test_split"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "image"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 50
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1_1_bn"
  type: "BatchNorm"
  bottom: "pool1"
  top: "conv1_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv1_1_bn_scale"
  type: "Scale"
  bottom: "conv1_1_bn"
  top: "conv1_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_1_relu"
  type: "ReLU"
  bottom: "conv1_1_bn"
  top: "conv1_1_bn"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv1_1_bn"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_1"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1_bn"
  type: "BatchNorm"
  bottom: "pool2"
  top: "conv2_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv2_1_bn_scale"
  type: "Scale"
  bottom: "conv2_1_bn"
  top: "conv2_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1_relu"
  type: "ReLU"
  bottom: "conv2_1_bn"
  top: "conv2_1_bn"
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv2_1_bn"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_1"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1_bn"
  type: "BatchNorm"
  bottom: "pool3"
  top: "conv3_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv3_1_bn_scale"
  type: "Scale"
  bottom: "conv3_1_bn"
  top: "conv3_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1_relu"
  type: "ReLU"
  bottom: "conv3_1_bn"
  top: "conv3_1_bn"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv3_1_bn"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_1"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1_bn"
  type: "BatchNorm"
  bottom: "pool4"
  top: "conv4_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv4_1_bn_scale"
  type: "Scale"
  bottom: "conv4_1_bn"
  top: "conv4_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1_relu"
  type: "ReLU"
  bottom: "conv4_1_bn"
  top: "conv4_1_bn"
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "conv4_1_bn"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv5_1_bn"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv5_1_bn_scale"
  type: "Scale"
  bottom: "conv5_1_bn"
  top: "conv5_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_1_relu"
  type: "ReLU"
  bottom: "conv5_1_bn"
  top: "conv5_1_bn"
}
layer {
  name: "conv6_1"
  type: "Convolution"
  bottom: "conv5_1_bn"
  top: "conv6_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv6_1_bn"
  type: "BatchNorm"
  bottom: "conv6_1"
  top: "conv6_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv6_1_bn_scale"
  type: "Scale"
  bottom: "conv6_1_bn"
  top: "conv6_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv6_1_relu"
  type: "ReLU"
  bottom: "conv6_1_bn"
  top: "conv6_1_bn"
}
layer {
  name: "conv7_1"
  type: "Convolution"
  bottom: "conv6_1_bn"
  top: "conv7_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv7_1_bn"
  type: "BatchNorm"
  bottom: "conv7_1"
  top: "conv7_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv7_1_bn_scale"
  type: "Scale"
  bottom: "conv7_1_bn"
  top: "conv7_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv7_1_relu"
  type: "ReLU"
  bottom: "conv7_1_bn"
  top: "conv7_1_bn"
}
layer {
  name: "score"
  type: "Convolution"
  bottom: "conv7_1_bn"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 4
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "upscore1"
  type: "Deconvolution"
  bottom: "score"
  top: "upscore1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 4
    bias_term: false
    pad: 0
    kernel_size: 8
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "upscore2"
  type: "Deconvolution"
  bottom: "upscore1"
  top: "upscore2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 4
    bias_term: false
    pad: 0
    kernel_size: 8
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "cropscore"
  type: "Crop"
  bottom: "upscore2"
  bottom: "image"
  top: "cropscore"
  crop_param {
    axis: 2
    offset: 14
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "cropscore"
  bottom: "label"
  top: "loss"
  loss_weight: 1
  loss_param {
    normalize: false
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "cropscore"
  bottom: "label"
  top: "accuracy"
}
I0826 17:59:16.859040  5239 layer_factory.hpp:77] Creating layer data
I0826 17:59:16.859117  5239 net.cpp:100] Creating Layer data
I0826 17:59:16.859124  5239 net.cpp:408] data -> image
I0826 17:59:16.859132  5239 net.cpp:408] data -> label
I0826 17:59:16.860982  5245 db_lmdb.cpp:35] Opened lmdb /raid/xuehan/segmentation_test_split
I0826 17:59:16.861165  5239 seg_data_layer.cpp:38] 200 200 4
I0826 17:59:16.861295  5239 seg_data_layer.cpp:51] output data size: 64,3,200,200
I0826 17:59:16.861366  5239 seg_data_layer.cpp:63] output label size: 64,1,200,200
I0826 17:59:16.932874  5239 net.cpp:150] Setting up data
I0826 17:59:16.932911  5239 net.cpp:157] Top shape: 64 3 200 200 (7680000)
I0826 17:59:16.932920  5239 net.cpp:157] Top shape: 64 1 200 200 (2560000)
I0826 17:59:16.932924  5239 net.cpp:165] Memory required for data: 40960000
I0826 17:59:16.932931  5239 layer_factory.hpp:77] Creating layer image_data_0_split
I0826 17:59:16.932945  5239 net.cpp:100] Creating Layer image_data_0_split
I0826 17:59:16.932950  5239 net.cpp:434] image_data_0_split <- image
I0826 17:59:16.932961  5239 net.cpp:408] image_data_0_split -> image_data_0_split_0
I0826 17:59:16.932972  5239 net.cpp:408] image_data_0_split -> image_data_0_split_1
I0826 17:59:16.933042  5239 net.cpp:150] Setting up image_data_0_split
I0826 17:59:16.933051  5239 net.cpp:157] Top shape: 64 3 200 200 (7680000)
I0826 17:59:16.933058  5239 net.cpp:157] Top shape: 64 3 200 200 (7680000)
I0826 17:59:16.933061  5239 net.cpp:165] Memory required for data: 102400000
I0826 17:59:16.933066  5239 layer_factory.hpp:77] Creating layer label_data_1_split
I0826 17:59:16.933076  5239 net.cpp:100] Creating Layer label_data_1_split
I0826 17:59:16.933082  5239 net.cpp:434] label_data_1_split <- label
I0826 17:59:16.933091  5239 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0826 17:59:16.933099  5239 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0826 17:59:16.933132  5239 net.cpp:150] Setting up label_data_1_split
I0826 17:59:16.933140  5239 net.cpp:157] Top shape: 64 1 200 200 (2560000)
I0826 17:59:16.933148  5239 net.cpp:157] Top shape: 64 1 200 200 (2560000)
I0826 17:59:16.933153  5239 net.cpp:165] Memory required for data: 122880000
I0826 17:59:16.933159  5239 layer_factory.hpp:77] Creating layer conv1_1
I0826 17:59:16.933174  5239 net.cpp:100] Creating Layer conv1_1
I0826 17:59:16.933179  5239 net.cpp:434] conv1_1 <- image_data_0_split_0
I0826 17:59:16.933189  5239 net.cpp:408] conv1_1 -> conv1_1
I0826 17:59:16.933399  5239 net.cpp:150] Setting up conv1_1
I0826 17:59:16.933410  5239 net.cpp:157] Top shape: 64 8 298 298 (45467648)
I0826 17:59:16.933416  5239 net.cpp:165] Memory required for data: 304750592
I0826 17:59:16.933426  5239 layer_factory.hpp:77] Creating layer pool1
I0826 17:59:16.933435  5239 net.cpp:100] Creating Layer pool1
I0826 17:59:16.933440  5239 net.cpp:434] pool1 <- conv1_1
I0826 17:59:16.933454  5239 net.cpp:408] pool1 -> pool1
I0826 17:59:16.933503  5239 net.cpp:150] Setting up pool1
I0826 17:59:16.933511  5239 net.cpp:157] Top shape: 64 8 149 149 (11366912)
I0826 17:59:16.933516  5239 net.cpp:165] Memory required for data: 350218240
I0826 17:59:16.933522  5239 layer_factory.hpp:77] Creating layer conv1_1_bn
I0826 17:59:16.933531  5239 net.cpp:100] Creating Layer conv1_1_bn
I0826 17:59:16.933537  5239 net.cpp:434] conv1_1_bn <- pool1
I0826 17:59:16.933545  5239 net.cpp:408] conv1_1_bn -> conv1_1_bn
I0826 17:59:16.933773  5239 net.cpp:150] Setting up conv1_1_bn
I0826 17:59:16.933782  5239 net.cpp:157] Top shape: 64 8 149 149 (11366912)
I0826 17:59:16.933786  5239 net.cpp:165] Memory required for data: 395685888
I0826 17:59:16.933799  5239 layer_factory.hpp:77] Creating layer conv1_1_bn_scale
I0826 17:59:16.933807  5239 net.cpp:100] Creating Layer conv1_1_bn_scale
I0826 17:59:16.933812  5239 net.cpp:434] conv1_1_bn_scale <- conv1_1_bn
I0826 17:59:16.933818  5239 net.cpp:395] conv1_1_bn_scale -> conv1_1_bn (in-place)
I0826 17:59:16.933864  5239 layer_factory.hpp:77] Creating layer conv1_1_bn_scale
I0826 17:59:16.934022  5239 net.cpp:150] Setting up conv1_1_bn_scale
I0826 17:59:16.934036  5239 net.cpp:157] Top shape: 64 8 149 149 (11366912)
I0826 17:59:16.934041  5239 net.cpp:165] Memory required for data: 441153536
I0826 17:59:16.934051  5239 layer_factory.hpp:77] Creating layer conv1_1_relu
I0826 17:59:16.934061  5239 net.cpp:100] Creating Layer conv1_1_relu
I0826 17:59:16.934065  5239 net.cpp:434] conv1_1_relu <- conv1_1_bn
I0826 17:59:16.934070  5239 net.cpp:395] conv1_1_relu -> conv1_1_bn (in-place)
I0826 17:59:16.934077  5239 net.cpp:150] Setting up conv1_1_relu
I0826 17:59:16.934082  5239 net.cpp:157] Top shape: 64 8 149 149 (11366912)
I0826 17:59:16.934087  5239 net.cpp:165] Memory required for data: 486621184
I0826 17:59:16.934090  5239 layer_factory.hpp:77] Creating layer conv2_1
I0826 17:59:16.934101  5239 net.cpp:100] Creating Layer conv2_1
I0826 17:59:16.934105  5239 net.cpp:434] conv2_1 <- conv1_1_bn
I0826 17:59:16.934113  5239 net.cpp:408] conv2_1 -> conv2_1
I0826 17:59:16.934386  5239 net.cpp:150] Setting up conv2_1
I0826 17:59:16.934401  5239 net.cpp:157] Top shape: 64 16 149 149 (22733824)
I0826 17:59:16.934407  5239 net.cpp:165] Memory required for data: 577556480
I0826 17:59:16.934415  5239 layer_factory.hpp:77] Creating layer pool2
I0826 17:59:16.934424  5239 net.cpp:100] Creating Layer pool2
I0826 17:59:16.934429  5239 net.cpp:434] pool2 <- conv2_1
I0826 17:59:16.934434  5239 net.cpp:408] pool2 -> pool2
I0826 17:59:16.934471  5239 net.cpp:150] Setting up pool2
I0826 17:59:16.934479  5239 net.cpp:157] Top shape: 64 16 75 75 (5760000)
I0826 17:59:16.934484  5239 net.cpp:165] Memory required for data: 600596480
I0826 17:59:16.934489  5239 layer_factory.hpp:77] Creating layer conv2_1_bn
I0826 17:59:16.934495  5239 net.cpp:100] Creating Layer conv2_1_bn
I0826 17:59:16.934500  5239 net.cpp:434] conv2_1_bn <- pool2
I0826 17:59:16.934507  5239 net.cpp:408] conv2_1_bn -> conv2_1_bn
I0826 17:59:16.934717  5239 net.cpp:150] Setting up conv2_1_bn
I0826 17:59:16.934725  5239 net.cpp:157] Top shape: 64 16 75 75 (5760000)
I0826 17:59:16.934729  5239 net.cpp:165] Memory required for data: 623636480
I0826 17:59:16.934744  5239 layer_factory.hpp:77] Creating layer conv2_1_bn_scale
I0826 17:59:16.934752  5239 net.cpp:100] Creating Layer conv2_1_bn_scale
I0826 17:59:16.934757  5239 net.cpp:434] conv2_1_bn_scale <- conv2_1_bn
I0826 17:59:16.934762  5239 net.cpp:395] conv2_1_bn_scale -> conv2_1_bn (in-place)
I0826 17:59:16.934808  5239 layer_factory.hpp:77] Creating layer conv2_1_bn_scale
I0826 17:59:16.934936  5239 net.cpp:150] Setting up conv2_1_bn_scale
I0826 17:59:16.934945  5239 net.cpp:157] Top shape: 64 16 75 75 (5760000)
I0826 17:59:16.934948  5239 net.cpp:165] Memory required for data: 646676480
I0826 17:59:16.934955  5239 layer_factory.hpp:77] Creating layer conv2_1_relu
I0826 17:59:16.934963  5239 net.cpp:100] Creating Layer conv2_1_relu
I0826 17:59:16.934968  5239 net.cpp:434] conv2_1_relu <- conv2_1_bn
I0826 17:59:16.934979  5239 net.cpp:395] conv2_1_relu -> conv2_1_bn (in-place)
I0826 17:59:16.934996  5239 net.cpp:150] Setting up conv2_1_relu
I0826 17:59:16.935005  5239 net.cpp:157] Top shape: 64 16 75 75 (5760000)
I0826 17:59:16.935009  5239 net.cpp:165] Memory required for data: 669716480
I0826 17:59:16.935014  5239 layer_factory.hpp:77] Creating layer conv3_1
I0826 17:59:16.935024  5239 net.cpp:100] Creating Layer conv3_1
I0826 17:59:16.935029  5239 net.cpp:434] conv3_1 <- conv2_1_bn
I0826 17:59:16.935034  5239 net.cpp:408] conv3_1 -> conv3_1
I0826 17:59:16.935379  5239 net.cpp:150] Setting up conv3_1
I0826 17:59:16.935389  5239 net.cpp:157] Top shape: 64 32 75 75 (11520000)
I0826 17:59:16.935395  5239 net.cpp:165] Memory required for data: 715796480
I0826 17:59:16.935400  5239 layer_factory.hpp:77] Creating layer pool3
I0826 17:59:16.935406  5239 net.cpp:100] Creating Layer pool3
I0826 17:59:16.935410  5239 net.cpp:434] pool3 <- conv3_1
I0826 17:59:16.935416  5239 net.cpp:408] pool3 -> pool3
I0826 17:59:16.935452  5239 net.cpp:150] Setting up pool3
I0826 17:59:16.935461  5239 net.cpp:157] Top shape: 64 32 38 38 (2957312)
I0826 17:59:16.935467  5239 net.cpp:165] Memory required for data: 727625728
I0826 17:59:16.935472  5239 layer_factory.hpp:77] Creating layer conv3_1_bn
I0826 17:59:16.935480  5239 net.cpp:100] Creating Layer conv3_1_bn
I0826 17:59:16.935485  5239 net.cpp:434] conv3_1_bn <- pool3
I0826 17:59:16.935493  5239 net.cpp:408] conv3_1_bn -> conv3_1_bn
I0826 17:59:16.935698  5239 net.cpp:150] Setting up conv3_1_bn
I0826 17:59:16.935706  5239 net.cpp:157] Top shape: 64 32 38 38 (2957312)
I0826 17:59:16.935710  5239 net.cpp:165] Memory required for data: 739454976
I0826 17:59:16.935719  5239 layer_factory.hpp:77] Creating layer conv3_1_bn_scale
I0826 17:59:16.935729  5239 net.cpp:100] Creating Layer conv3_1_bn_scale
I0826 17:59:16.935734  5239 net.cpp:434] conv3_1_bn_scale <- conv3_1_bn
I0826 17:59:16.935739  5239 net.cpp:395] conv3_1_bn_scale -> conv3_1_bn (in-place)
I0826 17:59:16.935784  5239 layer_factory.hpp:77] Creating layer conv3_1_bn_scale
I0826 17:59:16.935905  5239 net.cpp:150] Setting up conv3_1_bn_scale
I0826 17:59:16.935914  5239 net.cpp:157] Top shape: 64 32 38 38 (2957312)
I0826 17:59:16.935919  5239 net.cpp:165] Memory required for data: 751284224
I0826 17:59:16.935931  5239 layer_factory.hpp:77] Creating layer conv3_1_relu
I0826 17:59:16.935938  5239 net.cpp:100] Creating Layer conv3_1_relu
I0826 17:59:16.935945  5239 net.cpp:434] conv3_1_relu <- conv3_1_bn
I0826 17:59:16.935952  5239 net.cpp:395] conv3_1_relu -> conv3_1_bn (in-place)
I0826 17:59:16.935961  5239 net.cpp:150] Setting up conv3_1_relu
I0826 17:59:16.935967  5239 net.cpp:157] Top shape: 64 32 38 38 (2957312)
I0826 17:59:16.935971  5239 net.cpp:165] Memory required for data: 763113472
I0826 17:59:16.935974  5239 layer_factory.hpp:77] Creating layer conv4_1
I0826 17:59:16.935984  5239 net.cpp:100] Creating Layer conv4_1
I0826 17:59:16.935988  5239 net.cpp:434] conv4_1 <- conv3_1_bn
I0826 17:59:16.935994  5239 net.cpp:408] conv4_1 -> conv4_1
I0826 17:59:16.936800  5239 net.cpp:150] Setting up conv4_1
I0826 17:59:16.936812  5239 net.cpp:157] Top shape: 64 64 38 38 (5914624)
I0826 17:59:16.936818  5239 net.cpp:165] Memory required for data: 786771968
I0826 17:59:16.936825  5239 layer_factory.hpp:77] Creating layer pool4
I0826 17:59:16.936832  5239 net.cpp:100] Creating Layer pool4
I0826 17:59:16.936836  5239 net.cpp:434] pool4 <- conv4_1
I0826 17:59:16.936843  5239 net.cpp:408] pool4 -> pool4
I0826 17:59:16.936882  5239 net.cpp:150] Setting up pool4
I0826 17:59:16.936892  5239 net.cpp:157] Top shape: 64 64 19 19 (1478656)
I0826 17:59:16.936897  5239 net.cpp:165] Memory required for data: 792686592
I0826 17:59:16.936902  5239 layer_factory.hpp:77] Creating layer conv4_1_bn
I0826 17:59:16.936910  5239 net.cpp:100] Creating Layer conv4_1_bn
I0826 17:59:16.936914  5239 net.cpp:434] conv4_1_bn <- pool4
I0826 17:59:16.936921  5239 net.cpp:408] conv4_1_bn -> conv4_1_bn
I0826 17:59:16.937120  5239 net.cpp:150] Setting up conv4_1_bn
I0826 17:59:16.937134  5239 net.cpp:157] Top shape: 64 64 19 19 (1478656)
I0826 17:59:16.937144  5239 net.cpp:165] Memory required for data: 798601216
I0826 17:59:16.937153  5239 layer_factory.hpp:77] Creating layer conv4_1_bn_scale
I0826 17:59:16.937160  5239 net.cpp:100] Creating Layer conv4_1_bn_scale
I0826 17:59:16.937165  5239 net.cpp:434] conv4_1_bn_scale <- conv4_1_bn
I0826 17:59:16.937171  5239 net.cpp:395] conv4_1_bn_scale -> conv4_1_bn (in-place)
I0826 17:59:16.937217  5239 layer_factory.hpp:77] Creating layer conv4_1_bn_scale
I0826 17:59:16.937337  5239 net.cpp:150] Setting up conv4_1_bn_scale
I0826 17:59:16.937346  5239 net.cpp:157] Top shape: 64 64 19 19 (1478656)
I0826 17:59:16.937350  5239 net.cpp:165] Memory required for data: 804515840
I0826 17:59:16.937357  5239 layer_factory.hpp:77] Creating layer conv4_1_relu
I0826 17:59:16.937366  5239 net.cpp:100] Creating Layer conv4_1_relu
I0826 17:59:16.937371  5239 net.cpp:434] conv4_1_relu <- conv4_1_bn
I0826 17:59:16.937378  5239 net.cpp:395] conv4_1_relu -> conv4_1_bn (in-place)
I0826 17:59:16.937386  5239 net.cpp:150] Setting up conv4_1_relu
I0826 17:59:16.937392  5239 net.cpp:157] Top shape: 64 64 19 19 (1478656)
I0826 17:59:16.937397  5239 net.cpp:165] Memory required for data: 810430464
I0826 17:59:16.937400  5239 layer_factory.hpp:77] Creating layer conv5_1
I0826 17:59:16.937409  5239 net.cpp:100] Creating Layer conv5_1
I0826 17:59:16.937413  5239 net.cpp:434] conv5_1 <- conv4_1_bn
I0826 17:59:16.937420  5239 net.cpp:408] conv5_1 -> conv5_1
I0826 17:59:16.940182  5239 net.cpp:150] Setting up conv5_1
I0826 17:59:16.940215  5239 net.cpp:157] Top shape: 64 64 17 17 (1183744)
I0826 17:59:16.940222  5239 net.cpp:165] Memory required for data: 815165440
I0826 17:59:16.940232  5239 layer_factory.hpp:77] Creating layer conv5_1_bn
I0826 17:59:16.940243  5239 net.cpp:100] Creating Layer conv5_1_bn
I0826 17:59:16.940249  5239 net.cpp:434] conv5_1_bn <- conv5_1
I0826 17:59:16.940258  5239 net.cpp:408] conv5_1_bn -> conv5_1_bn
I0826 17:59:16.944811  5239 net.cpp:150] Setting up conv5_1_bn
I0826 17:59:16.944844  5239 net.cpp:157] Top shape: 64 64 17 17 (1183744)
I0826 17:59:16.944849  5239 net.cpp:165] Memory required for data: 819900416
I0826 17:59:16.944864  5239 layer_factory.hpp:77] Creating layer conv5_1_bn_scale
I0826 17:59:16.944878  5239 net.cpp:100] Creating Layer conv5_1_bn_scale
I0826 17:59:16.944887  5239 net.cpp:434] conv5_1_bn_scale <- conv5_1_bn
I0826 17:59:16.944897  5239 net.cpp:395] conv5_1_bn_scale -> conv5_1_bn (in-place)
I0826 17:59:16.944947  5239 layer_factory.hpp:77] Creating layer conv5_1_bn_scale
I0826 17:59:16.945083  5239 net.cpp:150] Setting up conv5_1_bn_scale
I0826 17:59:16.945093  5239 net.cpp:157] Top shape: 64 64 17 17 (1183744)
I0826 17:59:16.945097  5239 net.cpp:165] Memory required for data: 824635392
I0826 17:59:16.945104  5239 layer_factory.hpp:77] Creating layer conv5_1_relu
I0826 17:59:16.945111  5239 net.cpp:100] Creating Layer conv5_1_relu
I0826 17:59:16.945116  5239 net.cpp:434] conv5_1_relu <- conv5_1_bn
I0826 17:59:16.945123  5239 net.cpp:395] conv5_1_relu -> conv5_1_bn (in-place)
I0826 17:59:16.945132  5239 net.cpp:150] Setting up conv5_1_relu
I0826 17:59:16.945138  5239 net.cpp:157] Top shape: 64 64 17 17 (1183744)
I0826 17:59:16.945143  5239 net.cpp:165] Memory required for data: 829370368
I0826 17:59:16.945149  5239 layer_factory.hpp:77] Creating layer conv6_1
I0826 17:59:16.945163  5239 net.cpp:100] Creating Layer conv6_1
I0826 17:59:16.945169  5239 net.cpp:434] conv6_1 <- conv5_1_bn
I0826 17:59:16.945175  5239 net.cpp:408] conv6_1 -> conv6_1
I0826 17:59:16.946727  5239 net.cpp:150] Setting up conv6_1
I0826 17:59:16.946751  5239 net.cpp:157] Top shape: 64 64 15 15 (921600)
I0826 17:59:16.946758  5239 net.cpp:165] Memory required for data: 833056768
I0826 17:59:16.946765  5239 layer_factory.hpp:77] Creating layer conv6_1_bn
I0826 17:59:16.946774  5239 net.cpp:100] Creating Layer conv6_1_bn
I0826 17:59:16.946780  5239 net.cpp:434] conv6_1_bn <- conv6_1
I0826 17:59:16.946789  5239 net.cpp:408] conv6_1_bn -> conv6_1_bn
I0826 17:59:16.947015  5239 net.cpp:150] Setting up conv6_1_bn
I0826 17:59:16.947036  5239 net.cpp:157] Top shape: 64 64 15 15 (921600)
I0826 17:59:16.947041  5239 net.cpp:165] Memory required for data: 836743168
I0826 17:59:16.947058  5239 layer_factory.hpp:77] Creating layer conv6_1_bn_scale
I0826 17:59:16.947067  5239 net.cpp:100] Creating Layer conv6_1_bn_scale
I0826 17:59:16.947072  5239 net.cpp:434] conv6_1_bn_scale <- conv6_1_bn
I0826 17:59:16.947080  5239 net.cpp:395] conv6_1_bn_scale -> conv6_1_bn (in-place)
I0826 17:59:16.947126  5239 layer_factory.hpp:77] Creating layer conv6_1_bn_scale
I0826 17:59:16.947262  5239 net.cpp:150] Setting up conv6_1_bn_scale
I0826 17:59:16.947271  5239 net.cpp:157] Top shape: 64 64 15 15 (921600)
I0826 17:59:16.947275  5239 net.cpp:165] Memory required for data: 840429568
I0826 17:59:16.947283  5239 layer_factory.hpp:77] Creating layer conv6_1_relu
I0826 17:59:16.947290  5239 net.cpp:100] Creating Layer conv6_1_relu
I0826 17:59:16.947295  5239 net.cpp:434] conv6_1_relu <- conv6_1_bn
I0826 17:59:16.947304  5239 net.cpp:395] conv6_1_relu -> conv6_1_bn (in-place)
I0826 17:59:16.947311  5239 net.cpp:150] Setting up conv6_1_relu
I0826 17:59:16.947317  5239 net.cpp:157] Top shape: 64 64 15 15 (921600)
I0826 17:59:16.947321  5239 net.cpp:165] Memory required for data: 844115968
I0826 17:59:16.947325  5239 layer_factory.hpp:77] Creating layer conv7_1
I0826 17:59:16.947335  5239 net.cpp:100] Creating Layer conv7_1
I0826 17:59:16.947340  5239 net.cpp:434] conv7_1 <- conv6_1_bn
I0826 17:59:16.947346  5239 net.cpp:408] conv7_1 -> conv7_1
I0826 17:59:16.950120  5239 net.cpp:150] Setting up conv7_1
I0826 17:59:16.950155  5239 net.cpp:157] Top shape: 64 128 13 13 (1384448)
I0826 17:59:16.950163  5239 net.cpp:165] Memory required for data: 849653760
I0826 17:59:16.950176  5239 layer_factory.hpp:77] Creating layer conv7_1_bn
I0826 17:59:16.950197  5239 net.cpp:100] Creating Layer conv7_1_bn
I0826 17:59:16.950207  5239 net.cpp:434] conv7_1_bn <- conv7_1
I0826 17:59:16.950218  5239 net.cpp:408] conv7_1_bn -> conv7_1_bn
I0826 17:59:16.951932  5239 net.cpp:150] Setting up conv7_1_bn
I0826 17:59:16.951963  5239 net.cpp:157] Top shape: 64 128 13 13 (1384448)
I0826 17:59:16.951967  5239 net.cpp:165] Memory required for data: 855191552
I0826 17:59:16.951982  5239 layer_factory.hpp:77] Creating layer conv7_1_bn_scale
I0826 17:59:16.951992  5239 net.cpp:100] Creating Layer conv7_1_bn_scale
I0826 17:59:16.951998  5239 net.cpp:434] conv7_1_bn_scale <- conv7_1_bn
I0826 17:59:16.952006  5239 net.cpp:395] conv7_1_bn_scale -> conv7_1_bn (in-place)
I0826 17:59:16.952057  5239 layer_factory.hpp:77] Creating layer conv7_1_bn_scale
I0826 17:59:16.952163  5239 net.cpp:150] Setting up conv7_1_bn_scale
I0826 17:59:16.952172  5239 net.cpp:157] Top shape: 64 128 13 13 (1384448)
I0826 17:59:16.952177  5239 net.cpp:165] Memory required for data: 860729344
I0826 17:59:16.952183  5239 layer_factory.hpp:77] Creating layer conv7_1_relu
I0826 17:59:16.952193  5239 net.cpp:100] Creating Layer conv7_1_relu
I0826 17:59:16.952198  5239 net.cpp:434] conv7_1_relu <- conv7_1_bn
I0826 17:59:16.952203  5239 net.cpp:395] conv7_1_relu -> conv7_1_bn (in-place)
I0826 17:59:16.952210  5239 net.cpp:150] Setting up conv7_1_relu
I0826 17:59:16.952216  5239 net.cpp:157] Top shape: 64 128 13 13 (1384448)
I0826 17:59:16.952220  5239 net.cpp:165] Memory required for data: 866267136
I0826 17:59:16.952225  5239 layer_factory.hpp:77] Creating layer score
I0826 17:59:16.952239  5239 net.cpp:100] Creating Layer score
I0826 17:59:16.952242  5239 net.cpp:434] score <- conv7_1_bn
I0826 17:59:16.952250  5239 net.cpp:408] score -> score
I0826 17:59:16.952517  5239 net.cpp:150] Setting up score
I0826 17:59:16.952527  5239 net.cpp:157] Top shape: 64 4 13 13 (43264)
I0826 17:59:16.952530  5239 net.cpp:165] Memory required for data: 866440192
I0826 17:59:16.952538  5239 layer_factory.hpp:77] Creating layer upscore1
I0826 17:59:16.952548  5239 net.cpp:100] Creating Layer upscore1
I0826 17:59:16.952553  5239 net.cpp:434] upscore1 <- score
I0826 17:59:16.952571  5239 net.cpp:408] upscore1 -> upscore1
I0826 17:59:16.952797  5239 net.cpp:150] Setting up upscore1
I0826 17:59:16.952807  5239 net.cpp:157] Top shape: 64 4 56 56 (802816)
I0826 17:59:16.952811  5239 net.cpp:165] Memory required for data: 869651456
I0826 17:59:16.952817  5239 layer_factory.hpp:77] Creating layer upscore2
I0826 17:59:16.952826  5239 net.cpp:100] Creating Layer upscore2
I0826 17:59:16.952829  5239 net.cpp:434] upscore2 <- upscore1
I0826 17:59:16.952839  5239 net.cpp:408] upscore2 -> upscore2
I0826 17:59:16.953060  5239 net.cpp:150] Setting up upscore2
I0826 17:59:16.953073  5239 net.cpp:157] Top shape: 64 4 228 228 (13307904)
I0826 17:59:16.953078  5239 net.cpp:165] Memory required for data: 922883072
I0826 17:59:16.953084  5239 layer_factory.hpp:77] Creating layer cropscore
I0826 17:59:16.953094  5239 net.cpp:100] Creating Layer cropscore
I0826 17:59:16.953100  5239 net.cpp:434] cropscore <- upscore2
I0826 17:59:16.953106  5239 net.cpp:434] cropscore <- image_data_0_split_1
I0826 17:59:16.953112  5239 net.cpp:408] cropscore -> cropscore
I0826 17:59:16.953138  5239 net.cpp:150] Setting up cropscore
I0826 17:59:16.953147  5239 net.cpp:157] Top shape: 64 4 200 200 (10240000)
I0826 17:59:16.953151  5239 net.cpp:165] Memory required for data: 963843072
I0826 17:59:16.953156  5239 layer_factory.hpp:77] Creating layer cropscore_cropscore_0_split
I0826 17:59:16.953164  5239 net.cpp:100] Creating Layer cropscore_cropscore_0_split
I0826 17:59:16.953169  5239 net.cpp:434] cropscore_cropscore_0_split <- cropscore
I0826 17:59:16.953178  5239 net.cpp:408] cropscore_cropscore_0_split -> cropscore_cropscore_0_split_0
I0826 17:59:16.953188  5239 net.cpp:408] cropscore_cropscore_0_split -> cropscore_cropscore_0_split_1
I0826 17:59:16.953230  5239 net.cpp:150] Setting up cropscore_cropscore_0_split
I0826 17:59:16.953243  5239 net.cpp:157] Top shape: 64 4 200 200 (10240000)
I0826 17:59:16.953248  5239 net.cpp:157] Top shape: 64 4 200 200 (10240000)
I0826 17:59:16.953253  5239 net.cpp:165] Memory required for data: 1045763072
I0826 17:59:16.953258  5239 layer_factory.hpp:77] Creating layer loss
I0826 17:59:16.953269  5239 net.cpp:100] Creating Layer loss
I0826 17:59:16.953275  5239 net.cpp:434] loss <- cropscore_cropscore_0_split_0
I0826 17:59:16.953281  5239 net.cpp:434] loss <- label_data_1_split_0
I0826 17:59:16.953289  5239 net.cpp:408] loss -> loss
I0826 17:59:16.953299  5239 layer_factory.hpp:77] Creating layer loss
I0826 17:59:16.975704  5239 net.cpp:150] Setting up loss
I0826 17:59:16.975745  5239 net.cpp:157] Top shape: (1)
I0826 17:59:16.975751  5239 net.cpp:160]     with loss weight 1
I0826 17:59:16.975769  5239 net.cpp:165] Memory required for data: 1045763076
I0826 17:59:16.975777  5239 layer_factory.hpp:77] Creating layer accuracy
I0826 17:59:16.975791  5239 net.cpp:100] Creating Layer accuracy
I0826 17:59:16.975798  5239 net.cpp:434] accuracy <- cropscore_cropscore_0_split_1
I0826 17:59:16.975807  5239 net.cpp:434] accuracy <- label_data_1_split_1
I0826 17:59:16.975814  5239 net.cpp:408] accuracy -> accuracy
I0826 17:59:16.975826  5239 net.cpp:150] Setting up accuracy
I0826 17:59:16.975833  5239 net.cpp:157] Top shape: (1)
I0826 17:59:16.975837  5239 net.cpp:165] Memory required for data: 1045763080
I0826 17:59:16.975841  5239 net.cpp:228] accuracy does not need backward computation.
I0826 17:59:16.975847  5239 net.cpp:226] loss needs backward computation.
I0826 17:59:16.975852  5239 net.cpp:226] cropscore_cropscore_0_split needs backward computation.
I0826 17:59:16.975857  5239 net.cpp:226] cropscore needs backward computation.
I0826 17:59:16.975862  5239 net.cpp:226] upscore2 needs backward computation.
I0826 17:59:16.975867  5239 net.cpp:226] upscore1 needs backward computation.
I0826 17:59:16.975872  5239 net.cpp:226] score needs backward computation.
I0826 17:59:16.975875  5239 net.cpp:226] conv7_1_relu needs backward computation.
I0826 17:59:16.975879  5239 net.cpp:226] conv7_1_bn_scale needs backward computation.
I0826 17:59:16.975884  5239 net.cpp:226] conv7_1_bn needs backward computation.
I0826 17:59:16.975900  5239 net.cpp:226] conv7_1 needs backward computation.
I0826 17:59:16.975914  5239 net.cpp:226] conv6_1_relu needs backward computation.
I0826 17:59:16.975919  5239 net.cpp:226] conv6_1_bn_scale needs backward computation.
I0826 17:59:16.975924  5239 net.cpp:226] conv6_1_bn needs backward computation.
I0826 17:59:16.975929  5239 net.cpp:226] conv6_1 needs backward computation.
I0826 17:59:16.975932  5239 net.cpp:226] conv5_1_relu needs backward computation.
I0826 17:59:16.975937  5239 net.cpp:226] conv5_1_bn_scale needs backward computation.
I0826 17:59:16.975941  5239 net.cpp:226] conv5_1_bn needs backward computation.
I0826 17:59:16.975946  5239 net.cpp:226] conv5_1 needs backward computation.
I0826 17:59:16.975950  5239 net.cpp:226] conv4_1_relu needs backward computation.
I0826 17:59:16.975955  5239 net.cpp:226] conv4_1_bn_scale needs backward computation.
I0826 17:59:16.975960  5239 net.cpp:226] conv4_1_bn needs backward computation.
I0826 17:59:16.975963  5239 net.cpp:226] pool4 needs backward computation.
I0826 17:59:16.975968  5239 net.cpp:226] conv4_1 needs backward computation.
I0826 17:59:16.975973  5239 net.cpp:226] conv3_1_relu needs backward computation.
I0826 17:59:16.975977  5239 net.cpp:226] conv3_1_bn_scale needs backward computation.
I0826 17:59:16.975981  5239 net.cpp:226] conv3_1_bn needs backward computation.
I0826 17:59:16.975986  5239 net.cpp:226] pool3 needs backward computation.
I0826 17:59:16.975991  5239 net.cpp:226] conv3_1 needs backward computation.
I0826 17:59:16.975994  5239 net.cpp:226] conv2_1_relu needs backward computation.
I0826 17:59:16.975998  5239 net.cpp:226] conv2_1_bn_scale needs backward computation.
I0826 17:59:16.976003  5239 net.cpp:226] conv2_1_bn needs backward computation.
I0826 17:59:16.976008  5239 net.cpp:226] pool2 needs backward computation.
I0826 17:59:16.976013  5239 net.cpp:226] conv2_1 needs backward computation.
I0826 17:59:16.976017  5239 net.cpp:226] conv1_1_relu needs backward computation.
I0826 17:59:16.976022  5239 net.cpp:226] conv1_1_bn_scale needs backward computation.
I0826 17:59:16.976027  5239 net.cpp:226] conv1_1_bn needs backward computation.
I0826 17:59:16.976037  5239 net.cpp:226] pool1 needs backward computation.
I0826 17:59:16.976042  5239 net.cpp:226] conv1_1 needs backward computation.
I0826 17:59:16.976048  5239 net.cpp:228] label_data_1_split does not need backward computation.
I0826 17:59:16.976053  5239 net.cpp:228] image_data_0_split does not need backward computation.
I0826 17:59:16.976058  5239 net.cpp:228] data does not need backward computation.
I0826 17:59:16.976063  5239 net.cpp:270] This network produces output accuracy
I0826 17:59:16.976068  5239 net.cpp:270] This network produces output loss
I0826 17:59:16.976096  5239 net.cpp:283] Network initialization done.
I0826 17:59:16.976284  5239 solver.cpp:60] Solver scaffolding done.
I0826 17:59:16.977993  5239 caffe.cpp:251] Starting Optimization
I0826 17:59:16.978008  5239 solver.cpp:279] Solving segmentation
I0826 17:59:16.978013  5239 solver.cpp:280] Learning Rate Policy: step
I0826 17:59:16.983999  5239 solver.cpp:337] Iteration 0, Testing net (#0)
I0826 17:59:23.901489  5239 solver.cpp:454] Snapshotting to binary proto file portrait_one_stage4_iter_0.caffemodel
I0826 17:59:23.904598  5239 sgd_solver.cpp:273] Snapshotting solver state to binary proto file portrait_one_stage4_iter_0.solverstate
I0826 17:59:25.462177  5239 solver.cpp:404]     Test net output #0: accuracy = 0.252018
I0826 17:59:25.462218  5239 solver.cpp:404]     Test net output #1: loss = 2.61303e+06 (* 1 = 2.61303e+06 loss)
I0826 17:59:27.031834  5239 solver.cpp:228] Iteration 0, loss = 55451.7
I0826 17:59:27.031872  5239 solver.cpp:244]     Train net output #0: accuracy = 0.253412
I0826 17:59:27.031880  5239 solver.cpp:244]     Train net output #1: loss = 55451.7 (* 1 = 55451.7 loss)
I0826 17:59:27.031893  5239 sgd_solver.cpp:106] Iteration 0, lr = 1e-05
I0826 18:00:44.948864  5239 solver.cpp:228] Iteration 50, loss = 55451.2
I0826 18:00:44.948989  5239 solver.cpp:244]     Train net output #0: accuracy = 0.265952
I0826 18:00:44.949007  5239 solver.cpp:244]     Train net output #1: loss = 55451.2 (* 1 = 55451.2 loss)
I0826 18:00:44.949013  5239 sgd_solver.cpp:106] Iteration 50, lr = 1e-05
I0826 18:02:00.255496  5239 solver.cpp:228] Iteration 100, loss = 44855.9
I0826 18:02:00.255571  5239 solver.cpp:244]     Train net output #0: accuracy = 0.406514
I0826 18:02:00.255583  5239 solver.cpp:244]     Train net output #1: loss = 44855.9 (* 1 = 44855.9 loss)
I0826 18:02:00.255589  5239 sgd_solver.cpp:106] Iteration 100, lr = 1e-05
I0826 18:03:15.978386  5239 solver.cpp:228] Iteration 150, loss = 37015.6
I0826 18:03:15.978483  5239 solver.cpp:244]     Train net output #0: accuracy = 0.570395
I0826 18:03:15.978499  5239 solver.cpp:244]     Train net output #1: loss = 37015.6 (* 1 = 37015.6 loss)
I0826 18:03:15.978508  5239 sgd_solver.cpp:106] Iteration 150, lr = 1e-05
I0826 18:04:29.832340  5239 solver.cpp:337] Iteration 200, Testing net (#0)
I0826 18:04:37.337597  5239 solver.cpp:404]     Test net output #0: accuracy = 0.454134
I0826 18:04:37.337641  5239 solver.cpp:404]     Test net output #1: loss = 702886 (* 1 = 702886 loss)
I0826 18:04:38.618685  5239 solver.cpp:228] Iteration 200, loss = 31068.3
I0826 18:04:38.618731  5239 solver.cpp:244]     Train net output #0: accuracy = 0.644375
I0826 18:04:38.618746  5239 solver.cpp:244]     Train net output #1: loss = 31068.3 (* 1 = 31068.3 loss)
I0826 18:04:38.618754  5239 sgd_solver.cpp:106] Iteration 200, lr = 1e-05
I0826 18:05:54.645892  5239 solver.cpp:228] Iteration 250, loss = 30153.8
I0826 18:05:54.645972  5239 solver.cpp:244]     Train net output #0: accuracy = 0.663036
I0826 18:05:54.645984  5239 solver.cpp:244]     Train net output #1: loss = 30153.8 (* 1 = 30153.8 loss)
I0826 18:05:54.645992  5239 sgd_solver.cpp:106] Iteration 250, lr = 1e-05
I0826 18:07:09.632505  5239 solver.cpp:228] Iteration 300, loss = 32612.5
I0826 18:07:09.632609  5239 solver.cpp:244]     Train net output #0: accuracy = 0.673662
I0826 18:07:09.632621  5239 solver.cpp:244]     Train net output #1: loss = 32612.5 (* 1 = 32612.5 loss)
I0826 18:07:09.632627  5239 sgd_solver.cpp:106] Iteration 300, lr = 1e-05
I0826 18:08:26.876355  5239 solver.cpp:228] Iteration 350, loss = 32506.6
I0826 18:08:26.876430  5239 solver.cpp:244]     Train net output #0: accuracy = 0.668257
I0826 18:08:26.876442  5239 solver.cpp:244]     Train net output #1: loss = 32506.6 (* 1 = 32506.6 loss)
I0826 18:08:26.876448  5239 sgd_solver.cpp:106] Iteration 350, lr = 1e-05
I0826 18:09:42.517537  5239 solver.cpp:337] Iteration 400, Testing net (#0)
I0826 18:09:50.731320  5239 solver.cpp:404]     Test net output #0: accuracy = 0.622419
I0826 18:09:50.731364  5239 solver.cpp:404]     Test net output #1: loss = 61063.7 (* 1 = 61063.7 loss)
I0826 18:09:52.139797  5239 solver.cpp:228] Iteration 400, loss = 31988.1
I0826 18:09:52.139834  5239 solver.cpp:244]     Train net output #0: accuracy = 0.630747
I0826 18:09:52.139843  5239 solver.cpp:244]     Train net output #1: loss = 31988.1 (* 1 = 31988.1 loss)
I0826 18:09:52.139850  5239 sgd_solver.cpp:106] Iteration 400, lr = 1e-05
I0826 18:11:09.142729  5239 solver.cpp:228] Iteration 450, loss = 24304
I0826 18:11:09.142808  5239 solver.cpp:244]     Train net output #0: accuracy = 0.811338
I0826 18:11:09.142819  5239 solver.cpp:244]     Train net output #1: loss = 24304 (* 1 = 24304 loss)
I0826 18:11:09.142827  5239 sgd_solver.cpp:106] Iteration 450, lr = 1e-05
I0826 18:12:25.307891  5239 solver.cpp:228] Iteration 500, loss = 32922.9
I0826 18:12:25.307976  5239 solver.cpp:244]     Train net output #0: accuracy = 0.672839
I0826 18:12:25.307987  5239 solver.cpp:244]     Train net output #1: loss = 32922.9 (* 1 = 32922.9 loss)
I0826 18:12:25.307994  5239 sgd_solver.cpp:106] Iteration 500, lr = 1e-05
I0826 18:13:41.450268  5239 solver.cpp:228] Iteration 550, loss = 22537.2
I0826 18:13:41.450340  5239 solver.cpp:244]     Train net output #0: accuracy = 0.819229
I0826 18:13:41.450350  5239 solver.cpp:244]     Train net output #1: loss = 22537.2 (* 1 = 22537.2 loss)
I0826 18:13:41.450356  5239 sgd_solver.cpp:106] Iteration 550, lr = 1e-05
I0826 18:14:56.661797  5239 solver.cpp:337] Iteration 600, Testing net (#0)
I0826 18:15:05.030722  5239 solver.cpp:404]     Test net output #0: accuracy = 0.477383
I0826 18:15:05.030760  5239 solver.cpp:404]     Test net output #1: loss = 79865.8 (* 1 = 79865.8 loss)
I0826 18:15:06.430682  5239 solver.cpp:228] Iteration 600, loss = 28753.6
I0826 18:15:06.430722  5239 solver.cpp:244]     Train net output #0: accuracy = 0.702128
I0826 18:15:06.430732  5239 solver.cpp:244]     Train net output #1: loss = 28753.6 (* 1 = 28753.6 loss)
I0826 18:15:06.430739  5239 sgd_solver.cpp:106] Iteration 600, lr = 1e-05
I0826 18:16:21.697671  5239 solver.cpp:228] Iteration 650, loss = 20379.4
I0826 18:16:21.697751  5239 solver.cpp:244]     Train net output #0: accuracy = 0.831166
I0826 18:16:21.697763  5239 solver.cpp:244]     Train net output #1: loss = 20379.4 (* 1 = 20379.4 loss)
I0826 18:16:21.697770  5239 sgd_solver.cpp:106] Iteration 650, lr = 1e-05
I0826 18:17:38.660259  5239 solver.cpp:228] Iteration 700, loss = 25653.4
I0826 18:17:38.660342  5239 solver.cpp:244]     Train net output #0: accuracy = 0.689232
I0826 18:17:38.660353  5239 solver.cpp:244]     Train net output #1: loss = 25653.4 (* 1 = 25653.4 loss)
I0826 18:17:38.660361  5239 sgd_solver.cpp:106] Iteration 700, lr = 1e-05
I0826 18:18:55.278182  5239 solver.cpp:228] Iteration 750, loss = 25712
I0826 18:18:55.278257  5239 solver.cpp:244]     Train net output #0: accuracy = 0.765527
I0826 18:18:55.278270  5239 solver.cpp:244]     Train net output #1: loss = 25712 (* 1 = 25712 loss)
I0826 18:18:55.278275  5239 sgd_solver.cpp:106] Iteration 750, lr = 1e-05
I0826 18:20:11.704743  5239 solver.cpp:337] Iteration 800, Testing net (#0)
I0826 18:20:20.156476  5239 solver.cpp:404]     Test net output #0: accuracy = 0.561581
I0826 18:20:20.156517  5239 solver.cpp:404]     Test net output #1: loss = 53631.3 (* 1 = 53631.3 loss)
I0826 18:20:21.535343  5239 solver.cpp:228] Iteration 800, loss = 41482.6
I0826 18:20:21.535383  5239 solver.cpp:244]     Train net output #0: accuracy = 0.626538
I0826 18:20:21.535393  5239 solver.cpp:244]     Train net output #1: loss = 41482.6 (* 1 = 41482.6 loss)
I0826 18:20:21.535399  5239 sgd_solver.cpp:106] Iteration 800, lr = 1e-05
I0826 18:21:40.308531  5239 solver.cpp:228] Iteration 850, loss = 24212.3
I0826 18:21:40.308614  5239 solver.cpp:244]     Train net output #0: accuracy = 0.760175
I0826 18:21:40.308627  5239 solver.cpp:244]     Train net output #1: loss = 24212.3 (* 1 = 24212.3 loss)
I0826 18:21:40.308639  5239 sgd_solver.cpp:106] Iteration 850, lr = 1e-05
I0826 18:22:56.396842  5239 solver.cpp:228] Iteration 900, loss = 17920.1
I0826 18:22:56.396942  5239 solver.cpp:244]     Train net output #0: accuracy = 0.833926
I0826 18:22:56.396955  5239 solver.cpp:244]     Train net output #1: loss = 17920.1 (* 1 = 17920.1 loss)
I0826 18:22:56.396965  5239 sgd_solver.cpp:106] Iteration 900, lr = 1e-05
I0826 18:24:12.681311  5239 solver.cpp:228] Iteration 950, loss = 24503.8
I0826 18:24:12.681393  5239 solver.cpp:244]     Train net output #0: accuracy = 0.757525
I0826 18:24:12.681404  5239 solver.cpp:244]     Train net output #1: loss = 24503.8 (* 1 = 24503.8 loss)
I0826 18:24:12.681411  5239 sgd_solver.cpp:106] Iteration 950, lr = 1e-05
I0826 18:25:31.513705  5239 solver.cpp:337] Iteration 1000, Testing net (#0)
I0826 18:25:40.265792  5239 solver.cpp:404]     Test net output #0: accuracy = 0.521856
I0826 18:25:40.265838  5239 solver.cpp:404]     Test net output #1: loss = 50070.6 (* 1 = 50070.6 loss)
I0826 18:25:41.646445  5239 solver.cpp:228] Iteration 1000, loss = 15747.2
I0826 18:25:41.646494  5239 solver.cpp:244]     Train net output #0: accuracy = 0.849787
I0826 18:25:41.646507  5239 solver.cpp:244]     Train net output #1: loss = 15747.2 (* 1 = 15747.2 loss)
I0826 18:25:41.646517  5239 sgd_solver.cpp:106] Iteration 1000, lr = 1e-05
I0826 18:26:59.865255  5239 solver.cpp:228] Iteration 1050, loss = 20885.5
I0826 18:26:59.865391  5239 solver.cpp:244]     Train net output #0: accuracy = 0.811463
I0826 18:26:59.865417  5239 solver.cpp:244]     Train net output #1: loss = 20885.5 (* 1 = 20885.5 loss)
I0826 18:26:59.865429  5239 sgd_solver.cpp:106] Iteration 1050, lr = 1e-05
I0826 18:28:17.191517  5239 solver.cpp:228] Iteration 1100, loss = 15916.5
I0826 18:28:17.191653  5239 solver.cpp:244]     Train net output #0: accuracy = 0.857555
I0826 18:28:17.191673  5239 solver.cpp:244]     Train net output #1: loss = 15916.5 (* 1 = 15916.5 loss)
I0826 18:28:17.191689  5239 sgd_solver.cpp:106] Iteration 1100, lr = 1e-05
I0826 18:29:38.035048  5239 solver.cpp:228] Iteration 1150, loss = 17147.2
I0826 18:29:38.035125  5239 solver.cpp:244]     Train net output #0: accuracy = 0.835788
I0826 18:29:38.035136  5239 solver.cpp:244]     Train net output #1: loss = 17147.2 (* 1 = 17147.2 loss)
I0826 18:29:38.035142  5239 sgd_solver.cpp:106] Iteration 1150, lr = 1e-05
I0826 18:30:53.032296  5239 solver.cpp:337] Iteration 1200, Testing net (#0)
I0826 18:31:01.516904  5239 solver.cpp:404]     Test net output #0: accuracy = 0.375748
I0826 18:31:01.516959  5239 solver.cpp:404]     Test net output #1: loss = 84461 (* 1 = 84461 loss)
I0826 18:31:02.808660  5239 solver.cpp:228] Iteration 1200, loss = 18052
I0826 18:31:02.808701  5239 solver.cpp:244]     Train net output #0: accuracy = 0.82957
I0826 18:31:02.808711  5239 solver.cpp:244]     Train net output #1: loss = 18052 (* 1 = 18052 loss)
I0826 18:31:02.808717  5239 sgd_solver.cpp:106] Iteration 1200, lr = 1e-05
I0826 18:32:20.406549  5239 solver.cpp:228] Iteration 1250, loss = 16034.3
I0826 18:32:20.406620  5239 solver.cpp:244]     Train net output #0: accuracy = 0.848399
I0826 18:32:20.406630  5239 solver.cpp:244]     Train net output #1: loss = 16034.3 (* 1 = 16034.3 loss)
I0826 18:32:20.406636  5239 sgd_solver.cpp:106] Iteration 1250, lr = 1e-05
I0826 18:33:38.825292  5239 solver.cpp:228] Iteration 1300, loss = 15359.1
I0826 18:33:38.825392  5239 solver.cpp:244]     Train net output #0: accuracy = 0.857312
I0826 18:33:38.825407  5239 solver.cpp:244]     Train net output #1: loss = 15359.1 (* 1 = 15359.1 loss)
I0826 18:33:38.825417  5239 sgd_solver.cpp:106] Iteration 1300, lr = 1e-05
I0826 18:34:56.341456  5239 solver.cpp:228] Iteration 1350, loss = 11953.6
I0826 18:34:56.341533  5239 solver.cpp:244]     Train net output #0: accuracy = 0.888409
I0826 18:34:56.341545  5239 solver.cpp:244]     Train net output #1: loss = 11953.6 (* 1 = 11953.6 loss)
I0826 18:34:56.341552  5239 sgd_solver.cpp:106] Iteration 1350, lr = 1e-05
I0826 18:36:12.128803  5239 solver.cpp:337] Iteration 1400, Testing net (#0)
I0826 18:36:20.700279  5239 solver.cpp:404]     Test net output #0: accuracy = 0.472764
I0826 18:36:20.700326  5239 solver.cpp:404]     Test net output #1: loss = 50094.2 (* 1 = 50094.2 loss)
I0826 18:36:22.060360  5239 solver.cpp:228] Iteration 1400, loss = 16007.3
I0826 18:36:22.060410  5239 solver.cpp:244]     Train net output #0: accuracy = 0.847893
I0826 18:36:22.060422  5239 solver.cpp:244]     Train net output #1: loss = 16007.3 (* 1 = 16007.3 loss)
I0826 18:36:22.060432  5239 sgd_solver.cpp:106] Iteration 1400, lr = 1e-05
I0826 18:37:38.785063  5239 solver.cpp:228] Iteration 1450, loss = 9784.9
I0826 18:37:38.785146  5239 solver.cpp:244]     Train net output #0: accuracy = 0.910431
I0826 18:37:38.785158  5239 solver.cpp:244]     Train net output #1: loss = 9784.9 (* 1 = 9784.9 loss)
I0826 18:37:38.785166  5239 sgd_solver.cpp:106] Iteration 1450, lr = 1e-05
I0826 18:38:56.126200  5239 solver.cpp:228] Iteration 1500, loss = 14795.7
I0826 18:38:56.126276  5239 solver.cpp:244]     Train net output #0: accuracy = 0.861306
I0826 18:38:56.126286  5239 solver.cpp:244]     Train net output #1: loss = 14795.7 (* 1 = 14795.7 loss)
I0826 18:38:56.126293  5239 sgd_solver.cpp:106] Iteration 1500, lr = 1e-05
I0826 18:40:13.019021  5239 solver.cpp:228] Iteration 1550, loss = 17843.7
I0826 18:40:13.019098  5239 solver.cpp:244]     Train net output #0: accuracy = 0.832984
I0826 18:40:13.019109  5239 solver.cpp:244]     Train net output #1: loss = 17843.7 (* 1 = 17843.7 loss)
I0826 18:40:13.019115  5239 sgd_solver.cpp:106] Iteration 1550, lr = 1e-05
I0826 18:41:27.342696  5239 solver.cpp:337] Iteration 1600, Testing net (#0)
I0826 18:41:35.710775  5239 solver.cpp:404]     Test net output #0: accuracy = 0.560263
I0826 18:41:35.710819  5239 solver.cpp:404]     Test net output #1: loss = 42454.5 (* 1 = 42454.5 loss)
I0826 18:41:37.115116  5239 solver.cpp:228] Iteration 1600, loss = 13980.6
I0826 18:41:37.115154  5239 solver.cpp:244]     Train net output #0: accuracy = 0.865085
I0826 18:41:37.115164  5239 solver.cpp:244]     Train net output #1: loss = 13980.6 (* 1 = 13980.6 loss)
I0826 18:41:37.115170  5239 sgd_solver.cpp:106] Iteration 1600, lr = 1e-05
I0826 18:42:54.955822  5239 solver.cpp:228] Iteration 1650, loss = 12416.4
I0826 18:42:54.955936  5239 solver.cpp:244]     Train net output #0: accuracy = 0.883942
I0826 18:42:54.955955  5239 solver.cpp:244]     Train net output #1: loss = 12416.4 (* 1 = 12416.4 loss)
I0826 18:42:54.955963  5239 sgd_solver.cpp:106] Iteration 1650, lr = 1e-05
I0826 18:44:18.932658  5239 solver.cpp:228] Iteration 1700, loss = 9184.42
I0826 18:44:18.932739  5239 solver.cpp:244]     Train net output #0: accuracy = 0.917241
I0826 18:44:18.932750  5239 solver.cpp:244]     Train net output #1: loss = 9184.42 (* 1 = 9184.42 loss)
I0826 18:44:18.932757  5239 sgd_solver.cpp:106] Iteration 1700, lr = 1e-05
I0826 18:45:36.034431  5239 solver.cpp:228] Iteration 1750, loss = 10917.7
I0826 18:45:36.034523  5239 solver.cpp:244]     Train net output #0: accuracy = 0.894504
I0826 18:45:36.034538  5239 solver.cpp:244]     Train net output #1: loss = 10917.7 (* 1 = 10917.7 loss)
I0826 18:45:36.034545  5239 sgd_solver.cpp:106] Iteration 1750, lr = 1e-05
I0826 18:46:51.052754  5239 solver.cpp:337] Iteration 1800, Testing net (#0)
I0826 18:46:59.547905  5239 solver.cpp:404]     Test net output #0: accuracy = 0.534965
I0826 18:46:59.547957  5239 solver.cpp:404]     Test net output #1: loss = 44213.5 (* 1 = 44213.5 loss)
I0826 18:47:00.903569  5239 solver.cpp:228] Iteration 1800, loss = 7508
I0826 18:47:00.903607  5239 solver.cpp:244]     Train net output #0: accuracy = 0.931624
I0826 18:47:00.903616  5239 solver.cpp:244]     Train net output #1: loss = 7508 (* 1 = 7508 loss)
I0826 18:47:00.903623  5239 sgd_solver.cpp:106] Iteration 1800, lr = 1e-05
I0826 18:48:16.949280  5239 solver.cpp:228] Iteration 1850, loss = 14551.5
I0826 18:48:16.949355  5239 solver.cpp:244]     Train net output #0: accuracy = 0.859524
I0826 18:48:16.949367  5239 solver.cpp:244]     Train net output #1: loss = 14551.5 (* 1 = 14551.5 loss)
I0826 18:48:16.949373  5239 sgd_solver.cpp:106] Iteration 1850, lr = 1e-05
I0826 18:49:33.157480  5239 solver.cpp:228] Iteration 1900, loss = 15142.4
I0826 18:49:33.157575  5239 solver.cpp:244]     Train net output #0: accuracy = 0.858454
I0826 18:49:33.157593  5239 solver.cpp:244]     Train net output #1: loss = 15142.4 (* 1 = 15142.4 loss)
I0826 18:49:33.157603  5239 sgd_solver.cpp:106] Iteration 1900, lr = 1e-05
I0826 18:50:50.031553  5239 solver.cpp:228] Iteration 1950, loss = 9280.46
I0826 18:50:50.031638  5239 solver.cpp:244]     Train net output #0: accuracy = 0.913598
I0826 18:50:50.031651  5239 solver.cpp:244]     Train net output #1: loss = 9280.46 (* 1 = 9280.46 loss)
I0826 18:50:50.031657  5239 sgd_solver.cpp:106] Iteration 1950, lr = 1e-05
I0826 18:52:05.937763  5239 solver.cpp:337] Iteration 2000, Testing net (#0)
I0826 18:52:14.208046  5239 solver.cpp:404]     Test net output #0: accuracy = 0.758378
I0826 18:52:14.208091  5239 solver.cpp:404]     Test net output #1: loss = 24397.9 (* 1 = 24397.9 loss)
I0826 18:52:15.500509  5239 solver.cpp:228] Iteration 2000, loss = 14766.1
I0826 18:52:15.500555  5239 solver.cpp:244]     Train net output #0: accuracy = 0.855502
I0826 18:52:15.500567  5239 solver.cpp:244]     Train net output #1: loss = 14766.1 (* 1 = 14766.1 loss)
I0826 18:52:15.500576  5239 sgd_solver.cpp:106] Iteration 2000, lr = 1e-05
I0826 18:53:32.755813  5239 solver.cpp:228] Iteration 2050, loss = 9097.08
I0826 18:53:32.755944  5239 solver.cpp:244]     Train net output #0: accuracy = 0.914755
I0826 18:53:32.755971  5239 solver.cpp:244]     Train net output #1: loss = 9097.08 (* 1 = 9097.08 loss)
I0826 18:53:32.755985  5239 sgd_solver.cpp:106] Iteration 2050, lr = 1e-05
I0826 18:54:49.370333  5239 solver.cpp:228] Iteration 2100, loss = 10446.5
I0826 18:54:49.370414  5239 solver.cpp:244]     Train net output #0: accuracy = 0.901857
I0826 18:54:49.370424  5239 solver.cpp:244]     Train net output #1: loss = 10446.5 (* 1 = 10446.5 loss)
I0826 18:54:49.370430  5239 sgd_solver.cpp:106] Iteration 2100, lr = 1e-05
I0826 18:56:06.170750  5239 solver.cpp:228] Iteration 2150, loss = 6378.76
I0826 18:56:06.170841  5239 solver.cpp:244]     Train net output #0: accuracy = 0.941113
I0826 18:56:06.170856  5239 solver.cpp:244]     Train net output #1: loss = 6378.76 (* 1 = 6378.76 loss)
I0826 18:56:06.170866  5239 sgd_solver.cpp:106] Iteration 2150, lr = 1e-05
I0826 18:57:22.178706  5239 solver.cpp:337] Iteration 2200, Testing net (#0)
I0826 18:57:30.620403  5239 solver.cpp:404]     Test net output #0: accuracy = 0.720713
I0826 18:57:30.620442  5239 solver.cpp:404]     Test net output #1: loss = 27515.6 (* 1 = 27515.6 loss)
I0826 18:57:32.044720  5239 solver.cpp:228] Iteration 2200, loss = 9868.37
I0826 18:57:32.044759  5239 solver.cpp:244]     Train net output #0: accuracy = 0.904014
I0826 18:57:32.044770  5239 solver.cpp:244]     Train net output #1: loss = 9868.37 (* 1 = 9868.37 loss)
I0826 18:57:32.044775  5239 sgd_solver.cpp:106] Iteration 2200, lr = 1e-05
I0826 18:58:49.457598  5239 solver.cpp:228] Iteration 2250, loss = 8487.44
I0826 18:58:49.457686  5239 solver.cpp:244]     Train net output #0: accuracy = 0.92004
I0826 18:58:49.457698  5239 solver.cpp:244]     Train net output #1: loss = 8487.44 (* 1 = 8487.44 loss)
I0826 18:58:49.457705  5239 sgd_solver.cpp:106] Iteration 2250, lr = 1e-05
I0826 19:00:11.308830  5239 solver.cpp:228] Iteration 2300, loss = 8552.82
I0826 19:00:11.308928  5239 solver.cpp:244]     Train net output #0: accuracy = 0.919273
I0826 19:00:11.308941  5239 solver.cpp:244]     Train net output #1: loss = 8552.82 (* 1 = 8552.82 loss)
I0826 19:00:11.308950  5239 sgd_solver.cpp:106] Iteration 2300, lr = 1e-05
I0826 19:01:36.286734  5239 solver.cpp:228] Iteration 2350, loss = 13852.4
I0826 19:01:36.286828  5239 solver.cpp:244]     Train net output #0: accuracy = 0.86496
I0826 19:01:36.286842  5239 solver.cpp:244]     Train net output #1: loss = 13852.4 (* 1 = 13852.4 loss)
I0826 19:01:36.286851  5239 sgd_solver.cpp:106] Iteration 2350, lr = 1e-05
I0826 19:02:51.850003  5239 solver.cpp:337] Iteration 2400, Testing net (#0)
I0826 19:03:00.108451  5239 solver.cpp:404]     Test net output #0: accuracy = 0.760539
I0826 19:03:00.108492  5239 solver.cpp:404]     Test net output #1: loss = 23874.9 (* 1 = 23874.9 loss)
I0826 19:03:01.514994  5239 solver.cpp:228] Iteration 2400, loss = 6852.9
I0826 19:03:01.515033  5239 solver.cpp:244]     Train net output #0: accuracy = 0.936413
I0826 19:03:01.515043  5239 solver.cpp:244]     Train net output #1: loss = 6852.9 (* 1 = 6852.9 loss)
I0826 19:03:01.515049  5239 sgd_solver.cpp:106] Iteration 2400, lr = 1e-05
I0826 19:04:18.007500  5239 solver.cpp:228] Iteration 2450, loss = 11804.3
I0826 19:04:18.009086  5239 solver.cpp:244]     Train net output #0: accuracy = 0.886176
I0826 19:04:18.009114  5239 solver.cpp:244]     Train net output #1: loss = 11804.3 (* 1 = 11804.3 loss)
I0826 19:04:18.009124  5239 sgd_solver.cpp:106] Iteration 2450, lr = 1e-05
I0826 19:05:36.073976  5239 solver.cpp:228] Iteration 2500, loss = 7948.01
I0826 19:05:36.074071  5239 solver.cpp:244]     Train net output #0: accuracy = 0.925305
I0826 19:05:36.074092  5239 solver.cpp:244]     Train net output #1: loss = 7948.01 (* 1 = 7948.01 loss)
I0826 19:05:36.074105  5239 sgd_solver.cpp:106] Iteration 2500, lr = 1e-05
I0826 19:06:53.526834  5239 solver.cpp:228] Iteration 2550, loss = 9035.12
I0826 19:06:53.526926  5239 solver.cpp:244]     Train net output #0: accuracy = 0.915657
I0826 19:06:53.526938  5239 solver.cpp:244]     Train net output #1: loss = 9035.12 (* 1 = 9035.12 loss)
I0826 19:06:53.526954  5239 sgd_solver.cpp:106] Iteration 2550, lr = 1e-05
I0826 19:08:08.938935  5239 solver.cpp:337] Iteration 2600, Testing net (#0)
I0826 19:08:19.100863  5239 solver.cpp:404]     Test net output #0: accuracy = 0.844754
I0826 19:08:19.100911  5239 solver.cpp:404]     Test net output #1: loss = 16884.3 (* 1 = 16884.3 loss)
I0826 19:08:20.770707  5239 solver.cpp:228] Iteration 2600, loss = 6598.75
I0826 19:08:20.770758  5239 solver.cpp:244]     Train net output #0: accuracy = 0.940411
I0826 19:08:20.770772  5239 solver.cpp:244]     Train net output #1: loss = 6598.75 (* 1 = 6598.75 loss)
I0826 19:08:20.770782  5239 sgd_solver.cpp:106] Iteration 2600, lr = 1e-05
I0826 19:09:38.278601  5239 solver.cpp:228] Iteration 2650, loss = 9719.62
I0826 19:09:38.278697  5239 solver.cpp:244]     Train net output #0: accuracy = 0.909267
I0826 19:09:38.278714  5239 solver.cpp:244]     Train net output #1: loss = 9719.62 (* 1 = 9719.62 loss)
I0826 19:09:38.278723  5239 sgd_solver.cpp:106] Iteration 2650, lr = 1e-05
I0826 19:10:55.863598  5239 solver.cpp:228] Iteration 2700, loss = 9391.65
I0826 19:10:55.863673  5239 solver.cpp:244]     Train net output #0: accuracy = 0.906351
I0826 19:10:55.863685  5239 solver.cpp:244]     Train net output #1: loss = 9391.65 (* 1 = 9391.65 loss)
I0826 19:10:55.863692  5239 sgd_solver.cpp:106] Iteration 2700, lr = 1e-05
I0826 19:12:13.043227  5239 solver.cpp:228] Iteration 2750, loss = 6283.25
I0826 19:12:13.043308  5239 solver.cpp:244]     Train net output #0: accuracy = 0.940594
I0826 19:12:13.043320  5239 solver.cpp:244]     Train net output #1: loss = 6283.25 (* 1 = 6283.25 loss)
I0826 19:12:13.043326  5239 sgd_solver.cpp:106] Iteration 2750, lr = 1e-05
I0826 19:13:28.187058  5239 solver.cpp:337] Iteration 2800, Testing net (#0)
I0826 19:13:36.496789  5239 solver.cpp:404]     Test net output #0: accuracy = 0.861751
I0826 19:13:36.496832  5239 solver.cpp:404]     Test net output #1: loss = 14951.5 (* 1 = 14951.5 loss)
I0826 19:13:37.793036  5239 solver.cpp:228] Iteration 2800, loss = 11893.8
I0826 19:13:37.793076  5239 solver.cpp:244]     Train net output #0: accuracy = 0.883523
I0826 19:13:37.793084  5239 solver.cpp:244]     Train net output #1: loss = 11893.8 (* 1 = 11893.8 loss)
I0826 19:13:37.793092  5239 sgd_solver.cpp:106] Iteration 2800, lr = 1e-05
I0826 19:14:55.294195  5239 solver.cpp:228] Iteration 2850, loss = 6661.1
I0826 19:14:55.294284  5239 solver.cpp:244]     Train net output #0: accuracy = 0.937379
I0826 19:14:55.294299  5239 solver.cpp:244]     Train net output #1: loss = 6661.1 (* 1 = 6661.1 loss)
I0826 19:14:55.294309  5239 sgd_solver.cpp:106] Iteration 2850, lr = 1e-05
I0826 19:16:15.819810  5239 solver.cpp:228] Iteration 2900, loss = 11877.7
I0826 19:16:15.819910  5239 solver.cpp:244]     Train net output #0: accuracy = 0.885271
I0826 19:16:15.819926  5239 solver.cpp:244]     Train net output #1: loss = 11877.7 (* 1 = 11877.7 loss)
I0826 19:16:15.819934  5239 sgd_solver.cpp:106] Iteration 2900, lr = 1e-05
I0826 19:17:35.504545  5239 solver.cpp:228] Iteration 2950, loss = 9193.03
I0826 19:17:35.504616  5239 solver.cpp:244]     Train net output #0: accuracy = 0.915108
I0826 19:17:35.504627  5239 solver.cpp:244]     Train net output #1: loss = 9193.03 (* 1 = 9193.03 loss)
I0826 19:17:35.504634  5239 sgd_solver.cpp:106] Iteration 2950, lr = 1e-05
I0826 19:18:51.619599  5239 solver.cpp:337] Iteration 3000, Testing net (#0)
I0826 19:19:00.063112  5239 solver.cpp:404]     Test net output #0: accuracy = 0.890586
I0826 19:19:00.063166  5239 solver.cpp:404]     Test net output #1: loss = 11817.1 (* 1 = 11817.1 loss)
I0826 19:19:01.752547  5239 solver.cpp:228] Iteration 3000, loss = 7791.74
I0826 19:19:01.752594  5239 solver.cpp:244]     Train net output #0: accuracy = 0.924285
I0826 19:19:01.752607  5239 solver.cpp:244]     Train net output #1: loss = 7791.74 (* 1 = 7791.74 loss)
I0826 19:19:01.752617  5239 sgd_solver.cpp:106] Iteration 3000, lr = 1e-05
I0826 19:20:24.285320  5239 solver.cpp:228] Iteration 3050, loss = 9328.65
I0826 19:20:24.285439  5239 solver.cpp:244]     Train net output #0: accuracy = 0.914022
I0826 19:20:24.285455  5239 solver.cpp:244]     Train net output #1: loss = 9328.65 (* 1 = 9328.65 loss)
I0826 19:20:24.285461  5239 sgd_solver.cpp:106] Iteration 3050, lr = 1e-05
I0826 19:21:41.108453  5239 solver.cpp:228] Iteration 3100, loss = 6758.02
I0826 19:21:41.108538  5239 solver.cpp:244]     Train net output #0: accuracy = 0.935232
I0826 19:21:41.108549  5239 solver.cpp:244]     Train net output #1: loss = 6758.02 (* 1 = 6758.02 loss)
I0826 19:21:41.108556  5239 sgd_solver.cpp:106] Iteration 3100, lr = 1e-05
I0826 19:22:58.454823  5239 solver.cpp:228] Iteration 3150, loss = 8875.09
I0826 19:22:58.454910  5239 solver.cpp:244]     Train net output #0: accuracy = 0.913586
I0826 19:22:58.454926  5239 solver.cpp:244]     Train net output #1: loss = 8875.09 (* 1 = 8875.09 loss)
I0826 19:22:58.454936  5239 sgd_solver.cpp:106] Iteration 3150, lr = 1e-05
I0826 19:24:14.182539  5239 solver.cpp:337] Iteration 3200, Testing net (#0)
I0826 19:24:22.381613  5239 solver.cpp:404]     Test net output #0: accuracy = 0.875302
I0826 19:24:22.381669  5239 solver.cpp:404]     Test net output #1: loss = 13061.7 (* 1 = 13061.7 loss)
I0826 19:24:23.808384  5239 solver.cpp:228] Iteration 3200, loss = 6185.89
I0826 19:24:23.808429  5239 solver.cpp:244]     Train net output #0: accuracy = 0.941451
I0826 19:24:23.808447  5239 solver.cpp:244]     Train net output #1: loss = 6185.89 (* 1 = 6185.89 loss)
I0826 19:24:23.808459  5239 sgd_solver.cpp:106] Iteration 3200, lr = 1e-05
I0826 19:25:39.788884  5239 solver.cpp:228] Iteration 3250, loss = 11116.5
I0826 19:25:39.788959  5239 solver.cpp:244]     Train net output #0: accuracy = 0.890137
I0826 19:25:39.788969  5239 solver.cpp:244]     Train net output #1: loss = 11116.5 (* 1 = 11116.5 loss)
I0826 19:25:39.788976  5239 sgd_solver.cpp:106] Iteration 3250, lr = 1e-05
I0826 19:26:56.688803  5239 solver.cpp:228] Iteration 3300, loss = 6418.69
I0826 19:26:56.688875  5239 solver.cpp:244]     Train net output #0: accuracy = 0.942529
I0826 19:26:56.688886  5239 solver.cpp:244]     Train net output #1: loss = 6418.69 (* 1 = 6418.69 loss)
I0826 19:26:56.688894  5239 sgd_solver.cpp:106] Iteration 3300, lr = 1e-05
I0826 19:28:13.737283  5239 solver.cpp:228] Iteration 3350, loss = 12210.7
I0826 19:28:13.737385  5239 solver.cpp:244]     Train net output #0: accuracy = 0.881825
I0826 19:28:13.737401  5239 solver.cpp:244]     Train net output #1: loss = 12210.7 (* 1 = 12210.7 loss)
I0826 19:28:13.737411  5239 sgd_solver.cpp:106] Iteration 3350, lr = 1e-05
I0826 19:29:30.626461  5239 solver.cpp:337] Iteration 3400, Testing net (#0)
I0826 19:29:39.023242  5239 solver.cpp:404]     Test net output #0: accuracy = 0.902403
I0826 19:29:39.023282  5239 solver.cpp:404]     Test net output #1: loss = 10459.5 (* 1 = 10459.5 loss)
I0826 19:29:40.446456  5239 solver.cpp:228] Iteration 3400, loss = 8792.17
I0826 19:29:40.446502  5239 solver.cpp:244]     Train net output #0: accuracy = 0.915134
I0826 19:29:40.446516  5239 solver.cpp:244]     Train net output #1: loss = 8792.17 (* 1 = 8792.17 loss)
I0826 19:29:40.446524  5239 sgd_solver.cpp:106] Iteration 3400, lr = 1e-05
I0826 19:30:58.032626  5239 solver.cpp:228] Iteration 3450, loss = 9219.84
I0826 19:30:58.032707  5239 solver.cpp:244]     Train net output #0: accuracy = 0.916756
I0826 19:30:58.032722  5239 solver.cpp:244]     Train net output #1: loss = 9219.84 (* 1 = 9219.84 loss)
I0826 19:30:58.032732  5239 sgd_solver.cpp:106] Iteration 3450, lr = 1e-05
I0826 19:32:16.202713  5239 solver.cpp:228] Iteration 3500, loss = 8661.61
I0826 19:32:16.202798  5239 solver.cpp:244]     Train net output #0: accuracy = 0.918206
I0826 19:32:16.202813  5239 solver.cpp:244]     Train net output #1: loss = 8661.61 (* 1 = 8661.61 loss)
I0826 19:32:16.202822  5239 sgd_solver.cpp:106] Iteration 3500, lr = 1e-05
I0826 19:33:34.571072  5239 solver.cpp:228] Iteration 3550, loss = 5693.23
I0826 19:33:34.571151  5239 solver.cpp:244]     Train net output #0: accuracy = 0.946936
I0826 19:33:34.571166  5239 solver.cpp:244]     Train net output #1: loss = 5693.23 (* 1 = 5693.23 loss)
I0826 19:33:34.571188  5239 sgd_solver.cpp:106] Iteration 3550, lr = 1e-05
I0826 19:34:50.350185  5239 solver.cpp:337] Iteration 3600, Testing net (#0)
I0826 19:34:58.261720  5239 solver.cpp:404]     Test net output #0: accuracy = 0.895291
I0826 19:34:58.261771  5239 solver.cpp:404]     Test net output #1: loss = 11060.1 (* 1 = 11060.1 loss)
I0826 19:34:59.626818  5239 solver.cpp:228] Iteration 3600, loss = 8842.5
I0826 19:34:59.626868  5239 solver.cpp:244]     Train net output #0: accuracy = 0.914072
I0826 19:34:59.626888  5239 solver.cpp:244]     Train net output #1: loss = 8842.5 (* 1 = 8842.5 loss)
I0826 19:34:59.626900  5239 sgd_solver.cpp:106] Iteration 3600, lr = 1e-05
I0826 19:36:18.983165  5239 solver.cpp:228] Iteration 3650, loss = 5785.64
I0826 19:36:18.983244  5239 solver.cpp:244]     Train net output #0: accuracy = 0.942978
I0826 19:36:18.983255  5239 solver.cpp:244]     Train net output #1: loss = 5785.64 (* 1 = 5785.64 loss)
I0826 19:36:18.983263  5239 sgd_solver.cpp:106] Iteration 3650, lr = 1e-05
I0826 19:37:37.388453  5239 solver.cpp:228] Iteration 3700, loss = 10224.8
I0826 19:37:37.388535  5239 solver.cpp:244]     Train net output #0: accuracy = 0.8992
I0826 19:37:37.388546  5239 solver.cpp:244]     Train net output #1: loss = 10224.8 (* 1 = 10224.8 loss)
I0826 19:37:37.388552  5239 sgd_solver.cpp:106] Iteration 3700, lr = 1e-05
I0826 19:38:55.038174  5239 solver.cpp:228] Iteration 3750, loss = 5366.61
I0826 19:38:55.038247  5239 solver.cpp:244]     Train net output #0: accuracy = 0.950056
I0826 19:38:55.038259  5239 solver.cpp:244]     Train net output #1: loss = 5366.61 (* 1 = 5366.61 loss)
I0826 19:38:55.038266  5239 sgd_solver.cpp:106] Iteration 3750, lr = 1e-05
I0826 19:40:11.287740  5239 solver.cpp:337] Iteration 3800, Testing net (#0)
I0826 19:40:19.539083  5239 solver.cpp:404]     Test net output #0: accuracy = 0.907881
I0826 19:40:19.539130  5239 solver.cpp:404]     Test net output #1: loss = 10158.5 (* 1 = 10158.5 loss)
I0826 19:40:20.917836  5239 solver.cpp:228] Iteration 3800, loss = 8570.64
I0826 19:40:20.917882  5239 solver.cpp:244]     Train net output #0: accuracy = 0.920319
I0826 19:40:20.917896  5239 solver.cpp:244]     Train net output #1: loss = 8570.64 (* 1 = 8570.64 loss)
I0826 19:40:20.917906  5239 sgd_solver.cpp:106] Iteration 3800, lr = 1e-05
I0826 19:41:38.253129  5239 solver.cpp:228] Iteration 3850, loss = 10875.5
I0826 19:41:38.253201  5239 solver.cpp:244]     Train net output #0: accuracy = 0.896419
I0826 19:41:38.253212  5239 solver.cpp:244]     Train net output #1: loss = 10875.5 (* 1 = 10875.5 loss)
I0826 19:41:38.253219  5239 sgd_solver.cpp:106] Iteration 3850, lr = 1e-05
I0826 19:42:55.689800  5239 solver.cpp:228] Iteration 3900, loss = 6524.29
I0826 19:42:55.689887  5239 solver.cpp:244]     Train net output #0: accuracy = 0.937792
I0826 19:42:55.689898  5239 solver.cpp:244]     Train net output #1: loss = 6524.29 (* 1 = 6524.29 loss)
I0826 19:42:55.689904  5239 sgd_solver.cpp:106] Iteration 3900, lr = 1e-05
I0826 19:44:13.183171  5239 solver.cpp:228] Iteration 3950, loss = 7261.46
I0826 19:44:13.183257  5239 solver.cpp:244]     Train net output #0: accuracy = 0.930965
I0826 19:44:13.183274  5239 solver.cpp:244]     Train net output #1: loss = 7261.46 (* 1 = 7261.46 loss)
I0826 19:44:13.183282  5239 sgd_solver.cpp:106] Iteration 3950, lr = 1e-05
I0826 19:45:29.833580  5239 solver.cpp:454] Snapshotting to binary proto file portrait_one_stage4_iter_4000.caffemodel
I0826 19:45:29.840816  5239 sgd_solver.cpp:273] Snapshotting solver state to binary proto file portrait_one_stage4_iter_4000.solverstate
I0826 19:45:29.842376  5239 solver.cpp:337] Iteration 4000, Testing net (#0)
I0826 19:45:38.141784  5239 solver.cpp:404]     Test net output #0: accuracy = 0.901988
I0826 19:45:38.141825  5239 solver.cpp:404]     Test net output #1: loss = 10438.6 (* 1 = 10438.6 loss)
I0826 19:45:39.572681  5239 solver.cpp:228] Iteration 4000, loss = 4926.65
I0826 19:45:39.572734  5239 solver.cpp:244]     Train net output #0: accuracy = 0.953
I0826 19:45:39.572751  5239 solver.cpp:244]     Train net output #1: loss = 4926.65 (* 1 = 4926.65 loss)
I0826 19:45:39.572770  5239 sgd_solver.cpp:106] Iteration 4000, lr = 1e-06
I0826 19:46:55.821753  5239 solver.cpp:228] Iteration 4050, loss = 7934.68
I0826 19:46:55.821861  5239 solver.cpp:244]     Train net output #0: accuracy = 0.922463
I0826 19:46:55.821874  5239 solver.cpp:244]     Train net output #1: loss = 7934.68 (* 1 = 7934.68 loss)
I0826 19:46:55.821882  5239 sgd_solver.cpp:106] Iteration 4050, lr = 1e-06
I0826 19:48:12.393234  5239 solver.cpp:228] Iteration 4100, loss = 4432.99
I0826 19:48:12.393338  5239 solver.cpp:244]     Train net output #0: accuracy = 0.955778
I0826 19:48:12.393352  5239 solver.cpp:244]     Train net output #1: loss = 4432.99 (* 1 = 4432.99 loss)
I0826 19:48:12.393359  5239 sgd_solver.cpp:106] Iteration 4100, lr = 1e-06
I0826 19:49:28.932849  5239 solver.cpp:228] Iteration 4150, loss = 9508.05
I0826 19:49:28.932937  5239 solver.cpp:244]     Train net output #0: accuracy = 0.907104
I0826 19:49:28.932952  5239 solver.cpp:244]     Train net output #1: loss = 9508.05 (* 1 = 9508.05 loss)
I0826 19:49:28.932961  5239 sgd_solver.cpp:106] Iteration 4150, lr = 1e-06
I0826 19:50:45.864001  5239 solver.cpp:337] Iteration 4200, Testing net (#0)
I0826 19:50:53.769915  5239 solver.cpp:404]     Test net output #0: accuracy = 0.922293
I0826 19:50:53.769956  5239 solver.cpp:404]     Test net output #1: loss = 8299.18 (* 1 = 8299.18 loss)
I0826 19:50:55.216197  5239 solver.cpp:228] Iteration 4200, loss = 9511.2
I0826 19:50:55.216234  5239 solver.cpp:244]     Train net output #0: accuracy = 0.909548
I0826 19:50:55.216243  5239 solver.cpp:244]     Train net output #1: loss = 9511.2 (* 1 = 9511.2 loss)
I0826 19:50:55.216249  5239 sgd_solver.cpp:106] Iteration 4200, lr = 1e-06
I0826 19:52:12.361979  5239 solver.cpp:228] Iteration 4250, loss = 5088.12
I0826 19:52:12.362066  5239 solver.cpp:244]     Train net output #0: accuracy = 0.950756
I0826 19:52:12.362082  5239 solver.cpp:244]     Train net output #1: loss = 5088.12 (* 1 = 5088.12 loss)
I0826 19:52:12.362090  5239 sgd_solver.cpp:106] Iteration 4250, lr = 1e-06
I0826 19:53:28.409286  5239 solver.cpp:228] Iteration 4300, loss = 10760.8
I0826 19:53:28.409378  5239 solver.cpp:244]     Train net output #0: accuracy = 0.895253
I0826 19:53:28.409394  5239 solver.cpp:244]     Train net output #1: loss = 10760.8 (* 1 = 10760.8 loss)
I0826 19:53:28.409404  5239 sgd_solver.cpp:106] Iteration 4300, lr = 1e-06
I0826 19:54:48.026278  5239 solver.cpp:228] Iteration 4350, loss = 5862.04
I0826 19:54:48.026355  5239 solver.cpp:244]     Train net output #0: accuracy = 0.943747
I0826 19:54:48.026372  5239 solver.cpp:244]     Train net output #1: loss = 5862.04 (* 1 = 5862.04 loss)
I0826 19:54:48.026383  5239 sgd_solver.cpp:106] Iteration 4350, lr = 1e-06
I0826 19:56:04.637338  5239 solver.cpp:337] Iteration 4400, Testing net (#0)
I0826 19:56:12.866525  5239 solver.cpp:404]     Test net output #0: accuracy = 0.920267
I0826 19:56:12.866569  5239 solver.cpp:404]     Test net output #1: loss = 8413.11 (* 1 = 8413.11 loss)
I0826 19:56:14.285555  5239 solver.cpp:228] Iteration 4400, loss = 8473.92
I0826 19:56:14.285600  5239 solver.cpp:244]     Train net output #0: accuracy = 0.920188
I0826 19:56:14.285614  5239 solver.cpp:244]     Train net output #1: loss = 8473.92 (* 1 = 8473.92 loss)
I0826 19:56:14.285622  5239 sgd_solver.cpp:106] Iteration 4400, lr = 1e-06
I0826 19:57:33.585949  5239 solver.cpp:228] Iteration 4450, loss = 4605.28
I0826 19:57:33.586025  5239 solver.cpp:244]     Train net output #0: accuracy = 0.955352
I0826 19:57:33.586036  5239 solver.cpp:244]     Train net output #1: loss = 4605.28 (* 1 = 4605.28 loss)
I0826 19:57:33.586043  5239 sgd_solver.cpp:106] Iteration 4450, lr = 1e-06
I0826 19:58:50.281821  5239 solver.cpp:228] Iteration 4500, loss = 7906.59
I0826 19:58:50.281944  5239 solver.cpp:244]     Train net output #0: accuracy = 0.923627
I0826 19:58:50.281975  5239 solver.cpp:244]     Train net output #1: loss = 7906.59 (* 1 = 7906.59 loss)
I0826 19:58:50.281999  5239 sgd_solver.cpp:106] Iteration 4500, lr = 1e-06
I0826 20:00:06.792493  5239 solver.cpp:228] Iteration 4550, loss = 6329.37
I0826 20:00:06.792632  5239 solver.cpp:244]     Train net output #0: accuracy = 0.937439
I0826 20:00:06.792649  5239 solver.cpp:244]     Train net output #1: loss = 6329.37 (* 1 = 6329.37 loss)
I0826 20:00:06.792659  5239 sgd_solver.cpp:106] Iteration 4550, lr = 1e-06
I0826 20:01:21.620074  5239 solver.cpp:337] Iteration 4600, Testing net (#0)
I0826 20:01:30.035784  5239 solver.cpp:404]     Test net output #0: accuracy = 0.923571
I0826 20:01:30.035842  5239 solver.cpp:404]     Test net output #1: loss = 8023.38 (* 1 = 8023.38 loss)
I0826 20:01:31.554538  5239 solver.cpp:228] Iteration 4600, loss = 5327.78
I0826 20:01:31.554587  5239 solver.cpp:244]     Train net output #0: accuracy = 0.949205
I0826 20:01:31.554600  5239 solver.cpp:244]     Train net output #1: loss = 5327.78 (* 1 = 5327.78 loss)
I0826 20:01:31.554610  5239 sgd_solver.cpp:106] Iteration 4600, lr = 1e-06
I0826 20:02:49.111012  5239 solver.cpp:228] Iteration 4650, loss = 9123.11
I0826 20:02:49.111091  5239 solver.cpp:244]     Train net output #0: accuracy = 0.909555
I0826 20:02:49.111104  5239 solver.cpp:244]     Train net output #1: loss = 9123.11 (* 1 = 9123.11 loss)
I0826 20:02:49.111109  5239 sgd_solver.cpp:106] Iteration 4650, lr = 1e-06
I0826 20:04:06.648309  5239 solver.cpp:228] Iteration 4700, loss = 5037.08
I0826 20:04:06.648387  5239 solver.cpp:244]     Train net output #0: accuracy = 0.950194
I0826 20:04:06.648398  5239 solver.cpp:244]     Train net output #1: loss = 5037.08 (* 1 = 5037.08 loss)
I0826 20:04:06.648404  5239 sgd_solver.cpp:106] Iteration 4700, lr = 1e-06
I0826 20:05:23.569851  5239 solver.cpp:228] Iteration 4750, loss = 9787.16
I0826 20:05:23.569932  5239 solver.cpp:244]     Train net output #0: accuracy = 0.90654
I0826 20:05:23.569944  5239 solver.cpp:244]     Train net output #1: loss = 9787.16 (* 1 = 9787.16 loss)
I0826 20:05:23.569952  5239 sgd_solver.cpp:106] Iteration 4750, lr = 1e-06
I0826 20:06:39.596504  5239 solver.cpp:337] Iteration 4800, Testing net (#0)
I0826 20:06:47.829800  5239 solver.cpp:404]     Test net output #0: accuracy = 0.923042
I0826 20:06:47.829848  5239 solver.cpp:404]     Test net output #1: loss = 8085.44 (* 1 = 8085.44 loss)
I0826 20:06:49.180732  5239 solver.cpp:228] Iteration 4800, loss = 5690.65
I0826 20:06:49.180773  5239 solver.cpp:244]     Train net output #0: accuracy = 0.945424
I0826 20:06:49.180785  5239 solver.cpp:244]     Train net output #1: loss = 5690.65 (* 1 = 5690.65 loss)
I0826 20:06:49.180794  5239 sgd_solver.cpp:106] Iteration 4800, lr = 1e-06
I0826 20:08:05.380035  5239 solver.cpp:228] Iteration 4850, loss = 7045.23
I0826 20:08:05.380113  5239 solver.cpp:244]     Train net output #0: accuracy = 0.933014
I0826 20:08:05.380125  5239 solver.cpp:244]     Train net output #1: loss = 7045.23 (* 1 = 7045.23 loss)
I0826 20:08:05.380132  5239 sgd_solver.cpp:106] Iteration 4850, lr = 1e-06
I0826 20:09:20.268350  5239 solver.cpp:228] Iteration 4900, loss = 4681.16
I0826 20:09:20.268432  5239 solver.cpp:244]     Train net output #0: accuracy = 0.955194
I0826 20:09:20.268445  5239 solver.cpp:244]     Train net output #1: loss = 4681.16 (* 1 = 4681.16 loss)
I0826 20:09:20.268450  5239 sgd_solver.cpp:106] Iteration 4900, lr = 1e-06
I0826 20:10:37.096204  5239 solver.cpp:228] Iteration 4950, loss = 6512.63
I0826 20:10:37.096282  5239 solver.cpp:244]     Train net output #0: accuracy = 0.937014
I0826 20:10:37.096294  5239 solver.cpp:244]     Train net output #1: loss = 6512.63 (* 1 = 6512.63 loss)
I0826 20:10:37.096300  5239 sgd_solver.cpp:106] Iteration 4950, lr = 1e-06
I0826 20:11:53.493155  5239 solver.cpp:337] Iteration 5000, Testing net (#0)
I0826 20:12:01.852185  5239 solver.cpp:404]     Test net output #0: accuracy = 0.92456
I0826 20:12:01.852226  5239 solver.cpp:404]     Test net output #1: loss = 7851.67 (* 1 = 7851.67 loss)
I0826 20:12:03.244916  5239 solver.cpp:228] Iteration 5000, loss = 7715.69
I0826 20:12:03.244964  5239 solver.cpp:244]     Train net output #0: accuracy = 0.923159
I0826 20:12:03.244990  5239 solver.cpp:244]     Train net output #1: loss = 7715.69 (* 1 = 7715.69 loss)
I0826 20:12:03.244999  5239 sgd_solver.cpp:106] Iteration 5000, lr = 1e-06
I0826 20:13:19.724239  5239 solver.cpp:228] Iteration 5050, loss = 4669.64
I0826 20:13:19.724377  5239 solver.cpp:244]     Train net output #0: accuracy = 0.954714
I0826 20:13:19.724395  5239 solver.cpp:244]     Train net output #1: loss = 4669.64 (* 1 = 4669.64 loss)
I0826 20:13:19.724406  5239 sgd_solver.cpp:106] Iteration 5050, lr = 1e-06
I0826 20:14:38.096669  5239 solver.cpp:228] Iteration 5100, loss = 10178.4
I0826 20:14:38.096758  5239 solver.cpp:244]     Train net output #0: accuracy = 0.899246
I0826 20:14:38.096774  5239 solver.cpp:244]     Train net output #1: loss = 10178.4 (* 1 = 10178.4 loss)
I0826 20:14:38.096783  5239 sgd_solver.cpp:106] Iteration 5100, lr = 1e-06
I0826 20:15:55.287613  5239 solver.cpp:228] Iteration 5150, loss = 5502.31
I0826 20:15:55.287688  5239 solver.cpp:244]     Train net output #0: accuracy = 0.947499
I0826 20:15:55.287700  5239 solver.cpp:244]     Train net output #1: loss = 5502.31 (* 1 = 5502.31 loss)
I0826 20:15:55.287706  5239 sgd_solver.cpp:106] Iteration 5150, lr = 1e-06
I0826 20:17:10.592983  5239 solver.cpp:337] Iteration 5200, Testing net (#0)
I0826 20:17:18.858899  5239 solver.cpp:404]     Test net output #0: accuracy = 0.926735
I0826 20:17:18.858940  5239 solver.cpp:404]     Test net output #1: loss = 7677.42 (* 1 = 7677.42 loss)
I0826 20:17:20.144003  5239 solver.cpp:228] Iteration 5200, loss = 10350
I0826 20:17:20.144039  5239 solver.cpp:244]     Train net output #0: accuracy = 0.902013
I0826 20:17:20.144048  5239 solver.cpp:244]     Train net output #1: loss = 10350 (* 1 = 10350 loss)
I0826 20:17:20.144054  5239 sgd_solver.cpp:106] Iteration 5200, lr = 1e-06
I0826 20:18:36.662880  5239 solver.cpp:228] Iteration 5250, loss = 6106.09
I0826 20:18:36.662963  5239 solver.cpp:244]     Train net output #0: accuracy = 0.942127
I0826 20:18:36.662976  5239 solver.cpp:244]     Train net output #1: loss = 6106.09 (* 1 = 6106.09 loss)
I0826 20:18:36.662981  5239 sgd_solver.cpp:106] Iteration 5250, lr = 1e-06
I0826 20:19:52.714298  5239 solver.cpp:228] Iteration 5300, loss = 6644.42
I0826 20:19:52.714380  5239 solver.cpp:244]     Train net output #0: accuracy = 0.935128
I0826 20:19:52.714390  5239 solver.cpp:244]     Train net output #1: loss = 6644.42 (* 1 = 6644.42 loss)
I0826 20:19:52.714396  5239 sgd_solver.cpp:106] Iteration 5300, lr = 1e-06
I0826 20:21:10.879844  5239 solver.cpp:228] Iteration 5350, loss = 7837.17
I0826 20:21:10.879919  5239 solver.cpp:244]     Train net output #0: accuracy = 0.926701
I0826 20:21:10.879930  5239 solver.cpp:244]     Train net output #1: loss = 7837.17 (* 1 = 7837.17 loss)
I0826 20:21:10.879936  5239 sgd_solver.cpp:106] Iteration 5350, lr = 1e-06
I0826 20:22:26.954494  5239 solver.cpp:337] Iteration 5400, Testing net (#0)
I0826 20:22:35.354804  5239 solver.cpp:404]     Test net output #0: accuracy = 0.924011
I0826 20:22:35.354856  5239 solver.cpp:404]     Test net output #1: loss = 7889.42 (* 1 = 7889.42 loss)
I0826 20:22:36.701369  5239 solver.cpp:228] Iteration 5400, loss = 4670.04
I0826 20:22:36.701416  5239 solver.cpp:244]     Train net output #0: accuracy = 0.955297
I0826 20:22:36.701431  5239 solver.cpp:244]     Train net output #1: loss = 4670.04 (* 1 = 4670.04 loss)
I0826 20:22:36.701439  5239 sgd_solver.cpp:106] Iteration 5400, lr = 1e-06
I0826 20:23:53.158975  5239 solver.cpp:228] Iteration 5450, loss = 7420.87
I0826 20:23:53.159075  5239 solver.cpp:244]     Train net output #0: accuracy = 0.926409
I0826 20:23:53.159090  5239 solver.cpp:244]     Train net output #1: loss = 7420.87 (* 1 = 7420.87 loss)
I0826 20:23:53.159101  5239 sgd_solver.cpp:106] Iteration 5450, lr = 1e-06
I0826 20:25:10.387789  5239 solver.cpp:228] Iteration 5500, loss = 4857.95
I0826 20:25:10.387876  5239 solver.cpp:244]     Train net output #0: accuracy = 0.951867
I0826 20:25:10.387887  5239 solver.cpp:244]     Train net output #1: loss = 4857.95 (* 1 = 4857.95 loss)
I0826 20:25:10.387893  5239 sgd_solver.cpp:106] Iteration 5500, lr = 1e-06
I0826 20:26:28.698513  5239 solver.cpp:228] Iteration 5550, loss = 9373.54
I0826 20:26:28.698622  5239 solver.cpp:244]     Train net output #0: accuracy = 0.905978
I0826 20:26:28.698635  5239 solver.cpp:244]     Train net output #1: loss = 9373.54 (* 1 = 9373.54 loss)
I0826 20:26:28.698642  5239 sgd_solver.cpp:106] Iteration 5550, lr = 1e-06
I0826 20:27:44.198088  5239 solver.cpp:337] Iteration 5600, Testing net (#0)
I0826 20:27:52.476749  5239 solver.cpp:404]     Test net output #0: accuracy = 0.927188
I0826 20:27:52.476801  5239 solver.cpp:404]     Test net output #1: loss = 7623.49 (* 1 = 7623.49 loss)
I0826 20:27:53.921087  5239 solver.cpp:228] Iteration 5600, loss = 4891.46
I0826 20:27:53.921124  5239 solver.cpp:244]     Train net output #0: accuracy = 0.953799
I0826 20:27:53.921134  5239 solver.cpp:244]     Train net output #1: loss = 4891.46 (* 1 = 4891.46 loss)
I0826 20:27:53.921140  5239 sgd_solver.cpp:106] Iteration 5600, lr = 1e-06
I0826 20:29:09.656210  5239 solver.cpp:228] Iteration 5650, loss = 8432.5
I0826 20:29:09.656286  5239 solver.cpp:244]     Train net output #0: accuracy = 0.919496
I0826 20:29:09.656298  5239 solver.cpp:244]     Train net output #1: loss = 8432.5 (* 1 = 8432.5 loss)
I0826 20:29:09.656304  5239 sgd_solver.cpp:106] Iteration 5650, lr = 1e-06
I0826 20:30:27.471324  5239 solver.cpp:228] Iteration 5700, loss = 8196.2
I0826 20:30:27.471422  5239 solver.cpp:244]     Train net output #0: accuracy = 0.922549
I0826 20:30:27.471438  5239 solver.cpp:244]     Train net output #1: loss = 8196.2 (* 1 = 8196.2 loss)
I0826 20:30:27.471447  5239 sgd_solver.cpp:106] Iteration 5700, lr = 1e-06
I0826 20:31:43.231582  5239 solver.cpp:228] Iteration 5750, loss = 5597.13
I0826 20:31:43.231673  5239 solver.cpp:244]     Train net output #0: accuracy = 0.946894
I0826 20:31:43.231684  5239 solver.cpp:244]     Train net output #1: loss = 5597.13 (* 1 = 5597.13 loss)
I0826 20:31:43.231690  5239 sgd_solver.cpp:106] Iteration 5750, lr = 1e-06
I0826 20:32:58.737510  5239 solver.cpp:337] Iteration 5800, Testing net (#0)
I0826 20:33:06.934547  5239 solver.cpp:404]     Test net output #0: accuracy = 0.926476
I0826 20:33:06.934588  5239 solver.cpp:404]     Test net output #1: loss = 7672.83 (* 1 = 7672.83 loss)
I0826 20:33:08.290125  5239 solver.cpp:228] Iteration 5800, loss = 6706.13
I0826 20:33:08.290175  5239 solver.cpp:244]     Train net output #0: accuracy = 0.934576
I0826 20:33:08.290194  5239 solver.cpp:244]     Train net output #1: loss = 6706.13 (* 1 = 6706.13 loss)
I0826 20:33:08.290205  5239 sgd_solver.cpp:106] Iteration 5800, lr = 1e-06
I0826 20:34:25.322820  5239 solver.cpp:228] Iteration 5850, loss = 4570.28
I0826 20:34:25.322909  5239 solver.cpp:244]     Train net output #0: accuracy = 0.956078
I0826 20:34:25.322921  5239 solver.cpp:244]     Train net output #1: loss = 4570.28 (* 1 = 4570.28 loss)
I0826 20:34:25.322927  5239 sgd_solver.cpp:106] Iteration 5850, lr = 1e-06
I0826 20:35:45.533077  5239 solver.cpp:228] Iteration 5900, loss = 8140.66
I0826 20:35:45.533151  5239 solver.cpp:244]     Train net output #0: accuracy = 0.920502
I0826 20:35:45.533164  5239 solver.cpp:244]     Train net output #1: loss = 8140.66 (* 1 = 8140.66 loss)
I0826 20:35:45.533170  5239 sgd_solver.cpp:106] Iteration 5900, lr = 1e-06
I0826 20:37:02.117620  5239 solver.cpp:228] Iteration 5950, loss = 4898.06
I0826 20:37:02.117702  5239 solver.cpp:244]     Train net output #0: accuracy = 0.951133
I0826 20:37:02.117713  5239 solver.cpp:244]     Train net output #1: loss = 4898.06 (* 1 = 4898.06 loss)
I0826 20:37:02.117722  5239 sgd_solver.cpp:106] Iteration 5950, lr = 1e-06
I0826 20:38:17.210114  5239 solver.cpp:337] Iteration 6000, Testing net (#0)
I0826 20:38:25.519721  5239 solver.cpp:404]     Test net output #0: accuracy = 0.927827
I0826 20:38:25.519763  5239 solver.cpp:404]     Test net output #1: loss = 7526.98 (* 1 = 7526.98 loss)
I0826 20:38:26.857905  5239 solver.cpp:228] Iteration 6000, loss = 8299.48
I0826 20:38:26.857944  5239 solver.cpp:244]     Train net output #0: accuracy = 0.918162
I0826 20:38:26.857964  5239 solver.cpp:244]     Train net output #1: loss = 8299.48 (* 1 = 8299.48 loss)
I0826 20:38:26.857971  5239 sgd_solver.cpp:106] Iteration 6000, lr = 1e-06
I0826 20:39:44.534385  5239 solver.cpp:228] Iteration 6050, loss = 4736.97
I0826 20:39:44.534515  5239 solver.cpp:244]     Train net output #0: accuracy = 0.954392
I0826 20:39:44.534533  5239 solver.cpp:244]     Train net output #1: loss = 4736.97 (* 1 = 4736.97 loss)
I0826 20:39:44.534541  5239 sgd_solver.cpp:106] Iteration 6050, lr = 1e-06
I0826 20:41:01.576985  5239 solver.cpp:228] Iteration 6100, loss = 5781.94
I0826 20:41:01.577061  5239 solver.cpp:244]     Train net output #0: accuracy = 0.944113
I0826 20:41:01.577074  5239 solver.cpp:244]     Train net output #1: loss = 5781.94 (* 1 = 5781.94 loss)
I0826 20:41:01.577080  5239 sgd_solver.cpp:106] Iteration 6100, lr = 1e-06
I0826 20:42:18.326923  5239 solver.cpp:228] Iteration 6150, loss = 10303.3
I0826 20:42:18.326998  5239 solver.cpp:244]     Train net output #0: accuracy = 0.900521
I0826 20:42:18.327011  5239 solver.cpp:244]     Train net output #1: loss = 10303.3 (* 1 = 10303.3 loss)
I0826 20:42:18.327018  5239 sgd_solver.cpp:106] Iteration 6150, lr = 1e-06
I0826 20:43:34.438318  5239 solver.cpp:337] Iteration 6200, Testing net (#0)
I0826 20:43:42.587348  5239 solver.cpp:404]     Test net output #0: accuracy = 0.929302
I0826 20:43:42.587400  5239 solver.cpp:404]     Test net output #1: loss = 7397.33 (* 1 = 7397.33 loss)
I0826 20:43:43.939692  5239 solver.cpp:228] Iteration 6200, loss = 5403.85
I0826 20:43:43.939741  5239 solver.cpp:244]     Train net output #0: accuracy = 0.947802
I0826 20:43:43.939754  5239 solver.cpp:244]     Train net output #1: loss = 5403.85 (* 1 = 5403.85 loss)
I0826 20:43:43.939764  5239 sgd_solver.cpp:106] Iteration 6200, lr = 1e-06
I0826 20:44:59.532482  5239 solver.cpp:228] Iteration 6250, loss = 6753.71
I0826 20:44:59.532572  5239 solver.cpp:244]     Train net output #0: accuracy = 0.934098
I0826 20:44:59.532583  5239 solver.cpp:244]     Train net output #1: loss = 6753.71 (* 1 = 6753.71 loss)
I0826 20:44:59.532590  5239 sgd_solver.cpp:106] Iteration 6250, lr = 1e-06
I0826 20:46:17.237833  5239 solver.cpp:228] Iteration 6300, loss = 4648.87
I0826 20:46:17.237910  5239 solver.cpp:244]     Train net output #0: accuracy = 0.955395
I0826 20:46:17.237921  5239 solver.cpp:244]     Train net output #1: loss = 4648.87 (* 1 = 4648.87 loss)
I0826 20:46:17.237928  5239 sgd_solver.cpp:106] Iteration 6300, lr = 1e-06
I0826 20:47:35.971096  5239 solver.cpp:228] Iteration 6350, loss = 7354.24
I0826 20:47:35.971170  5239 solver.cpp:244]     Train net output #0: accuracy = 0.927472
I0826 20:47:35.971182  5239 solver.cpp:244]     Train net output #1: loss = 7354.24 (* 1 = 7354.24 loss)
I0826 20:47:35.971189  5239 sgd_solver.cpp:106] Iteration 6350, lr = 1e-06
I0826 20:48:50.894851  5239 solver.cpp:337] Iteration 6400, Testing net (#0)
I0826 20:48:58.716642  5239 solver.cpp:404]     Test net output #0: accuracy = 0.924422
I0826 20:48:58.716686  5239 solver.cpp:404]     Test net output #1: loss = 7824.15 (* 1 = 7824.15 loss)
I0826 20:49:00.100216  5239 solver.cpp:228] Iteration 6400, loss = 4231.03
I0826 20:49:00.100253  5239 solver.cpp:244]     Train net output #0: accuracy = 0.958286
I0826 20:49:00.100263  5239 solver.cpp:244]     Train net output #1: loss = 4231.03 (* 1 = 4231.03 loss)
I0826 20:49:00.100270  5239 sgd_solver.cpp:106] Iteration 6400, lr = 1e-06
I0826 20:50:16.320029  5239 solver.cpp:228] Iteration 6450, loss = 8422.86
I0826 20:50:16.320111  5239 solver.cpp:244]     Train net output #0: accuracy = 0.91898
I0826 20:50:16.320122  5239 solver.cpp:244]     Train net output #1: loss = 8422.86 (* 1 = 8422.86 loss)
I0826 20:50:16.320128  5239 sgd_solver.cpp:106] Iteration 6450, lr = 1e-06
I0826 20:51:32.900185  5239 solver.cpp:228] Iteration 6500, loss = 9015.05
I0826 20:51:32.900279  5239 solver.cpp:244]     Train net output #0: accuracy = 0.913363
I0826 20:51:32.900296  5239 solver.cpp:244]     Train net output #1: loss = 9015.05 (* 1 = 9015.05 loss)
I0826 20:51:32.900321  5239 sgd_solver.cpp:106] Iteration 6500, lr = 1e-06
I0826 20:52:51.742710  5239 solver.cpp:228] Iteration 6550, loss = 4771.75
I0826 20:52:51.742851  5239 solver.cpp:244]     Train net output #0: accuracy = 0.953278
I0826 20:52:51.742864  5239 solver.cpp:244]     Train net output #1: loss = 4771.75 (* 1 = 4771.75 loss)
I0826 20:52:51.742871  5239 sgd_solver.cpp:106] Iteration 6550, lr = 1e-06
I0826 20:54:07.039082  5239 solver.cpp:337] Iteration 6600, Testing net (#0)
I0826 20:54:15.244804  5239 solver.cpp:404]     Test net output #0: accuracy = 0.928595
I0826 20:54:15.244858  5239 solver.cpp:404]     Test net output #1: loss = 7481.09 (* 1 = 7481.09 loss)
I0826 20:54:16.618528  5239 solver.cpp:228] Iteration 6600, loss = 10261.2
I0826 20:54:16.618566  5239 solver.cpp:244]     Train net output #0: accuracy = 0.901004
I0826 20:54:16.618577  5239 solver.cpp:244]     Train net output #1: loss = 10261.2 (* 1 = 10261.2 loss)
I0826 20:54:16.618582  5239 sgd_solver.cpp:106] Iteration 6600, lr = 1e-06
I0826 20:55:33.666370  5239 solver.cpp:228] Iteration 6650, loss = 5425.19
I0826 20:55:33.666447  5239 solver.cpp:244]     Train net output #0: accuracy = 0.947266
I0826 20:55:33.666460  5239 solver.cpp:244]     Train net output #1: loss = 5425.19 (* 1 = 5425.19 loss)
I0826 20:55:33.666467  5239 sgd_solver.cpp:106] Iteration 6650, lr = 1e-06
I0826 20:56:50.908818  5239 solver.cpp:228] Iteration 6700, loss = 8142.68
I0826 20:56:50.908902  5239 solver.cpp:244]     Train net output #0: accuracy = 0.923088
I0826 20:56:50.908921  5239 solver.cpp:244]     Train net output #1: loss = 8142.68 (* 1 = 8142.68 loss)
I0826 20:56:50.908931  5239 sgd_solver.cpp:106] Iteration 6700, lr = 1e-06
I0826 20:58:07.531759  5239 solver.cpp:228] Iteration 6750, loss = 4324.09
I0826 20:58:07.531833  5239 solver.cpp:244]     Train net output #0: accuracy = 0.957852
I0826 20:58:07.531846  5239 solver.cpp:244]     Train net output #1: loss = 4324.09 (* 1 = 4324.09 loss)
I0826 20:58:07.531852  5239 sgd_solver.cpp:106] Iteration 6750, lr = 1e-06
I0826 20:59:24.671589  5239 solver.cpp:337] Iteration 6800, Testing net (#0)
I0826 20:59:32.684039  5239 solver.cpp:404]     Test net output #0: accuracy = 0.927295
I0826 20:59:32.684080  5239 solver.cpp:404]     Test net output #1: loss = 7550.48 (* 1 = 7550.48 loss)
I0826 20:59:33.984362  5239 solver.cpp:228] Iteration 6800, loss = 7768.81
I0826 20:59:33.984400  5239 solver.cpp:244]     Train net output #0: accuracy = 0.92355
I0826 20:59:33.984408  5239 solver.cpp:244]     Train net output #1: loss = 7768.81 (* 1 = 7768.81 loss)
I0826 20:59:33.984416  5239 sgd_solver.cpp:106] Iteration 6800, lr = 1e-06
I0826 21:00:51.903918  5239 solver.cpp:228] Iteration 6850, loss = 6485.13
I0826 21:00:51.903995  5239 solver.cpp:244]     Train net output #0: accuracy = 0.936214
I0826 21:00:51.904006  5239 solver.cpp:244]     Train net output #1: loss = 6485.13 (* 1 = 6485.13 loss)
I0826 21:00:51.904012  5239 sgd_solver.cpp:106] Iteration 6850, lr = 1e-06
I0826 21:02:09.030112  5239 solver.cpp:228] Iteration 6900, loss = 4744.69
I0826 21:02:09.030189  5239 solver.cpp:244]     Train net output #0: accuracy = 0.954001
I0826 21:02:09.030200  5239 solver.cpp:244]     Train net output #1: loss = 4744.69 (* 1 = 4744.69 loss)
I0826 21:02:09.030206  5239 sgd_solver.cpp:106] Iteration 6900, lr = 1e-06
I0826 21:03:26.218708  5239 solver.cpp:228] Iteration 6950, loss = 8994.58
I0826 21:03:26.218786  5239 solver.cpp:244]     Train net output #0: accuracy = 0.909767
I0826 21:03:26.218797  5239 solver.cpp:244]     Train net output #1: loss = 8994.58 (* 1 = 8994.58 loss)
I0826 21:03:26.218804  5239 sgd_solver.cpp:106] Iteration 6950, lr = 1e-06
I0826 21:04:41.235868  5239 solver.cpp:337] Iteration 7000, Testing net (#0)
I0826 21:04:49.326833  5239 solver.cpp:404]     Test net output #0: accuracy = 0.928195
I0826 21:04:49.326874  5239 solver.cpp:404]     Test net output #1: loss = 7489.04 (* 1 = 7489.04 loss)
I0826 21:04:50.755038  5239 solver.cpp:228] Iteration 7000, loss = 4698.77
I0826 21:04:50.755084  5239 solver.cpp:244]     Train net output #0: accuracy = 0.95314
I0826 21:04:50.755110  5239 solver.cpp:244]     Train net output #1: loss = 4698.77 (* 1 = 4698.77 loss)
I0826 21:04:50.755120  5239 sgd_solver.cpp:106] Iteration 7000, lr = 1e-06
I0826 21:06:06.846814  5239 solver.cpp:228] Iteration 7050, loss = 8861.62
I0826 21:06:06.846940  5239 solver.cpp:244]     Train net output #0: accuracy = 0.915714
I0826 21:06:06.846953  5239 solver.cpp:244]     Train net output #1: loss = 8861.62 (* 1 = 8861.62 loss)
I0826 21:06:06.846961  5239 sgd_solver.cpp:106] Iteration 7050, lr = 1e-06
I0826 21:07:23.471238  5239 solver.cpp:228] Iteration 7100, loss = 5680.78
I0826 21:07:23.471316  5239 solver.cpp:244]     Train net output #0: accuracy = 0.944669
I0826 21:07:23.471328  5239 solver.cpp:244]     Train net output #1: loss = 5680.78 (* 1 = 5680.78 loss)
I0826 21:07:23.471335  5239 sgd_solver.cpp:106] Iteration 7100, lr = 1e-06
I0826 21:08:40.029695  5239 solver.cpp:228] Iteration 7150, loss = 6856.96
I0826 21:08:40.029783  5239 solver.cpp:244]     Train net output #0: accuracy = 0.933645
I0826 21:08:40.029800  5239 solver.cpp:244]     Train net output #1: loss = 6856.96 (* 1 = 6856.96 loss)
I0826 21:08:40.029809  5239 sgd_solver.cpp:106] Iteration 7150, lr = 1e-06
I0826 21:09:56.135309  5239 solver.cpp:337] Iteration 7200, Testing net (#0)
I0826 21:10:04.499253  5239 solver.cpp:404]     Test net output #0: accuracy = 0.929747
I0826 21:10:04.499301  5239 solver.cpp:404]     Test net output #1: loss = 7323.81 (* 1 = 7323.81 loss)
I0826 21:10:05.894281  5239 solver.cpp:228] Iteration 7200, loss = 4321.17
I0826 21:10:05.894320  5239 solver.cpp:244]     Train net output #0: accuracy = 0.957956
I0826 21:10:05.894330  5239 solver.cpp:244]     Train net output #1: loss = 4321.17 (* 1 = 4321.17 loss)
I0826 21:10:05.894336  5239 sgd_solver.cpp:106] Iteration 7200, lr = 1e-06
I0826 21:11:22.653177  5239 solver.cpp:228] Iteration 7250, loss = 5718.52
I0826 21:11:22.653257  5239 solver.cpp:244]     Train net output #0: accuracy = 0.944566
I0826 21:11:22.653270  5239 solver.cpp:244]     Train net output #1: loss = 5718.52 (* 1 = 5718.52 loss)
I0826 21:11:22.653275  5239 sgd_solver.cpp:106] Iteration 7250, lr = 1e-06
I0826 21:12:38.925302  5239 solver.cpp:228] Iteration 7300, loss = 7323.16
I0826 21:12:38.925376  5239 solver.cpp:244]     Train net output #0: accuracy = 0.926452
I0826 21:12:38.925389  5239 solver.cpp:244]     Train net output #1: loss = 7323.16 (* 1 = 7323.16 loss)
I0826 21:12:38.925395  5239 sgd_solver.cpp:106] Iteration 7300, lr = 1e-06
I0826 21:13:55.957361  5239 solver.cpp:228] Iteration 7350, loss = 4670.45
I0826 21:13:55.957460  5239 solver.cpp:244]     Train net output #0: accuracy = 0.954462
I0826 21:13:55.957471  5239 solver.cpp:244]     Train net output #1: loss = 4670.45 (* 1 = 4670.45 loss)
I0826 21:13:55.957479  5239 sgd_solver.cpp:106] Iteration 7350, lr = 1e-06
I0826 21:15:10.638074  5239 solver.cpp:337] Iteration 7400, Testing net (#0)
I0826 21:15:19.023522  5239 solver.cpp:404]     Test net output #0: accuracy = 0.926971
I0826 21:15:19.023568  5239 solver.cpp:404]     Test net output #1: loss = 7618.25 (* 1 = 7618.25 loss)
I0826 21:15:20.423104  5239 solver.cpp:228] Iteration 7400, loss = 8688.23
I0826 21:15:20.423152  5239 solver.cpp:244]     Train net output #0: accuracy = 0.914119
I0826 21:15:20.423167  5239 solver.cpp:244]     Train net output #1: loss = 8688.23 (* 1 = 8688.23 loss)
I0826 21:15:20.423177  5239 sgd_solver.cpp:106] Iteration 7400, lr = 1e-06
I0826 21:16:37.185480  5239 solver.cpp:228] Iteration 7450, loss = 5278.49
I0826 21:16:37.185572  5239 solver.cpp:244]     Train net output #0: accuracy = 0.949249
I0826 21:16:37.185587  5239 solver.cpp:244]     Train net output #1: loss = 5278.49 (* 1 = 5278.49 loss)
I0826 21:16:37.185596  5239 sgd_solver.cpp:106] Iteration 7450, lr = 1e-06
I0826 21:17:54.187877  5239 solver.cpp:228] Iteration 7500, loss = 10328.4
I0826 21:17:54.187954  5239 solver.cpp:244]     Train net output #0: accuracy = 0.903115
I0826 21:17:54.187966  5239 solver.cpp:244]     Train net output #1: loss = 10328.4 (* 1 = 10328.4 loss)
I0826 21:17:54.187981  5239 sgd_solver.cpp:106] Iteration 7500, lr = 1e-06
I0826 21:19:11.484840  5239 solver.cpp:228] Iteration 7550, loss = 5892
I0826 21:19:11.484948  5239 solver.cpp:244]     Train net output #0: accuracy = 0.943478
I0826 21:19:11.484961  5239 solver.cpp:244]     Train net output #1: loss = 5892 (* 1 = 5892 loss)
I0826 21:19:11.484967  5239 sgd_solver.cpp:106] Iteration 7550, lr = 1e-06
I0826 21:20:29.152968  5239 solver.cpp:337] Iteration 7600, Testing net (#0)
I0826 21:20:36.968665  5239 solver.cpp:404]     Test net output #0: accuracy = 0.930167
I0826 21:20:36.968719  5239 solver.cpp:404]     Test net output #1: loss = 7286.53 (* 1 = 7286.53 loss)
I0826 21:20:38.367807  5239 solver.cpp:228] Iteration 7600, loss = 6336.14
I0826 21:20:38.367846  5239 solver.cpp:244]     Train net output #0: accuracy = 0.938773
I0826 21:20:38.367856  5239 solver.cpp:244]     Train net output #1: loss = 6336.14 (* 1 = 6336.14 loss)
I0826 21:20:38.367862  5239 sgd_solver.cpp:106] Iteration 7600, lr = 1e-06
I0826 21:21:57.005717  5239 solver.cpp:228] Iteration 7650, loss = 7404.93
I0826 21:21:57.005813  5239 solver.cpp:244]     Train net output #0: accuracy = 0.930295
I0826 21:21:57.005831  5239 solver.cpp:244]     Train net output #1: loss = 7404.93 (* 1 = 7404.93 loss)
I0826 21:21:57.005839  5239 sgd_solver.cpp:106] Iteration 7650, lr = 1e-06
I0826 21:23:14.312484  5239 solver.cpp:228] Iteration 7700, loss = 4407.46
I0826 21:23:14.312566  5239 solver.cpp:244]     Train net output #0: accuracy = 0.958255
I0826 21:23:14.312578  5239 solver.cpp:244]     Train net output #1: loss = 4407.46 (* 1 = 4407.46 loss)
I0826 21:23:14.312584  5239 sgd_solver.cpp:106] Iteration 7700, lr = 1e-06
I0826 21:24:30.098578  5239 solver.cpp:228] Iteration 7750, loss = 7285.36
I0826 21:24:30.098657  5239 solver.cpp:244]     Train net output #0: accuracy = 0.92754
I0826 21:24:30.098669  5239 solver.cpp:244]     Train net output #1: loss = 7285.36 (* 1 = 7285.36 loss)
I0826 21:24:30.098675  5239 sgd_solver.cpp:106] Iteration 7750, lr = 1e-06
I0826 21:25:45.540307  5239 solver.cpp:337] Iteration 7800, Testing net (#0)
I0826 21:25:53.714377  5239 solver.cpp:404]     Test net output #0: accuracy = 0.928033
I0826 21:25:53.714422  5239 solver.cpp:404]     Test net output #1: loss = 7484 (* 1 = 7484 loss)
I0826 21:25:55.244249  5239 solver.cpp:228] Iteration 7800, loss = 4674.42
I0826 21:25:55.244298  5239 solver.cpp:244]     Train net output #0: accuracy = 0.953778
I0826 21:25:55.244313  5239 solver.cpp:244]     Train net output #1: loss = 4674.42 (* 1 = 4674.42 loss)
I0826 21:25:55.244323  5239 sgd_solver.cpp:106] Iteration 7800, lr = 1e-06
I0826 21:27:13.052739  5239 solver.cpp:228] Iteration 7850, loss = 8960.7
I0826 21:27:13.052826  5239 solver.cpp:244]     Train net output #0: accuracy = 0.910361
I0826 21:27:13.052839  5239 solver.cpp:244]     Train net output #1: loss = 8960.7 (* 1 = 8960.7 loss)
I0826 21:27:13.052846  5239 sgd_solver.cpp:106] Iteration 7850, lr = 1e-06
I0826 21:28:26.796381  5239 solver.cpp:228] Iteration 7900, loss = 4815.83
I0826 21:28:26.796455  5239 solver.cpp:244]     Train net output #0: accuracy = 0.953996
I0826 21:28:26.796466  5239 solver.cpp:244]     Train net output #1: loss = 4815.83 (* 1 = 4815.83 loss)
I0826 21:28:26.796473  5239 sgd_solver.cpp:106] Iteration 7900, lr = 1e-06
I0826 21:29:42.625928  5239 solver.cpp:228] Iteration 7950, loss = 8385.12
I0826 21:29:42.626022  5239 solver.cpp:244]     Train net output #0: accuracy = 0.919487
I0826 21:29:42.626037  5239 solver.cpp:244]     Train net output #1: loss = 8385.12 (* 1 = 8385.12 loss)
I0826 21:29:42.626047  5239 sgd_solver.cpp:106] Iteration 7950, lr = 1e-06
I0826 21:30:57.905321  5239 solver.cpp:454] Snapshotting to binary proto file portrait_one_stage4_iter_8000.caffemodel
I0826 21:30:57.911038  5239 sgd_solver.cpp:273] Snapshotting solver state to binary proto file portrait_one_stage4_iter_8000.solverstate
I0826 21:30:57.912137  5239 solver.cpp:337] Iteration 8000, Testing net (#0)
I0826 21:31:06.391186  5239 solver.cpp:404]     Test net output #0: accuracy = 0.929517
I0826 21:31:06.391252  5239 solver.cpp:404]     Test net output #1: loss = 7346.29 (* 1 = 7346.29 loss)
I0826 21:31:07.806886  5239 solver.cpp:228] Iteration 8000, loss = 7903.44
I0826 21:31:07.806933  5239 solver.cpp:244]     Train net output #0: accuracy = 0.925731
I0826 21:31:07.806946  5239 solver.cpp:244]     Train net output #1: loss = 7903.44 (* 1 = 7903.44 loss)
I0826 21:31:07.806957  5239 sgd_solver.cpp:106] Iteration 8000, lr = 1e-07
I0826 21:32:27.170341  5239 solver.cpp:228] Iteration 8050, loss = 4871.79
I0826 21:32:27.170469  5239 solver.cpp:244]     Train net output #0: accuracy = 0.95358
I0826 21:32:27.170487  5239 solver.cpp:244]     Train net output #1: loss = 4871.79 (* 1 = 4871.79 loss)
I0826 21:32:27.170496  5239 sgd_solver.cpp:106] Iteration 8050, lr = 1e-07
I0826 21:33:43.482677  5239 solver.cpp:228] Iteration 8100, loss = 6245.15
I0826 21:33:43.482774  5239 solver.cpp:244]     Train net output #0: accuracy = 0.939199
I0826 21:33:43.482792  5239 solver.cpp:244]     Train net output #1: loss = 6245.15 (* 1 = 6245.15 loss)
I0826 21:33:43.482802  5239 sgd_solver.cpp:106] Iteration 8100, lr = 1e-07
I0826 21:35:00.149627  5239 solver.cpp:228] Iteration 8150, loss = 4232.57
I0826 21:35:00.149708  5239 solver.cpp:244]     Train net output #0: accuracy = 0.959454
I0826 21:35:00.149720  5239 solver.cpp:244]     Train net output #1: loss = 4232.57 (* 1 = 4232.57 loss)
I0826 21:35:00.149726  5239 sgd_solver.cpp:106] Iteration 8150, lr = 1e-07
I0826 21:36:15.719841  5239 solver.cpp:337] Iteration 8200, Testing net (#0)
I0826 21:36:23.997253  5239 solver.cpp:404]     Test net output #0: accuracy = 0.931163
I0826 21:36:23.997305  5239 solver.cpp:404]     Test net output #1: loss = 7190.42 (* 1 = 7190.42 loss)
I0826 21:36:25.399608  5239 solver.cpp:228] Iteration 8200, loss = 7865.08
I0826 21:36:25.399654  5239 solver.cpp:244]     Train net output #0: accuracy = 0.923371
I0826 21:36:25.399664  5239 solver.cpp:244]     Train net output #1: loss = 7865.08 (* 1 = 7865.08 loss)
I0826 21:36:25.399672  5239 sgd_solver.cpp:106] Iteration 8200, lr = 1e-07
I0826 21:37:42.619788  5239 solver.cpp:228] Iteration 8250, loss = 4617.3
I0826 21:37:42.619887  5239 solver.cpp:244]     Train net output #0: accuracy = 0.954593
I0826 21:37:42.619904  5239 solver.cpp:244]     Train net output #1: loss = 4617.3 (* 1 = 4617.3 loss)
I0826 21:37:42.619912  5239 sgd_solver.cpp:106] Iteration 8250, lr = 1e-07
I0826 21:39:00.538100  5239 solver.cpp:228] Iteration 8300, loss = 8134.33
I0826 21:39:00.538205  5239 solver.cpp:244]     Train net output #0: accuracy = 0.918921
I0826 21:39:00.538223  5239 solver.cpp:244]     Train net output #1: loss = 8134.33 (* 1 = 8134.33 loss)
I0826 21:39:00.538230  5239 sgd_solver.cpp:106] Iteration 8300, lr = 1e-07
I0826 21:40:17.142722  5239 solver.cpp:228] Iteration 8350, loss = 4687.02
I0826 21:40:17.142817  5239 solver.cpp:244]     Train net output #0: accuracy = 0.954103
I0826 21:40:17.142837  5239 solver.cpp:244]     Train net output #1: loss = 4687.02 (* 1 = 4687.02 loss)
I0826 21:40:17.142848  5239 sgd_solver.cpp:106] Iteration 8350, lr = 1e-07
I0826 21:41:32.190475  5239 solver.cpp:337] Iteration 8400, Testing net (#0)
I0826 21:41:40.487735  5239 solver.cpp:404]     Test net output #0: accuracy = 0.927544
I0826 21:41:40.487777  5239 solver.cpp:404]     Test net output #1: loss = 7555.86 (* 1 = 7555.86 loss)
I0826 21:41:41.889497  5239 solver.cpp:228] Iteration 8400, loss = 4799.5
I0826 21:41:41.889536  5239 solver.cpp:244]     Train net output #0: accuracy = 0.953779
I0826 21:41:41.889546  5239 solver.cpp:244]     Train net output #1: loss = 4799.5 (* 1 = 4799.5 loss)
I0826 21:41:41.889552  5239 sgd_solver.cpp:106] Iteration 8400, lr = 1e-07
I0826 21:42:57.144773  5239 solver.cpp:228] Iteration 8450, loss = 10022.4
I0826 21:42:57.144875  5239 solver.cpp:244]     Train net output #0: accuracy = 0.904178
I0826 21:42:57.144886  5239 solver.cpp:244]     Train net output #1: loss = 10022.4 (* 1 = 10022.4 loss)
I0826 21:42:57.144893  5239 sgd_solver.cpp:106] Iteration 8450, lr = 1e-07
I0826 21:44:13.693948  5239 solver.cpp:228] Iteration 8500, loss = 5154.96
I0826 21:44:13.694058  5239 solver.cpp:244]     Train net output #0: accuracy = 0.949551
I0826 21:44:13.694072  5239 solver.cpp:244]     Train net output #1: loss = 5154.96 (* 1 = 5154.96 loss)
I0826 21:44:13.694078  5239 sgd_solver.cpp:106] Iteration 8500, lr = 1e-07
I0826 21:45:28.727349  5239 solver.cpp:228] Iteration 8550, loss = 6480.6
I0826 21:45:28.727430  5239 solver.cpp:244]     Train net output #0: accuracy = 0.936891
I0826 21:45:28.727442  5239 solver.cpp:244]     Train net output #1: loss = 6480.6 (* 1 = 6480.6 loss)
I0826 21:45:28.727448  5239 sgd_solver.cpp:106] Iteration 8550, lr = 1e-07
I0826 21:46:44.149399  5239 solver.cpp:337] Iteration 8600, Testing net (#0)
I0826 21:46:52.270402  5239 solver.cpp:404]     Test net output #0: accuracy = 0.930979
I0826 21:46:52.270445  5239 solver.cpp:404]     Test net output #1: loss = 7212.29 (* 1 = 7212.29 loss)
I0826 21:46:53.665392  5239 solver.cpp:228] Iteration 8600, loss = 4397.5
I0826 21:46:53.665429  5239 solver.cpp:244]     Train net output #0: accuracy = 0.957892
I0826 21:46:53.665438  5239 solver.cpp:244]     Train net output #1: loss = 4397.5 (* 1 = 4397.5 loss)
I0826 21:46:53.665444  5239 sgd_solver.cpp:106] Iteration 8600, lr = 1e-07
I0826 21:48:10.396572  5239 solver.cpp:228] Iteration 8650, loss = 7265.18
I0826 21:48:10.396667  5239 solver.cpp:244]     Train net output #0: accuracy = 0.928831
I0826 21:48:10.396682  5239 solver.cpp:244]     Train net output #1: loss = 7265.18 (* 1 = 7265.18 loss)
I0826 21:48:10.396692  5239 sgd_solver.cpp:106] Iteration 8650, lr = 1e-07
I0826 21:49:28.715584  5239 solver.cpp:228] Iteration 8700, loss = 4198.06
I0826 21:49:28.715682  5239 solver.cpp:244]     Train net output #0: accuracy = 0.958278
I0826 21:49:28.715694  5239 solver.cpp:244]     Train net output #1: loss = 4198.06 (* 1 = 4198.06 loss)
I0826 21:49:28.715701  5239 sgd_solver.cpp:106] Iteration 8700, lr = 1e-07
I0826 21:50:46.139185  5239 solver.cpp:228] Iteration 8750, loss = 7955.54
I0826 21:50:46.139292  5239 solver.cpp:244]     Train net output #0: accuracy = 0.925713
I0826 21:50:46.139310  5239 solver.cpp:244]     Train net output #1: loss = 7955.54 (* 1 = 7955.54 loss)
I0826 21:50:46.139320  5239 sgd_solver.cpp:106] Iteration 8750, lr = 1e-07
I0826 21:52:02.776487  5239 solver.cpp:337] Iteration 8800, Testing net (#0)
I0826 21:52:10.689112  5239 solver.cpp:404]     Test net output #0: accuracy = 0.931064
I0826 21:52:10.689163  5239 solver.cpp:404]     Test net output #1: loss = 7216.95 (* 1 = 7216.95 loss)
I0826 21:52:12.081553  5239 solver.cpp:228] Iteration 8800, loss = 8588.12
I0826 21:52:12.081609  5239 solver.cpp:244]     Train net output #0: accuracy = 0.916851
I0826 21:52:12.081619  5239 solver.cpp:244]     Train net output #1: loss = 8588.12 (* 1 = 8588.12 loss)
I0826 21:52:12.081627  5239 sgd_solver.cpp:106] Iteration 8800, lr = 1e-07
I0826 21:53:29.211258  5239 solver.cpp:228] Iteration 8850, loss = 4644.93
I0826 21:53:29.211334  5239 solver.cpp:244]     Train net output #0: accuracy = 0.955295
I0826 21:53:29.211346  5239 solver.cpp:244]     Train net output #1: loss = 4644.93 (* 1 = 4644.93 loss)
I0826 21:53:29.211352  5239 sgd_solver.cpp:106] Iteration 8850, lr = 1e-07
I0826 21:54:46.880714  5239 solver.cpp:228] Iteration 8900, loss = 9498.52
I0826 21:54:46.880790  5239 solver.cpp:244]     Train net output #0: accuracy = 0.909304
I0826 21:54:46.880801  5239 solver.cpp:244]     Train net output #1: loss = 9498.52 (* 1 = 9498.52 loss)
I0826 21:54:46.880807  5239 sgd_solver.cpp:106] Iteration 8900, lr = 1e-07
I0826 21:56:10.187288  5239 solver.cpp:228] Iteration 8950, loss = 5156.09
I0826 21:56:10.187364  5239 solver.cpp:244]     Train net output #0: accuracy = 0.949336
I0826 21:56:10.187376  5239 solver.cpp:244]     Train net output #1: loss = 5156.09 (* 1 = 5156.09 loss)
I0826 21:56:10.187382  5239 sgd_solver.cpp:106] Iteration 8950, lr = 1e-07
I0826 21:57:29.284823  5239 solver.cpp:337] Iteration 9000, Testing net (#0)
I0826 21:57:37.478659  5239 solver.cpp:404]     Test net output #0: accuracy = 0.93088
I0826 21:57:37.478708  5239 solver.cpp:404]     Test net output #1: loss = 7183.22 (* 1 = 7183.22 loss)
I0826 21:57:38.898133  5239 solver.cpp:228] Iteration 9000, loss = 7289.85
I0826 21:57:38.898170  5239 solver.cpp:244]     Train net output #0: accuracy = 0.9304
I0826 21:57:38.898180  5239 solver.cpp:244]     Train net output #1: loss = 7289.85 (* 1 = 7289.85 loss)
I0826 21:57:38.898185  5239 sgd_solver.cpp:106] Iteration 9000, lr = 1e-07
I0826 21:58:56.311035  5239 solver.cpp:228] Iteration 9050, loss = 4208.47
I0826 21:58:56.311108  5239 solver.cpp:244]     Train net output #0: accuracy = 0.958914
I0826 21:58:56.311121  5239 solver.cpp:244]     Train net output #1: loss = 4208.47 (* 1 = 4208.47 loss)
I0826 21:58:56.311128  5239 sgd_solver.cpp:106] Iteration 9050, lr = 1e-07
I0826 22:00:13.393877  5239 solver.cpp:228] Iteration 9100, loss = 7649.7
I0826 22:00:13.393982  5239 solver.cpp:244]     Train net output #0: accuracy = 0.925084
I0826 22:00:13.394003  5239 solver.cpp:244]     Train net output #1: loss = 7649.7 (* 1 = 7649.7 loss)
I0826 22:00:13.394011  5239 sgd_solver.cpp:106] Iteration 9100, lr = 1e-07
I0826 22:01:30.790545  5239 solver.cpp:228] Iteration 9150, loss = 6856.51
I0826 22:01:30.790642  5239 solver.cpp:244]     Train net output #0: accuracy = 0.933214
I0826 22:01:30.790657  5239 solver.cpp:244]     Train net output #1: loss = 6856.51 (* 1 = 6856.51 loss)
I0826 22:01:30.790666  5239 sgd_solver.cpp:106] Iteration 9150, lr = 1e-07
I0826 22:02:51.386319  5239 solver.cpp:337] Iteration 9200, Testing net (#0)
I0826 22:03:01.641525  5239 solver.cpp:404]     Test net output #0: accuracy = 0.931826
I0826 22:03:01.641599  5239 solver.cpp:404]     Test net output #1: loss = 7122.77 (* 1 = 7122.77 loss)
I0826 22:03:03.407706  5239 solver.cpp:228] Iteration 9200, loss = 4780.47
I0826 22:03:03.407771  5239 solver.cpp:244]     Train net output #0: accuracy = 0.953911
I0826 22:03:03.407790  5239 solver.cpp:244]     Train net output #1: loss = 4780.47 (* 1 = 4780.47 loss)
I0826 22:03:03.407802  5239 sgd_solver.cpp:106] Iteration 9200, lr = 1e-07
I0826 22:04:19.398308  5239 solver.cpp:228] Iteration 9250, loss = 9254.86
I0826 22:04:19.398387  5239 solver.cpp:244]     Train net output #0: accuracy = 0.908927
I0826 22:04:19.398399  5239 solver.cpp:244]     Train net output #1: loss = 9254.86 (* 1 = 9254.86 loss)
I0826 22:04:19.398406  5239 sgd_solver.cpp:106] Iteration 9250, lr = 1e-07
I0826 22:05:43.694602  5239 solver.cpp:228] Iteration 9300, loss = 4310.46
I0826 22:05:43.694690  5239 solver.cpp:244]     Train net output #0: accuracy = 0.956906
I0826 22:05:43.694701  5239 solver.cpp:244]     Train net output #1: loss = 4310.46 (* 1 = 4310.46 loss)
I0826 22:05:43.694708  5239 sgd_solver.cpp:106] Iteration 9300, lr = 1e-07
I0826 22:07:02.304060  5239 solver.cpp:228] Iteration 9350, loss = 8592.72
I0826 22:07:02.304146  5239 solver.cpp:244]     Train net output #0: accuracy = 0.917806
I0826 22:07:02.304157  5239 solver.cpp:244]     Train net output #1: loss = 8592.72 (* 1 = 8592.72 loss)
I0826 22:07:02.304164  5239 sgd_solver.cpp:106] Iteration 9350, lr = 1e-07
I0826 22:08:15.742719  5239 solver.cpp:337] Iteration 9400, Testing net (#0)
I0826 22:08:24.122164  5239 solver.cpp:404]     Test net output #0: accuracy = 0.927236
I0826 22:08:24.122205  5239 solver.cpp:404]     Test net output #1: loss = 7596.62 (* 1 = 7596.62 loss)
I0826 22:08:25.512212  5239 solver.cpp:228] Iteration 9400, loss = 5723.03
I0826 22:08:25.512248  5239 solver.cpp:244]     Train net output #0: accuracy = 0.945017
I0826 22:08:25.512257  5239 solver.cpp:244]     Train net output #1: loss = 5723.03 (* 1 = 5723.03 loss)
I0826 22:08:25.512265  5239 sgd_solver.cpp:106] Iteration 9400, lr = 1e-07
I0826 22:09:43.648654  5239 solver.cpp:228] Iteration 9450, loss = 6864.76
I0826 22:09:43.648758  5239 solver.cpp:244]     Train net output #0: accuracy = 0.933166
I0826 22:09:43.648774  5239 solver.cpp:244]     Train net output #1: loss = 6864.76 (* 1 = 6864.76 loss)
I0826 22:09:43.648784  5239 sgd_solver.cpp:106] Iteration 9450, lr = 1e-07
I0826 22:11:02.009470  5239 solver.cpp:228] Iteration 9500, loss = 4570.21
I0826 22:11:02.009584  5239 solver.cpp:244]     Train net output #0: accuracy = 0.956144
I0826 22:11:02.009598  5239 solver.cpp:244]     Train net output #1: loss = 4570.21 (* 1 = 4570.21 loss)
I0826 22:11:02.009603  5239 sgd_solver.cpp:106] Iteration 9500, lr = 1e-07
I0826 22:12:18.928051  5239 solver.cpp:228] Iteration 9550, loss = 4395.68
I0826 22:12:18.928127  5239 solver.cpp:244]     Train net output #0: accuracy = 0.957826
I0826 22:12:18.928138  5239 solver.cpp:244]     Train net output #1: loss = 4395.68 (* 1 = 4395.68 loss)
I0826 22:12:18.928145  5239 sgd_solver.cpp:106] Iteration 9550, lr = 1e-07
I0826 22:13:34.897291  5239 solver.cpp:337] Iteration 9600, Testing net (#0)
I0826 22:13:43.381047  5239 solver.cpp:404]     Test net output #0: accuracy = 0.931146
I0826 22:13:43.381088  5239 solver.cpp:404]     Test net output #1: loss = 7184.64 (* 1 = 7184.64 loss)
I0826 22:13:44.670516  5239 solver.cpp:228] Iteration 9600, loss = 7389.51
I0826 22:13:44.670554  5239 solver.cpp:244]     Train net output #0: accuracy = 0.926688
I0826 22:13:44.670564  5239 solver.cpp:244]     Train net output #1: loss = 7389.51 (* 1 = 7389.51 loss)
I0826 22:13:44.670572  5239 sgd_solver.cpp:106] Iteration 9600, lr = 1e-07
I0826 22:15:02.328811  5239 solver.cpp:228] Iteration 9650, loss = 4573.98
I0826 22:15:02.328879  5239 solver.cpp:244]     Train net output #0: accuracy = 0.955497
I0826 22:15:02.328891  5239 solver.cpp:244]     Train net output #1: loss = 4573.98 (* 1 = 4573.98 loss)
I0826 22:15:02.328897  5239 sgd_solver.cpp:106] Iteration 9650, lr = 1e-07
I0826 22:16:19.035325  5239 solver.cpp:228] Iteration 9700, loss = 8422.93
I0826 22:16:19.035394  5239 solver.cpp:244]     Train net output #0: accuracy = 0.916849
I0826 22:16:19.035404  5239 solver.cpp:244]     Train net output #1: loss = 8422.93 (* 1 = 8422.93 loss)
I0826 22:16:19.035411  5239 sgd_solver.cpp:106] Iteration 9700, lr = 1e-07
I0826 22:17:35.478895  5239 solver.cpp:228] Iteration 9750, loss = 4914.12
I0826 22:17:35.478965  5239 solver.cpp:244]     Train net output #0: accuracy = 0.951769
I0826 22:17:35.478976  5239 solver.cpp:244]     Train net output #1: loss = 4914.12 (* 1 = 4914.12 loss)
I0826 22:17:35.478983  5239 sgd_solver.cpp:106] Iteration 9750, lr = 1e-07
I0826 22:18:53.870115  5239 solver.cpp:337] Iteration 9800, Testing net (#0)
I0826 22:19:02.201416  5239 solver.cpp:404]     Test net output #0: accuracy = 0.931838
I0826 22:19:02.201468  5239 solver.cpp:404]     Test net output #1: loss = 7126.26 (* 1 = 7126.26 loss)
I0826 22:19:03.618162  5239 solver.cpp:228] Iteration 9800, loss = 10021.3
I0826 22:19:03.618213  5239 solver.cpp:244]     Train net output #0: accuracy = 0.905506
I0826 22:19:03.618224  5239 solver.cpp:244]     Train net output #1: loss = 10021.3 (* 1 = 10021.3 loss)
I0826 22:19:03.618232  5239 sgd_solver.cpp:106] Iteration 9800, lr = 1e-07
I0826 22:20:21.236981  5239 solver.cpp:228] Iteration 9850, loss = 5919.6
I0826 22:20:21.237049  5239 solver.cpp:244]     Train net output #0: accuracy = 0.943003
I0826 22:20:21.237061  5239 solver.cpp:244]     Train net output #1: loss = 5919.6 (* 1 = 5919.6 loss)
I0826 22:20:21.237068  5239 sgd_solver.cpp:106] Iteration 9850, lr = 1e-07
I0826 22:21:37.764530  5239 solver.cpp:228] Iteration 9900, loss = 6192.59
I0826 22:21:37.764623  5239 solver.cpp:244]     Train net output #0: accuracy = 0.939022
I0826 22:21:37.764644  5239 solver.cpp:244]     Train net output #1: loss = 6192.59 (* 1 = 6192.59 loss)
I0826 22:21:37.764657  5239 sgd_solver.cpp:106] Iteration 9900, lr = 1e-07
I0826 22:22:55.060154  5239 solver.cpp:228] Iteration 9950, loss = 7254.51
I0826 22:22:55.060242  5239 solver.cpp:244]     Train net output #0: accuracy = 0.930533
I0826 22:22:55.060258  5239 solver.cpp:244]     Train net output #1: loss = 7254.51 (* 1 = 7254.51 loss)
I0826 22:22:55.060269  5239 sgd_solver.cpp:106] Iteration 9950, lr = 1e-07
I0826 22:24:09.679654  5239 solver.cpp:337] Iteration 10000, Testing net (#0)
I0826 22:24:17.785501  5239 solver.cpp:404]     Test net output #0: accuracy = 0.931389
I0826 22:24:17.785542  5239 solver.cpp:404]     Test net output #1: loss = 7137.53 (* 1 = 7137.53 loss)
I0826 22:24:19.144763  5239 solver.cpp:228] Iteration 10000, loss = 4189.18
I0826 22:24:19.144801  5239 solver.cpp:244]     Train net output #0: accuracy = 0.959979
I0826 22:24:19.144810  5239 solver.cpp:244]     Train net output #1: loss = 4189.18 (* 1 = 4189.18 loss)
I0826 22:24:19.144816  5239 sgd_solver.cpp:106] Iteration 10000, lr = 1e-07
I0826 22:25:34.665640  5239 solver.cpp:228] Iteration 10050, loss = 7277.79
I0826 22:25:34.665719  5239 solver.cpp:244]     Train net output #0: accuracy = 0.927807
I0826 22:25:34.665729  5239 solver.cpp:244]     Train net output #1: loss = 7277.79 (* 1 = 7277.79 loss)
I0826 22:25:34.665735  5239 sgd_solver.cpp:106] Iteration 10050, lr = 1e-07
I0826 22:26:52.044903  5239 solver.cpp:228] Iteration 10100, loss = 4809.78
I0826 22:26:52.044991  5239 solver.cpp:244]     Train net output #0: accuracy = 0.953011
I0826 22:26:52.045006  5239 solver.cpp:244]     Train net output #1: loss = 4809.78 (* 1 = 4809.78 loss)
I0826 22:26:52.045016  5239 sgd_solver.cpp:106] Iteration 10100, lr = 1e-07
I0826 22:28:09.276326  5239 solver.cpp:228] Iteration 10150, loss = 9082.88
I0826 22:28:09.276401  5239 solver.cpp:244]     Train net output #0: accuracy = 0.91016
I0826 22:28:09.276412  5239 solver.cpp:244]     Train net output #1: loss = 9082.88 (* 1 = 9082.88 loss)
I0826 22:28:09.276419  5239 sgd_solver.cpp:106] Iteration 10150, lr = 1e-07
I0826 22:29:25.300781  5239 solver.cpp:337] Iteration 10200, Testing net (#0)
I0826 22:29:33.681375  5239 solver.cpp:404]     Test net output #0: accuracy = 0.931809
I0826 22:29:33.681416  5239 solver.cpp:404]     Test net output #1: loss = 7124 (* 1 = 7124 loss)
I0826 22:29:35.078719  5239 solver.cpp:228] Iteration 10200, loss = 4354.11
I0826 22:29:35.078759  5239 solver.cpp:244]     Train net output #0: accuracy = 0.958396
I0826 22:29:35.078768  5239 solver.cpp:244]     Train net output #1: loss = 4354.11 (* 1 = 4354.11 loss)
I0826 22:29:35.078775  5239 sgd_solver.cpp:106] Iteration 10200, lr = 1e-07
I0826 22:30:52.485426  5239 solver.cpp:228] Iteration 10250, loss = 8405.26
I0826 22:30:52.485520  5239 solver.cpp:244]     Train net output #0: accuracy = 0.919107
I0826 22:30:52.485532  5239 solver.cpp:244]     Train net output #1: loss = 8405.26 (* 1 = 8405.26 loss)
I0826 22:30:52.485538  5239 sgd_solver.cpp:106] Iteration 10250, lr = 1e-07
I0826 22:32:08.887152  5239 solver.cpp:228] Iteration 10300, loss = 8595.84
I0826 22:32:08.887234  5239 solver.cpp:244]     Train net output #0: accuracy = 0.918659
I0826 22:32:08.887245  5239 solver.cpp:244]     Train net output #1: loss = 8595.84 (* 1 = 8595.84 loss)
I0826 22:32:08.887253  5239 sgd_solver.cpp:106] Iteration 10300, lr = 1e-07
I0826 22:33:26.596314  5239 solver.cpp:228] Iteration 10350, loss = 5086.26
I0826 22:33:26.596401  5239 solver.cpp:244]     Train net output #0: accuracy = 0.950997
I0826 22:33:26.596413  5239 solver.cpp:244]     Train net output #1: loss = 5086.26 (* 1 = 5086.26 loss)
I0826 22:33:26.596420  5239 sgd_solver.cpp:106] Iteration 10350, lr = 1e-07
I0826 22:34:41.682885  5239 solver.cpp:337] Iteration 10400, Testing net (#0)
I0826 22:34:49.987920  5239 solver.cpp:404]     Test net output #0: accuracy = 0.927635
I0826 22:34:49.987965  5239 solver.cpp:404]     Test net output #1: loss = 7556.91 (* 1 = 7556.91 loss)
I0826 22:34:51.353058  5239 solver.cpp:228] Iteration 10400, loss = 6277.24
I0826 22:34:51.353101  5239 solver.cpp:244]     Train net output #0: accuracy = 0.938052
I0826 22:34:51.353111  5239 solver.cpp:244]     Train net output #1: loss = 6277.24 (* 1 = 6277.24 loss)
I0826 22:34:51.353117  5239 sgd_solver.cpp:106] Iteration 10400, lr = 1e-07
I0826 22:36:06.724817  5239 solver.cpp:228] Iteration 10450, loss = 4146.81
I0826 22:36:06.724907  5239 solver.cpp:244]     Train net output #0: accuracy = 0.959437
I0826 22:36:06.724918  5239 solver.cpp:244]     Train net output #1: loss = 4146.81 (* 1 = 4146.81 loss)
I0826 22:36:06.724933  5239 sgd_solver.cpp:106] Iteration 10450, lr = 1e-07
I0826 22:37:23.557103  5239 solver.cpp:228] Iteration 10500, loss = 7871.18
I0826 22:37:23.557206  5239 solver.cpp:244]     Train net output #0: accuracy = 0.922612
I0826 22:37:23.557219  5239 solver.cpp:244]     Train net output #1: loss = 7871.18 (* 1 = 7871.18 loss)
I0826 22:37:23.557225  5239 sgd_solver.cpp:106] Iteration 10500, lr = 1e-07
I0826 22:38:40.372313  5239 solver.cpp:228] Iteration 10550, loss = 4366.77
I0826 22:38:40.372413  5239 solver.cpp:244]     Train net output #0: accuracy = 0.957369
I0826 22:38:40.372431  5239 solver.cpp:244]     Train net output #1: loss = 4366.77 (* 1 = 4366.77 loss)
I0826 22:38:40.372438  5239 sgd_solver.cpp:106] Iteration 10550, lr = 1e-07
I0826 22:39:56.587889  5239 solver.cpp:337] Iteration 10600, Testing net (#0)
I0826 22:40:04.905320  5239 solver.cpp:404]     Test net output #0: accuracy = 0.93091
I0826 22:40:04.905364  5239 solver.cpp:404]     Test net output #1: loss = 7204.36 (* 1 = 7204.36 loss)
I0826 22:40:06.318397  5239 solver.cpp:228] Iteration 10600, loss = 8152.11
I0826 22:40:06.318439  5239 solver.cpp:244]     Train net output #0: accuracy = 0.919141
I0826 22:40:06.318449  5239 solver.cpp:244]     Train net output #1: loss = 8152.11 (* 1 = 8152.11 loss)
I0826 22:40:06.318454  5239 sgd_solver.cpp:106] Iteration 10600, lr = 1e-07
I0826 22:41:23.624799  5239 solver.cpp:228] Iteration 10650, loss = 5451.96
I0826 22:41:23.624878  5239 solver.cpp:244]     Train net output #0: accuracy = 0.946799
I0826 22:41:23.624892  5239 solver.cpp:244]     Train net output #1: loss = 5451.96 (* 1 = 5451.96 loss)
I0826 22:41:23.624899  5239 sgd_solver.cpp:106] Iteration 10650, lr = 1e-07
I0826 22:42:40.744004  5239 solver.cpp:228] Iteration 10700, loss = 4174.74
I0826 22:42:40.744083  5239 solver.cpp:244]     Train net output #0: accuracy = 0.958915
I0826 22:42:40.744094  5239 solver.cpp:244]     Train net output #1: loss = 4174.74 (* 1 = 4174.74 loss)
I0826 22:42:40.744102  5239 sgd_solver.cpp:106] Iteration 10700, lr = 1e-07
I0826 22:43:57.460763  5239 solver.cpp:228] Iteration 10750, loss = 10116
I0826 22:43:57.460835  5239 solver.cpp:244]     Train net output #0: accuracy = 0.903409
I0826 22:43:57.460847  5239 solver.cpp:244]     Train net output #1: loss = 10116 (* 1 = 10116 loss)
I0826 22:43:57.460855  5239 sgd_solver.cpp:106] Iteration 10750, lr = 1e-07
I0826 22:45:12.854010  5239 solver.cpp:337] Iteration 10800, Testing net (#0)
I0826 22:45:20.801439  5239 solver.cpp:404]     Test net output #0: accuracy = 0.931798
I0826 22:45:20.801481  5239 solver.cpp:404]     Test net output #1: loss = 7129.29 (* 1 = 7129.29 loss)
I0826 22:45:22.168217  5239 solver.cpp:228] Iteration 10800, loss = 5192.03
I0826 22:45:22.168254  5239 solver.cpp:244]     Train net output #0: accuracy = 0.950686
I0826 22:45:22.168264  5239 solver.cpp:244]     Train net output #1: loss = 5192.03 (* 1 = 5192.03 loss)
I0826 22:45:22.168270  5239 sgd_solver.cpp:106] Iteration 10800, lr = 1e-07
I0826 22:46:41.573662  5239 solver.cpp:228] Iteration 10850, loss = 6697.59
I0826 22:46:41.573734  5239 solver.cpp:244]     Train net output #0: accuracy = 0.934489
I0826 22:46:41.573752  5239 solver.cpp:244]     Train net output #1: loss = 6697.59 (* 1 = 6697.59 loss)
I0826 22:46:41.573763  5239 sgd_solver.cpp:106] Iteration 10850, lr = 1e-07
I0826 22:47:59.156631  5239 solver.cpp:228] Iteration 10900, loss = 4393.76
I0826 22:47:59.156718  5239 solver.cpp:244]     Train net output #0: accuracy = 0.958547
I0826 22:47:59.156729  5239 solver.cpp:244]     Train net output #1: loss = 4393.76 (* 1 = 4393.76 loss)
I0826 22:47:59.156736  5239 sgd_solver.cpp:106] Iteration 10900, lr = 1e-07
I0826 22:49:16.316365  5239 solver.cpp:228] Iteration 10950, loss = 7348.72
I0826 22:49:16.316442  5239 solver.cpp:244]     Train net output #0: accuracy = 0.929503
I0826 22:49:16.316455  5239 solver.cpp:244]     Train net output #1: loss = 7348.72 (* 1 = 7348.72 loss)
I0826 22:49:16.316462  5239 sgd_solver.cpp:106] Iteration 10950, lr = 1e-07
I0826 22:50:32.366642  5239 solver.cpp:337] Iteration 11000, Testing net (#0)
I0826 22:50:40.631044  5239 solver.cpp:404]     Test net output #0: accuracy = 0.932044
I0826 22:50:40.631090  5239 solver.cpp:404]     Test net output #1: loss = 7078.28 (* 1 = 7078.28 loss)
I0826 22:50:41.929244  5239 solver.cpp:228] Iteration 11000, loss = 4437.94
I0826 22:50:41.929282  5239 solver.cpp:244]     Train net output #0: accuracy = 0.956274
I0826 22:50:41.929292  5239 solver.cpp:244]     Train net output #1: loss = 4437.94 (* 1 = 4437.94 loss)
I0826 22:50:41.929298  5239 sgd_solver.cpp:106] Iteration 11000, lr = 1e-07
I0826 22:52:01.629575  5239 solver.cpp:228] Iteration 11050, loss = 7293.29
I0826 22:52:01.629652  5239 solver.cpp:244]     Train net output #0: accuracy = 0.932323
I0826 22:52:01.629664  5239 solver.cpp:244]     Train net output #1: loss = 7293.29 (* 1 = 7293.29 loss)
I0826 22:52:01.629670  5239 sgd_solver.cpp:106] Iteration 11050, lr = 1e-07
I0826 22:53:22.465395  5239 solver.cpp:228] Iteration 11100, loss = 8515.78
I0826 22:53:22.465483  5239 solver.cpp:244]     Train net output #0: accuracy = 0.917229
I0826 22:53:22.465495  5239 solver.cpp:244]     Train net output #1: loss = 8515.78 (* 1 = 8515.78 loss)
I0826 22:53:22.465502  5239 sgd_solver.cpp:106] Iteration 11100, lr = 1e-07
I0826 22:54:39.374946  5239 solver.cpp:228] Iteration 11150, loss = 4829.85
I0826 22:54:39.376478  5239 solver.cpp:244]     Train net output #0: accuracy = 0.952572
I0826 22:54:39.376500  5239 solver.cpp:244]     Train net output #1: loss = 4829.85 (* 1 = 4829.85 loss)
I0826 22:54:39.376509  5239 sgd_solver.cpp:106] Iteration 11150, lr = 1e-07
I0826 22:55:54.421572  5239 solver.cpp:337] Iteration 11200, Testing net (#0)
I0826 22:56:02.289288  5239 solver.cpp:404]     Test net output #0: accuracy = 0.931114
I0826 22:56:02.289330  5239 solver.cpp:404]     Test net output #1: loss = 7184.13 (* 1 = 7184.13 loss)
I0826 22:56:03.721030  5239 solver.cpp:228] Iteration 11200, loss = 10149.8
I0826 22:56:03.721077  5239 solver.cpp:244]     Train net output #0: accuracy = 0.903861
I0826 22:56:03.721091  5239 solver.cpp:244]     Train net output #1: loss = 10149.8 (* 1 = 10149.8 loss)
I0826 22:56:03.721099  5239 sgd_solver.cpp:106] Iteration 11200, lr = 1e-07
I0826 22:57:19.101613  5239 solver.cpp:228] Iteration 11250, loss = 5210.96
I0826 22:57:19.101687  5239 solver.cpp:244]     Train net output #0: accuracy = 0.949819
I0826 22:57:19.101701  5239 solver.cpp:244]     Train net output #1: loss = 5210.96 (* 1 = 5210.96 loss)
I0826 22:57:19.101708  5239 sgd_solver.cpp:106] Iteration 11250, lr = 1e-07
I0826 22:58:35.618468  5239 solver.cpp:228] Iteration 11300, loss = 7036.09
I0826 22:58:35.618543  5239 solver.cpp:244]     Train net output #0: accuracy = 0.933377
I0826 22:58:35.618554  5239 solver.cpp:244]     Train net output #1: loss = 7036.09 (* 1 = 7036.09 loss)
I0826 22:58:35.618561  5239 sgd_solver.cpp:106] Iteration 11300, lr = 1e-07
I0826 22:59:51.748177  5239 solver.cpp:228] Iteration 11350, loss = 4031.55
I0826 22:59:51.748275  5239 solver.cpp:244]     Train net output #0: accuracy = 0.960618
I0826 22:59:51.748286  5239 solver.cpp:244]     Train net output #1: loss = 4031.55 (* 1 = 4031.55 loss)
I0826 22:59:51.748292  5239 sgd_solver.cpp:106] Iteration 11350, lr = 1e-07
I0826 23:01:07.684762  5239 solver.cpp:337] Iteration 11400, Testing net (#0)
I0826 23:01:15.908771  5239 solver.cpp:404]     Test net output #0: accuracy = 0.927882
I0826 23:01:15.908813  5239 solver.cpp:404]     Test net output #1: loss = 7543.26 (* 1 = 7543.26 loss)
I0826 23:01:17.298627  5239 solver.cpp:228] Iteration 11400, loss = 7902.65
I0826 23:01:17.298667  5239 solver.cpp:244]     Train net output #0: accuracy = 0.922059
I0826 23:01:17.298676  5239 solver.cpp:244]     Train net output #1: loss = 7902.65 (* 1 = 7902.65 loss)
I0826 23:01:17.298683  5239 sgd_solver.cpp:106] Iteration 11400, lr = 1e-07
I0826 23:02:34.492735  5239 solver.cpp:228] Iteration 11450, loss = 7003.7
I0826 23:02:34.492841  5239 solver.cpp:244]     Train net output #0: accuracy = 0.931291
I0826 23:02:34.492857  5239 solver.cpp:244]     Train net output #1: loss = 7003.7 (* 1 = 7003.7 loss)
I0826 23:02:34.492863  5239 sgd_solver.cpp:106] Iteration 11450, lr = 1e-07
I0826 23:03:51.860021  5239 solver.cpp:228] Iteration 11500, loss = 4645.47
I0826 23:03:51.860103  5239 solver.cpp:244]     Train net output #0: accuracy = 0.955105
I0826 23:03:51.860115  5239 solver.cpp:244]     Train net output #1: loss = 4645.47 (* 1 = 4645.47 loss)
I0826 23:03:51.860121  5239 sgd_solver.cpp:106] Iteration 11500, lr = 1e-07
I0826 23:05:18.442438  5239 solver.cpp:228] Iteration 11550, loss = 9577.6
I0826 23:05:18.442518  5239 solver.cpp:244]     Train net output #0: accuracy = 0.905683
I0826 23:05:18.442529  5239 solver.cpp:244]     Train net output #1: loss = 9577.6 (* 1 = 9577.6 loss)
I0826 23:05:18.442536  5239 sgd_solver.cpp:106] Iteration 11550, lr = 1e-07
I0826 23:06:39.208421  5239 solver.cpp:337] Iteration 11600, Testing net (#0)
I0826 23:06:47.512186  5239 solver.cpp:404]     Test net output #0: accuracy = 0.930736
I0826 23:06:47.512228  5239 solver.cpp:404]     Test net output #1: loss = 7220.78 (* 1 = 7220.78 loss)
I0826 23:06:48.854567  5239 solver.cpp:228] Iteration 11600, loss = 4523.8
I0826 23:06:48.854604  5239 solver.cpp:244]     Train net output #0: accuracy = 0.955565
I0826 23:06:48.854614  5239 solver.cpp:244]     Train net output #1: loss = 4523.8 (* 1 = 4523.8 loss)
I0826 23:06:48.854619  5239 sgd_solver.cpp:106] Iteration 11600, lr = 1e-07
I0826 23:08:06.112442  5239 solver.cpp:228] Iteration 11650, loss = 8983.13
I0826 23:08:06.112517  5239 solver.cpp:244]     Train net output #0: accuracy = 0.914727
I0826 23:08:06.112529  5239 solver.cpp:244]     Train net output #1: loss = 8983.13 (* 1 = 8983.13 loss)
I0826 23:08:06.112535  5239 sgd_solver.cpp:106] Iteration 11650, lr = 1e-07
I0826 23:09:24.210803  5239 solver.cpp:228] Iteration 11700, loss = 5737.84
I0826 23:09:24.210885  5239 solver.cpp:244]     Train net output #0: accuracy = 0.944625
I0826 23:09:24.210897  5239 solver.cpp:244]     Train net output #1: loss = 5737.84 (* 1 = 5737.84 loss)
I0826 23:09:24.210903  5239 sgd_solver.cpp:106] Iteration 11700, lr = 1e-07
I0826 23:10:43.228322  5239 solver.cpp:228] Iteration 11750, loss = 6918.53
I0826 23:10:43.228421  5239 solver.cpp:244]     Train net output #0: accuracy = 0.932941
I0826 23:10:43.228436  5239 solver.cpp:244]     Train net output #1: loss = 6918.53 (* 1 = 6918.53 loss)
I0826 23:10:43.228446  5239 sgd_solver.cpp:106] Iteration 11750, lr = 1e-07
I0826 23:12:02.700428  5239 solver.cpp:337] Iteration 11800, Testing net (#0)
I0826 23:12:10.691215  5239 solver.cpp:404]     Test net output #0: accuracy = 0.931825
I0826 23:12:10.691254  5239 solver.cpp:404]     Test net output #1: loss = 7117.69 (* 1 = 7117.69 loss)
I0826 23:12:12.121587  5239 solver.cpp:228] Iteration 11800, loss = 5135.05
I0826 23:12:12.121623  5239 solver.cpp:244]     Train net output #0: accuracy = 0.950574
I0826 23:12:12.121631  5239 solver.cpp:244]     Train net output #1: loss = 5135.05 (* 1 = 5135.05 loss)
I0826 23:12:12.121637  5239 sgd_solver.cpp:106] Iteration 11800, lr = 1e-07
I0826 23:13:29.854754  5239 solver.cpp:228] Iteration 11850, loss = 3921.38
I0826 23:13:29.854846  5239 solver.cpp:244]     Train net output #0: accuracy = 0.961747
I0826 23:13:29.854858  5239 solver.cpp:244]     Train net output #1: loss = 3921.38 (* 1 = 3921.38 loss)
I0826 23:13:29.854866  5239 sgd_solver.cpp:106] Iteration 11850, lr = 1e-07
I0826 23:14:48.404669  5239 solver.cpp:228] Iteration 11900, loss = 7264.68
I0826 23:14:48.404759  5239 solver.cpp:244]     Train net output #0: accuracy = 0.927778
I0826 23:14:48.404774  5239 solver.cpp:244]     Train net output #1: loss = 7264.68 (* 1 = 7264.68 loss)
I0826 23:14:48.404783  5239 sgd_solver.cpp:106] Iteration 11900, lr = 1e-07
I0826 23:16:04.757939  5239 solver.cpp:228] Iteration 11950, loss = 4800.97
I0826 23:16:04.758014  5239 solver.cpp:244]     Train net output #0: accuracy = 0.951713
I0826 23:16:04.758026  5239 solver.cpp:244]     Train net output #1: loss = 4800.97 (* 1 = 4800.97 loss)
I0826 23:16:04.758044  5239 sgd_solver.cpp:106] Iteration 11950, lr = 1e-07
I0826 23:17:20.371315  5239 solver.cpp:454] Snapshotting to binary proto file portrait_one_stage4_iter_12000.caffemodel
I0826 23:17:20.373816  5239 sgd_solver.cpp:273] Snapshotting solver state to binary proto file portrait_one_stage4_iter_12000.solverstate
I0826 23:17:20.374732  5239 solver.cpp:337] Iteration 12000, Testing net (#0)
I0826 23:17:28.522594  5239 solver.cpp:404]     Test net output #0: accuracy = 0.932472
I0826 23:17:28.522634  5239 solver.cpp:404]     Test net output #1: loss = 7036.32 (* 1 = 7036.32 loss)
I0826 23:17:29.954485  5239 solver.cpp:228] Iteration 12000, loss = 8480.15
I0826 23:17:29.954522  5239 solver.cpp:244]     Train net output #0: accuracy = 0.915656
I0826 23:17:29.954531  5239 solver.cpp:244]     Train net output #1: loss = 8480.15 (* 1 = 8480.15 loss)
I0826 23:17:29.954546  5239 sgd_solver.cpp:106] Iteration 12000, lr = 1e-08
I0826 23:18:46.013270  5239 solver.cpp:228] Iteration 12050, loss = 4878.98
I0826 23:18:46.013347  5239 solver.cpp:244]     Train net output #0: accuracy = 0.952806
I0826 23:18:46.013360  5239 solver.cpp:244]     Train net output #1: loss = 4878.98 (* 1 = 4878.98 loss)
I0826 23:18:46.013366  5239 sgd_solver.cpp:106] Iteration 12050, lr = 1e-08
I0826 23:20:00.838759  5239 solver.cpp:228] Iteration 12100, loss = 9681.12
I0826 23:20:00.838841  5239 solver.cpp:244]     Train net output #0: accuracy = 0.909404
I0826 23:20:00.838853  5239 solver.cpp:244]     Train net output #1: loss = 9681.12 (* 1 = 9681.12 loss)
I0826 23:20:00.838860  5239 sgd_solver.cpp:106] Iteration 12100, lr = 1e-08
I0826 23:21:17.487500  5239 solver.cpp:228] Iteration 12150, loss = 5875.36
I0826 23:21:17.487581  5239 solver.cpp:244]     Train net output #0: accuracy = 0.941804
I0826 23:21:17.487592  5239 solver.cpp:244]     Train net output #1: loss = 5875.36 (* 1 = 5875.36 loss)
I0826 23:21:17.487599  5239 sgd_solver.cpp:106] Iteration 12150, lr = 1e-08
I0826 23:22:32.782119  5239 solver.cpp:337] Iteration 12200, Testing net (#0)
I0826 23:22:41.155774  5239 solver.cpp:404]     Test net output #0: accuracy = 0.931359
I0826 23:22:41.155827  5239 solver.cpp:404]     Test net output #1: loss = 7163.65 (* 1 = 7163.65 loss)
I0826 23:22:42.569078  5239 solver.cpp:228] Iteration 12200, loss = 6128.87
I0826 23:22:42.569115  5239 solver.cpp:244]     Train net output #0: accuracy = 0.939307
I0826 23:22:42.569124  5239 solver.cpp:244]     Train net output #1: loss = 6128.87 (* 1 = 6128.87 loss)
I0826 23:22:42.569133  5239 sgd_solver.cpp:106] Iteration 12200, lr = 1e-08
I0826 23:23:59.932343  5239 solver.cpp:228] Iteration 12250, loss = 7367.8
I0826 23:23:59.932456  5239 solver.cpp:244]     Train net output #0: accuracy = 0.930172
I0826 23:23:59.932472  5239 solver.cpp:244]     Train net output #1: loss = 7367.8 (* 1 = 7367.8 loss)
I0826 23:23:59.932482  5239 sgd_solver.cpp:106] Iteration 12250, lr = 1e-08
I0826 23:25:24.297322  5239 solver.cpp:228] Iteration 12300, loss = 4101.2
I0826 23:25:24.297432  5239 solver.cpp:244]     Train net output #0: accuracy = 0.960253
I0826 23:25:24.297453  5239 solver.cpp:244]     Train net output #1: loss = 4101.2 (* 1 = 4101.2 loss)
I0826 23:25:24.297463  5239 sgd_solver.cpp:106] Iteration 12300, lr = 1e-08
I0826 23:26:47.851243  5239 solver.cpp:228] Iteration 12350, loss = 7193.31
I0826 23:26:47.851327  5239 solver.cpp:244]     Train net output #0: accuracy = 0.927361
I0826 23:26:47.851339  5239 solver.cpp:244]     Train net output #1: loss = 7193.31 (* 1 = 7193.31 loss)
I0826 23:26:47.851347  5239 sgd_solver.cpp:106] Iteration 12350, lr = 1e-08
I0826 23:28:05.798420  5239 solver.cpp:337] Iteration 12400, Testing net (#0)
I0826 23:28:13.842134  5239 solver.cpp:404]     Test net output #0: accuracy = 0.927944
I0826 23:28:13.842175  5239 solver.cpp:404]     Test net output #1: loss = 7538.61 (* 1 = 7538.61 loss)
I0826 23:28:15.212929  5239 solver.cpp:228] Iteration 12400, loss = 4767.98
I0826 23:28:15.212966  5239 solver.cpp:244]     Train net output #0: accuracy = 0.953048
I0826 23:28:15.212975  5239 solver.cpp:244]     Train net output #1: loss = 4767.98 (* 1 = 4767.98 loss)
I0826 23:28:15.212990  5239 sgd_solver.cpp:106] Iteration 12400, lr = 1e-08
I0826 23:29:32.263335  5239 solver.cpp:228] Iteration 12450, loss = 8867.45
I0826 23:29:32.263450  5239 solver.cpp:244]     Train net output #0: accuracy = 0.910845
I0826 23:29:32.263464  5239 solver.cpp:244]     Train net output #1: loss = 8867.45 (* 1 = 8867.45 loss)
I0826 23:29:32.263473  5239 sgd_solver.cpp:106] Iteration 12450, lr = 1e-08
I0826 23:30:49.577893  5239 solver.cpp:228] Iteration 12500, loss = 4370.14
I0826 23:30:49.577983  5239 solver.cpp:244]     Train net output #0: accuracy = 0.958155
I0826 23:30:49.577998  5239 solver.cpp:244]     Train net output #1: loss = 4370.14 (* 1 = 4370.14 loss)
I0826 23:30:49.578008  5239 sgd_solver.cpp:106] Iteration 12500, lr = 1e-08
I0826 23:32:06.829545  5239 solver.cpp:228] Iteration 12550, loss = 8614.8
I0826 23:32:06.829627  5239 solver.cpp:244]     Train net output #0: accuracy = 0.918822
I0826 23:32:06.829638  5239 solver.cpp:244]     Train net output #1: loss = 8614.8 (* 1 = 8614.8 loss)
I0826 23:32:06.829646  5239 sgd_solver.cpp:106] Iteration 12550, lr = 1e-08
I0826 23:33:21.139732  5239 solver.cpp:337] Iteration 12600, Testing net (#0)
I0826 23:33:29.313669  5239 solver.cpp:404]     Test net output #0: accuracy = 0.929982
I0826 23:33:29.313721  5239 solver.cpp:404]     Test net output #1: loss = 7297.31 (* 1 = 7297.31 loss)
I0826 23:33:30.736496  5239 solver.cpp:228] Iteration 12600, loss = 9071.24
I0826 23:33:30.736543  5239 solver.cpp:244]     Train net output #0: accuracy = 0.91318
I0826 23:33:30.736553  5239 solver.cpp:244]     Train net output #1: loss = 9071.24 (* 1 = 9071.24 loss)
I0826 23:33:30.736562  5239 sgd_solver.cpp:106] Iteration 12600, lr = 1e-08
I0826 23:34:47.732763  5239 solver.cpp:228] Iteration 12650, loss = 4692.5
I0826 23:34:47.732843  5239 solver.cpp:244]     Train net output #0: accuracy = 0.954463
I0826 23:34:47.732854  5239 solver.cpp:244]     Train net output #1: loss = 4692.5 (* 1 = 4692.5 loss)
I0826 23:34:47.732862  5239 sgd_solver.cpp:106] Iteration 12650, lr = 1e-08
I0826 23:36:04.221278  5239 solver.cpp:228] Iteration 12700, loss = 6264.45
I0826 23:36:04.221350  5239 solver.cpp:244]     Train net output #0: accuracy = 0.93812
I0826 23:36:04.221361  5239 solver.cpp:244]     Train net output #1: loss = 6264.45 (* 1 = 6264.45 loss)
I0826 23:36:04.221369  5239 sgd_solver.cpp:106] Iteration 12700, lr = 1e-08
I0826 23:37:21.486865  5239 solver.cpp:228] Iteration 12750, loss = 4238.95
I0826 23:37:21.486958  5239 solver.cpp:244]     Train net output #0: accuracy = 0.959103
I0826 23:37:21.486973  5239 solver.cpp:244]     Train net output #1: loss = 4238.95 (* 1 = 4238.95 loss)
I0826 23:37:21.486982  5239 sgd_solver.cpp:106] Iteration 12750, lr = 1e-08
I0826 23:38:36.958892  5239 solver.cpp:337] Iteration 12800, Testing net (#0)
I0826 23:38:44.940217  5239 solver.cpp:404]     Test net output #0: accuracy = 0.932011
I0826 23:38:44.940259  5239 solver.cpp:404]     Test net output #1: loss = 7097.82 (* 1 = 7097.82 loss)
I0826 23:38:46.327615  5239 solver.cpp:228] Iteration 12800, loss = 7537.8
I0826 23:38:46.327652  5239 solver.cpp:244]     Train net output #0: accuracy = 0.926696
I0826 23:38:46.327662  5239 solver.cpp:244]     Train net output #1: loss = 7537.8 (* 1 = 7537.8 loss)
I0826 23:38:46.327669  5239 sgd_solver.cpp:106] Iteration 12800, lr = 1e-08
I0826 23:40:02.414963  5239 solver.cpp:228] Iteration 12850, loss = 4293.08
I0826 23:40:02.415042  5239 solver.cpp:244]     Train net output #0: accuracy = 0.957752
I0826 23:40:02.415055  5239 solver.cpp:244]     Train net output #1: loss = 4293.08 (* 1 = 4293.08 loss)
I0826 23:40:02.415061  5239 sgd_solver.cpp:106] Iteration 12850, lr = 1e-08
I0826 23:41:19.063599  5239 solver.cpp:228] Iteration 12900, loss = 8049.23
I0826 23:41:19.063676  5239 solver.cpp:244]     Train net output #0: accuracy = 0.920348
I0826 23:41:19.063688  5239 solver.cpp:244]     Train net output #1: loss = 8049.23 (* 1 = 8049.23 loss)
I0826 23:41:19.063695  5239 sgd_solver.cpp:106] Iteration 12900, lr = 1e-08
I0826 23:42:36.142380  5239 solver.cpp:228] Iteration 12950, loss = 5889.96
I0826 23:42:36.142488  5239 solver.cpp:244]     Train net output #0: accuracy = 0.942371
I0826 23:42:36.142501  5239 solver.cpp:244]     Train net output #1: loss = 5889.96 (* 1 = 5889.96 loss)
I0826 23:42:36.142508  5239 sgd_solver.cpp:106] Iteration 12950, lr = 1e-08
I0826 23:43:51.103682  5239 solver.cpp:337] Iteration 13000, Testing net (#0)
I0826 23:43:59.431363  5239 solver.cpp:404]     Test net output #0: accuracy = 0.932659
I0826 23:43:59.431406  5239 solver.cpp:404]     Test net output #1: loss = 7016.72 (* 1 = 7016.72 loss)
I0826 23:44:00.802086  5239 solver.cpp:228] Iteration 13000, loss = 4261.9
I0826 23:44:00.802139  5239 solver.cpp:244]     Train net output #0: accuracy = 0.957564
I0826 23:44:00.802155  5239 solver.cpp:244]     Train net output #1: loss = 4261.9 (* 1 = 4261.9 loss)
I0826 23:44:00.802166  5239 sgd_solver.cpp:106] Iteration 13000, lr = 1e-08
I0826 23:45:19.872975  5239 solver.cpp:228] Iteration 13050, loss = 10012.3
I0826 23:45:19.873055  5239 solver.cpp:244]     Train net output #0: accuracy = 0.901061
I0826 23:45:19.873066  5239 solver.cpp:244]     Train net output #1: loss = 10012.3 (* 1 = 10012.3 loss)
I0826 23:45:19.873073  5239 sgd_solver.cpp:106] Iteration 13050, lr = 1e-08
I0826 23:46:34.814505  5239 solver.cpp:228] Iteration 13100, loss = 5253.03
I0826 23:46:34.814589  5239 solver.cpp:244]     Train net output #0: accuracy = 0.949631
I0826 23:46:34.814600  5239 solver.cpp:244]     Train net output #1: loss = 5253.03 (* 1 = 5253.03 loss)
I0826 23:46:34.814609  5239 sgd_solver.cpp:106] Iteration 13100, lr = 1e-08
I0826 23:47:49.577119  5239 solver.cpp:228] Iteration 13150, loss = 7258
I0826 23:47:49.577203  5239 solver.cpp:244]     Train net output #0: accuracy = 0.930585
I0826 23:47:49.577214  5239 solver.cpp:244]     Train net output #1: loss = 7258 (* 1 = 7258 loss)
I0826 23:47:49.577221  5239 sgd_solver.cpp:106] Iteration 13150, lr = 1e-08
I0826 23:49:02.379426  5239 solver.cpp:337] Iteration 13200, Testing net (#0)
I0826 23:49:10.345916  5239 solver.cpp:404]     Test net output #0: accuracy = 0.931575
I0826 23:49:10.345957  5239 solver.cpp:404]     Test net output #1: loss = 7144.63 (* 1 = 7144.63 loss)
I0826 23:49:11.630692  5239 solver.cpp:228] Iteration 13200, loss = 4247.5
I0826 23:49:11.630731  5239 solver.cpp:244]     Train net output #0: accuracy = 0.959173
I0826 23:49:11.630740  5239 solver.cpp:244]     Train net output #1: loss = 4247.5 (* 1 = 4247.5 loss)
I0826 23:49:11.630748  5239 sgd_solver.cpp:106] Iteration 13200, lr = 1e-08
I0826 23:50:26.734807  5239 solver.cpp:228] Iteration 13250, loss = 7069.88
I0826 23:50:26.734882  5239 solver.cpp:244]     Train net output #0: accuracy = 0.931925
I0826 23:50:26.734894  5239 solver.cpp:244]     Train net output #1: loss = 7069.88 (* 1 = 7069.88 loss)
I0826 23:50:26.734905  5239 sgd_solver.cpp:106] Iteration 13250, lr = 1e-08
I0826 23:51:40.825151  5239 solver.cpp:228] Iteration 13300, loss = 4162.81
I0826 23:51:40.825232  5239 solver.cpp:244]     Train net output #0: accuracy = 0.959312
I0826 23:51:40.825243  5239 solver.cpp:244]     Train net output #1: loss = 4162.81 (* 1 = 4162.81 loss)
I0826 23:51:40.825250  5239 sgd_solver.cpp:106] Iteration 13300, lr = 1e-08
I0826 23:52:58.247079  5239 solver.cpp:228] Iteration 13350, loss = 6653.16
I0826 23:52:58.247175  5239 solver.cpp:244]     Train net output #0: accuracy = 0.937941
I0826 23:52:58.247192  5239 solver.cpp:244]     Train net output #1: loss = 6653.16 (* 1 = 6653.16 loss)
I0826 23:52:58.247202  5239 sgd_solver.cpp:106] Iteration 13350, lr = 1e-08
I0826 23:54:23.059638  5239 solver.cpp:337] Iteration 13400, Testing net (#0)
I0826 23:54:33.452625  5239 solver.cpp:404]     Test net output #0: accuracy = 0.927886
I0826 23:54:33.452668  5239 solver.cpp:404]     Test net output #1: loss = 7537.6 (* 1 = 7537.6 loss)
I0826 23:54:35.140466  5239 solver.cpp:228] Iteration 13400, loss = 8597.45
I0826 23:54:35.140513  5239 solver.cpp:244]     Train net output #0: accuracy = 0.915854
I0826 23:54:35.140539  5239 solver.cpp:244]     Train net output #1: loss = 8597.45 (* 1 = 8597.45 loss)
I0826 23:54:35.140549  5239 sgd_solver.cpp:106] Iteration 13400, lr = 1e-08
I0826 23:56:02.055089  5239 solver.cpp:228] Iteration 13450, loss = 4584.47
I0826 23:56:02.055210  5239 solver.cpp:244]     Train net output #0: accuracy = 0.954655
I0826 23:56:02.055223  5239 solver.cpp:244]     Train net output #1: loss = 4584.47 (* 1 = 4584.47 loss)
I0826 23:56:02.055232  5239 sgd_solver.cpp:106] Iteration 13450, lr = 1e-08
I0826 23:57:25.153760  5239 solver.cpp:228] Iteration 13500, loss = 9710.58
I0826 23:57:25.153867  5239 solver.cpp:244]     Train net output #0: accuracy = 0.906955
I0826 23:57:25.153883  5239 solver.cpp:244]     Train net output #1: loss = 9710.58 (* 1 = 9710.58 loss)
I0826 23:57:25.153892  5239 sgd_solver.cpp:106] Iteration 13500, lr = 1e-08
I0826 23:58:50.828295  5239 solver.cpp:228] Iteration 13550, loss = 4958.88
I0826 23:58:50.828388  5239 solver.cpp:244]     Train net output #0: accuracy = 0.951046
I0826 23:58:50.828403  5239 solver.cpp:244]     Train net output #1: loss = 4958.88 (* 1 = 4958.88 loss)
I0826 23:58:50.828413  5239 sgd_solver.cpp:106] Iteration 13550, lr = 1e-08
I0827 00:00:13.327703  5239 solver.cpp:337] Iteration 13600, Testing net (#0)
I0827 00:00:20.901146  5239 solver.cpp:404]     Test net output #0: accuracy = 0.929909
I0827 00:00:20.901197  5239 solver.cpp:404]     Test net output #1: loss = 7304.56 (* 1 = 7304.56 loss)
I0827 00:00:22.210221  5239 solver.cpp:228] Iteration 13600, loss = 6877.33
I0827 00:00:22.210258  5239 solver.cpp:244]     Train net output #0: accuracy = 0.93479
I0827 00:00:22.210268  5239 solver.cpp:244]     Train net output #1: loss = 6877.33 (* 1 = 6877.33 loss)
I0827 00:00:22.210275  5239 sgd_solver.cpp:106] Iteration 13600, lr = 1e-08
I0827 00:01:42.390557  5239 solver.cpp:228] Iteration 13650, loss = 4260.46
I0827 00:01:42.390641  5239 solver.cpp:244]     Train net output #0: accuracy = 0.959305
I0827 00:01:42.390658  5239 solver.cpp:244]     Train net output #1: loss = 4260.46 (* 1 = 4260.46 loss)
I0827 00:01:42.390668  5239 sgd_solver.cpp:106] Iteration 13650, lr = 1e-08
I0827 00:02:55.811111  5239 solver.cpp:228] Iteration 13700, loss = 7984.95
I0827 00:02:55.811185  5239 solver.cpp:244]     Train net output #0: accuracy = 0.922966
I0827 00:02:55.811198  5239 solver.cpp:244]     Train net output #1: loss = 7984.95 (* 1 = 7984.95 loss)
I0827 00:02:55.811205  5239 sgd_solver.cpp:106] Iteration 13700, lr = 1e-08
I0827 00:04:09.702853  5239 solver.cpp:228] Iteration 13750, loss = 7348.4
I0827 00:04:09.702934  5239 solver.cpp:244]     Train net output #0: accuracy = 0.928588
I0827 00:04:09.702945  5239 solver.cpp:244]     Train net output #1: loss = 7348.4 (* 1 = 7348.4 loss)
I0827 00:04:09.702953  5239 sgd_solver.cpp:106] Iteration 13750, lr = 1e-08
I0827 00:05:22.936092  5239 solver.cpp:337] Iteration 13800, Testing net (#0)
I0827 00:05:30.711042  5239 solver.cpp:404]     Test net output #0: accuracy = 0.931479
I0827 00:05:30.711098  5239 solver.cpp:404]     Test net output #1: loss = 7157.2 (* 1 = 7157.2 loss)
I0827 00:05:32.049140  5239 solver.cpp:228] Iteration 13800, loss = 4503.36
I0827 00:05:32.049186  5239 solver.cpp:244]     Train net output #0: accuracy = 0.956932
I0827 00:05:32.049201  5239 solver.cpp:244]     Train net output #1: loss = 4503.36 (* 1 = 4503.36 loss)
I0827 00:05:32.049211  5239 sgd_solver.cpp:106] Iteration 13800, lr = 1e-08
I0827 00:06:45.807457  5239 solver.cpp:228] Iteration 13850, loss = 9779.49
I0827 00:06:45.807539  5239 solver.cpp:244]     Train net output #0: accuracy = 0.903631
I0827 00:06:45.807551  5239 solver.cpp:244]     Train net output #1: loss = 9779.49 (* 1 = 9779.49 loss)
I0827 00:06:45.807559  5239 sgd_solver.cpp:106] Iteration 13850, lr = 1e-08
I0827 00:08:00.891687  5239 solver.cpp:228] Iteration 13900, loss = 4832.99
I0827 00:08:00.891769  5239 solver.cpp:244]     Train net output #0: accuracy = 0.953182
I0827 00:08:00.891782  5239 solver.cpp:244]     Train net output #1: loss = 4832.99 (* 1 = 4832.99 loss)
I0827 00:08:00.891796  5239 sgd_solver.cpp:106] Iteration 13900, lr = 1e-08
I0827 00:09:16.789456  5239 solver.cpp:228] Iteration 13950, loss = 8966.08
I0827 00:09:16.789583  5239 solver.cpp:244]     Train net output #0: accuracy = 0.913862
I0827 00:09:16.789598  5239 solver.cpp:244]     Train net output #1: loss = 8966.08 (* 1 = 8966.08 loss)
I0827 00:09:16.789605  5239 sgd_solver.cpp:106] Iteration 13950, lr = 1e-08
I0827 00:10:30.648378  5239 solver.cpp:337] Iteration 14000, Testing net (#0)
I0827 00:10:38.588670  5239 solver.cpp:404]     Test net output #0: accuracy = 0.933179
I0827 00:10:38.588711  5239 solver.cpp:404]     Test net output #1: loss = 6960.16 (* 1 = 6960.16 loss)
I0827 00:10:39.957516  5239 solver.cpp:228] Iteration 14000, loss = 5969.62
I0827 00:10:39.957556  5239 solver.cpp:244]     Train net output #0: accuracy = 0.94347
I0827 00:10:39.957566  5239 solver.cpp:244]     Train net output #1: loss = 5969.62 (* 1 = 5969.62 loss)
I0827 00:10:39.957573  5239 sgd_solver.cpp:106] Iteration 14000, lr = 1e-08
I0827 00:11:53.472151  5239 solver.cpp:228] Iteration 14050, loss = 6908.24
I0827 00:11:53.472234  5239 solver.cpp:244]     Train net output #0: accuracy = 0.932638
I0827 00:11:53.472246  5239 solver.cpp:244]     Train net output #1: loss = 6908.24 (* 1 = 6908.24 loss)
I0827 00:11:53.472254  5239 sgd_solver.cpp:106] Iteration 14050, lr = 1e-08
I0827 00:13:09.130290  5239 solver.cpp:228] Iteration 14100, loss = 5402.42
I0827 00:13:09.130369  5239 solver.cpp:244]     Train net output #0: accuracy = 0.948576
I0827 00:13:09.130381  5239 solver.cpp:244]     Train net output #1: loss = 5402.42 (* 1 = 5402.42 loss)
I0827 00:13:09.130389  5239 sgd_solver.cpp:106] Iteration 14100, lr = 1e-08
I0827 00:14:23.338677  5239 solver.cpp:228] Iteration 14150, loss = 4058.68
I0827 00:14:23.338769  5239 solver.cpp:244]     Train net output #0: accuracy = 0.960824
I0827 00:14:23.338785  5239 solver.cpp:244]     Train net output #1: loss = 4058.68 (* 1 = 4058.68 loss)
I0827 00:14:23.338795  5239 sgd_solver.cpp:106] Iteration 14150, lr = 1e-08
I0827 00:15:39.089570  5239 solver.cpp:337] Iteration 14200, Testing net (#0)
I0827 00:15:48.046807  5239 solver.cpp:404]     Test net output #0: accuracy = 0.931179
I0827 00:15:48.046859  5239 solver.cpp:404]     Test net output #1: loss = 7189.28 (* 1 = 7189.28 loss)
I0827 00:15:49.336513  5239 solver.cpp:228] Iteration 14200, loss = 7536.3
I0827 00:15:49.336550  5239 solver.cpp:244]     Train net output #0: accuracy = 0.924811
I0827 00:15:49.336560  5239 solver.cpp:244]     Train net output #1: loss = 7536.3 (* 1 = 7536.3 loss)
I0827 00:15:49.336566  5239 sgd_solver.cpp:106] Iteration 14200, lr = 1e-08
I0827 00:17:14.954290  5239 solver.cpp:228] Iteration 14250, loss = 4707.71
I0827 00:17:14.954396  5239 solver.cpp:244]     Train net output #0: accuracy = 0.952762
I0827 00:17:14.954407  5239 solver.cpp:244]     Train net output #1: loss = 4707.71 (* 1 = 4707.71 loss)
I0827 00:17:14.954414  5239 sgd_solver.cpp:106] Iteration 14250, lr = 1e-08
I0827 00:18:29.730595  5239 solver.cpp:228] Iteration 14300, loss = 8294.62
I0827 00:18:29.730675  5239 solver.cpp:244]     Train net output #0: accuracy = 0.917854
I0827 00:18:29.730686  5239 solver.cpp:244]     Train net output #1: loss = 8294.62 (* 1 = 8294.62 loss)
I0827 00:18:29.730695  5239 sgd_solver.cpp:106] Iteration 14300, lr = 1e-08
I0827 00:19:46.056215  5239 solver.cpp:228] Iteration 14350, loss = 4791.84
I0827 00:19:46.056288  5239 solver.cpp:244]     Train net output #0: accuracy = 0.952988
I0827 00:19:46.056303  5239 solver.cpp:244]     Train net output #1: loss = 4791.84 (* 1 = 4791.84 loss)
I0827 00:19:46.056313  5239 sgd_solver.cpp:106] Iteration 14350, lr = 1e-08
I0827 00:20:57.805716  5239 solver.cpp:337] Iteration 14400, Testing net (#0)
I0827 00:21:05.861738  5239 solver.cpp:404]     Test net output #0: accuracy = 0.928525
I0827 00:21:05.861781  5239 solver.cpp:404]     Test net output #1: loss = 7464.33 (* 1 = 7464.33 loss)
I0827 00:21:07.157218  5239 solver.cpp:228] Iteration 14400, loss = 9295.31
I0827 00:21:07.157266  5239 solver.cpp:244]     Train net output #0: accuracy = 0.913003
I0827 00:21:07.157276  5239 solver.cpp:244]     Train net output #1: loss = 9295.31 (* 1 = 9295.31 loss)
I0827 00:21:07.157284  5239 sgd_solver.cpp:106] Iteration 14400, lr = 1e-08
I0827 00:22:22.114060  5239 solver.cpp:228] Iteration 14450, loss = 5674.4
I0827 00:22:22.114194  5239 solver.cpp:244]     Train net output #0: accuracy = 0.944116
I0827 00:22:22.114213  5239 solver.cpp:244]     Train net output #1: loss = 5674.4 (* 1 = 5674.4 loss)
I0827 00:22:22.114225  5239 sgd_solver.cpp:106] Iteration 14450, lr = 1e-08
I0827 00:23:38.867903  5239 solver.cpp:228] Iteration 14500, loss = 6248.2
I0827 00:23:38.867997  5239 solver.cpp:244]     Train net output #0: accuracy = 0.938708
I0827 00:23:38.868010  5239 solver.cpp:244]     Train net output #1: loss = 6248.2 (* 1 = 6248.2 loss)
I0827 00:23:38.868016  5239 sgd_solver.cpp:106] Iteration 14500, lr = 1e-08
I0827 00:25:00.342553  5239 solver.cpp:228] Iteration 14550, loss = 6573.51
I0827 00:25:00.342650  5239 solver.cpp:244]     Train net output #0: accuracy = 0.937027
I0827 00:25:00.342666  5239 solver.cpp:244]     Train net output #1: loss = 6573.51 (* 1 = 6573.51 loss)
I0827 00:25:00.342676  5239 sgd_solver.cpp:106] Iteration 14550, lr = 1e-08
I0827 00:26:22.007792  5239 solver.cpp:337] Iteration 14600, Testing net (#0)
I0827 00:26:29.597915  5239 solver.cpp:404]     Test net output #0: accuracy = 0.929878
I0827 00:26:29.597959  5239 solver.cpp:404]     Test net output #1: loss = 7307.27 (* 1 = 7307.27 loss)
I0827 00:26:30.901895  5239 solver.cpp:228] Iteration 14600, loss = 4209.38
I0827 00:26:30.901931  5239 solver.cpp:244]     Train net output #0: accuracy = 0.960072
I0827 00:26:30.901939  5239 solver.cpp:244]     Train net output #1: loss = 4209.38 (* 1 = 4209.38 loss)
I0827 00:26:30.901947  5239 sgd_solver.cpp:106] Iteration 14600, lr = 1e-08
I0827 00:27:44.952497  5239 solver.cpp:228] Iteration 14650, loss = 7141.4
I0827 00:27:44.952596  5239 solver.cpp:244]     Train net output #0: accuracy = 0.928828
I0827 00:27:44.952612  5239 solver.cpp:244]     Train net output #1: loss = 7141.4 (* 1 = 7141.4 loss)
I0827 00:27:44.952622  5239 sgd_solver.cpp:106] Iteration 14650, lr = 1e-08
I0827 00:28:59.263558  5239 solver.cpp:228] Iteration 14700, loss = 4908.36
I0827 00:28:59.263635  5239 solver.cpp:244]     Train net output #0: accuracy = 0.951366
I0827 00:28:59.263646  5239 solver.cpp:244]     Train net output #1: loss = 4908.36 (* 1 = 4908.36 loss)
I0827 00:28:59.263653  5239 sgd_solver.cpp:106] Iteration 14700, lr = 1e-08
I0827 00:30:15.327096  5239 solver.cpp:228] Iteration 14750, loss = 9086.69
I0827 00:30:15.327177  5239 solver.cpp:244]     Train net output #0: accuracy = 0.907935
I0827 00:30:15.327188  5239 solver.cpp:244]     Train net output #1: loss = 9086.69 (* 1 = 9086.69 loss)
I0827 00:30:15.327196  5239 sgd_solver.cpp:106] Iteration 14750, lr = 1e-08
I0827 00:31:29.647977  5239 solver.cpp:337] Iteration 14800, Testing net (#0)
I0827 00:31:37.505622  5239 solver.cpp:404]     Test net output #0: accuracy = 0.930879
I0827 00:31:37.505657  5239 solver.cpp:404]     Test net output #1: loss = 7212.72 (* 1 = 7212.72 loss)
I0827 00:31:38.817667  5239 solver.cpp:228] Iteration 14800, loss = 4410.65
I0827 00:31:38.817705  5239 solver.cpp:244]     Train net output #0: accuracy = 0.957385
I0827 00:31:38.817713  5239 solver.cpp:244]     Train net output #1: loss = 4410.65 (* 1 = 4410.65 loss)
I0827 00:31:38.817720  5239 sgd_solver.cpp:106] Iteration 14800, lr = 1e-08
I0827 00:32:54.568441  5239 solver.cpp:228] Iteration 14850, loss = 8320.22
I0827 00:32:54.568512  5239 solver.cpp:244]     Train net output #0: accuracy = 0.920316
I0827 00:32:54.568524  5239 solver.cpp:244]     Train net output #1: loss = 8320.22 (* 1 = 8320.22 loss)
I0827 00:32:54.568531  5239 sgd_solver.cpp:106] Iteration 14850, lr = 1e-08
I0827 00:34:09.624438  5239 solver.cpp:228] Iteration 14900, loss = 9677.94
I0827 00:34:09.624574  5239 solver.cpp:244]     Train net output #0: accuracy = 0.908416
I0827 00:34:09.624593  5239 solver.cpp:244]     Train net output #1: loss = 9677.94 (* 1 = 9677.94 loss)
I0827 00:34:09.624610  5239 sgd_solver.cpp:106] Iteration 14900, lr = 1e-08
I0827 00:35:24.752795  5239 solver.cpp:228] Iteration 14950, loss = 4960.38
I0827 00:35:24.752910  5239 solver.cpp:244]     Train net output #0: accuracy = 0.952339
I0827 00:35:24.752926  5239 solver.cpp:244]     Train net output #1: loss = 4960.38 (* 1 = 4960.38 loss)
I0827 00:35:24.752936  5239 sgd_solver.cpp:106] Iteration 14950, lr = 1e-08
I0827 00:36:37.702756  5239 solver.cpp:337] Iteration 15000, Testing net (#0)
I0827 00:36:45.839030  5239 solver.cpp:404]     Test net output #0: accuracy = 0.933137
I0827 00:36:45.839072  5239 solver.cpp:404]     Test net output #1: loss = 6982.03 (* 1 = 6982.03 loss)
I0827 00:36:47.218578  5239 solver.cpp:228] Iteration 15000, loss = 6230.55
I0827 00:36:47.218616  5239 solver.cpp:244]     Train net output #0: accuracy = 0.937948
I0827 00:36:47.218624  5239 solver.cpp:244]     Train net output #1: loss = 6230.55 (* 1 = 6230.55 loss)
I0827 00:36:47.218632  5239 sgd_solver.cpp:106] Iteration 15000, lr = 1e-08
I0827 00:38:03.319509  5239 solver.cpp:228] Iteration 15050, loss = 4299.27
I0827 00:38:03.319587  5239 solver.cpp:244]     Train net output #0: accuracy = 0.958547
I0827 00:38:03.319598  5239 solver.cpp:244]     Train net output #1: loss = 4299.27 (* 1 = 4299.27 loss)
I0827 00:38:03.319607  5239 sgd_solver.cpp:106] Iteration 15050, lr = 1e-08
I0827 00:39:18.185919  5239 solver.cpp:228] Iteration 15100, loss = 7237.06
I0827 00:39:18.185997  5239 solver.cpp:244]     Train net output #0: accuracy = 0.928189
I0827 00:39:18.186008  5239 solver.cpp:244]     Train net output #1: loss = 7237.06 (* 1 = 7237.06 loss)
I0827 00:39:18.186015  5239 sgd_solver.cpp:106] Iteration 15100, lr = 1e-08
I0827 00:40:32.734172  5239 solver.cpp:228] Iteration 15150, loss = 4325.7
I0827 00:40:32.734251  5239 solver.cpp:244]     Train net output #0: accuracy = 0.957274
I0827 00:40:32.734261  5239 solver.cpp:244]     Train net output #1: loss = 4325.7 (* 1 = 4325.7 loss)
I0827 00:40:32.734269  5239 sgd_solver.cpp:106] Iteration 15150, lr = 1e-08
I0827 00:41:45.534601  5239 solver.cpp:337] Iteration 15200, Testing net (#0)
I0827 00:41:53.027132  5239 solver.cpp:404]     Test net output #0: accuracy = 0.930804
I0827 00:41:53.027173  5239 solver.cpp:404]     Test net output #1: loss = 7231.83 (* 1 = 7231.83 loss)
I0827 00:41:54.329795  5239 solver.cpp:228] Iteration 15200, loss = 8493.27
I0827 00:41:54.329831  5239 solver.cpp:244]     Train net output #0: accuracy = 0.916091
I0827 00:41:54.329841  5239 solver.cpp:244]     Train net output #1: loss = 8493.27 (* 1 = 8493.27 loss)
I0827 00:41:54.329849  5239 sgd_solver.cpp:106] Iteration 15200, lr = 1e-08
I0827 00:43:09.579182  5239 solver.cpp:228] Iteration 15250, loss = 6622.24
I0827 00:43:09.579257  5239 solver.cpp:244]     Train net output #0: accuracy = 0.936013
I0827 00:43:09.579267  5239 solver.cpp:244]     Train net output #1: loss = 6622.24 (* 1 = 6622.24 loss)
I0827 00:43:09.579275  5239 sgd_solver.cpp:106] Iteration 15250, lr = 1e-08
I0827 00:44:23.910451  5239 solver.cpp:228] Iteration 15300, loss = 4424.51
I0827 00:44:23.910531  5239 solver.cpp:244]     Train net output #0: accuracy = 0.956503
I0827 00:44:23.910542  5239 solver.cpp:244]     Train net output #1: loss = 4424.51 (* 1 = 4424.51 loss)
I0827 00:44:23.910549  5239 sgd_solver.cpp:106] Iteration 15300, lr = 1e-08
I0827 00:45:40.018615  5239 solver.cpp:228] Iteration 15350, loss = 10073.5
I0827 00:45:40.018697  5239 solver.cpp:244]     Train net output #0: accuracy = 0.902321
I0827 00:45:40.018708  5239 solver.cpp:244]     Train net output #1: loss = 10073.5 (* 1 = 10073.5 loss)
I0827 00:45:40.018715  5239 sgd_solver.cpp:106] Iteration 15350, lr = 1e-08
I0827 00:46:52.310899  5239 solver.cpp:337] Iteration 15400, Testing net (#0)
I0827 00:47:00.501190  5239 solver.cpp:404]     Test net output #0: accuracy = 0.929563
I0827 00:47:00.501247  5239 solver.cpp:404]     Test net output #1: loss = 7338.86 (* 1 = 7338.86 loss)
I0827 00:47:02.166956  5239 solver.cpp:228] Iteration 15400, loss = 5204.46
I0827 00:47:02.167017  5239 solver.cpp:244]     Train net output #0: accuracy = 0.950491
I0827 00:47:02.167032  5239 solver.cpp:244]     Train net output #1: loss = 5204.46 (* 1 = 5204.46 loss)
I0827 00:47:02.167040  5239 sgd_solver.cpp:106] Iteration 15400, lr = 1e-08
I0827 00:48:25.274680  5239 solver.cpp:228] Iteration 15450, loss = 7423.68
I0827 00:48:25.274790  5239 solver.cpp:244]     Train net output #0: accuracy = 0.928267
I0827 00:48:25.274802  5239 solver.cpp:244]     Train net output #1: loss = 7423.68 (* 1 = 7423.68 loss)
I0827 00:48:25.274811  5239 sgd_solver.cpp:106] Iteration 15450, lr = 1e-08
I0827 00:49:39.544029  5239 solver.cpp:228] Iteration 15500, loss = 4406.9
I0827 00:49:39.544106  5239 solver.cpp:244]     Train net output #0: accuracy = 0.957348
I0827 00:49:39.544118  5239 solver.cpp:244]     Train net output #1: loss = 4406.9 (* 1 = 4406.9 loss)
I0827 00:49:39.544124  5239 sgd_solver.cpp:106] Iteration 15500, lr = 1e-08
I0827 00:50:59.696995  5239 solver.cpp:228] Iteration 15550, loss = 7119.36
I0827 00:50:59.697077  5239 solver.cpp:244]     Train net output #0: accuracy = 0.931682
I0827 00:50:59.697088  5239 solver.cpp:244]     Train net output #1: loss = 7119.36 (* 1 = 7119.36 loss)
I0827 00:50:59.697094  5239 sgd_solver.cpp:106] Iteration 15550, lr = 1e-08
I0827 00:52:12.359290  5239 solver.cpp:337] Iteration 15600, Testing net (#0)
I0827 00:52:20.644232  5239 solver.cpp:404]     Test net output #0: accuracy = 0.929634
I0827 00:52:20.644273  5239 solver.cpp:404]     Test net output #1: loss = 7355.46 (* 1 = 7355.46 loss)
I0827 00:52:21.940562  5239 solver.cpp:228] Iteration 15600, loss = 4428.5
I0827 00:52:21.940598  5239 solver.cpp:244]     Train net output #0: accuracy = 0.95708
I0827 00:52:21.940608  5239 solver.cpp:244]     Train net output #1: loss = 4428.5 (* 1 = 4428.5 loss)
I0827 00:52:21.940614  5239 sgd_solver.cpp:106] Iteration 15600, lr = 1e-08
I0827 00:53:36.328766  5239 solver.cpp:228] Iteration 15650, loss = 5788.31
I0827 00:53:36.328869  5239 solver.cpp:244]     Train net output #0: accuracy = 0.945694
I0827 00:53:36.328881  5239 solver.cpp:244]     Train net output #1: loss = 5788.31 (* 1 = 5788.31 loss)
I0827 00:53:36.328889  5239 sgd_solver.cpp:106] Iteration 15650, lr = 1e-08
I0827 00:54:50.976456  5239 solver.cpp:228] Iteration 15700, loss = 8297.09
I0827 00:54:50.976526  5239 solver.cpp:244]     Train net output #0: accuracy = 0.918056
I0827 00:54:50.976537  5239 solver.cpp:244]     Train net output #1: loss = 8297.09 (* 1 = 8297.09 loss)
I0827 00:54:50.976544  5239 sgd_solver.cpp:106] Iteration 15700, lr = 1e-08
I0827 00:56:05.070200  5239 solver.cpp:228] Iteration 15750, loss = 4637.2
I0827 00:56:05.070281  5239 solver.cpp:244]     Train net output #0: accuracy = 0.953866
I0827 00:56:05.070291  5239 solver.cpp:244]     Train net output #1: loss = 4637.2 (* 1 = 4637.2 loss)
I0827 00:56:05.070299  5239 sgd_solver.cpp:106] Iteration 15750, lr = 1e-08
I0827 00:57:21.083726  5239 solver.cpp:337] Iteration 15800, Testing net (#0)
I0827 00:57:28.836830  5239 solver.cpp:404]     Test net output #0: accuracy = 0.930745
I0827 00:57:28.836874  5239 solver.cpp:404]     Test net output #1: loss = 7205.87 (* 1 = 7205.87 loss)
I0827 00:57:30.134929  5239 solver.cpp:228] Iteration 15800, loss = 9497.57
I0827 00:57:30.134968  5239 solver.cpp:244]     Train net output #0: accuracy = 0.909496
I0827 00:57:30.134977  5239 solver.cpp:244]     Train net output #1: loss = 9497.57 (* 1 = 9497.57 loss)
I0827 00:57:30.134984  5239 sgd_solver.cpp:106] Iteration 15800, lr = 1e-08
I0827 00:58:43.329041  5239 solver.cpp:228] Iteration 15850, loss = 5131.33
I0827 00:58:43.329126  5239 solver.cpp:244]     Train net output #0: accuracy = 0.949764
I0827 00:58:43.329138  5239 solver.cpp:244]     Train net output #1: loss = 5131.33 (* 1 = 5131.33 loss)
I0827 00:58:43.329145  5239 sgd_solver.cpp:106] Iteration 15850, lr = 1e-08
I0827 00:59:56.988353  5239 solver.cpp:228] Iteration 15900, loss = 6975.49
I0827 00:59:56.988473  5239 solver.cpp:244]     Train net output #0: accuracy = 0.933472
I0827 00:59:56.988495  5239 solver.cpp:244]     Train net output #1: loss = 6975.49 (* 1 = 6975.49 loss)
I0827 00:59:56.988505  5239 sgd_solver.cpp:106] Iteration 15900, lr = 1e-08
I0827 01:01:12.301831  5239 solver.cpp:228] Iteration 15950, loss = 4394.21
I0827 01:01:12.301915  5239 solver.cpp:244]     Train net output #0: accuracy = 0.958375
I0827 01:01:12.301928  5239 solver.cpp:244]     Train net output #1: loss = 4394.21 (* 1 = 4394.21 loss)
I0827 01:01:12.301934  5239 sgd_solver.cpp:106] Iteration 15950, lr = 1e-08
I0827 01:02:25.323292  5239 solver.cpp:454] Snapshotting to binary proto file portrait_one_stage4_iter_16000.caffemodel
I0827 01:02:25.325798  5239 sgd_solver.cpp:273] Snapshotting solver state to binary proto file portrait_one_stage4_iter_16000.solverstate
I0827 01:02:26.356065  5239 solver.cpp:317] Iteration 16000, loss = 7396.75
I0827 01:02:26.356102  5239 solver.cpp:337] Iteration 16000, Testing net (#0)
I0827 01:02:34.296993  5239 solver.cpp:404]     Test net output #0: accuracy = 0.933252
I0827 01:02:34.297034  5239 solver.cpp:404]     Test net output #1: loss = 6969.37 (* 1 = 6969.37 loss)
I0827 01:02:34.297039  5239 solver.cpp:322] Optimization Done.
I0827 01:02:34.297044  5239 caffe.cpp:254] Optimization Done.
