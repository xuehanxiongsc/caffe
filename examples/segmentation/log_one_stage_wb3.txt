I0831 12:58:56.618171 24386 caffe.cpp:217] Using GPUs 2
I0831 12:58:56.639425 24386 caffe.cpp:222] GPU 2: GeForce GTX TITAN X
I0831 12:58:56.826993 24386 solver.cpp:48] Initializing solver from parameters: 
test_iter: 14
test_interval: 200
base_lr: 1e-05
display: 50
max_iter: 16000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 1e-05
stepsize: 4000
snapshot: 4000
snapshot_prefix: "portrait_wb_one_stage3"
solver_mode: GPU
device_id: 2
net: "portrait_wb_train_test_one_stage.prototxt3"
train_state {
  level: 0
  stage: ""
}
I0831 12:58:56.827097 24386 solver.cpp:91] Creating training net from net file: portrait_wb_train_test_one_stage.prototxt3
I0831 12:58:56.827661 24386 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0831 12:58:56.827823 24386 net.cpp:58] Initializing net from parameters: 
name: "segmentation"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "SegData"
  top: "image"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 200
  }
  data_param {
    source: "/raid/xuehan/segmentation_wb_train_split"
    batch_size: 128
    backend: LMDB
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "image"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 50
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1_1_bn"
  type: "BatchNorm"
  bottom: "pool1"
  top: "conv1_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv1_1_bn_scale"
  type: "Scale"
  bottom: "conv1_1_bn"
  top: "conv1_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_1_relu"
  type: "ReLU"
  bottom: "conv1_1_bn"
  top: "conv1_1_bn"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv1_1_bn"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_1"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1_bn"
  type: "BatchNorm"
  bottom: "pool2"
  top: "conv2_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv2_1_bn_scale"
  type: "Scale"
  bottom: "conv2_1_bn"
  top: "conv2_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1_relu"
  type: "ReLU"
  bottom: "conv2_1_bn"
  top: "conv2_1_bn"
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv2_1_bn"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_1"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1_bn"
  type: "BatchNorm"
  bottom: "pool3"
  top: "conv3_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv3_1_bn_scale"
  type: "Scale"
  bottom: "conv3_1_bn"
  top: "conv3_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1_relu"
  type: "ReLU"
  bottom: "conv3_1_bn"
  top: "conv3_1_bn"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv3_1_bn"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_1"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1_bn"
  type: "BatchNorm"
  bottom: "pool4"
  top: "conv4_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv4_1_bn_scale"
  type: "Scale"
  bottom: "conv4_1_bn"
  top: "conv4_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1_relu"
  type: "ReLU"
  bottom: "conv4_1_bn"
  top: "conv4_1_bn"
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "conv4_1_bn"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv5_1_bn"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv5_1_bn_scale"
  type: "Scale"
  bottom: "conv5_1_bn"
  top: "conv5_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_1_relu"
  type: "ReLU"
  bottom: "conv5_1_bn"
  top: "conv5_1_bn"
}
layer {
  name: "conv6_1"
  type: "Convolution"
  bottom: "conv5_1_bn"
  top: "conv6_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv6_1_bn"
  type: "BatchNorm"
  bottom: "conv6_1"
  top: "conv6_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv6_1_bn_scale"
  type: "Scale"
  bottom: "conv6_1_bn"
  top: "conv6_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv6_1_relu"
  type: "ReLU"
  bottom: "conv6_1_bn"
  top: "conv6_1_bn"
}
layer {
  name: "conv7_1"
  type: "Convolution"
  bottom: "conv6_1_bn"
  top: "conv7_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv7_1_bn"
  type: "BatchNorm"
  bottom: "conv7_1"
  top: "conv7_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv7_1_bn_scale"
  type: "Scale"
  bottom: "conv7_1_bn"
  top: "conv7_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv7_1_relu"
  type: "ReLU"
  bottom: "conv7_1_bn"
  top: "conv7_1_bn"
}
layer {
  name: "score"
  type: "Convolution"
  bottom: "conv7_1_bn"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 4
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "upscore"
  type: "Deconvolution"
  bottom: "score"
  top: "upscore"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 4
    bias_term: false
    pad: 0
    kernel_size: 32
    stride: 16
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "cropscore"
  type: "Crop"
  bottom: "upscore"
  bottom: "image"
  top: "cropscore"
  crop_param {
    axis: 2
    offset: 12
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "cropscore"
  bottom: "label"
  top: "loss"
  loss_weight: 1
  loss_param {
    normalize: false
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "cropscore"
  bottom: "label"
  top: "accuracy"
}
I0831 12:58:56.827970 24386 layer_factory.hpp:77] Creating layer data
I0831 12:58:56.828428 24386 net.cpp:100] Creating Layer data
I0831 12:58:56.828438 24386 net.cpp:408] data -> image
I0831 12:58:56.828455 24386 net.cpp:408] data -> label
I0831 12:58:56.829336 24391 db_lmdb.cpp:35] Opened lmdb /raid/xuehan/segmentation_wb_train_split
I0831 12:58:56.829532 24386 seg_data_layer.cpp:38] 200 200 4
I0831 12:58:56.836982 24386 seg_data_layer.cpp:51] output data size: 128,3,200,200
I0831 12:58:56.837050 24386 seg_data_layer.cpp:63] output label size: 128,1,200,200
I0831 12:58:56.945956 24386 net.cpp:150] Setting up data
I0831 12:58:56.945991 24386 net.cpp:157] Top shape: 128 3 200 200 (15360000)
I0831 12:58:56.945994 24386 net.cpp:157] Top shape: 128 1 200 200 (5120000)
I0831 12:58:56.945997 24386 net.cpp:165] Memory required for data: 81920000
I0831 12:58:56.946008 24386 layer_factory.hpp:77] Creating layer image_data_0_split
I0831 12:58:56.946019 24386 net.cpp:100] Creating Layer image_data_0_split
I0831 12:58:56.946024 24386 net.cpp:434] image_data_0_split <- image
I0831 12:58:56.946034 24386 net.cpp:408] image_data_0_split -> image_data_0_split_0
I0831 12:58:56.946044 24386 net.cpp:408] image_data_0_split -> image_data_0_split_1
I0831 12:58:56.946105 24386 net.cpp:150] Setting up image_data_0_split
I0831 12:58:56.946111 24386 net.cpp:157] Top shape: 128 3 200 200 (15360000)
I0831 12:58:56.946115 24386 net.cpp:157] Top shape: 128 3 200 200 (15360000)
I0831 12:58:56.946117 24386 net.cpp:165] Memory required for data: 204800000
I0831 12:58:56.946120 24386 layer_factory.hpp:77] Creating layer label_data_1_split
I0831 12:58:56.946126 24386 net.cpp:100] Creating Layer label_data_1_split
I0831 12:58:56.946130 24386 net.cpp:434] label_data_1_split <- label
I0831 12:58:56.946132 24386 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0831 12:58:56.946137 24386 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0831 12:58:56.946161 24386 net.cpp:150] Setting up label_data_1_split
I0831 12:58:56.946166 24386 net.cpp:157] Top shape: 128 1 200 200 (5120000)
I0831 12:58:56.946169 24386 net.cpp:157] Top shape: 128 1 200 200 (5120000)
I0831 12:58:56.946172 24386 net.cpp:165] Memory required for data: 245760000
I0831 12:58:56.946174 24386 layer_factory.hpp:77] Creating layer conv1_1
I0831 12:58:56.946189 24386 net.cpp:100] Creating Layer conv1_1
I0831 12:58:56.946192 24386 net.cpp:434] conv1_1 <- image_data_0_split_0
I0831 12:58:56.946199 24386 net.cpp:408] conv1_1 -> conv1_1
I0831 12:58:56.946354 24386 net.cpp:150] Setting up conv1_1
I0831 12:58:56.946362 24386 net.cpp:157] Top shape: 128 8 298 298 (90935296)
I0831 12:58:56.946363 24386 net.cpp:165] Memory required for data: 609501184
I0831 12:58:56.946380 24386 layer_factory.hpp:77] Creating layer pool1
I0831 12:58:56.946389 24386 net.cpp:100] Creating Layer pool1
I0831 12:58:56.946393 24386 net.cpp:434] pool1 <- conv1_1
I0831 12:58:56.946396 24386 net.cpp:408] pool1 -> pool1
I0831 12:58:56.946426 24386 net.cpp:150] Setting up pool1
I0831 12:58:56.946431 24386 net.cpp:157] Top shape: 128 8 149 149 (22733824)
I0831 12:58:56.946434 24386 net.cpp:165] Memory required for data: 700436480
I0831 12:58:56.946436 24386 layer_factory.hpp:77] Creating layer conv1_1_bn
I0831 12:58:56.946441 24386 net.cpp:100] Creating Layer conv1_1_bn
I0831 12:58:56.946444 24386 net.cpp:434] conv1_1_bn <- pool1
I0831 12:58:56.946447 24386 net.cpp:408] conv1_1_bn -> conv1_1_bn
I0831 12:58:56.947039 24386 net.cpp:150] Setting up conv1_1_bn
I0831 12:58:56.947052 24386 net.cpp:157] Top shape: 128 8 149 149 (22733824)
I0831 12:58:56.947054 24386 net.cpp:165] Memory required for data: 791371776
I0831 12:58:56.947064 24386 layer_factory.hpp:77] Creating layer conv1_1_bn_scale
I0831 12:58:56.947072 24386 net.cpp:100] Creating Layer conv1_1_bn_scale
I0831 12:58:56.947074 24386 net.cpp:434] conv1_1_bn_scale <- conv1_1_bn
I0831 12:58:56.947078 24386 net.cpp:395] conv1_1_bn_scale -> conv1_1_bn (in-place)
I0831 12:58:56.947108 24386 layer_factory.hpp:77] Creating layer conv1_1_bn_scale
I0831 12:58:56.947203 24386 net.cpp:150] Setting up conv1_1_bn_scale
I0831 12:58:56.947211 24386 net.cpp:157] Top shape: 128 8 149 149 (22733824)
I0831 12:58:56.947213 24386 net.cpp:165] Memory required for data: 882307072
I0831 12:58:56.947221 24386 layer_factory.hpp:77] Creating layer conv1_1_relu
I0831 12:58:56.947226 24386 net.cpp:100] Creating Layer conv1_1_relu
I0831 12:58:56.947243 24386 net.cpp:434] conv1_1_relu <- conv1_1_bn
I0831 12:58:56.947247 24386 net.cpp:395] conv1_1_relu -> conv1_1_bn (in-place)
I0831 12:58:56.947252 24386 net.cpp:150] Setting up conv1_1_relu
I0831 12:58:56.947255 24386 net.cpp:157] Top shape: 128 8 149 149 (22733824)
I0831 12:58:56.947258 24386 net.cpp:165] Memory required for data: 973242368
I0831 12:58:56.947262 24386 layer_factory.hpp:77] Creating layer conv2_1
I0831 12:58:56.947269 24386 net.cpp:100] Creating Layer conv2_1
I0831 12:58:56.947273 24386 net.cpp:434] conv2_1 <- conv1_1_bn
I0831 12:58:56.947278 24386 net.cpp:408] conv2_1 -> conv2_1
I0831 12:58:56.947898 24386 net.cpp:150] Setting up conv2_1
I0831 12:58:56.947911 24386 net.cpp:157] Top shape: 128 16 149 149 (45467648)
I0831 12:58:56.947914 24386 net.cpp:165] Memory required for data: 1155112960
I0831 12:58:56.947919 24386 layer_factory.hpp:77] Creating layer pool2
I0831 12:58:56.947927 24386 net.cpp:100] Creating Layer pool2
I0831 12:58:56.947932 24386 net.cpp:434] pool2 <- conv2_1
I0831 12:58:56.947935 24386 net.cpp:408] pool2 -> pool2
I0831 12:58:56.953047 24386 net.cpp:150] Setting up pool2
I0831 12:58:56.953095 24386 net.cpp:157] Top shape: 128 16 75 75 (11520000)
I0831 12:58:56.953104 24386 net.cpp:165] Memory required for data: 1201192960
I0831 12:58:56.953114 24386 layer_factory.hpp:77] Creating layer conv2_1_bn
I0831 12:58:56.953133 24386 net.cpp:100] Creating Layer conv2_1_bn
I0831 12:58:56.953143 24386 net.cpp:434] conv2_1_bn <- pool2
I0831 12:58:56.953155 24386 net.cpp:408] conv2_1_bn -> conv2_1_bn
I0831 12:58:56.955454 24386 net.cpp:150] Setting up conv2_1_bn
I0831 12:58:56.955481 24386 net.cpp:157] Top shape: 128 16 75 75 (11520000)
I0831 12:58:56.955483 24386 net.cpp:165] Memory required for data: 1247272960
I0831 12:58:56.955500 24386 layer_factory.hpp:77] Creating layer conv2_1_bn_scale
I0831 12:58:56.955513 24386 net.cpp:100] Creating Layer conv2_1_bn_scale
I0831 12:58:56.955516 24386 net.cpp:434] conv2_1_bn_scale <- conv2_1_bn
I0831 12:58:56.955521 24386 net.cpp:395] conv2_1_bn_scale -> conv2_1_bn (in-place)
I0831 12:58:56.955554 24386 layer_factory.hpp:77] Creating layer conv2_1_bn_scale
I0831 12:58:56.955641 24386 net.cpp:150] Setting up conv2_1_bn_scale
I0831 12:58:56.955646 24386 net.cpp:157] Top shape: 128 16 75 75 (11520000)
I0831 12:58:56.955648 24386 net.cpp:165] Memory required for data: 1293352960
I0831 12:58:56.955653 24386 layer_factory.hpp:77] Creating layer conv2_1_relu
I0831 12:58:56.955659 24386 net.cpp:100] Creating Layer conv2_1_relu
I0831 12:58:56.955662 24386 net.cpp:434] conv2_1_relu <- conv2_1_bn
I0831 12:58:56.955667 24386 net.cpp:395] conv2_1_relu -> conv2_1_bn (in-place)
I0831 12:58:56.955672 24386 net.cpp:150] Setting up conv2_1_relu
I0831 12:58:56.955675 24386 net.cpp:157] Top shape: 128 16 75 75 (11520000)
I0831 12:58:56.955678 24386 net.cpp:165] Memory required for data: 1339432960
I0831 12:58:56.955680 24386 layer_factory.hpp:77] Creating layer conv3_1
I0831 12:58:56.955690 24386 net.cpp:100] Creating Layer conv3_1
I0831 12:58:56.955693 24386 net.cpp:434] conv3_1 <- conv2_1_bn
I0831 12:58:56.955698 24386 net.cpp:408] conv3_1 -> conv3_1
I0831 12:58:56.955921 24386 net.cpp:150] Setting up conv3_1
I0831 12:58:56.955927 24386 net.cpp:157] Top shape: 128 32 75 75 (23040000)
I0831 12:58:56.955930 24386 net.cpp:165] Memory required for data: 1431592960
I0831 12:58:56.955934 24386 layer_factory.hpp:77] Creating layer pool3
I0831 12:58:56.955940 24386 net.cpp:100] Creating Layer pool3
I0831 12:58:56.955942 24386 net.cpp:434] pool3 <- conv3_1
I0831 12:58:56.955946 24386 net.cpp:408] pool3 -> pool3
I0831 12:58:56.955971 24386 net.cpp:150] Setting up pool3
I0831 12:58:56.955976 24386 net.cpp:157] Top shape: 128 32 38 38 (5914624)
I0831 12:58:56.955977 24386 net.cpp:165] Memory required for data: 1455251456
I0831 12:58:56.955981 24386 layer_factory.hpp:77] Creating layer conv3_1_bn
I0831 12:58:56.955986 24386 net.cpp:100] Creating Layer conv3_1_bn
I0831 12:58:56.955988 24386 net.cpp:434] conv3_1_bn <- pool3
I0831 12:58:56.956009 24386 net.cpp:408] conv3_1_bn -> conv3_1_bn
I0831 12:58:56.956148 24386 net.cpp:150] Setting up conv3_1_bn
I0831 12:58:56.956154 24386 net.cpp:157] Top shape: 128 32 38 38 (5914624)
I0831 12:58:56.956156 24386 net.cpp:165] Memory required for data: 1478909952
I0831 12:58:56.956162 24386 layer_factory.hpp:77] Creating layer conv3_1_bn_scale
I0831 12:58:56.956171 24386 net.cpp:100] Creating Layer conv3_1_bn_scale
I0831 12:58:56.956173 24386 net.cpp:434] conv3_1_bn_scale <- conv3_1_bn
I0831 12:58:56.956176 24386 net.cpp:395] conv3_1_bn_scale -> conv3_1_bn (in-place)
I0831 12:58:56.956200 24386 layer_factory.hpp:77] Creating layer conv3_1_bn_scale
I0831 12:58:56.956281 24386 net.cpp:150] Setting up conv3_1_bn_scale
I0831 12:58:56.956286 24386 net.cpp:157] Top shape: 128 32 38 38 (5914624)
I0831 12:58:56.956290 24386 net.cpp:165] Memory required for data: 1502568448
I0831 12:58:56.956297 24386 layer_factory.hpp:77] Creating layer conv3_1_relu
I0831 12:58:56.956302 24386 net.cpp:100] Creating Layer conv3_1_relu
I0831 12:58:56.956305 24386 net.cpp:434] conv3_1_relu <- conv3_1_bn
I0831 12:58:56.956310 24386 net.cpp:395] conv3_1_relu -> conv3_1_bn (in-place)
I0831 12:58:56.956313 24386 net.cpp:150] Setting up conv3_1_relu
I0831 12:58:56.956317 24386 net.cpp:157] Top shape: 128 32 38 38 (5914624)
I0831 12:58:56.956320 24386 net.cpp:165] Memory required for data: 1526226944
I0831 12:58:56.956322 24386 layer_factory.hpp:77] Creating layer conv4_1
I0831 12:58:56.956329 24386 net.cpp:100] Creating Layer conv4_1
I0831 12:58:56.956332 24386 net.cpp:434] conv4_1 <- conv3_1_bn
I0831 12:58:56.956336 24386 net.cpp:408] conv4_1 -> conv4_1
I0831 12:58:56.956851 24386 net.cpp:150] Setting up conv4_1
I0831 12:58:56.956859 24386 net.cpp:157] Top shape: 128 64 38 38 (11829248)
I0831 12:58:56.956861 24386 net.cpp:165] Memory required for data: 1573543936
I0831 12:58:56.956866 24386 layer_factory.hpp:77] Creating layer pool4
I0831 12:58:56.956871 24386 net.cpp:100] Creating Layer pool4
I0831 12:58:56.956873 24386 net.cpp:434] pool4 <- conv4_1
I0831 12:58:56.956877 24386 net.cpp:408] pool4 -> pool4
I0831 12:58:56.956907 24386 net.cpp:150] Setting up pool4
I0831 12:58:56.956912 24386 net.cpp:157] Top shape: 128 64 19 19 (2957312)
I0831 12:58:56.956914 24386 net.cpp:165] Memory required for data: 1585373184
I0831 12:58:56.956918 24386 layer_factory.hpp:77] Creating layer conv4_1_bn
I0831 12:58:56.956923 24386 net.cpp:100] Creating Layer conv4_1_bn
I0831 12:58:56.956928 24386 net.cpp:434] conv4_1_bn <- pool4
I0831 12:58:56.956933 24386 net.cpp:408] conv4_1_bn -> conv4_1_bn
I0831 12:58:56.957685 24386 net.cpp:150] Setting up conv4_1_bn
I0831 12:58:56.957703 24386 net.cpp:157] Top shape: 128 64 19 19 (2957312)
I0831 12:58:56.957707 24386 net.cpp:165] Memory required for data: 1597202432
I0831 12:58:56.957715 24386 layer_factory.hpp:77] Creating layer conv4_1_bn_scale
I0831 12:58:56.957722 24386 net.cpp:100] Creating Layer conv4_1_bn_scale
I0831 12:58:56.957726 24386 net.cpp:434] conv4_1_bn_scale <- conv4_1_bn
I0831 12:58:56.957731 24386 net.cpp:395] conv4_1_bn_scale -> conv4_1_bn (in-place)
I0831 12:58:56.957762 24386 layer_factory.hpp:77] Creating layer conv4_1_bn_scale
I0831 12:58:56.957841 24386 net.cpp:150] Setting up conv4_1_bn_scale
I0831 12:58:56.957847 24386 net.cpp:157] Top shape: 128 64 19 19 (2957312)
I0831 12:58:56.957849 24386 net.cpp:165] Memory required for data: 1609031680
I0831 12:58:56.957854 24386 layer_factory.hpp:77] Creating layer conv4_1_relu
I0831 12:58:56.957860 24386 net.cpp:100] Creating Layer conv4_1_relu
I0831 12:58:56.957862 24386 net.cpp:434] conv4_1_relu <- conv4_1_bn
I0831 12:58:56.957867 24386 net.cpp:395] conv4_1_relu -> conv4_1_bn (in-place)
I0831 12:58:56.957872 24386 net.cpp:150] Setting up conv4_1_relu
I0831 12:58:56.957876 24386 net.cpp:157] Top shape: 128 64 19 19 (2957312)
I0831 12:58:56.957878 24386 net.cpp:165] Memory required for data: 1620860928
I0831 12:58:56.957881 24386 layer_factory.hpp:77] Creating layer conv5_1
I0831 12:58:56.957890 24386 net.cpp:100] Creating Layer conv5_1
I0831 12:58:56.957900 24386 net.cpp:434] conv5_1 <- conv4_1_bn
I0831 12:58:56.957911 24386 net.cpp:408] conv5_1 -> conv5_1
I0831 12:58:56.958871 24386 net.cpp:150] Setting up conv5_1
I0831 12:58:56.958889 24386 net.cpp:157] Top shape: 128 64 17 17 (2367488)
I0831 12:58:56.958894 24386 net.cpp:165] Memory required for data: 1630330880
I0831 12:58:56.958901 24386 layer_factory.hpp:77] Creating layer conv5_1_bn
I0831 12:58:56.958911 24386 net.cpp:100] Creating Layer conv5_1_bn
I0831 12:58:56.958917 24386 net.cpp:434] conv5_1_bn <- conv5_1
I0831 12:58:56.958927 24386 net.cpp:408] conv5_1_bn -> conv5_1_bn
I0831 12:58:56.959117 24386 net.cpp:150] Setting up conv5_1_bn
I0831 12:58:56.959127 24386 net.cpp:157] Top shape: 128 64 17 17 (2367488)
I0831 12:58:56.959131 24386 net.cpp:165] Memory required for data: 1639800832
I0831 12:58:56.959136 24386 layer_factory.hpp:77] Creating layer conv5_1_bn_scale
I0831 12:58:56.959143 24386 net.cpp:100] Creating Layer conv5_1_bn_scale
I0831 12:58:56.959146 24386 net.cpp:434] conv5_1_bn_scale <- conv5_1_bn
I0831 12:58:56.959151 24386 net.cpp:395] conv5_1_bn_scale -> conv5_1_bn (in-place)
I0831 12:58:56.959190 24386 layer_factory.hpp:77] Creating layer conv5_1_bn_scale
I0831 12:58:56.959316 24386 net.cpp:150] Setting up conv5_1_bn_scale
I0831 12:58:56.959327 24386 net.cpp:157] Top shape: 128 64 17 17 (2367488)
I0831 12:58:56.959331 24386 net.cpp:165] Memory required for data: 1649270784
I0831 12:58:56.959339 24386 layer_factory.hpp:77] Creating layer conv5_1_relu
I0831 12:58:56.959347 24386 net.cpp:100] Creating Layer conv5_1_relu
I0831 12:58:56.959352 24386 net.cpp:434] conv5_1_relu <- conv5_1_bn
I0831 12:58:56.959360 24386 net.cpp:395] conv5_1_relu -> conv5_1_bn (in-place)
I0831 12:58:56.959369 24386 net.cpp:150] Setting up conv5_1_relu
I0831 12:58:56.959377 24386 net.cpp:157] Top shape: 128 64 17 17 (2367488)
I0831 12:58:56.959381 24386 net.cpp:165] Memory required for data: 1658740736
I0831 12:58:56.959386 24386 layer_factory.hpp:77] Creating layer conv6_1
I0831 12:58:56.959398 24386 net.cpp:100] Creating Layer conv6_1
I0831 12:58:56.959403 24386 net.cpp:434] conv6_1 <- conv5_1_bn
I0831 12:58:56.959414 24386 net.cpp:408] conv6_1 -> conv6_1
I0831 12:58:56.960453 24386 net.cpp:150] Setting up conv6_1
I0831 12:58:56.960469 24386 net.cpp:157] Top shape: 128 64 15 15 (1843200)
I0831 12:58:56.960470 24386 net.cpp:165] Memory required for data: 1666113536
I0831 12:58:56.960475 24386 layer_factory.hpp:77] Creating layer conv6_1_bn
I0831 12:58:56.960484 24386 net.cpp:100] Creating Layer conv6_1_bn
I0831 12:58:56.960487 24386 net.cpp:434] conv6_1_bn <- conv6_1
I0831 12:58:56.960492 24386 net.cpp:408] conv6_1_bn -> conv6_1_bn
I0831 12:58:56.960623 24386 net.cpp:150] Setting up conv6_1_bn
I0831 12:58:56.960629 24386 net.cpp:157] Top shape: 128 64 15 15 (1843200)
I0831 12:58:56.960631 24386 net.cpp:165] Memory required for data: 1673486336
I0831 12:58:56.960644 24386 layer_factory.hpp:77] Creating layer conv6_1_bn_scale
I0831 12:58:56.960650 24386 net.cpp:100] Creating Layer conv6_1_bn_scale
I0831 12:58:56.960654 24386 net.cpp:434] conv6_1_bn_scale <- conv6_1_bn
I0831 12:58:56.960659 24386 net.cpp:395] conv6_1_bn_scale -> conv6_1_bn (in-place)
I0831 12:58:56.960683 24386 layer_factory.hpp:77] Creating layer conv6_1_bn_scale
I0831 12:58:56.960758 24386 net.cpp:150] Setting up conv6_1_bn_scale
I0831 12:58:56.960763 24386 net.cpp:157] Top shape: 128 64 15 15 (1843200)
I0831 12:58:56.960767 24386 net.cpp:165] Memory required for data: 1680859136
I0831 12:58:56.960770 24386 layer_factory.hpp:77] Creating layer conv6_1_relu
I0831 12:58:56.960777 24386 net.cpp:100] Creating Layer conv6_1_relu
I0831 12:58:56.960779 24386 net.cpp:434] conv6_1_relu <- conv6_1_bn
I0831 12:58:56.960783 24386 net.cpp:395] conv6_1_relu -> conv6_1_bn (in-place)
I0831 12:58:56.960788 24386 net.cpp:150] Setting up conv6_1_relu
I0831 12:58:56.960791 24386 net.cpp:157] Top shape: 128 64 15 15 (1843200)
I0831 12:58:56.960794 24386 net.cpp:165] Memory required for data: 1688231936
I0831 12:58:56.960798 24386 layer_factory.hpp:77] Creating layer conv7_1
I0831 12:58:56.960813 24386 net.cpp:100] Creating Layer conv7_1
I0831 12:58:56.960824 24386 net.cpp:434] conv7_1 <- conv6_1_bn
I0831 12:58:56.960829 24386 net.cpp:408] conv7_1 -> conv7_1
I0831 12:58:56.963083 24386 net.cpp:150] Setting up conv7_1
I0831 12:58:56.963117 24386 net.cpp:157] Top shape: 128 128 13 13 (2768896)
I0831 12:58:56.963120 24386 net.cpp:165] Memory required for data: 1699307520
I0831 12:58:56.963127 24386 layer_factory.hpp:77] Creating layer conv7_1_bn
I0831 12:58:56.963143 24386 net.cpp:100] Creating Layer conv7_1_bn
I0831 12:58:56.963148 24386 net.cpp:434] conv7_1_bn <- conv7_1
I0831 12:58:56.963156 24386 net.cpp:408] conv7_1_bn -> conv7_1_bn
I0831 12:58:56.963291 24386 net.cpp:150] Setting up conv7_1_bn
I0831 12:58:56.963297 24386 net.cpp:157] Top shape: 128 128 13 13 (2768896)
I0831 12:58:56.963300 24386 net.cpp:165] Memory required for data: 1710383104
I0831 12:58:56.963306 24386 layer_factory.hpp:77] Creating layer conv7_1_bn_scale
I0831 12:58:56.963313 24386 net.cpp:100] Creating Layer conv7_1_bn_scale
I0831 12:58:56.963316 24386 net.cpp:434] conv7_1_bn_scale <- conv7_1_bn
I0831 12:58:56.963320 24386 net.cpp:395] conv7_1_bn_scale -> conv7_1_bn (in-place)
I0831 12:58:56.963351 24386 layer_factory.hpp:77] Creating layer conv7_1_bn_scale
I0831 12:58:56.963421 24386 net.cpp:150] Setting up conv7_1_bn_scale
I0831 12:58:56.963428 24386 net.cpp:157] Top shape: 128 128 13 13 (2768896)
I0831 12:58:56.963429 24386 net.cpp:165] Memory required for data: 1721458688
I0831 12:58:56.963434 24386 layer_factory.hpp:77] Creating layer conv7_1_relu
I0831 12:58:56.963439 24386 net.cpp:100] Creating Layer conv7_1_relu
I0831 12:58:56.963443 24386 net.cpp:434] conv7_1_relu <- conv7_1_bn
I0831 12:58:56.963448 24386 net.cpp:395] conv7_1_relu -> conv7_1_bn (in-place)
I0831 12:58:56.963452 24386 net.cpp:150] Setting up conv7_1_relu
I0831 12:58:56.963456 24386 net.cpp:157] Top shape: 128 128 13 13 (2768896)
I0831 12:58:56.963459 24386 net.cpp:165] Memory required for data: 1732534272
I0831 12:58:56.963461 24386 layer_factory.hpp:77] Creating layer score
I0831 12:58:56.963471 24386 net.cpp:100] Creating Layer score
I0831 12:58:56.963474 24386 net.cpp:434] score <- conv7_1_bn
I0831 12:58:56.963479 24386 net.cpp:408] score -> score
I0831 12:58:56.963647 24386 net.cpp:150] Setting up score
I0831 12:58:56.963655 24386 net.cpp:157] Top shape: 128 4 13 13 (86528)
I0831 12:58:56.963659 24386 net.cpp:165] Memory required for data: 1732880384
I0831 12:58:56.963662 24386 layer_factory.hpp:77] Creating layer upscore
I0831 12:58:56.963670 24386 net.cpp:100] Creating Layer upscore
I0831 12:58:56.963671 24386 net.cpp:434] upscore <- score
I0831 12:58:56.963677 24386 net.cpp:408] upscore -> upscore
I0831 12:58:56.964155 24386 net.cpp:150] Setting up upscore
I0831 12:58:56.964162 24386 net.cpp:157] Top shape: 128 4 224 224 (25690112)
I0831 12:58:56.964165 24386 net.cpp:165] Memory required for data: 1835640832
I0831 12:58:56.964169 24386 layer_factory.hpp:77] Creating layer cropscore
I0831 12:58:56.964176 24386 net.cpp:100] Creating Layer cropscore
I0831 12:58:56.964179 24386 net.cpp:434] cropscore <- upscore
I0831 12:58:56.964184 24386 net.cpp:434] cropscore <- image_data_0_split_1
I0831 12:58:56.964188 24386 net.cpp:408] cropscore -> cropscore
I0831 12:58:56.964208 24386 net.cpp:150] Setting up cropscore
I0831 12:58:56.964212 24386 net.cpp:157] Top shape: 128 4 200 200 (20480000)
I0831 12:58:56.964215 24386 net.cpp:165] Memory required for data: 1917560832
I0831 12:58:56.964218 24386 layer_factory.hpp:77] Creating layer cropscore_cropscore_0_split
I0831 12:58:56.964223 24386 net.cpp:100] Creating Layer cropscore_cropscore_0_split
I0831 12:58:56.964226 24386 net.cpp:434] cropscore_cropscore_0_split <- cropscore
I0831 12:58:56.964231 24386 net.cpp:408] cropscore_cropscore_0_split -> cropscore_cropscore_0_split_0
I0831 12:58:56.964236 24386 net.cpp:408] cropscore_cropscore_0_split -> cropscore_cropscore_0_split_1
I0831 12:58:56.964257 24386 net.cpp:150] Setting up cropscore_cropscore_0_split
I0831 12:58:56.964260 24386 net.cpp:157] Top shape: 128 4 200 200 (20480000)
I0831 12:58:56.964277 24386 net.cpp:157] Top shape: 128 4 200 200 (20480000)
I0831 12:58:56.964288 24386 net.cpp:165] Memory required for data: 2081400832
I0831 12:58:56.964292 24386 layer_factory.hpp:77] Creating layer loss
I0831 12:58:56.964299 24386 net.cpp:100] Creating Layer loss
I0831 12:58:56.964303 24386 net.cpp:434] loss <- cropscore_cropscore_0_split_0
I0831 12:58:56.964305 24386 net.cpp:434] loss <- label_data_1_split_0
I0831 12:58:56.964310 24386 net.cpp:408] loss -> loss
I0831 12:58:56.964318 24386 layer_factory.hpp:77] Creating layer loss
I0831 12:58:57.011626 24386 net.cpp:150] Setting up loss
I0831 12:58:57.011670 24386 net.cpp:157] Top shape: (1)
I0831 12:58:57.011677 24386 net.cpp:160]     with loss weight 1
I0831 12:58:57.011708 24386 net.cpp:165] Memory required for data: 2081400836
I0831 12:58:57.011713 24386 layer_factory.hpp:77] Creating layer accuracy
I0831 12:58:57.011735 24386 net.cpp:100] Creating Layer accuracy
I0831 12:58:57.011745 24386 net.cpp:434] accuracy <- cropscore_cropscore_0_split_1
I0831 12:58:57.011756 24386 net.cpp:434] accuracy <- label_data_1_split_1
I0831 12:58:57.011764 24386 net.cpp:408] accuracy -> accuracy
I0831 12:58:57.011775 24386 net.cpp:150] Setting up accuracy
I0831 12:58:57.011780 24386 net.cpp:157] Top shape: (1)
I0831 12:58:57.011782 24386 net.cpp:165] Memory required for data: 2081400840
I0831 12:58:57.011785 24386 net.cpp:228] accuracy does not need backward computation.
I0831 12:58:57.011788 24386 net.cpp:226] loss needs backward computation.
I0831 12:58:57.011792 24386 net.cpp:226] cropscore_cropscore_0_split needs backward computation.
I0831 12:58:57.011795 24386 net.cpp:226] cropscore needs backward computation.
I0831 12:58:57.011800 24386 net.cpp:226] upscore needs backward computation.
I0831 12:58:57.011802 24386 net.cpp:226] score needs backward computation.
I0831 12:58:57.011806 24386 net.cpp:226] conv7_1_relu needs backward computation.
I0831 12:58:57.011808 24386 net.cpp:226] conv7_1_bn_scale needs backward computation.
I0831 12:58:57.011811 24386 net.cpp:226] conv7_1_bn needs backward computation.
I0831 12:58:57.011814 24386 net.cpp:226] conv7_1 needs backward computation.
I0831 12:58:57.011817 24386 net.cpp:226] conv6_1_relu needs backward computation.
I0831 12:58:57.011821 24386 net.cpp:226] conv6_1_bn_scale needs backward computation.
I0831 12:58:57.011822 24386 net.cpp:226] conv6_1_bn needs backward computation.
I0831 12:58:57.011826 24386 net.cpp:226] conv6_1 needs backward computation.
I0831 12:58:57.011828 24386 net.cpp:226] conv5_1_relu needs backward computation.
I0831 12:58:57.011831 24386 net.cpp:226] conv5_1_bn_scale needs backward computation.
I0831 12:58:57.011834 24386 net.cpp:226] conv5_1_bn needs backward computation.
I0831 12:58:57.011837 24386 net.cpp:226] conv5_1 needs backward computation.
I0831 12:58:57.011840 24386 net.cpp:226] conv4_1_relu needs backward computation.
I0831 12:58:57.011842 24386 net.cpp:226] conv4_1_bn_scale needs backward computation.
I0831 12:58:57.011845 24386 net.cpp:226] conv4_1_bn needs backward computation.
I0831 12:58:57.011850 24386 net.cpp:226] pool4 needs backward computation.
I0831 12:58:57.011854 24386 net.cpp:226] conv4_1 needs backward computation.
I0831 12:58:57.011857 24386 net.cpp:226] conv3_1_relu needs backward computation.
I0831 12:58:57.011860 24386 net.cpp:226] conv3_1_bn_scale needs backward computation.
I0831 12:58:57.011863 24386 net.cpp:226] conv3_1_bn needs backward computation.
I0831 12:58:57.011867 24386 net.cpp:226] pool3 needs backward computation.
I0831 12:58:57.011869 24386 net.cpp:226] conv3_1 needs backward computation.
I0831 12:58:57.011871 24386 net.cpp:226] conv2_1_relu needs backward computation.
I0831 12:58:57.011874 24386 net.cpp:226] conv2_1_bn_scale needs backward computation.
I0831 12:58:57.011878 24386 net.cpp:226] conv2_1_bn needs backward computation.
I0831 12:58:57.011880 24386 net.cpp:226] pool2 needs backward computation.
I0831 12:58:57.011883 24386 net.cpp:226] conv2_1 needs backward computation.
I0831 12:58:57.011886 24386 net.cpp:226] conv1_1_relu needs backward computation.
I0831 12:58:57.011904 24386 net.cpp:226] conv1_1_bn_scale needs backward computation.
I0831 12:58:57.011907 24386 net.cpp:226] conv1_1_bn needs backward computation.
I0831 12:58:57.011910 24386 net.cpp:226] pool1 needs backward computation.
I0831 12:58:57.011914 24386 net.cpp:226] conv1_1 needs backward computation.
I0831 12:58:57.011916 24386 net.cpp:228] label_data_1_split does not need backward computation.
I0831 12:58:57.011920 24386 net.cpp:228] image_data_0_split does not need backward computation.
I0831 12:58:57.011924 24386 net.cpp:228] data does not need backward computation.
I0831 12:58:57.011926 24386 net.cpp:270] This network produces output accuracy
I0831 12:58:57.011929 24386 net.cpp:270] This network produces output loss
I0831 12:58:57.011955 24386 net.cpp:283] Network initialization done.
I0831 12:58:57.012553 24386 solver.cpp:181] Creating test net (#0) specified by net file: portrait_wb_train_test_one_stage.prototxt3
I0831 12:58:57.012594 24386 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0831 12:58:57.012748 24386 net.cpp:58] Initializing net from parameters: 
name: "segmentation"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "SegData"
  top: "image"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 200
  }
  data_param {
    source: "/raid/xuehan/segmentation_wb_test_split"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "image"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 50
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1_1_bn"
  type: "BatchNorm"
  bottom: "pool1"
  top: "conv1_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv1_1_bn_scale"
  type: "Scale"
  bottom: "conv1_1_bn"
  top: "conv1_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_1_relu"
  type: "ReLU"
  bottom: "conv1_1_bn"
  top: "conv1_1_bn"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv1_1_bn"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_1"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1_bn"
  type: "BatchNorm"
  bottom: "pool2"
  top: "conv2_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv2_1_bn_scale"
  type: "Scale"
  bottom: "conv2_1_bn"
  top: "conv2_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1_relu"
  type: "ReLU"
  bottom: "conv2_1_bn"
  top: "conv2_1_bn"
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv2_1_bn"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_1"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1_bn"
  type: "BatchNorm"
  bottom: "pool3"
  top: "conv3_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv3_1_bn_scale"
  type: "Scale"
  bottom: "conv3_1_bn"
  top: "conv3_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1_relu"
  type: "ReLU"
  bottom: "conv3_1_bn"
  top: "conv3_1_bn"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv3_1_bn"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_1"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1_bn"
  type: "BatchNorm"
  bottom: "pool4"
  top: "conv4_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv4_1_bn_scale"
  type: "Scale"
  bottom: "conv4_1_bn"
  top: "conv4_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1_relu"
  type: "ReLU"
  bottom: "conv4_1_bn"
  top: "conv4_1_bn"
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "conv4_1_bn"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv5_1_bn"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv5_1_bn_scale"
  type: "Scale"
  bottom: "conv5_1_bn"
  top: "conv5_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_1_relu"
  type: "ReLU"
  bottom: "conv5_1_bn"
  top: "conv5_1_bn"
}
layer {
  name: "conv6_1"
  type: "Convolution"
  bottom: "conv5_1_bn"
  top: "conv6_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv6_1_bn"
  type: "BatchNorm"
  bottom: "conv6_1"
  top: "conv6_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv6_1_bn_scale"
  type: "Scale"
  bottom: "conv6_1_bn"
  top: "conv6_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv6_1_relu"
  type: "ReLU"
  bottom: "conv6_1_bn"
  top: "conv6_1_bn"
}
layer {
  name: "conv7_1"
  type: "Convolution"
  bottom: "conv6_1_bn"
  top: "conv7_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv7_1_bn"
  type: "BatchNorm"
  bottom: "conv7_1"
  top: "conv7_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv7_1_bn_scale"
  type: "Scale"
  bottom: "conv7_1_bn"
  top: "conv7_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv7_1_relu"
  type: "ReLU"
  bottom: "conv7_1_bn"
  top: "conv7_1_bn"
}
layer {
  name: "score"
  type: "Convolution"
  bottom: "conv7_1_bn"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 4
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "upscore"
  type: "Deconvolution"
  bottom: "score"
  top: "upscore"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 4
    bias_term: false
    pad: 0
    kernel_size: 32
    stride: 16
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "cropscore"
  type: "Crop"
  bottom: "upscore"
  bottom: "image"
  top: "cropscore"
  crop_param {
    axis: 2
    offset: 12
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "cropscore"
  bottom: "label"
  top: "loss"
  loss_weight: 1
  loss_param {
    normalize: false
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "cropscore"
  bottom: "label"
  top: "accuracy"
}
I0831 12:58:57.012866 24386 layer_factory.hpp:77] Creating layer data
I0831 12:58:57.012955 24386 net.cpp:100] Creating Layer data
I0831 12:58:57.012962 24386 net.cpp:408] data -> image
I0831 12:58:57.012969 24386 net.cpp:408] data -> label
I0831 12:58:57.015447 24394 db_lmdb.cpp:35] Opened lmdb /raid/xuehan/segmentation_wb_test_split
I0831 12:58:57.015597 24386 seg_data_layer.cpp:38] 200 200 4
I0831 12:58:57.015686 24386 seg_data_layer.cpp:51] output data size: 64,3,200,200
I0831 12:58:57.015734 24386 seg_data_layer.cpp:63] output label size: 64,1,200,200
I0831 12:58:57.087985 24386 net.cpp:150] Setting up data
I0831 12:58:57.088014 24386 net.cpp:157] Top shape: 64 3 200 200 (7680000)
I0831 12:58:57.088021 24386 net.cpp:157] Top shape: 64 1 200 200 (2560000)
I0831 12:58:57.088022 24386 net.cpp:165] Memory required for data: 40960000
I0831 12:58:57.088028 24386 layer_factory.hpp:77] Creating layer image_data_0_split
I0831 12:58:57.088039 24386 net.cpp:100] Creating Layer image_data_0_split
I0831 12:58:57.088043 24386 net.cpp:434] image_data_0_split <- image
I0831 12:58:57.088052 24386 net.cpp:408] image_data_0_split -> image_data_0_split_0
I0831 12:58:57.088059 24386 net.cpp:408] image_data_0_split -> image_data_0_split_1
I0831 12:58:57.088126 24386 net.cpp:150] Setting up image_data_0_split
I0831 12:58:57.088134 24386 net.cpp:157] Top shape: 64 3 200 200 (7680000)
I0831 12:58:57.088137 24386 net.cpp:157] Top shape: 64 3 200 200 (7680000)
I0831 12:58:57.088140 24386 net.cpp:165] Memory required for data: 102400000
I0831 12:58:57.088142 24386 layer_factory.hpp:77] Creating layer label_data_1_split
I0831 12:58:57.088147 24386 net.cpp:100] Creating Layer label_data_1_split
I0831 12:58:57.088150 24386 net.cpp:434] label_data_1_split <- label
I0831 12:58:57.088155 24386 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0831 12:58:57.088160 24386 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0831 12:58:57.088186 24386 net.cpp:150] Setting up label_data_1_split
I0831 12:58:57.088191 24386 net.cpp:157] Top shape: 64 1 200 200 (2560000)
I0831 12:58:57.088194 24386 net.cpp:157] Top shape: 64 1 200 200 (2560000)
I0831 12:58:57.088197 24386 net.cpp:165] Memory required for data: 122880000
I0831 12:58:57.088199 24386 layer_factory.hpp:77] Creating layer conv1_1
I0831 12:58:57.088209 24386 net.cpp:100] Creating Layer conv1_1
I0831 12:58:57.088212 24386 net.cpp:434] conv1_1 <- image_data_0_split_0
I0831 12:58:57.088218 24386 net.cpp:408] conv1_1 -> conv1_1
I0831 12:58:57.088371 24386 net.cpp:150] Setting up conv1_1
I0831 12:58:57.088377 24386 net.cpp:157] Top shape: 64 8 298 298 (45467648)
I0831 12:58:57.088381 24386 net.cpp:165] Memory required for data: 304750592
I0831 12:58:57.088387 24386 layer_factory.hpp:77] Creating layer pool1
I0831 12:58:57.088393 24386 net.cpp:100] Creating Layer pool1
I0831 12:58:57.088397 24386 net.cpp:434] pool1 <- conv1_1
I0831 12:58:57.088400 24386 net.cpp:408] pool1 -> pool1
I0831 12:58:57.088426 24386 net.cpp:150] Setting up pool1
I0831 12:58:57.088431 24386 net.cpp:157] Top shape: 64 8 149 149 (11366912)
I0831 12:58:57.088434 24386 net.cpp:165] Memory required for data: 350218240
I0831 12:58:57.088436 24386 layer_factory.hpp:77] Creating layer conv1_1_bn
I0831 12:58:57.088443 24386 net.cpp:100] Creating Layer conv1_1_bn
I0831 12:58:57.088445 24386 net.cpp:434] conv1_1_bn <- pool1
I0831 12:58:57.088449 24386 net.cpp:408] conv1_1_bn -> conv1_1_bn
I0831 12:58:57.088604 24386 net.cpp:150] Setting up conv1_1_bn
I0831 12:58:57.088610 24386 net.cpp:157] Top shape: 64 8 149 149 (11366912)
I0831 12:58:57.088613 24386 net.cpp:165] Memory required for data: 395685888
I0831 12:58:57.088621 24386 layer_factory.hpp:77] Creating layer conv1_1_bn_scale
I0831 12:58:57.088629 24386 net.cpp:100] Creating Layer conv1_1_bn_scale
I0831 12:58:57.088631 24386 net.cpp:434] conv1_1_bn_scale <- conv1_1_bn
I0831 12:58:57.088634 24386 net.cpp:395] conv1_1_bn_scale -> conv1_1_bn (in-place)
I0831 12:58:57.088662 24386 layer_factory.hpp:77] Creating layer conv1_1_bn_scale
I0831 12:58:57.088771 24386 net.cpp:150] Setting up conv1_1_bn_scale
I0831 12:58:57.088791 24386 net.cpp:157] Top shape: 64 8 149 149 (11366912)
I0831 12:58:57.088794 24386 net.cpp:165] Memory required for data: 441153536
I0831 12:58:57.088801 24386 layer_factory.hpp:77] Creating layer conv1_1_relu
I0831 12:58:57.088809 24386 net.cpp:100] Creating Layer conv1_1_relu
I0831 12:58:57.088811 24386 net.cpp:434] conv1_1_relu <- conv1_1_bn
I0831 12:58:57.088815 24386 net.cpp:395] conv1_1_relu -> conv1_1_bn (in-place)
I0831 12:58:57.088820 24386 net.cpp:150] Setting up conv1_1_relu
I0831 12:58:57.088824 24386 net.cpp:157] Top shape: 64 8 149 149 (11366912)
I0831 12:58:57.088826 24386 net.cpp:165] Memory required for data: 486621184
I0831 12:58:57.088829 24386 layer_factory.hpp:77] Creating layer conv2_1
I0831 12:58:57.088836 24386 net.cpp:100] Creating Layer conv2_1
I0831 12:58:57.088840 24386 net.cpp:434] conv2_1 <- conv1_1_bn
I0831 12:58:57.088843 24386 net.cpp:408] conv2_1 -> conv2_1
I0831 12:58:57.088997 24386 net.cpp:150] Setting up conv2_1
I0831 12:58:57.089004 24386 net.cpp:157] Top shape: 64 16 149 149 (22733824)
I0831 12:58:57.089005 24386 net.cpp:165] Memory required for data: 577556480
I0831 12:58:57.089010 24386 layer_factory.hpp:77] Creating layer pool2
I0831 12:58:57.089015 24386 net.cpp:100] Creating Layer pool2
I0831 12:58:57.089017 24386 net.cpp:434] pool2 <- conv2_1
I0831 12:58:57.089020 24386 net.cpp:408] pool2 -> pool2
I0831 12:58:57.089045 24386 net.cpp:150] Setting up pool2
I0831 12:58:57.089049 24386 net.cpp:157] Top shape: 64 16 75 75 (5760000)
I0831 12:58:57.089051 24386 net.cpp:165] Memory required for data: 600596480
I0831 12:58:57.089054 24386 layer_factory.hpp:77] Creating layer conv2_1_bn
I0831 12:58:57.089061 24386 net.cpp:100] Creating Layer conv2_1_bn
I0831 12:58:57.089063 24386 net.cpp:434] conv2_1_bn <- pool2
I0831 12:58:57.089066 24386 net.cpp:408] conv2_1_bn -> conv2_1_bn
I0831 12:58:57.089211 24386 net.cpp:150] Setting up conv2_1_bn
I0831 12:58:57.089216 24386 net.cpp:157] Top shape: 64 16 75 75 (5760000)
I0831 12:58:57.089220 24386 net.cpp:165] Memory required for data: 623636480
I0831 12:58:57.089226 24386 layer_factory.hpp:77] Creating layer conv2_1_bn_scale
I0831 12:58:57.089231 24386 net.cpp:100] Creating Layer conv2_1_bn_scale
I0831 12:58:57.089234 24386 net.cpp:434] conv2_1_bn_scale <- conv2_1_bn
I0831 12:58:57.089237 24386 net.cpp:395] conv2_1_bn_scale -> conv2_1_bn (in-place)
I0831 12:58:57.089284 24386 layer_factory.hpp:77] Creating layer conv2_1_bn_scale
I0831 12:58:57.094454 24386 net.cpp:150] Setting up conv2_1_bn_scale
I0831 12:58:57.094467 24386 net.cpp:157] Top shape: 64 16 75 75 (5760000)
I0831 12:58:57.094470 24386 net.cpp:165] Memory required for data: 646676480
I0831 12:58:57.094476 24386 layer_factory.hpp:77] Creating layer conv2_1_relu
I0831 12:58:57.094482 24386 net.cpp:100] Creating Layer conv2_1_relu
I0831 12:58:57.094485 24386 net.cpp:434] conv2_1_relu <- conv2_1_bn
I0831 12:58:57.094490 24386 net.cpp:395] conv2_1_relu -> conv2_1_bn (in-place)
I0831 12:58:57.094496 24386 net.cpp:150] Setting up conv2_1_relu
I0831 12:58:57.094498 24386 net.cpp:157] Top shape: 64 16 75 75 (5760000)
I0831 12:58:57.094501 24386 net.cpp:165] Memory required for data: 669716480
I0831 12:58:57.094504 24386 layer_factory.hpp:77] Creating layer conv3_1
I0831 12:58:57.094512 24386 net.cpp:100] Creating Layer conv3_1
I0831 12:58:57.094514 24386 net.cpp:434] conv3_1 <- conv2_1_bn
I0831 12:58:57.094519 24386 net.cpp:408] conv3_1 -> conv3_1
I0831 12:58:57.094779 24386 net.cpp:150] Setting up conv3_1
I0831 12:58:57.094789 24386 net.cpp:157] Top shape: 64 32 75 75 (11520000)
I0831 12:58:57.094790 24386 net.cpp:165] Memory required for data: 715796480
I0831 12:58:57.094794 24386 layer_factory.hpp:77] Creating layer pool3
I0831 12:58:57.094800 24386 net.cpp:100] Creating Layer pool3
I0831 12:58:57.094804 24386 net.cpp:434] pool3 <- conv3_1
I0831 12:58:57.094807 24386 net.cpp:408] pool3 -> pool3
I0831 12:58:57.094843 24386 net.cpp:150] Setting up pool3
I0831 12:58:57.094851 24386 net.cpp:157] Top shape: 64 32 38 38 (2957312)
I0831 12:58:57.094862 24386 net.cpp:165] Memory required for data: 727625728
I0831 12:58:57.094872 24386 layer_factory.hpp:77] Creating layer conv3_1_bn
I0831 12:58:57.094880 24386 net.cpp:100] Creating Layer conv3_1_bn
I0831 12:58:57.094884 24386 net.cpp:434] conv3_1_bn <- pool3
I0831 12:58:57.094888 24386 net.cpp:408] conv3_1_bn -> conv3_1_bn
I0831 12:58:57.095032 24386 net.cpp:150] Setting up conv3_1_bn
I0831 12:58:57.095037 24386 net.cpp:157] Top shape: 64 32 38 38 (2957312)
I0831 12:58:57.095041 24386 net.cpp:165] Memory required for data: 739454976
I0831 12:58:57.095046 24386 layer_factory.hpp:77] Creating layer conv3_1_bn_scale
I0831 12:58:57.095054 24386 net.cpp:100] Creating Layer conv3_1_bn_scale
I0831 12:58:57.095057 24386 net.cpp:434] conv3_1_bn_scale <- conv3_1_bn
I0831 12:58:57.095060 24386 net.cpp:395] conv3_1_bn_scale -> conv3_1_bn (in-place)
I0831 12:58:57.095089 24386 layer_factory.hpp:77] Creating layer conv3_1_bn_scale
I0831 12:58:57.095209 24386 net.cpp:150] Setting up conv3_1_bn_scale
I0831 12:58:57.095224 24386 net.cpp:157] Top shape: 64 32 38 38 (2957312)
I0831 12:58:57.095230 24386 net.cpp:165] Memory required for data: 751284224
I0831 12:58:57.095242 24386 layer_factory.hpp:77] Creating layer conv3_1_relu
I0831 12:58:57.095252 24386 net.cpp:100] Creating Layer conv3_1_relu
I0831 12:58:57.095257 24386 net.cpp:434] conv3_1_relu <- conv3_1_bn
I0831 12:58:57.095265 24386 net.cpp:395] conv3_1_relu -> conv3_1_bn (in-place)
I0831 12:58:57.095274 24386 net.cpp:150] Setting up conv3_1_relu
I0831 12:58:57.095281 24386 net.cpp:157] Top shape: 64 32 38 38 (2957312)
I0831 12:58:57.095285 24386 net.cpp:165] Memory required for data: 763113472
I0831 12:58:57.095289 24386 layer_factory.hpp:77] Creating layer conv4_1
I0831 12:58:57.095300 24386 net.cpp:100] Creating Layer conv4_1
I0831 12:58:57.095306 24386 net.cpp:434] conv4_1 <- conv3_1_bn
I0831 12:58:57.095314 24386 net.cpp:408] conv4_1 -> conv4_1
I0831 12:58:57.102851 24386 net.cpp:150] Setting up conv4_1
I0831 12:58:57.102891 24386 net.cpp:157] Top shape: 64 64 38 38 (5914624)
I0831 12:58:57.102897 24386 net.cpp:165] Memory required for data: 786771968
I0831 12:58:57.102907 24386 layer_factory.hpp:77] Creating layer pool4
I0831 12:58:57.102921 24386 net.cpp:100] Creating Layer pool4
I0831 12:58:57.102926 24386 net.cpp:434] pool4 <- conv4_1
I0831 12:58:57.102936 24386 net.cpp:408] pool4 -> pool4
I0831 12:58:57.102982 24386 net.cpp:150] Setting up pool4
I0831 12:58:57.102993 24386 net.cpp:157] Top shape: 64 64 19 19 (1478656)
I0831 12:58:57.102996 24386 net.cpp:165] Memory required for data: 792686592
I0831 12:58:57.103001 24386 layer_factory.hpp:77] Creating layer conv4_1_bn
I0831 12:58:57.103011 24386 net.cpp:100] Creating Layer conv4_1_bn
I0831 12:58:57.103016 24386 net.cpp:434] conv4_1_bn <- pool4
I0831 12:58:57.103023 24386 net.cpp:408] conv4_1_bn -> conv4_1_bn
I0831 12:58:57.103231 24386 net.cpp:150] Setting up conv4_1_bn
I0831 12:58:57.103240 24386 net.cpp:157] Top shape: 64 64 19 19 (1478656)
I0831 12:58:57.103245 24386 net.cpp:165] Memory required for data: 798601216
I0831 12:58:57.103255 24386 layer_factory.hpp:77] Creating layer conv4_1_bn_scale
I0831 12:58:57.103265 24386 net.cpp:100] Creating Layer conv4_1_bn_scale
I0831 12:58:57.103269 24386 net.cpp:434] conv4_1_bn_scale <- conv4_1_bn
I0831 12:58:57.103276 24386 net.cpp:395] conv4_1_bn_scale -> conv4_1_bn (in-place)
I0831 12:58:57.103319 24386 layer_factory.hpp:77] Creating layer conv4_1_bn_scale
I0831 12:58:57.103441 24386 net.cpp:150] Setting up conv4_1_bn_scale
I0831 12:58:57.103449 24386 net.cpp:157] Top shape: 64 64 19 19 (1478656)
I0831 12:58:57.103453 24386 net.cpp:165] Memory required for data: 804515840
I0831 12:58:57.103461 24386 layer_factory.hpp:77] Creating layer conv4_1_relu
I0831 12:58:57.103469 24386 net.cpp:100] Creating Layer conv4_1_relu
I0831 12:58:57.103473 24386 net.cpp:434] conv4_1_relu <- conv4_1_bn
I0831 12:58:57.103482 24386 net.cpp:395] conv4_1_relu -> conv4_1_bn (in-place)
I0831 12:58:57.103489 24386 net.cpp:150] Setting up conv4_1_relu
I0831 12:58:57.103495 24386 net.cpp:157] Top shape: 64 64 19 19 (1478656)
I0831 12:58:57.103521 24386 net.cpp:165] Memory required for data: 810430464
I0831 12:58:57.103526 24386 layer_factory.hpp:77] Creating layer conv5_1
I0831 12:58:57.103538 24386 net.cpp:100] Creating Layer conv5_1
I0831 12:58:57.103543 24386 net.cpp:434] conv5_1 <- conv4_1_bn
I0831 12:58:57.103550 24386 net.cpp:408] conv5_1 -> conv5_1
I0831 12:58:57.109344 24386 net.cpp:150] Setting up conv5_1
I0831 12:58:57.109387 24386 net.cpp:157] Top shape: 64 64 17 17 (1183744)
I0831 12:58:57.109392 24386 net.cpp:165] Memory required for data: 815165440
I0831 12:58:57.109402 24386 layer_factory.hpp:77] Creating layer conv5_1_bn
I0831 12:58:57.109417 24386 net.cpp:100] Creating Layer conv5_1_bn
I0831 12:58:57.109424 24386 net.cpp:434] conv5_1_bn <- conv5_1
I0831 12:58:57.109433 24386 net.cpp:408] conv5_1_bn -> conv5_1_bn
I0831 12:58:57.109653 24386 net.cpp:150] Setting up conv5_1_bn
I0831 12:58:57.109663 24386 net.cpp:157] Top shape: 64 64 17 17 (1183744)
I0831 12:58:57.109666 24386 net.cpp:165] Memory required for data: 819900416
I0831 12:58:57.109675 24386 layer_factory.hpp:77] Creating layer conv5_1_bn_scale
I0831 12:58:57.109686 24386 net.cpp:100] Creating Layer conv5_1_bn_scale
I0831 12:58:57.109691 24386 net.cpp:434] conv5_1_bn_scale <- conv5_1_bn
I0831 12:58:57.109699 24386 net.cpp:395] conv5_1_bn_scale -> conv5_1_bn (in-place)
I0831 12:58:57.109743 24386 layer_factory.hpp:77] Creating layer conv5_1_bn_scale
I0831 12:58:57.109863 24386 net.cpp:150] Setting up conv5_1_bn_scale
I0831 12:58:57.109872 24386 net.cpp:157] Top shape: 64 64 17 17 (1183744)
I0831 12:58:57.109876 24386 net.cpp:165] Memory required for data: 824635392
I0831 12:58:57.109884 24386 layer_factory.hpp:77] Creating layer conv5_1_relu
I0831 12:58:57.109891 24386 net.cpp:100] Creating Layer conv5_1_relu
I0831 12:58:57.109896 24386 net.cpp:434] conv5_1_relu <- conv5_1_bn
I0831 12:58:57.109904 24386 net.cpp:395] conv5_1_relu -> conv5_1_bn (in-place)
I0831 12:58:57.109910 24386 net.cpp:150] Setting up conv5_1_relu
I0831 12:58:57.109916 24386 net.cpp:157] Top shape: 64 64 17 17 (1183744)
I0831 12:58:57.109920 24386 net.cpp:165] Memory required for data: 829370368
I0831 12:58:57.109925 24386 layer_factory.hpp:77] Creating layer conv6_1
I0831 12:58:57.109936 24386 net.cpp:100] Creating Layer conv6_1
I0831 12:58:57.109941 24386 net.cpp:434] conv6_1 <- conv5_1_bn
I0831 12:58:57.109947 24386 net.cpp:408] conv6_1 -> conv6_1
I0831 12:58:57.111444 24386 net.cpp:150] Setting up conv6_1
I0831 12:58:57.111474 24386 net.cpp:157] Top shape: 64 64 15 15 (921600)
I0831 12:58:57.111479 24386 net.cpp:165] Memory required for data: 833056768
I0831 12:58:57.111486 24386 layer_factory.hpp:77] Creating layer conv6_1_bn
I0831 12:58:57.111497 24386 net.cpp:100] Creating Layer conv6_1_bn
I0831 12:58:57.111502 24386 net.cpp:434] conv6_1_bn <- conv6_1
I0831 12:58:57.111517 24386 net.cpp:408] conv6_1_bn -> conv6_1_bn
I0831 12:58:57.111733 24386 net.cpp:150] Setting up conv6_1_bn
I0831 12:58:57.111744 24386 net.cpp:157] Top shape: 64 64 15 15 (921600)
I0831 12:58:57.111747 24386 net.cpp:165] Memory required for data: 836743168
I0831 12:58:57.111759 24386 layer_factory.hpp:77] Creating layer conv6_1_bn_scale
I0831 12:58:57.111766 24386 net.cpp:100] Creating Layer conv6_1_bn_scale
I0831 12:58:57.111769 24386 net.cpp:434] conv6_1_bn_scale <- conv6_1_bn
I0831 12:58:57.111775 24386 net.cpp:395] conv6_1_bn_scale -> conv6_1_bn (in-place)
I0831 12:58:57.111806 24386 layer_factory.hpp:77] Creating layer conv6_1_bn_scale
I0831 12:58:57.111887 24386 net.cpp:150] Setting up conv6_1_bn_scale
I0831 12:58:57.111893 24386 net.cpp:157] Top shape: 64 64 15 15 (921600)
I0831 12:58:57.111896 24386 net.cpp:165] Memory required for data: 840429568
I0831 12:58:57.111901 24386 layer_factory.hpp:77] Creating layer conv6_1_relu
I0831 12:58:57.111908 24386 net.cpp:100] Creating Layer conv6_1_relu
I0831 12:58:57.111912 24386 net.cpp:434] conv6_1_relu <- conv6_1_bn
I0831 12:58:57.111915 24386 net.cpp:395] conv6_1_relu -> conv6_1_bn (in-place)
I0831 12:58:57.111919 24386 net.cpp:150] Setting up conv6_1_relu
I0831 12:58:57.111932 24386 net.cpp:157] Top shape: 64 64 15 15 (921600)
I0831 12:58:57.111943 24386 net.cpp:165] Memory required for data: 844115968
I0831 12:58:57.111946 24386 layer_factory.hpp:77] Creating layer conv7_1
I0831 12:58:57.111954 24386 net.cpp:100] Creating Layer conv7_1
I0831 12:58:57.111958 24386 net.cpp:434] conv7_1 <- conv6_1_bn
I0831 12:58:57.111961 24386 net.cpp:408] conv7_1 -> conv7_1
I0831 12:58:57.114501 24386 net.cpp:150] Setting up conv7_1
I0831 12:58:57.114550 24386 net.cpp:157] Top shape: 64 128 13 13 (1384448)
I0831 12:58:57.114555 24386 net.cpp:165] Memory required for data: 849653760
I0831 12:58:57.114565 24386 layer_factory.hpp:77] Creating layer conv7_1_bn
I0831 12:58:57.114584 24386 net.cpp:100] Creating Layer conv7_1_bn
I0831 12:58:57.114591 24386 net.cpp:434] conv7_1_bn <- conv7_1
I0831 12:58:57.114600 24386 net.cpp:408] conv7_1_bn -> conv7_1_bn
I0831 12:58:57.114809 24386 net.cpp:150] Setting up conv7_1_bn
I0831 12:58:57.114817 24386 net.cpp:157] Top shape: 64 128 13 13 (1384448)
I0831 12:58:57.114821 24386 net.cpp:165] Memory required for data: 855191552
I0831 12:58:57.114831 24386 layer_factory.hpp:77] Creating layer conv7_1_bn_scale
I0831 12:58:57.114840 24386 net.cpp:100] Creating Layer conv7_1_bn_scale
I0831 12:58:57.114845 24386 net.cpp:434] conv7_1_bn_scale <- conv7_1_bn
I0831 12:58:57.114850 24386 net.cpp:395] conv7_1_bn_scale -> conv7_1_bn (in-place)
I0831 12:58:57.114897 24386 layer_factory.hpp:77] Creating layer conv7_1_bn_scale
I0831 12:58:57.115008 24386 net.cpp:150] Setting up conv7_1_bn_scale
I0831 12:58:57.115017 24386 net.cpp:157] Top shape: 64 128 13 13 (1384448)
I0831 12:58:57.115021 24386 net.cpp:165] Memory required for data: 860729344
I0831 12:58:57.115030 24386 layer_factory.hpp:77] Creating layer conv7_1_relu
I0831 12:58:57.115038 24386 net.cpp:100] Creating Layer conv7_1_relu
I0831 12:58:57.115042 24386 net.cpp:434] conv7_1_relu <- conv7_1_bn
I0831 12:58:57.115051 24386 net.cpp:395] conv7_1_relu -> conv7_1_bn (in-place)
I0831 12:58:57.115057 24386 net.cpp:150] Setting up conv7_1_relu
I0831 12:58:57.115063 24386 net.cpp:157] Top shape: 64 128 13 13 (1384448)
I0831 12:58:57.115068 24386 net.cpp:165] Memory required for data: 866267136
I0831 12:58:57.115072 24386 layer_factory.hpp:77] Creating layer score
I0831 12:58:57.115083 24386 net.cpp:100] Creating Layer score
I0831 12:58:57.115088 24386 net.cpp:434] score <- conv7_1_bn
I0831 12:58:57.115104 24386 net.cpp:408] score -> score
I0831 12:58:57.115365 24386 net.cpp:150] Setting up score
I0831 12:58:57.115375 24386 net.cpp:157] Top shape: 64 4 13 13 (43264)
I0831 12:58:57.115380 24386 net.cpp:165] Memory required for data: 866440192
I0831 12:58:57.115387 24386 layer_factory.hpp:77] Creating layer upscore
I0831 12:58:57.115401 24386 net.cpp:100] Creating Layer upscore
I0831 12:58:57.115406 24386 net.cpp:434] upscore <- score
I0831 12:58:57.115414 24386 net.cpp:408] upscore -> upscore
I0831 12:58:57.116019 24386 net.cpp:150] Setting up upscore
I0831 12:58:57.116036 24386 net.cpp:157] Top shape: 64 4 224 224 (12845056)
I0831 12:58:57.116041 24386 net.cpp:165] Memory required for data: 917820416
I0831 12:58:57.116049 24386 layer_factory.hpp:77] Creating layer cropscore
I0831 12:58:57.116057 24386 net.cpp:100] Creating Layer cropscore
I0831 12:58:57.116062 24386 net.cpp:434] cropscore <- upscore
I0831 12:58:57.116068 24386 net.cpp:434] cropscore <- image_data_0_split_1
I0831 12:58:57.116075 24386 net.cpp:408] cropscore -> cropscore
I0831 12:58:57.116102 24386 net.cpp:150] Setting up cropscore
I0831 12:58:57.116109 24386 net.cpp:157] Top shape: 64 4 200 200 (10240000)
I0831 12:58:57.116113 24386 net.cpp:165] Memory required for data: 958780416
I0831 12:58:57.116118 24386 layer_factory.hpp:77] Creating layer cropscore_cropscore_0_split
I0831 12:58:57.116125 24386 net.cpp:100] Creating Layer cropscore_cropscore_0_split
I0831 12:58:57.116130 24386 net.cpp:434] cropscore_cropscore_0_split <- cropscore
I0831 12:58:57.116135 24386 net.cpp:408] cropscore_cropscore_0_split -> cropscore_cropscore_0_split_0
I0831 12:58:57.116154 24386 net.cpp:408] cropscore_cropscore_0_split -> cropscore_cropscore_0_split_1
I0831 12:58:57.116201 24386 net.cpp:150] Setting up cropscore_cropscore_0_split
I0831 12:58:57.116210 24386 net.cpp:157] Top shape: 64 4 200 200 (10240000)
I0831 12:58:57.116215 24386 net.cpp:157] Top shape: 64 4 200 200 (10240000)
I0831 12:58:57.116220 24386 net.cpp:165] Memory required for data: 1040700416
I0831 12:58:57.116225 24386 layer_factory.hpp:77] Creating layer loss
I0831 12:58:57.116232 24386 net.cpp:100] Creating Layer loss
I0831 12:58:57.116236 24386 net.cpp:434] loss <- cropscore_cropscore_0_split_0
I0831 12:58:57.116242 24386 net.cpp:434] loss <- label_data_1_split_0
I0831 12:58:57.116248 24386 net.cpp:408] loss -> loss
I0831 12:58:57.116256 24386 layer_factory.hpp:77] Creating layer loss
I0831 12:58:57.140559 24386 net.cpp:150] Setting up loss
I0831 12:58:57.140606 24386 net.cpp:157] Top shape: (1)
I0831 12:58:57.140614 24386 net.cpp:160]     with loss weight 1
I0831 12:58:57.140630 24386 net.cpp:165] Memory required for data: 1040700420
I0831 12:58:57.140640 24386 layer_factory.hpp:77] Creating layer accuracy
I0831 12:58:57.140656 24386 net.cpp:100] Creating Layer accuracy
I0831 12:58:57.140664 24386 net.cpp:434] accuracy <- cropscore_cropscore_0_split_1
I0831 12:58:57.140673 24386 net.cpp:434] accuracy <- label_data_1_split_1
I0831 12:58:57.140681 24386 net.cpp:408] accuracy -> accuracy
I0831 12:58:57.140696 24386 net.cpp:150] Setting up accuracy
I0831 12:58:57.140703 24386 net.cpp:157] Top shape: (1)
I0831 12:58:57.140707 24386 net.cpp:165] Memory required for data: 1040700424
I0831 12:58:57.140712 24386 net.cpp:228] accuracy does not need backward computation.
I0831 12:58:57.140717 24386 net.cpp:226] loss needs backward computation.
I0831 12:58:57.140722 24386 net.cpp:226] cropscore_cropscore_0_split needs backward computation.
I0831 12:58:57.140727 24386 net.cpp:226] cropscore needs backward computation.
I0831 12:58:57.140732 24386 net.cpp:226] upscore needs backward computation.
I0831 12:58:57.140736 24386 net.cpp:226] score needs backward computation.
I0831 12:58:57.140740 24386 net.cpp:226] conv7_1_relu needs backward computation.
I0831 12:58:57.140744 24386 net.cpp:226] conv7_1_bn_scale needs backward computation.
I0831 12:58:57.140748 24386 net.cpp:226] conv7_1_bn needs backward computation.
I0831 12:58:57.140753 24386 net.cpp:226] conv7_1 needs backward computation.
I0831 12:58:57.140758 24386 net.cpp:226] conv6_1_relu needs backward computation.
I0831 12:58:57.140761 24386 net.cpp:226] conv6_1_bn_scale needs backward computation.
I0831 12:58:57.140765 24386 net.cpp:226] conv6_1_bn needs backward computation.
I0831 12:58:57.140770 24386 net.cpp:226] conv6_1 needs backward computation.
I0831 12:58:57.140774 24386 net.cpp:226] conv5_1_relu needs backward computation.
I0831 12:58:57.140779 24386 net.cpp:226] conv5_1_bn_scale needs backward computation.
I0831 12:58:57.140782 24386 net.cpp:226] conv5_1_bn needs backward computation.
I0831 12:58:57.140787 24386 net.cpp:226] conv5_1 needs backward computation.
I0831 12:58:57.140791 24386 net.cpp:226] conv4_1_relu needs backward computation.
I0831 12:58:57.140796 24386 net.cpp:226] conv4_1_bn_scale needs backward computation.
I0831 12:58:57.140800 24386 net.cpp:226] conv4_1_bn needs backward computation.
I0831 12:58:57.140805 24386 net.cpp:226] pool4 needs backward computation.
I0831 12:58:57.140810 24386 net.cpp:226] conv4_1 needs backward computation.
I0831 12:58:57.140813 24386 net.cpp:226] conv3_1_relu needs backward computation.
I0831 12:58:57.140818 24386 net.cpp:226] conv3_1_bn_scale needs backward computation.
I0831 12:58:57.140822 24386 net.cpp:226] conv3_1_bn needs backward computation.
I0831 12:58:57.140826 24386 net.cpp:226] pool3 needs backward computation.
I0831 12:58:57.140831 24386 net.cpp:226] conv3_1 needs backward computation.
I0831 12:58:57.140836 24386 net.cpp:226] conv2_1_relu needs backward computation.
I0831 12:58:57.140839 24386 net.cpp:226] conv2_1_bn_scale needs backward computation.
I0831 12:58:57.140843 24386 net.cpp:226] conv2_1_bn needs backward computation.
I0831 12:58:57.140874 24386 net.cpp:226] pool2 needs backward computation.
I0831 12:58:57.140879 24386 net.cpp:226] conv2_1 needs backward computation.
I0831 12:58:57.140884 24386 net.cpp:226] conv1_1_relu needs backward computation.
I0831 12:58:57.140889 24386 net.cpp:226] conv1_1_bn_scale needs backward computation.
I0831 12:58:57.140893 24386 net.cpp:226] conv1_1_bn needs backward computation.
I0831 12:58:57.140898 24386 net.cpp:226] pool1 needs backward computation.
I0831 12:58:57.140903 24386 net.cpp:226] conv1_1 needs backward computation.
I0831 12:58:57.140908 24386 net.cpp:228] label_data_1_split does not need backward computation.
I0831 12:58:57.140913 24386 net.cpp:228] image_data_0_split does not need backward computation.
I0831 12:58:57.140918 24386 net.cpp:228] data does not need backward computation.
I0831 12:58:57.140921 24386 net.cpp:270] This network produces output accuracy
I0831 12:58:57.140926 24386 net.cpp:270] This network produces output loss
I0831 12:58:57.140954 24386 net.cpp:283] Network initialization done.
I0831 12:58:57.141134 24386 solver.cpp:60] Solver scaffolding done.
I0831 12:58:57.142774 24386 caffe.cpp:251] Starting Optimization
I0831 12:58:57.142796 24386 solver.cpp:279] Solving segmentation
I0831 12:58:57.142802 24386 solver.cpp:280] Learning Rate Policy: step
I0831 12:58:57.144292 24386 solver.cpp:337] Iteration 0, Testing net (#0)
I0831 12:59:02.856966 24386 solver.cpp:454] Snapshotting to binary proto file portrait_wb_one_stage3_iter_0.caffemodel
I0831 12:59:02.860287 24386 sgd_solver.cpp:273] Snapshotting solver state to binary proto file portrait_wb_one_stage3_iter_0.solverstate
I0831 12:59:04.934490 24386 solver.cpp:404]     Test net output #0: accuracy = 0.252131
I0831 12:59:04.934533 24386 solver.cpp:404]     Test net output #1: loss = 2.61265e+06 (* 1 = 2.61265e+06 loss)
I0831 12:59:06.356703 24386 solver.cpp:228] Iteration 0, loss = 55452.6
I0831 12:59:06.356741 24386 solver.cpp:244]     Train net output #0: accuracy = 0.248799
I0831 12:59:06.356751 24386 solver.cpp:244]     Train net output #1: loss = 55452.6 (* 1 = 55452.6 loss)
I0831 12:59:06.356765 24386 sgd_solver.cpp:106] Iteration 0, lr = 1e-05
I0831 13:00:20.918720 24386 solver.cpp:228] Iteration 50, loss = 41133.8
I0831 13:00:20.918797 24386 solver.cpp:244]     Train net output #0: accuracy = 0.517035
I0831 13:00:20.918807 24386 solver.cpp:244]     Train net output #1: loss = 41133.8 (* 1 = 41133.8 loss)
I0831 13:00:20.918814 24386 sgd_solver.cpp:106] Iteration 50, lr = 1e-05
I0831 13:01:35.853162 24386 solver.cpp:228] Iteration 100, loss = 37111.1
I0831 13:01:35.853263 24386 solver.cpp:244]     Train net output #0: accuracy = 0.604416
I0831 13:01:35.853276 24386 solver.cpp:244]     Train net output #1: loss = 37111.1 (* 1 = 37111.1 loss)
I0831 13:01:35.853283 24386 sgd_solver.cpp:106] Iteration 100, lr = 1e-05
I0831 13:02:50.323500 24386 solver.cpp:228] Iteration 150, loss = 35115.5
I0831 13:02:50.323719 24386 solver.cpp:244]     Train net output #0: accuracy = 0.633054
I0831 13:02:50.323739 24386 solver.cpp:244]     Train net output #1: loss = 35115.5 (* 1 = 35115.5 loss)
I0831 13:02:50.323748 24386 sgd_solver.cpp:106] Iteration 150, lr = 1e-05
I0831 13:04:05.454973 24386 solver.cpp:337] Iteration 200, Testing net (#0)
I0831 13:04:12.713119 24386 solver.cpp:404]     Test net output #0: accuracy = 0.307412
I0831 13:04:12.713177 24386 solver.cpp:404]     Test net output #1: loss = 59911.6 (* 1 = 59911.6 loss)
I0831 13:04:14.120882 24386 solver.cpp:228] Iteration 200, loss = 34801.1
I0831 13:04:14.120934 24386 solver.cpp:244]     Train net output #0: accuracy = 0.676478
I0831 13:04:14.120949 24386 solver.cpp:244]     Train net output #1: loss = 34801.1 (* 1 = 34801.1 loss)
I0831 13:04:14.120959 24386 sgd_solver.cpp:106] Iteration 200, lr = 1e-05
I0831 13:05:28.853153 24386 solver.cpp:228] Iteration 250, loss = 38928.2
I0831 13:05:28.853231 24386 solver.cpp:244]     Train net output #0: accuracy = 0.665763
I0831 13:05:28.853242 24386 solver.cpp:244]     Train net output #1: loss = 38928.2 (* 1 = 38928.2 loss)
I0831 13:05:28.853258 24386 sgd_solver.cpp:106] Iteration 250, lr = 1e-05
I0831 13:06:43.432536 24386 solver.cpp:228] Iteration 300, loss = 30630.8
I0831 13:06:43.432679 24386 solver.cpp:244]     Train net output #0: accuracy = 0.665607
I0831 13:06:43.432695 24386 solver.cpp:244]     Train net output #1: loss = 30630.8 (* 1 = 30630.8 loss)
I0831 13:06:43.432704 24386 sgd_solver.cpp:106] Iteration 300, lr = 1e-05
I0831 13:07:57.563896 24386 solver.cpp:228] Iteration 350, loss = 27296
I0831 13:07:57.564000 24386 solver.cpp:244]     Train net output #0: accuracy = 0.755606
I0831 13:07:57.564016 24386 solver.cpp:244]     Train net output #1: loss = 27296 (* 1 = 27296 loss)
I0831 13:07:57.564026 24386 sgd_solver.cpp:106] Iteration 350, lr = 1e-05
I0831 13:09:11.046016 24386 solver.cpp:337] Iteration 400, Testing net (#0)
I0831 13:09:18.392060 24386 solver.cpp:404]     Test net output #0: accuracy = 0.451124
I0831 13:09:18.392122 24386 solver.cpp:404]     Test net output #1: loss = 58112.1 (* 1 = 58112.1 loss)
I0831 13:09:19.735127 24386 solver.cpp:228] Iteration 400, loss = 28174.2
I0831 13:09:19.735167 24386 solver.cpp:244]     Train net output #0: accuracy = 0.75852
I0831 13:09:19.735177 24386 solver.cpp:244]     Train net output #1: loss = 28174.2 (* 1 = 28174.2 loss)
I0831 13:09:19.735184 24386 sgd_solver.cpp:106] Iteration 400, lr = 1e-05
I0831 13:10:34.174394 24386 solver.cpp:228] Iteration 450, loss = 28583.2
I0831 13:10:34.174480 24386 solver.cpp:244]     Train net output #0: accuracy = 0.649928
I0831 13:10:34.174491 24386 solver.cpp:244]     Train net output #1: loss = 28583.2 (* 1 = 28583.2 loss)
I0831 13:10:34.174499 24386 sgd_solver.cpp:106] Iteration 450, lr = 1e-05
I0831 13:11:49.945315 24386 solver.cpp:228] Iteration 500, loss = 39922.4
I0831 13:11:49.945422 24386 solver.cpp:244]     Train net output #0: accuracy = 0.602129
I0831 13:11:49.945435 24386 solver.cpp:244]     Train net output #1: loss = 39922.4 (* 1 = 39922.4 loss)
I0831 13:11:49.945442 24386 sgd_solver.cpp:106] Iteration 500, lr = 1e-05
I0831 13:13:32.649178 24386 solver.cpp:228] Iteration 550, loss = 32530.8
I0831 13:13:32.649274 24386 solver.cpp:244]     Train net output #0: accuracy = 0.631446
I0831 13:13:32.649288 24386 solver.cpp:244]     Train net output #1: loss = 32530.8 (* 1 = 32530.8 loss)
I0831 13:13:32.649296 24386 sgd_solver.cpp:106] Iteration 550, lr = 1e-05
I0831 13:15:24.892658 24386 solver.cpp:337] Iteration 600, Testing net (#0)
I0831 13:15:34.476490 24386 solver.cpp:404]     Test net output #0: accuracy = 0.44894
I0831 13:15:34.476543 24386 solver.cpp:404]     Test net output #1: loss = 84749 (* 1 = 84749 loss)
I0831 13:15:36.333781 24386 solver.cpp:228] Iteration 600, loss = 19434.3
I0831 13:15:36.333823 24386 solver.cpp:244]     Train net output #0: accuracy = 0.839659
I0831 13:15:36.333833 24386 solver.cpp:244]     Train net output #1: loss = 19434.3 (* 1 = 19434.3 loss)
I0831 13:15:36.333840 24386 sgd_solver.cpp:106] Iteration 600, lr = 1e-05
I0831 13:17:26.792554 24386 solver.cpp:228] Iteration 650, loss = 30327.7
I0831 13:17:26.792660 24386 solver.cpp:244]     Train net output #0: accuracy = 0.698184
I0831 13:17:26.792673 24386 solver.cpp:244]     Train net output #1: loss = 30327.7 (* 1 = 30327.7 loss)
I0831 13:17:26.792680 24386 sgd_solver.cpp:106] Iteration 650, lr = 1e-05
I0831 13:19:18.781167 24386 solver.cpp:228] Iteration 700, loss = 25837
I0831 13:19:18.781261 24386 solver.cpp:244]     Train net output #0: accuracy = 0.739455
I0831 13:19:18.781275 24386 solver.cpp:244]     Train net output #1: loss = 25837 (* 1 = 25837 loss)
I0831 13:19:18.781281 24386 sgd_solver.cpp:106] Iteration 700, lr = 1e-05
I0831 13:21:08.297838 24386 solver.cpp:228] Iteration 750, loss = 32920.8
I0831 13:21:08.297926 24386 solver.cpp:244]     Train net output #0: accuracy = 0.733345
I0831 13:21:08.297938 24386 solver.cpp:244]     Train net output #1: loss = 32920.8 (* 1 = 32920.8 loss)
I0831 13:21:08.297945 24386 sgd_solver.cpp:106] Iteration 750, lr = 1e-05
I0831 13:22:54.529081 24386 solver.cpp:337] Iteration 800, Testing net (#0)
I0831 13:23:03.924167 24386 solver.cpp:404]     Test net output #0: accuracy = 0.504855
I0831 13:23:03.924209 24386 solver.cpp:404]     Test net output #1: loss = 90234.8 (* 1 = 90234.8 loss)
I0831 13:23:05.660212 24386 solver.cpp:228] Iteration 800, loss = 69581.6
I0831 13:23:05.660256 24386 solver.cpp:244]     Train net output #0: accuracy = 0.454974
I0831 13:23:05.660269 24386 solver.cpp:244]     Train net output #1: loss = 69581.6 (* 1 = 69581.6 loss)
I0831 13:23:05.660277 24386 sgd_solver.cpp:106] Iteration 800, lr = 1e-05
I0831 13:24:54.931944 24386 solver.cpp:228] Iteration 850, loss = 28629.8
I0831 13:24:54.932054 24386 solver.cpp:244]     Train net output #0: accuracy = 0.70421
I0831 13:24:54.932067 24386 solver.cpp:244]     Train net output #1: loss = 28629.8 (* 1 = 28629.8 loss)
I0831 13:24:54.932075 24386 sgd_solver.cpp:106] Iteration 850, lr = 1e-05
I0831 13:26:46.733495 24386 solver.cpp:228] Iteration 900, loss = 24335.8
I0831 13:26:46.733563 24386 solver.cpp:244]     Train net output #0: accuracy = 0.776796
I0831 13:26:46.733574 24386 solver.cpp:244]     Train net output #1: loss = 24335.8 (* 1 = 24335.8 loss)
I0831 13:26:46.733582 24386 sgd_solver.cpp:106] Iteration 900, lr = 1e-05
I0831 13:28:39.960809 24386 solver.cpp:228] Iteration 950, loss = 18135.4
I0831 13:28:39.960888 24386 solver.cpp:244]     Train net output #0: accuracy = 0.847083
I0831 13:28:39.960901 24386 solver.cpp:244]     Train net output #1: loss = 18135.4 (* 1 = 18135.4 loss)
I0831 13:28:39.960908 24386 sgd_solver.cpp:106] Iteration 950, lr = 1e-05
I0831 13:30:30.477977 24386 solver.cpp:337] Iteration 1000, Testing net (#0)
I0831 13:30:39.707180 24386 solver.cpp:404]     Test net output #0: accuracy = 0.66051
I0831 13:30:39.707221 24386 solver.cpp:404]     Test net output #1: loss = 35676.5 (* 1 = 35676.5 loss)
I0831 13:30:41.626325 24386 solver.cpp:228] Iteration 1000, loss = 26088.3
I0831 13:30:41.626364 24386 solver.cpp:244]     Train net output #0: accuracy = 0.72988
I0831 13:30:41.626379 24386 solver.cpp:244]     Train net output #1: loss = 26088.3 (* 1 = 26088.3 loss)
I0831 13:30:41.626385 24386 sgd_solver.cpp:106] Iteration 1000, lr = 1e-05
I0831 13:32:33.525202 24386 solver.cpp:228] Iteration 1050, loss = 25966.4
I0831 13:32:33.525302 24386 solver.cpp:244]     Train net output #0: accuracy = 0.694393
I0831 13:32:33.525321 24386 solver.cpp:244]     Train net output #1: loss = 25966.4 (* 1 = 25966.4 loss)
I0831 13:32:33.525332 24386 sgd_solver.cpp:106] Iteration 1050, lr = 1e-05
I0831 13:34:24.688498 24386 solver.cpp:228] Iteration 1100, loss = 32210
I0831 13:34:24.688599 24386 solver.cpp:244]     Train net output #0: accuracy = 0.66826
I0831 13:34:24.688621 24386 solver.cpp:244]     Train net output #1: loss = 32210 (* 1 = 32210 loss)
I0831 13:34:24.688632 24386 sgd_solver.cpp:106] Iteration 1100, lr = 1e-05
I0831 13:36:17.866698 24386 solver.cpp:228] Iteration 1150, loss = 17772.5
I0831 13:36:17.866775 24386 solver.cpp:244]     Train net output #0: accuracy = 0.824113
I0831 13:36:17.866787 24386 solver.cpp:244]     Train net output #1: loss = 17772.5 (* 1 = 17772.5 loss)
I0831 13:36:17.866794 24386 sgd_solver.cpp:106] Iteration 1150, lr = 1e-05
I0831 13:38:05.037725 24386 solver.cpp:337] Iteration 1200, Testing net (#0)
I0831 13:38:13.662567 24386 solver.cpp:404]     Test net output #0: accuracy = 0.687637
I0831 13:38:13.662617 24386 solver.cpp:404]     Test net output #1: loss = 37498.9 (* 1 = 37498.9 loss)
I0831 13:38:15.317646 24386 solver.cpp:228] Iteration 1200, loss = 20341.5
I0831 13:38:15.317698 24386 solver.cpp:244]     Train net output #0: accuracy = 0.820965
I0831 13:38:15.317711 24386 solver.cpp:244]     Train net output #1: loss = 20341.5 (* 1 = 20341.5 loss)
I0831 13:38:15.317721 24386 sgd_solver.cpp:106] Iteration 1200, lr = 1e-05
I0831 13:40:06.317963 24386 solver.cpp:228] Iteration 1250, loss = 20880.2
I0831 13:40:06.318091 24386 solver.cpp:244]     Train net output #0: accuracy = 0.796342
I0831 13:40:06.318114 24386 solver.cpp:244]     Train net output #1: loss = 20880.2 (* 1 = 20880.2 loss)
I0831 13:40:06.318135 24386 sgd_solver.cpp:106] Iteration 1250, lr = 1e-05
I0831 13:41:55.958926 24386 solver.cpp:228] Iteration 1300, loss = 21341.3
I0831 13:41:55.959038 24386 solver.cpp:244]     Train net output #0: accuracy = 0.803867
I0831 13:41:55.959049 24386 solver.cpp:244]     Train net output #1: loss = 21341.3 (* 1 = 21341.3 loss)
I0831 13:41:55.959056 24386 sgd_solver.cpp:106] Iteration 1300, lr = 1e-05
I0831 13:43:48.606431 24386 solver.cpp:228] Iteration 1350, loss = 16702.4
I0831 13:43:48.606515 24386 solver.cpp:244]     Train net output #0: accuracy = 0.812415
I0831 13:43:48.606528 24386 solver.cpp:244]     Train net output #1: loss = 16702.4 (* 1 = 16702.4 loss)
I0831 13:43:48.606534 24386 sgd_solver.cpp:106] Iteration 1350, lr = 1e-05
I0831 13:45:33.951295 24386 solver.cpp:337] Iteration 1400, Testing net (#0)
I0831 13:45:41.630322 24386 solver.cpp:404]     Test net output #0: accuracy = 0.579476
I0831 13:45:41.630388 24386 solver.cpp:404]     Test net output #1: loss = 56305.7 (* 1 = 56305.7 loss)
I0831 13:45:43.373013 24386 solver.cpp:228] Iteration 1400, loss = 14612.5
I0831 13:45:43.373054 24386 solver.cpp:244]     Train net output #0: accuracy = 0.861594
I0831 13:45:43.373065 24386 solver.cpp:244]     Train net output #1: loss = 14612.5 (* 1 = 14612.5 loss)
I0831 13:45:43.373072 24386 sgd_solver.cpp:106] Iteration 1400, lr = 1e-05
I0831 13:47:35.537021 24386 solver.cpp:228] Iteration 1450, loss = 21447.1
I0831 13:47:35.537101 24386 solver.cpp:244]     Train net output #0: accuracy = 0.790707
I0831 13:47:35.537111 24386 solver.cpp:244]     Train net output #1: loss = 21447.1 (* 1 = 21447.1 loss)
I0831 13:47:35.537119 24386 sgd_solver.cpp:106] Iteration 1450, lr = 1e-05
I0831 13:49:27.247283 24386 solver.cpp:228] Iteration 1500, loss = 19582
I0831 13:49:27.247372 24386 solver.cpp:244]     Train net output #0: accuracy = 0.799977
I0831 13:49:27.247385 24386 solver.cpp:244]     Train net output #1: loss = 19582 (* 1 = 19582 loss)
I0831 13:49:27.247391 24386 sgd_solver.cpp:106] Iteration 1500, lr = 1e-05
I0831 13:51:19.248152 24386 solver.cpp:228] Iteration 1550, loss = 23723.8
I0831 13:51:19.248245 24386 solver.cpp:244]     Train net output #0: accuracy = 0.765421
I0831 13:51:19.248260 24386 solver.cpp:244]     Train net output #1: loss = 23723.8 (* 1 = 23723.8 loss)
I0831 13:51:19.248266 24386 sgd_solver.cpp:106] Iteration 1550, lr = 1e-05
I0831 13:53:08.567292 24386 solver.cpp:337] Iteration 1600, Testing net (#0)
I0831 13:53:18.192337 24386 solver.cpp:404]     Test net output #0: accuracy = 0.591639
I0831 13:53:18.192386 24386 solver.cpp:404]     Test net output #1: loss = 61614.8 (* 1 = 61614.8 loss)
I0831 13:53:20.267264 24386 solver.cpp:228] Iteration 1600, loss = 25577.5
I0831 13:53:20.267307 24386 solver.cpp:244]     Train net output #0: accuracy = 0.743446
I0831 13:53:20.267318 24386 solver.cpp:244]     Train net output #1: loss = 25577.5 (* 1 = 25577.5 loss)
I0831 13:53:20.267325 24386 sgd_solver.cpp:106] Iteration 1600, lr = 1e-05
I0831 13:55:12.879549 24386 solver.cpp:228] Iteration 1650, loss = 20806.2
I0831 13:55:12.879657 24386 solver.cpp:244]     Train net output #0: accuracy = 0.794764
I0831 13:55:12.879678 24386 solver.cpp:244]     Train net output #1: loss = 20806.2 (* 1 = 20806.2 loss)
I0831 13:55:12.879688 24386 sgd_solver.cpp:106] Iteration 1650, lr = 1e-05
I0831 13:57:04.148181 24386 solver.cpp:228] Iteration 1700, loss = 16815.5
I0831 13:57:04.148262 24386 solver.cpp:244]     Train net output #0: accuracy = 0.839982
I0831 13:57:04.148273 24386 solver.cpp:244]     Train net output #1: loss = 16815.5 (* 1 = 16815.5 loss)
I0831 13:57:04.148280 24386 sgd_solver.cpp:106] Iteration 1700, lr = 1e-05
I0831 13:58:55.523994 24386 solver.cpp:228] Iteration 1750, loss = 12959.9
I0831 13:58:55.524070 24386 solver.cpp:244]     Train net output #0: accuracy = 0.877711
I0831 13:58:55.524081 24386 solver.cpp:244]     Train net output #1: loss = 12959.9 (* 1 = 12959.9 loss)
I0831 13:58:55.524090 24386 sgd_solver.cpp:106] Iteration 1750, lr = 1e-05
I0831 14:00:47.700067 24386 solver.cpp:337] Iteration 1800, Testing net (#0)
I0831 14:00:56.744279 24386 solver.cpp:404]     Test net output #0: accuracy = 0.74596
I0831 14:00:56.744325 24386 solver.cpp:404]     Test net output #1: loss = 26401.6 (* 1 = 26401.6 loss)
I0831 14:00:58.600430 24386 solver.cpp:228] Iteration 1800, loss = 13242.6
I0831 14:00:58.600468 24386 solver.cpp:244]     Train net output #0: accuracy = 0.882857
I0831 14:00:58.600478 24386 solver.cpp:244]     Train net output #1: loss = 13242.6 (* 1 = 13242.6 loss)
I0831 14:00:58.600486 24386 sgd_solver.cpp:106] Iteration 1800, lr = 1e-05
I0831 14:02:50.077860 24386 solver.cpp:228] Iteration 1850, loss = 19770
I0831 14:02:50.077963 24386 solver.cpp:244]     Train net output #0: accuracy = 0.809132
I0831 14:02:50.077977 24386 solver.cpp:244]     Train net output #1: loss = 19770 (* 1 = 19770 loss)
I0831 14:02:50.077986 24386 sgd_solver.cpp:106] Iteration 1850, lr = 1e-05
I0831 14:04:42.394134 24386 solver.cpp:228] Iteration 1900, loss = 14996.9
I0831 14:04:42.394237 24386 solver.cpp:244]     Train net output #0: accuracy = 0.842489
I0831 14:04:42.394253 24386 solver.cpp:244]     Train net output #1: loss = 14996.9 (* 1 = 14996.9 loss)
I0831 14:04:42.394263 24386 sgd_solver.cpp:106] Iteration 1900, lr = 1e-05
I0831 14:06:36.851788 24386 solver.cpp:228] Iteration 1950, loss = 12273
I0831 14:06:36.851871 24386 solver.cpp:244]     Train net output #0: accuracy = 0.886607
I0831 14:06:36.851882 24386 solver.cpp:244]     Train net output #1: loss = 12273 (* 1 = 12273 loss)
I0831 14:06:36.851891 24386 sgd_solver.cpp:106] Iteration 1950, lr = 1e-05
I0831 14:08:26.198691 24386 solver.cpp:337] Iteration 2000, Testing net (#0)
I0831 14:08:35.238003 24386 solver.cpp:404]     Test net output #0: accuracy = 0.753433
I0831 14:08:35.238061 24386 solver.cpp:404]     Test net output #1: loss = 25233.9 (* 1 = 25233.9 loss)
I0831 14:08:37.239619 24386 solver.cpp:228] Iteration 2000, loss = 14144.8
I0831 14:08:37.239656 24386 solver.cpp:244]     Train net output #0: accuracy = 0.868574
I0831 14:08:37.239665 24386 solver.cpp:244]     Train net output #1: loss = 14144.8 (* 1 = 14144.8 loss)
I0831 14:08:37.239672 24386 sgd_solver.cpp:106] Iteration 2000, lr = 1e-05
I0831 14:10:28.924407 24386 solver.cpp:228] Iteration 2050, loss = 14753.5
I0831 14:10:28.924515 24386 solver.cpp:244]     Train net output #0: accuracy = 0.854851
I0831 14:10:28.924528 24386 solver.cpp:244]     Train net output #1: loss = 14753.5 (* 1 = 14753.5 loss)
I0831 14:10:28.924536 24386 sgd_solver.cpp:106] Iteration 2050, lr = 1e-05
I0831 14:12:20.713562 24386 solver.cpp:228] Iteration 2100, loss = 13817.6
I0831 14:12:20.713644 24386 solver.cpp:244]     Train net output #0: accuracy = 0.863297
I0831 14:12:20.713656 24386 solver.cpp:244]     Train net output #1: loss = 13817.6 (* 1 = 13817.6 loss)
I0831 14:12:20.713663 24386 sgd_solver.cpp:106] Iteration 2100, lr = 1e-05
I0831 14:14:12.978118 24386 solver.cpp:228] Iteration 2150, loss = 15951.4
I0831 14:14:12.978200 24386 solver.cpp:244]     Train net output #0: accuracy = 0.839826
I0831 14:14:12.978211 24386 solver.cpp:244]     Train net output #1: loss = 15951.4 (* 1 = 15951.4 loss)
I0831 14:14:12.978219 24386 sgd_solver.cpp:106] Iteration 2150, lr = 1e-05
I0831 14:16:03.164074 24386 solver.cpp:337] Iteration 2200, Testing net (#0)
I0831 14:16:12.854060 24386 solver.cpp:404]     Test net output #0: accuracy = 0.714267
I0831 14:16:12.854105 24386 solver.cpp:404]     Test net output #1: loss = 28262.2 (* 1 = 28262.2 loss)
I0831 14:16:14.712913 24386 solver.cpp:228] Iteration 2200, loss = 20840.7
I0831 14:16:14.712949 24386 solver.cpp:244]     Train net output #0: accuracy = 0.80481
I0831 14:16:14.712960 24386 solver.cpp:244]     Train net output #1: loss = 20840.7 (* 1 = 20840.7 loss)
I0831 14:16:14.712965 24386 sgd_solver.cpp:106] Iteration 2200, lr = 1e-05
I0831 14:18:05.088979 24386 solver.cpp:228] Iteration 2250, loss = 15578.3
I0831 14:18:05.089072 24386 solver.cpp:244]     Train net output #0: accuracy = 0.852131
I0831 14:18:05.089084 24386 solver.cpp:244]     Train net output #1: loss = 15578.3 (* 1 = 15578.3 loss)
I0831 14:18:05.089099 24386 sgd_solver.cpp:106] Iteration 2250, lr = 1e-05
I0831 14:20:00.370849 24386 solver.cpp:228] Iteration 2300, loss = 10781.3
I0831 14:20:00.370990 24386 solver.cpp:244]     Train net output #0: accuracy = 0.895491
I0831 14:20:00.371006 24386 solver.cpp:244]     Train net output #1: loss = 10781.3 (* 1 = 10781.3 loss)
I0831 14:20:00.371016 24386 sgd_solver.cpp:106] Iteration 2300, lr = 1e-05
I0831 14:21:52.969724 24386 solver.cpp:228] Iteration 2350, loss = 12582.5
I0831 14:21:52.969825 24386 solver.cpp:244]     Train net output #0: accuracy = 0.881839
I0831 14:21:52.969837 24386 solver.cpp:244]     Train net output #1: loss = 12582.5 (* 1 = 12582.5 loss)
I0831 14:21:52.969844 24386 sgd_solver.cpp:106] Iteration 2350, lr = 1e-05
I0831 14:23:42.733413 24386 solver.cpp:337] Iteration 2400, Testing net (#0)
I0831 14:23:51.833467 24386 solver.cpp:404]     Test net output #0: accuracy = 0.723449
I0831 14:23:51.833509 24386 solver.cpp:404]     Test net output #1: loss = 28219.6 (* 1 = 28219.6 loss)
I0831 14:23:53.663105 24386 solver.cpp:228] Iteration 2400, loss = 8628.97
I0831 14:23:53.663148 24386 solver.cpp:244]     Train net output #0: accuracy = 0.916431
I0831 14:23:53.664603 24386 solver.cpp:244]     Train net output #1: loss = 8628.97 (* 1 = 8628.97 loss)
I0831 14:23:53.664621 24386 sgd_solver.cpp:106] Iteration 2400, lr = 1e-05
I0831 14:25:47.147083 24386 solver.cpp:228] Iteration 2450, loss = 13671.1
I0831 14:25:47.147171 24386 solver.cpp:244]     Train net output #0: accuracy = 0.862442
I0831 14:25:47.147184 24386 solver.cpp:244]     Train net output #1: loss = 13671.1 (* 1 = 13671.1 loss)
I0831 14:25:47.147192 24386 sgd_solver.cpp:106] Iteration 2450, lr = 1e-05
I0831 14:27:37.656258 24386 solver.cpp:228] Iteration 2500, loss = 10165.1
I0831 14:27:37.656369 24386 solver.cpp:244]     Train net output #0: accuracy = 0.905234
I0831 14:27:37.656388 24386 solver.cpp:244]     Train net output #1: loss = 10165.1 (* 1 = 10165.1 loss)
I0831 14:27:37.656397 24386 sgd_solver.cpp:106] Iteration 2500, lr = 1e-05
I0831 14:29:32.122974 24386 solver.cpp:228] Iteration 2550, loss = 9459.69
I0831 14:29:32.123059 24386 solver.cpp:244]     Train net output #0: accuracy = 0.908905
I0831 14:29:32.123071 24386 solver.cpp:244]     Train net output #1: loss = 9459.69 (* 1 = 9459.69 loss)
I0831 14:29:32.123078 24386 sgd_solver.cpp:106] Iteration 2550, lr = 1e-05
I0831 14:31:21.896150 24386 solver.cpp:337] Iteration 2600, Testing net (#0)
I0831 14:31:31.454768 24386 solver.cpp:404]     Test net output #0: accuracy = 0.797343
I0831 14:31:31.454826 24386 solver.cpp:404]     Test net output #1: loss = 20777.1 (* 1 = 20777.1 loss)
I0831 14:31:33.524255 24386 solver.cpp:228] Iteration 2600, loss = 9349.92
I0831 14:31:33.524297 24386 solver.cpp:244]     Train net output #0: accuracy = 0.914399
I0831 14:31:33.524307 24386 solver.cpp:244]     Train net output #1: loss = 9349.92 (* 1 = 9349.92 loss)
I0831 14:31:33.524315 24386 sgd_solver.cpp:106] Iteration 2600, lr = 1e-05
I0831 14:33:23.902427 24386 solver.cpp:228] Iteration 2650, loss = 12763.5
I0831 14:33:23.902530 24386 solver.cpp:244]     Train net output #0: accuracy = 0.873714
I0831 14:33:23.902545 24386 solver.cpp:244]     Train net output #1: loss = 12763.5 (* 1 = 12763.5 loss)
I0831 14:33:23.902555 24386 sgd_solver.cpp:106] Iteration 2650, lr = 1e-05
I0831 14:35:17.263851 24386 solver.cpp:228] Iteration 2700, loss = 1745.18
I0831 14:35:17.263934 24386 solver.cpp:244]     Train net output #0: accuracy = 0.995412
I0831 14:35:17.263947 24386 solver.cpp:244]     Train net output #1: loss = 1745.18 (* 1 = 1745.18 loss)
I0831 14:35:17.263953 24386 sgd_solver.cpp:106] Iteration 2700, lr = 1e-05
I0831 14:37:10.248464 24386 solver.cpp:228] Iteration 2750, loss = 7975.45
I0831 14:37:10.248555 24386 solver.cpp:244]     Train net output #0: accuracy = 0.924447
I0831 14:37:10.248567 24386 solver.cpp:244]     Train net output #1: loss = 7975.45 (* 1 = 7975.45 loss)
I0831 14:37:10.248574 24386 sgd_solver.cpp:106] Iteration 2750, lr = 1e-05
I0831 14:38:58.181907 24386 solver.cpp:337] Iteration 2800, Testing net (#0)
I0831 14:39:07.443265 24386 solver.cpp:404]     Test net output #0: accuracy = 0.801576
I0831 14:39:07.443312 24386 solver.cpp:404]     Test net output #1: loss = 19585.9 (* 1 = 19585.9 loss)
I0831 14:39:09.428772 24386 solver.cpp:228] Iteration 2800, loss = 14305.2
I0831 14:39:09.428828 24386 solver.cpp:244]     Train net output #0: accuracy = 0.860021
I0831 14:39:09.428841 24386 solver.cpp:244]     Train net output #1: loss = 14305.2 (* 1 = 14305.2 loss)
I0831 14:39:09.428848 24386 sgd_solver.cpp:106] Iteration 2800, lr = 1e-05
I0831 14:40:59.668851 24386 solver.cpp:228] Iteration 2850, loss = 10774.7
I0831 14:40:59.668956 24386 solver.cpp:244]     Train net output #0: accuracy = 0.89657
I0831 14:40:59.668969 24386 solver.cpp:244]     Train net output #1: loss = 10774.7 (* 1 = 10774.7 loss)
I0831 14:40:59.668977 24386 sgd_solver.cpp:106] Iteration 2850, lr = 1e-05
I0831 14:42:51.658416 24386 solver.cpp:228] Iteration 2900, loss = 11221.7
I0831 14:42:51.658493 24386 solver.cpp:244]     Train net output #0: accuracy = 0.888071
I0831 14:42:51.658504 24386 solver.cpp:244]     Train net output #1: loss = 11221.7 (* 1 = 11221.7 loss)
I0831 14:42:51.658511 24386 sgd_solver.cpp:106] Iteration 2900, lr = 1e-05
I0831 14:44:44.320188 24386 solver.cpp:228] Iteration 2950, loss = 9767.62
I0831 14:44:44.320293 24386 solver.cpp:244]     Train net output #0: accuracy = 0.906407
I0831 14:44:44.320309 24386 solver.cpp:244]     Train net output #1: loss = 9767.62 (* 1 = 9767.62 loss)
I0831 14:44:44.320318 24386 sgd_solver.cpp:106] Iteration 2950, lr = 1e-05
I0831 14:46:35.206512 24386 solver.cpp:337] Iteration 3000, Testing net (#0)
I0831 14:46:44.468137 24386 solver.cpp:404]     Test net output #0: accuracy = 0.777131
I0831 14:46:44.468183 24386 solver.cpp:404]     Test net output #1: loss = 22545.6 (* 1 = 22545.6 loss)
I0831 14:46:46.530637 24386 solver.cpp:228] Iteration 3000, loss = 13933.6
I0831 14:46:46.530683 24386 solver.cpp:244]     Train net output #0: accuracy = 0.862141
I0831 14:46:46.530694 24386 solver.cpp:244]     Train net output #1: loss = 13933.6 (* 1 = 13933.6 loss)
I0831 14:46:46.530701 24386 sgd_solver.cpp:106] Iteration 3000, lr = 1e-05
I0831 14:48:35.896136 24386 solver.cpp:228] Iteration 3050, loss = 13761.8
I0831 14:48:35.896217 24386 solver.cpp:244]     Train net output #0: accuracy = 0.869252
I0831 14:48:35.896230 24386 solver.cpp:244]     Train net output #1: loss = 13761.8 (* 1 = 13761.8 loss)
I0831 14:48:35.896237 24386 sgd_solver.cpp:106] Iteration 3050, lr = 1e-05
I0831 14:50:28.946085 24386 solver.cpp:228] Iteration 3100, loss = 9116.67
I0831 14:50:28.946195 24386 solver.cpp:244]     Train net output #0: accuracy = 0.915132
I0831 14:50:28.946215 24386 solver.cpp:244]     Train net output #1: loss = 9116.67 (* 1 = 9116.67 loss)
I0831 14:50:28.946226 24386 sgd_solver.cpp:106] Iteration 3100, lr = 1e-05
I0831 14:52:21.320248 24386 solver.cpp:228] Iteration 3150, loss = 7192.77
I0831 14:52:21.320336 24386 solver.cpp:244]     Train net output #0: accuracy = 0.931892
I0831 14:52:21.320349 24386 solver.cpp:244]     Train net output #1: loss = 7192.77 (* 1 = 7192.77 loss)
I0831 14:52:21.320356 24386 sgd_solver.cpp:106] Iteration 3150, lr = 1e-05
I0831 14:54:12.668539 24386 solver.cpp:337] Iteration 3200, Testing net (#0)
I0831 14:54:21.665544 24386 solver.cpp:404]     Test net output #0: accuracy = 0.717995
I0831 14:54:21.665588 24386 solver.cpp:404]     Test net output #1: loss = 29479.9 (* 1 = 29479.9 loss)
I0831 14:54:23.633152 24386 solver.cpp:228] Iteration 3200, loss = 6128.47
I0831 14:54:23.633208 24386 solver.cpp:244]     Train net output #0: accuracy = 0.940227
I0831 14:54:23.633219 24386 solver.cpp:244]     Train net output #1: loss = 6128.47 (* 1 = 6128.47 loss)
I0831 14:54:23.633226 24386 sgd_solver.cpp:106] Iteration 3200, lr = 1e-05
I0831 14:56:12.226056 24386 solver.cpp:228] Iteration 3250, loss = 12761.3
I0831 14:56:12.226163 24386 solver.cpp:244]     Train net output #0: accuracy = 0.87509
I0831 14:56:12.226176 24386 solver.cpp:244]     Train net output #1: loss = 12761.3 (* 1 = 12761.3 loss)
I0831 14:56:12.226186 24386 sgd_solver.cpp:106] Iteration 3250, lr = 1e-05
I0831 14:58:04.038681 24386 solver.cpp:228] Iteration 3300, loss = 6804.46
I0831 14:58:04.038772 24386 solver.cpp:244]     Train net output #0: accuracy = 0.933714
I0831 14:58:04.038785 24386 solver.cpp:244]     Train net output #1: loss = 6804.46 (* 1 = 6804.46 loss)
I0831 14:58:04.038792 24386 sgd_solver.cpp:106] Iteration 3300, lr = 1e-05
I0831 14:59:54.953992 24386 solver.cpp:228] Iteration 3350, loss = 9702.38
I0831 14:59:54.954095 24386 solver.cpp:244]     Train net output #0: accuracy = 0.911199
I0831 14:59:54.954108 24386 solver.cpp:244]     Train net output #1: loss = 9702.38 (* 1 = 9702.38 loss)
I0831 14:59:54.954115 24386 sgd_solver.cpp:106] Iteration 3350, lr = 1e-05
I0831 15:01:45.319800 24386 solver.cpp:337] Iteration 3400, Testing net (#0)
I0831 15:01:54.177865 24386 solver.cpp:404]     Test net output #0: accuracy = 0.758931
I0831 15:01:54.177911 24386 solver.cpp:404]     Test net output #1: loss = 25037.6 (* 1 = 25037.6 loss)
I0831 15:01:56.189280 24386 solver.cpp:228] Iteration 3400, loss = 9412.78
I0831 15:01:56.189316 24386 solver.cpp:244]     Train net output #0: accuracy = 0.908443
I0831 15:01:56.189326 24386 solver.cpp:244]     Train net output #1: loss = 9412.78 (* 1 = 9412.78 loss)
I0831 15:01:56.189332 24386 sgd_solver.cpp:106] Iteration 3400, lr = 1e-05
I0831 15:03:48.034953 24386 solver.cpp:228] Iteration 3450, loss = 10351.1
I0831 15:03:48.035037 24386 solver.cpp:244]     Train net output #0: accuracy = 0.89802
I0831 15:03:48.035048 24386 solver.cpp:244]     Train net output #1: loss = 10351.1 (* 1 = 10351.1 loss)
I0831 15:03:48.035055 24386 sgd_solver.cpp:106] Iteration 3450, lr = 1e-05
I0831 15:05:39.352627 24386 solver.cpp:228] Iteration 3500, loss = 390.774
I0831 15:05:39.352715 24386 solver.cpp:244]     Train net output #0: accuracy = 0.99943
I0831 15:05:39.352727 24386 solver.cpp:244]     Train net output #1: loss = 390.776 (* 1 = 390.776 loss)
I0831 15:05:39.352735 24386 sgd_solver.cpp:106] Iteration 3500, lr = 1e-05
I0831 15:07:31.908449 24386 solver.cpp:228] Iteration 3550, loss = 8594.39
I0831 15:07:31.908545 24386 solver.cpp:244]     Train net output #0: accuracy = 0.917008
I0831 15:07:31.908557 24386 solver.cpp:244]     Train net output #1: loss = 8594.39 (* 1 = 8594.39 loss)
I0831 15:07:31.908565 24386 sgd_solver.cpp:106] Iteration 3550, lr = 1e-05
I0831 15:09:22.780839 24386 solver.cpp:337] Iteration 3600, Testing net (#0)
I0831 15:09:32.122928 24386 solver.cpp:404]     Test net output #0: accuracy = 0.783367
I0831 15:09:32.122974 24386 solver.cpp:404]     Test net output #1: loss = 23568 (* 1 = 23568 loss)
I0831 15:09:34.052067 24386 solver.cpp:228] Iteration 3600, loss = 12769.7
I0831 15:09:34.052121 24386 solver.cpp:244]     Train net output #0: accuracy = 0.876847
I0831 15:09:34.052135 24386 solver.cpp:244]     Train net output #1: loss = 12769.7 (* 1 = 12769.7 loss)
I0831 15:09:34.052145 24386 sgd_solver.cpp:106] Iteration 3600, lr = 1e-05
I0831 15:11:27.155084 24386 solver.cpp:228] Iteration 3650, loss = 8704.92
I0831 15:11:27.155185 24386 solver.cpp:244]     Train net output #0: accuracy = 0.915206
I0831 15:11:27.155200 24386 solver.cpp:244]     Train net output #1: loss = 8704.92 (* 1 = 8704.92 loss)
I0831 15:11:27.155210 24386 sgd_solver.cpp:106] Iteration 3650, lr = 1e-05
I0831 15:13:18.582079 24386 solver.cpp:228] Iteration 3700, loss = 6604.29
I0831 15:13:18.582178 24386 solver.cpp:244]     Train net output #0: accuracy = 0.936017
I0831 15:13:18.582196 24386 solver.cpp:244]     Train net output #1: loss = 6604.29 (* 1 = 6604.29 loss)
I0831 15:13:18.582206 24386 sgd_solver.cpp:106] Iteration 3700, lr = 1e-05
I0831 15:15:11.719274 24386 solver.cpp:228] Iteration 3750, loss = 6901.32
I0831 15:15:11.719382 24386 solver.cpp:244]     Train net output #0: accuracy = 0.933297
I0831 15:15:11.719393 24386 solver.cpp:244]     Train net output #1: loss = 6901.32 (* 1 = 6901.32 loss)
I0831 15:15:11.719401 24386 sgd_solver.cpp:106] Iteration 3750, lr = 1e-05
I0831 15:17:03.754770 24386 solver.cpp:337] Iteration 3800, Testing net (#0)
I0831 15:17:13.303784 24386 solver.cpp:404]     Test net output #0: accuracy = 0.774757
I0831 15:17:13.303830 24386 solver.cpp:404]     Test net output #1: loss = 23072 (* 1 = 23072 loss)
I0831 15:17:15.254107 24386 solver.cpp:228] Iteration 3800, loss = 11139.1
I0831 15:17:15.254148 24386 solver.cpp:244]     Train net output #0: accuracy = 0.89011
I0831 15:17:15.254158 24386 solver.cpp:244]     Train net output #1: loss = 11139.1 (* 1 = 11139.1 loss)
I0831 15:17:15.254164 24386 sgd_solver.cpp:106] Iteration 3800, lr = 1e-05
I0831 15:19:06.461505 24386 solver.cpp:228] Iteration 3850, loss = 10902
I0831 15:19:06.461585 24386 solver.cpp:244]     Train net output #0: accuracy = 0.895056
I0831 15:19:06.461597 24386 solver.cpp:244]     Train net output #1: loss = 10902 (* 1 = 10902 loss)
I0831 15:19:06.461604 24386 sgd_solver.cpp:106] Iteration 3850, lr = 1e-05
I0831 15:20:55.214104 24386 solver.cpp:228] Iteration 3900, loss = 7856.97
I0831 15:20:55.214201 24386 solver.cpp:244]     Train net output #0: accuracy = 0.925268
I0831 15:20:55.214215 24386 solver.cpp:244]     Train net output #1: loss = 7856.97 (* 1 = 7856.97 loss)
I0831 15:20:55.214223 24386 sgd_solver.cpp:106] Iteration 3900, lr = 1e-05
I0831 15:22:48.124377 24386 solver.cpp:228] Iteration 3950, loss = 5759.85
I0831 15:22:48.124465 24386 solver.cpp:244]     Train net output #0: accuracy = 0.945243
I0831 15:22:48.124478 24386 solver.cpp:244]     Train net output #1: loss = 5759.85 (* 1 = 5759.85 loss)
I0831 15:22:48.124485 24386 sgd_solver.cpp:106] Iteration 3950, lr = 1e-05
I0831 15:24:38.859998 24386 solver.cpp:454] Snapshotting to binary proto file portrait_wb_one_stage3_iter_4000.caffemodel
I0831 15:24:38.884820 24386 sgd_solver.cpp:273] Snapshotting solver state to binary proto file portrait_wb_one_stage3_iter_4000.solverstate
I0831 15:24:38.886164 24386 solver.cpp:337] Iteration 4000, Testing net (#0)
I0831 15:24:48.241926 24386 solver.cpp:404]     Test net output #0: accuracy = 0.788832
I0831 15:24:48.241984 24386 solver.cpp:404]     Test net output #1: loss = 21741.8 (* 1 = 21741.8 loss)
I0831 15:24:50.273695 24386 solver.cpp:228] Iteration 4000, loss = 8958.34
I0831 15:24:50.273733 24386 solver.cpp:244]     Train net output #0: accuracy = 0.910442
I0831 15:24:50.273742 24386 solver.cpp:244]     Train net output #1: loss = 8958.34 (* 1 = 8958.34 loss)
I0831 15:24:50.273749 24386 sgd_solver.cpp:106] Iteration 4000, lr = 1e-06
I0831 15:26:40.932552 24386 solver.cpp:228] Iteration 4050, loss = 476.117
I0831 15:26:40.932669 24386 solver.cpp:244]     Train net output #0: accuracy = 0.998262
I0831 15:26:40.932685 24386 solver.cpp:244]     Train net output #1: loss = 476.119 (* 1 = 476.119 loss)
I0831 15:26:40.932696 24386 sgd_solver.cpp:106] Iteration 4050, lr = 1e-06
I0831 15:28:34.594321 24386 solver.cpp:228] Iteration 4100, loss = 6776.27
I0831 15:28:34.594411 24386 solver.cpp:244]     Train net output #0: accuracy = 0.93489
I0831 15:28:34.594424 24386 solver.cpp:244]     Train net output #1: loss = 6776.27 (* 1 = 6776.27 loss)
I0831 15:28:34.594431 24386 sgd_solver.cpp:106] Iteration 4100, lr = 1e-06
I0831 15:30:23.100077 24386 solver.cpp:228] Iteration 4150, loss = 7558.31
I0831 15:30:23.100163 24386 solver.cpp:244]     Train net output #0: accuracy = 0.92393
I0831 15:30:23.100174 24386 solver.cpp:244]     Train net output #1: loss = 7558.31 (* 1 = 7558.31 loss)
I0831 15:30:23.100181 24386 sgd_solver.cpp:106] Iteration 4150, lr = 1e-06
I0831 15:32:11.040381 24386 solver.cpp:337] Iteration 4200, Testing net (#0)
I0831 15:32:20.546829 24386 solver.cpp:404]     Test net output #0: accuracy = 0.83919
I0831 15:32:20.546872 24386 solver.cpp:404]     Test net output #1: loss = 16401.9 (* 1 = 16401.9 loss)
I0831 15:32:22.478214 24386 solver.cpp:228] Iteration 4200, loss = 7847.57
I0831 15:32:22.478257 24386 solver.cpp:244]     Train net output #0: accuracy = 0.923172
I0831 15:32:22.478267 24386 solver.cpp:244]     Train net output #1: loss = 7847.57 (* 1 = 7847.57 loss)
I0831 15:32:22.478288 24386 sgd_solver.cpp:106] Iteration 4200, lr = 1e-06
I0831 15:34:15.238148 24386 solver.cpp:228] Iteration 4250, loss = 8909.38
I0831 15:34:15.238288 24386 solver.cpp:244]     Train net output #0: accuracy = 0.910222
I0831 15:34:15.238301 24386 solver.cpp:244]     Train net output #1: loss = 8909.38 (* 1 = 8909.38 loss)
I0831 15:34:15.238309 24386 sgd_solver.cpp:106] Iteration 4250, lr = 1e-06
I0831 15:36:11.361716 24386 solver.cpp:228] Iteration 4300, loss = 6413.8
I0831 15:36:11.361800 24386 solver.cpp:244]     Train net output #0: accuracy = 0.93891
I0831 15:36:11.361811 24386 solver.cpp:244]     Train net output #1: loss = 6413.8 (* 1 = 6413.8 loss)
I0831 15:36:11.361819 24386 sgd_solver.cpp:106] Iteration 4300, lr = 1e-06
I0831 15:38:05.960762 24386 solver.cpp:228] Iteration 4350, loss = 10565
I0831 15:38:05.960835 24386 solver.cpp:244]     Train net output #0: accuracy = 0.899118
I0831 15:38:05.960847 24386 solver.cpp:244]     Train net output #1: loss = 10565 (* 1 = 10565 loss)
I0831 15:38:05.960855 24386 sgd_solver.cpp:106] Iteration 4350, lr = 1e-06
I0831 15:39:59.027276 24386 solver.cpp:337] Iteration 4400, Testing net (#0)
I0831 15:40:08.438233 24386 solver.cpp:404]     Test net output #0: accuracy = 0.860119
I0831 15:40:08.438279 24386 solver.cpp:404]     Test net output #1: loss = 14289.5 (* 1 = 14289.5 loss)
I0831 15:40:10.341358 24386 solver.cpp:228] Iteration 4400, loss = 10761.2
I0831 15:40:10.341397 24386 solver.cpp:244]     Train net output #0: accuracy = 0.898355
I0831 15:40:10.341406 24386 solver.cpp:244]     Train net output #1: loss = 10761.2 (* 1 = 10761.2 loss)
I0831 15:40:10.341413 24386 sgd_solver.cpp:106] Iteration 4400, lr = 1e-06
I0831 15:42:04.459810 24386 solver.cpp:228] Iteration 4450, loss = 8065.11
I0831 15:42:04.459894 24386 solver.cpp:244]     Train net output #0: accuracy = 0.920713
I0831 15:42:04.459906 24386 solver.cpp:244]     Train net output #1: loss = 8065.12 (* 1 = 8065.12 loss)
I0831 15:42:04.459913 24386 sgd_solver.cpp:106] Iteration 4450, lr = 1e-06
I0831 15:43:56.371132 24386 solver.cpp:228] Iteration 4500, loss = 5720.78
I0831 15:43:56.371220 24386 solver.cpp:244]     Train net output #0: accuracy = 0.944613
I0831 15:43:56.371232 24386 solver.cpp:244]     Train net output #1: loss = 5720.78 (* 1 = 5720.78 loss)
I0831 15:43:56.371239 24386 sgd_solver.cpp:106] Iteration 4500, lr = 1e-06
I0831 15:45:49.289671 24386 solver.cpp:228] Iteration 4550, loss = 5730.95
I0831 15:45:49.289755 24386 solver.cpp:244]     Train net output #0: accuracy = 0.943858
I0831 15:45:49.289767 24386 solver.cpp:244]     Train net output #1: loss = 5730.95 (* 1 = 5730.95 loss)
I0831 15:45:49.289774 24386 sgd_solver.cpp:106] Iteration 4550, lr = 1e-06
I0831 15:47:40.063113 24386 solver.cpp:337] Iteration 4600, Testing net (#0)
I0831 15:47:49.497427 24386 solver.cpp:404]     Test net output #0: accuracy = 0.878957
I0831 15:47:49.497488 24386 solver.cpp:404]     Test net output #1: loss = 12391.9 (* 1 = 12391.9 loss)
I0831 15:47:51.676229 24386 solver.cpp:228] Iteration 4600, loss = 10171.6
I0831 15:47:51.676270 24386 solver.cpp:244]     Train net output #0: accuracy = 0.900554
I0831 15:47:51.676280 24386 solver.cpp:244]     Train net output #1: loss = 10171.6 (* 1 = 10171.6 loss)
I0831 15:47:51.676287 24386 sgd_solver.cpp:106] Iteration 4600, lr = 1e-06
I0831 15:49:45.533323 24386 solver.cpp:228] Iteration 4650, loss = 5962.63
I0831 15:49:45.533435 24386 solver.cpp:244]     Train net output #0: accuracy = 0.943977
I0831 15:49:45.533453 24386 solver.cpp:244]     Train net output #1: loss = 5962.63 (* 1 = 5962.63 loss)
I0831 15:49:45.533464 24386 sgd_solver.cpp:106] Iteration 4650, lr = 1e-06
I0831 15:51:38.764667 24386 solver.cpp:228] Iteration 4700, loss = 6574.13
I0831 15:51:38.764736 24386 solver.cpp:244]     Train net output #0: accuracy = 0.936044
I0831 15:51:38.764747 24386 solver.cpp:244]     Train net output #1: loss = 6574.13 (* 1 = 6574.13 loss)
I0831 15:51:38.764755 24386 sgd_solver.cpp:106] Iteration 4700, lr = 1e-06
I0831 15:53:29.381736 24386 solver.cpp:228] Iteration 4750, loss = 5676.92
I0831 15:53:29.381850 24386 solver.cpp:244]     Train net output #0: accuracy = 0.946793
I0831 15:53:29.381862 24386 solver.cpp:244]     Train net output #1: loss = 5676.92 (* 1 = 5676.92 loss)
I0831 15:53:29.381870 24386 sgd_solver.cpp:106] Iteration 4750, lr = 1e-06
I0831 15:55:21.148524 24386 solver.cpp:337] Iteration 4800, Testing net (#0)
I0831 15:55:32.036933 24386 solver.cpp:404]     Test net output #0: accuracy = 0.88624
I0831 15:55:32.036976 24386 solver.cpp:404]     Test net output #1: loss = 11633.9 (* 1 = 11633.9 loss)
I0831 15:55:33.946633 24386 solver.cpp:228] Iteration 4800, loss = 8759.25
I0831 15:55:33.946672 24386 solver.cpp:244]     Train net output #0: accuracy = 0.912036
I0831 15:55:33.946682 24386 solver.cpp:244]     Train net output #1: loss = 8759.25 (* 1 = 8759.25 loss)
I0831 15:55:33.946689 24386 sgd_solver.cpp:106] Iteration 4800, lr = 1e-06
I0831 15:57:26.194442 24386 solver.cpp:228] Iteration 4850, loss = 639.997
I0831 15:57:26.194519 24386 solver.cpp:244]     Train net output #0: accuracy = 0.997972
I0831 15:57:26.194530 24386 solver.cpp:244]     Train net output #1: loss = 639.999 (* 1 = 639.999 loss)
I0831 15:57:26.194537 24386 sgd_solver.cpp:106] Iteration 4850, lr = 1e-06
I0831 15:59:12.650744 24386 solver.cpp:228] Iteration 4900, loss = 5812.36
I0831 15:59:12.650853 24386 solver.cpp:244]     Train net output #0: accuracy = 0.944765
I0831 15:59:12.650873 24386 solver.cpp:244]     Train net output #1: loss = 5812.36 (* 1 = 5812.36 loss)
I0831 15:59:12.650883 24386 sgd_solver.cpp:106] Iteration 4900, lr = 1e-06
I0831 16:01:04.741693 24386 solver.cpp:228] Iteration 4950, loss = 11216.6
I0831 16:01:04.741813 24386 solver.cpp:244]     Train net output #0: accuracy = 0.892136
I0831 16:01:04.741858 24386 solver.cpp:244]     Train net output #1: loss = 11216.6 (* 1 = 11216.6 loss)
I0831 16:01:04.741879 24386 sgd_solver.cpp:106] Iteration 4950, lr = 1e-06
I0831 16:02:57.600193 24386 solver.cpp:337] Iteration 5000, Testing net (#0)
I0831 16:03:07.211112 24386 solver.cpp:404]     Test net output #0: accuracy = 0.895285
I0831 16:03:07.211163 24386 solver.cpp:404]     Test net output #1: loss = 10756.5 (* 1 = 10756.5 loss)
I0831 16:03:09.238699 24386 solver.cpp:228] Iteration 5000, loss = 8652.18
I0831 16:03:09.238740 24386 solver.cpp:244]     Train net output #0: accuracy = 0.917139
I0831 16:03:09.238749 24386 solver.cpp:244]     Train net output #1: loss = 8652.18 (* 1 = 8652.18 loss)
I0831 16:03:09.238757 24386 sgd_solver.cpp:106] Iteration 5000, lr = 1e-06
I0831 16:05:01.308614 24386 solver.cpp:228] Iteration 5050, loss = 8904.1
I0831 16:05:01.308701 24386 solver.cpp:244]     Train net output #0: accuracy = 0.911358
I0831 16:05:01.308712 24386 solver.cpp:244]     Train net output #1: loss = 8904.1 (* 1 = 8904.1 loss)
I0831 16:05:01.308719 24386 sgd_solver.cpp:106] Iteration 5050, lr = 1e-06
I0831 16:06:54.446669 24386 solver.cpp:228] Iteration 5100, loss = 5871.74
I0831 16:06:54.446766 24386 solver.cpp:244]     Train net output #0: accuracy = 0.945294
I0831 16:06:54.446779 24386 solver.cpp:244]     Train net output #1: loss = 5871.74 (* 1 = 5871.74 loss)
I0831 16:06:54.446787 24386 sgd_solver.cpp:106] Iteration 5100, lr = 1e-06
I0831 16:08:45.310953 24386 solver.cpp:228] Iteration 5150, loss = 11688
I0831 16:08:45.311039 24386 solver.cpp:244]     Train net output #0: accuracy = 0.884283
I0831 16:08:45.311051 24386 solver.cpp:244]     Train net output #1: loss = 11688 (* 1 = 11688 loss)
I0831 16:08:45.311058 24386 sgd_solver.cpp:106] Iteration 5150, lr = 1e-06
I0831 16:10:35.075891 24386 solver.cpp:337] Iteration 5200, Testing net (#0)
I0831 16:10:43.962324 24386 solver.cpp:404]     Test net output #0: accuracy = 0.902175
I0831 16:10:43.962389 24386 solver.cpp:404]     Test net output #1: loss = 10086 (* 1 = 10086 loss)
I0831 16:10:45.762819 24386 solver.cpp:228] Iteration 5200, loss = 11645.5
I0831 16:10:45.762856 24386 solver.cpp:244]     Train net output #0: accuracy = 0.893341
I0831 16:10:45.762866 24386 solver.cpp:244]     Train net output #1: loss = 11645.5 (* 1 = 11645.5 loss)
I0831 16:10:45.762889 24386 sgd_solver.cpp:106] Iteration 5200, lr = 1e-06
I0831 16:12:38.577463 24386 solver.cpp:228] Iteration 5250, loss = 6348.11
I0831 16:12:38.579059 24386 solver.cpp:244]     Train net output #0: accuracy = 0.937584
I0831 16:12:38.579082 24386 solver.cpp:244]     Train net output #1: loss = 6348.11 (* 1 = 6348.11 loss)
I0831 16:12:38.579095 24386 sgd_solver.cpp:106] Iteration 5250, lr = 1e-06
I0831 16:14:33.028373 24386 solver.cpp:228] Iteration 5300, loss = 5511.75
I0831 16:14:33.028468 24386 solver.cpp:244]     Train net output #0: accuracy = 0.94679
I0831 16:14:33.028481 24386 solver.cpp:244]     Train net output #1: loss = 5511.76 (* 1 = 5511.76 loss)
I0831 16:14:33.028486 24386 sgd_solver.cpp:106] Iteration 5300, lr = 1e-06
I0831 16:16:24.668372 24386 solver.cpp:228] Iteration 5350, loss = 5164.18
I0831 16:16:24.668486 24386 solver.cpp:244]     Train net output #0: accuracy = 0.950219
I0831 16:16:24.668500 24386 solver.cpp:244]     Train net output #1: loss = 5164.18 (* 1 = 5164.18 loss)
I0831 16:16:24.668507 24386 sgd_solver.cpp:106] Iteration 5350, lr = 1e-06
I0831 16:18:15.987747 24386 solver.cpp:337] Iteration 5400, Testing net (#0)
I0831 16:18:24.943347 24386 solver.cpp:404]     Test net output #0: accuracy = 0.908119
I0831 16:18:24.943393 24386 solver.cpp:404]     Test net output #1: loss = 9554.65 (* 1 = 9554.65 loss)
I0831 16:18:26.827767 24386 solver.cpp:228] Iteration 5400, loss = 9834.94
I0831 16:18:26.827812 24386 solver.cpp:244]     Train net output #0: accuracy = 0.905701
I0831 16:18:26.827822 24386 solver.cpp:244]     Train net output #1: loss = 9834.94 (* 1 = 9834.94 loss)
I0831 16:18:26.827829 24386 sgd_solver.cpp:106] Iteration 5400, lr = 1e-06
I0831 16:20:19.851861 24386 solver.cpp:228] Iteration 5450, loss = 5354.36
I0831 16:20:19.851960 24386 solver.cpp:244]     Train net output #0: accuracy = 0.94686
I0831 16:20:19.851976 24386 solver.cpp:244]     Train net output #1: loss = 5354.36 (* 1 = 5354.36 loss)
I0831 16:20:19.851985 24386 sgd_solver.cpp:106] Iteration 5450, lr = 1e-06
I0831 16:22:14.080452 24386 solver.cpp:228] Iteration 5500, loss = 7330.24
I0831 16:22:14.080561 24386 solver.cpp:244]     Train net output #0: accuracy = 0.929355
I0831 16:22:14.080576 24386 solver.cpp:244]     Train net output #1: loss = 7330.24 (* 1 = 7330.24 loss)
I0831 16:22:14.080585 24386 sgd_solver.cpp:106] Iteration 5500, lr = 1e-06
I0831 16:24:08.120894 24386 solver.cpp:228] Iteration 5550, loss = 8469.35
I0831 16:24:08.120980 24386 solver.cpp:244]     Train net output #0: accuracy = 0.918483
I0831 16:24:08.120991 24386 solver.cpp:244]     Train net output #1: loss = 8469.35 (* 1 = 8469.35 loss)
I0831 16:24:08.120997 24386 sgd_solver.cpp:106] Iteration 5550, lr = 1e-06
I0831 16:26:01.027336 24386 solver.cpp:337] Iteration 5600, Testing net (#0)
I0831 16:26:12.314913 24386 solver.cpp:404]     Test net output #0: accuracy = 0.910887
I0831 16:26:12.314973 24386 solver.cpp:404]     Test net output #1: loss = 9281.89 (* 1 = 9281.89 loss)
I0831 16:26:14.656469 24386 solver.cpp:228] Iteration 5600, loss = 9342.09
I0831 16:26:14.656522 24386 solver.cpp:244]     Train net output #0: accuracy = 0.90831
I0831 16:26:14.656536 24386 solver.cpp:244]     Train net output #1: loss = 9342.09 (* 1 = 9342.09 loss)
I0831 16:26:14.656548 24386 sgd_solver.cpp:106] Iteration 5600, lr = 1e-06
I0831 16:28:10.267534 24386 solver.cpp:228] Iteration 5650, loss = 266.254
I0831 16:28:10.267648 24386 solver.cpp:244]     Train net output #0: accuracy = 0.999379
I0831 16:28:10.267664 24386 solver.cpp:244]     Train net output #1: loss = 266.256 (* 1 = 266.256 loss)
I0831 16:28:10.267674 24386 sgd_solver.cpp:106] Iteration 5650, lr = 1e-06
I0831 16:30:02.505381 24386 solver.cpp:228] Iteration 5700, loss = 6718.7
I0831 16:30:02.505478 24386 solver.cpp:244]     Train net output #0: accuracy = 0.935987
I0831 16:30:02.505491 24386 solver.cpp:244]     Train net output #1: loss = 6718.7 (* 1 = 6718.7 loss)
I0831 16:30:02.505498 24386 sgd_solver.cpp:106] Iteration 5700, lr = 1e-06
I0831 16:31:53.521069 24386 solver.cpp:228] Iteration 5750, loss = 10977.8
I0831 16:31:53.521175 24386 solver.cpp:244]     Train net output #0: accuracy = 0.892052
I0831 16:31:53.521188 24386 solver.cpp:244]     Train net output #1: loss = 10977.8 (* 1 = 10977.8 loss)
I0831 16:31:53.521194 24386 sgd_solver.cpp:106] Iteration 5750, lr = 1e-06
I0831 16:33:44.834492 24386 solver.cpp:337] Iteration 5800, Testing net (#0)
I0831 16:33:54.465309 24386 solver.cpp:404]     Test net output #0: accuracy = 0.912666
I0831 16:33:54.465355 24386 solver.cpp:404]     Test net output #1: loss = 9070.93 (* 1 = 9070.93 loss)
I0831 16:33:56.593744 24386 solver.cpp:228] Iteration 5800, loss = 8199.47
I0831 16:33:56.593782 24386 solver.cpp:244]     Train net output #0: accuracy = 0.921694
I0831 16:33:56.593792 24386 solver.cpp:244]     Train net output #1: loss = 8199.47 (* 1 = 8199.47 loss)
I0831 16:33:56.593799 24386 sgd_solver.cpp:106] Iteration 5800, lr = 1e-06
I0831 16:35:49.882194 24386 solver.cpp:228] Iteration 5850, loss = 5201.66
I0831 16:35:49.882280 24386 solver.cpp:244]     Train net output #0: accuracy = 0.949018
I0831 16:35:49.882292 24386 solver.cpp:244]     Train net output #1: loss = 5201.66 (* 1 = 5201.66 loss)
I0831 16:35:49.882299 24386 sgd_solver.cpp:106] Iteration 5850, lr = 1e-06
I0831 16:37:41.686744 24386 solver.cpp:228] Iteration 5900, loss = 5641.49
I0831 16:37:41.686849 24386 solver.cpp:244]     Train net output #0: accuracy = 0.944563
I0831 16:37:41.686871 24386 solver.cpp:244]     Train net output #1: loss = 5641.49 (* 1 = 5641.49 loss)
I0831 16:37:41.686882 24386 sgd_solver.cpp:106] Iteration 5900, lr = 1e-06
I0831 16:39:32.226696 24386 solver.cpp:228] Iteration 5950, loss = 10138.8
I0831 16:39:32.226805 24386 solver.cpp:244]     Train net output #0: accuracy = 0.900009
I0831 16:39:32.226822 24386 solver.cpp:244]     Train net output #1: loss = 10138.8 (* 1 = 10138.8 loss)
I0831 16:39:32.226833 24386 sgd_solver.cpp:106] Iteration 5950, lr = 1e-06
I0831 16:41:22.273759 24386 solver.cpp:337] Iteration 6000, Testing net (#0)
I0831 16:41:30.974907 24386 solver.cpp:404]     Test net output #0: accuracy = 0.913754
I0831 16:41:30.974954 24386 solver.cpp:404]     Test net output #1: loss = 8923.29 (* 1 = 8923.29 loss)
I0831 16:41:32.922555 24386 solver.cpp:228] Iteration 6000, loss = 10011.5
I0831 16:41:32.922595 24386 solver.cpp:244]     Train net output #0: accuracy = 0.90288
I0831 16:41:32.922605 24386 solver.cpp:244]     Train net output #1: loss = 10011.5 (* 1 = 10011.5 loss)
I0831 16:41:32.922611 24386 sgd_solver.cpp:106] Iteration 6000, lr = 1e-06
I0831 16:43:26.766377 24386 solver.cpp:228] Iteration 6050, loss = 6551.15
I0831 16:43:26.766490 24386 solver.cpp:244]     Train net output #0: accuracy = 0.934971
I0831 16:43:26.766508 24386 solver.cpp:244]     Train net output #1: loss = 6551.15 (* 1 = 6551.15 loss)
I0831 16:43:26.766518 24386 sgd_solver.cpp:106] Iteration 6050, lr = 1e-06
I0831 16:45:21.300243 24386 solver.cpp:228] Iteration 6100, loss = 5401.26
I0831 16:45:21.300335 24386 solver.cpp:244]     Train net output #0: accuracy = 0.947536
I0831 16:45:21.300346 24386 solver.cpp:244]     Train net output #1: loss = 5401.26 (* 1 = 5401.26 loss)
I0831 16:45:21.300354 24386 sgd_solver.cpp:106] Iteration 6100, lr = 1e-06
I0831 16:47:10.618574 24386 solver.cpp:228] Iteration 6150, loss = 8185.75
I0831 16:47:10.618669 24386 solver.cpp:244]     Train net output #0: accuracy = 0.920106
I0831 16:47:10.618685 24386 solver.cpp:244]     Train net output #1: loss = 8185.75 (* 1 = 8185.75 loss)
I0831 16:47:10.618695 24386 sgd_solver.cpp:106] Iteration 6150, lr = 1e-06
I0831 16:49:01.843950 24386 solver.cpp:337] Iteration 6200, Testing net (#0)
I0831 16:49:11.074146 24386 solver.cpp:404]     Test net output #0: accuracy = 0.913013
I0831 16:49:11.074194 24386 solver.cpp:404]     Test net output #1: loss = 8973.2 (* 1 = 8973.2 loss)
I0831 16:49:13.081423 24386 solver.cpp:228] Iteration 6200, loss = 393.064
I0831 16:49:13.081457 24386 solver.cpp:244]     Train net output #0: accuracy = 0.998754
I0831 16:49:13.081466 24386 solver.cpp:244]     Train net output #1: loss = 393.066 (* 1 = 393.066 loss)
I0831 16:49:13.081485 24386 sgd_solver.cpp:106] Iteration 6200, lr = 1e-06
I0831 16:51:08.332152 24386 solver.cpp:228] Iteration 6250, loss = 6327.35
I0831 16:51:08.332267 24386 solver.cpp:244]     Train net output #0: accuracy = 0.939233
I0831 16:51:08.332279 24386 solver.cpp:244]     Train net output #1: loss = 6327.35 (* 1 = 6327.35 loss)
I0831 16:51:08.332286 24386 sgd_solver.cpp:106] Iteration 6250, lr = 1e-06
I0831 16:53:02.693709 24386 solver.cpp:228] Iteration 6300, loss = 7098.06
I0831 16:53:02.693792 24386 solver.cpp:244]     Train net output #0: accuracy = 0.929645
I0831 16:53:02.693804 24386 solver.cpp:244]     Train net output #1: loss = 7098.06 (* 1 = 7098.06 loss)
I0831 16:53:02.693811 24386 sgd_solver.cpp:106] Iteration 6300, lr = 1e-06
I0831 16:54:54.390885 24386 solver.cpp:228] Iteration 6350, loss = 7144.89
I0831 16:54:54.390966 24386 solver.cpp:244]     Train net output #0: accuracy = 0.928722
I0831 16:54:54.390980 24386 solver.cpp:244]     Train net output #1: loss = 7144.9 (* 1 = 7144.9 loss)
I0831 16:54:54.390986 24386 sgd_solver.cpp:106] Iteration 6350, lr = 1e-06
I0831 16:56:17.884457 24386 solver.cpp:337] Iteration 6400, Testing net (#0)
I0831 16:56:25.912992 24386 solver.cpp:404]     Test net output #0: accuracy = 0.91346
I0831 16:56:25.913034 24386 solver.cpp:404]     Test net output #1: loss = 8921.78 (* 1 = 8921.78 loss)
I0831 16:56:27.320008 24386 solver.cpp:228] Iteration 6400, loss = 8749.42
I0831 16:56:27.320046 24386 solver.cpp:244]     Train net output #0: accuracy = 0.91184
I0831 16:56:27.320055 24386 solver.cpp:244]     Train net output #1: loss = 8749.42 (* 1 = 8749.42 loss)
I0831 16:56:27.320062 24386 sgd_solver.cpp:106] Iteration 6400, lr = 1e-06
I0831 16:57:50.853147 24386 solver.cpp:228] Iteration 6450, loss = 6045.28
I0831 16:57:50.853226 24386 solver.cpp:244]     Train net output #0: accuracy = 0.940202
I0831 16:57:50.853238 24386 solver.cpp:244]     Train net output #1: loss = 6045.28 (* 1 = 6045.28 loss)
I0831 16:57:50.853245 24386 sgd_solver.cpp:106] Iteration 6450, lr = 1e-06
I0831 16:59:44.353907 24386 solver.cpp:228] Iteration 6500, loss = 10002.4
I0831 16:59:44.353996 24386 solver.cpp:244]     Train net output #0: accuracy = 0.904578
I0831 16:59:44.354007 24386 solver.cpp:244]     Train net output #1: loss = 10002.4 (* 1 = 10002.4 loss)
I0831 16:59:44.354014 24386 sgd_solver.cpp:106] Iteration 6500, lr = 1e-06
I0831 17:01:38.658916 24386 solver.cpp:228] Iteration 6550, loss = 10202.5
I0831 17:01:38.658998 24386 solver.cpp:244]     Train net output #0: accuracy = 0.903482
I0831 17:01:38.659009 24386 solver.cpp:244]     Train net output #1: loss = 10202.5 (* 1 = 10202.5 loss)
I0831 17:01:38.659015 24386 sgd_solver.cpp:106] Iteration 6550, lr = 1e-06
I0831 17:03:29.140596 24386 solver.cpp:337] Iteration 6600, Testing net (#0)
I0831 17:03:37.906177 24386 solver.cpp:404]     Test net output #0: accuracy = 0.913909
I0831 17:03:37.906225 24386 solver.cpp:404]     Test net output #1: loss = 8825.96 (* 1 = 8825.96 loss)
I0831 17:03:39.930675 24386 solver.cpp:228] Iteration 6600, loss = 7740.66
I0831 17:03:39.930717 24386 solver.cpp:244]     Train net output #0: accuracy = 0.923565
I0831 17:03:39.930727 24386 solver.cpp:244]     Train net output #1: loss = 7740.66 (* 1 = 7740.66 loss)
I0831 17:03:39.930734 24386 sgd_solver.cpp:106] Iteration 6600, lr = 1e-06
I0831 17:05:32.119390 24386 solver.cpp:228] Iteration 6650, loss = 5334.04
I0831 17:05:32.119482 24386 solver.cpp:244]     Train net output #0: accuracy = 0.948602
I0831 17:05:32.119493 24386 solver.cpp:244]     Train net output #1: loss = 5334.04 (* 1 = 5334.04 loss)
I0831 17:05:32.119501 24386 sgd_solver.cpp:106] Iteration 6650, lr = 1e-06
I0831 17:07:22.716327 24386 solver.cpp:228] Iteration 6700, loss = 5436.32
I0831 17:07:22.716434 24386 solver.cpp:244]     Train net output #0: accuracy = 0.946039
I0831 17:07:22.716452 24386 solver.cpp:244]     Train net output #1: loss = 5436.33 (* 1 = 5436.33 loss)
I0831 17:07:22.716462 24386 sgd_solver.cpp:106] Iteration 6700, lr = 1e-06
I0831 17:09:13.908638 24386 solver.cpp:228] Iteration 6750, loss = 9368.43
I0831 17:09:13.908757 24386 solver.cpp:244]     Train net output #0: accuracy = 0.907411
I0831 17:09:13.908773 24386 solver.cpp:244]     Train net output #1: loss = 9368.44 (* 1 = 9368.44 loss)
I0831 17:09:13.908783 24386 sgd_solver.cpp:106] Iteration 6750, lr = 1e-06
I0831 17:11:06.518438 24386 solver.cpp:337] Iteration 6800, Testing net (#0)
I0831 17:11:17.108573 24386 solver.cpp:404]     Test net output #0: accuracy = 0.914104
I0831 17:11:17.108633 24386 solver.cpp:404]     Test net output #1: loss = 8805.54 (* 1 = 8805.54 loss)
I0831 17:11:19.428495 24386 solver.cpp:228] Iteration 6800, loss = 5643.74
I0831 17:11:19.428545 24386 solver.cpp:244]     Train net output #0: accuracy = 0.946605
I0831 17:11:19.428560 24386 solver.cpp:244]     Train net output #1: loss = 5643.74 (* 1 = 5643.74 loss)
I0831 17:11:19.428568 24386 sgd_solver.cpp:106] Iteration 6800, lr = 1e-06
I0831 17:13:11.826910 24386 solver.cpp:228] Iteration 6850, loss = 6313.14
I0831 17:13:11.826997 24386 solver.cpp:244]     Train net output #0: accuracy = 0.93907
I0831 17:13:11.827010 24386 solver.cpp:244]     Train net output #1: loss = 6313.15 (* 1 = 6313.15 loss)
I0831 17:13:11.827018 24386 sgd_solver.cpp:106] Iteration 6850, lr = 1e-06
I0831 17:15:03.968590 24386 solver.cpp:228] Iteration 6900, loss = 5421.11
I0831 17:15:03.968673 24386 solver.cpp:244]     Train net output #0: accuracy = 0.948882
I0831 17:15:03.968684 24386 solver.cpp:244]     Train net output #1: loss = 5421.11 (* 1 = 5421.11 loss)
I0831 17:15:03.968691 24386 sgd_solver.cpp:106] Iteration 6900, lr = 1e-06
I0831 17:16:56.892782 24386 solver.cpp:228] Iteration 6950, loss = 8547.18
I0831 17:16:56.892870 24386 solver.cpp:244]     Train net output #0: accuracy = 0.913877
I0831 17:16:56.892882 24386 solver.cpp:244]     Train net output #1: loss = 8547.18 (* 1 = 8547.18 loss)
I0831 17:16:56.892889 24386 sgd_solver.cpp:106] Iteration 6950, lr = 1e-06
I0831 17:18:48.822150 24386 solver.cpp:337] Iteration 7000, Testing net (#0)
I0831 17:18:58.186482 24386 solver.cpp:404]     Test net output #0: accuracy = 0.914248
I0831 17:18:58.186538 24386 solver.cpp:404]     Test net output #1: loss = 8788.82 (* 1 = 8788.82 loss)
I0831 17:19:00.016964 24386 solver.cpp:228] Iteration 7000, loss = 335.205
I0831 17:19:00.017009 24386 solver.cpp:244]     Train net output #0: accuracy = 0.999375
I0831 17:19:00.017019 24386 solver.cpp:244]     Train net output #1: loss = 335.207 (* 1 = 335.207 loss)
I0831 17:19:00.017027 24386 sgd_solver.cpp:106] Iteration 7000, lr = 1e-06
I0831 17:20:49.329722 24386 solver.cpp:228] Iteration 7050, loss = 5638.74
I0831 17:20:49.329818 24386 solver.cpp:244]     Train net output #0: accuracy = 0.946998
I0831 17:20:49.329830 24386 solver.cpp:244]     Train net output #1: loss = 5638.74 (* 1 = 5638.74 loss)
I0831 17:20:49.329836 24386 sgd_solver.cpp:106] Iteration 7050, lr = 1e-06
I0831 17:22:44.806217 24386 solver.cpp:228] Iteration 7100, loss = 10862
I0831 17:22:44.806300 24386 solver.cpp:244]     Train net output #0: accuracy = 0.894734
I0831 17:22:44.806313 24386 solver.cpp:244]     Train net output #1: loss = 10862 (* 1 = 10862 loss)
I0831 17:22:44.806319 24386 sgd_solver.cpp:106] Iteration 7100, lr = 1e-06
I0831 17:24:35.312681 24386 solver.cpp:228] Iteration 7150, loss = 8214.95
I0831 17:24:35.312804 24386 solver.cpp:244]     Train net output #0: accuracy = 0.920824
I0831 17:24:35.312824 24386 solver.cpp:244]     Train net output #1: loss = 8214.95 (* 1 = 8214.95 loss)
I0831 17:24:35.312835 24386 sgd_solver.cpp:106] Iteration 7150, lr = 1e-06
I0831 17:26:26.284157 24386 solver.cpp:337] Iteration 7200, Testing net (#0)
I0831 17:26:35.952364 24386 solver.cpp:404]     Test net output #0: accuracy = 0.914638
I0831 17:26:35.952410 24386 solver.cpp:404]     Test net output #1: loss = 8731.83 (* 1 = 8731.83 loss)
I0831 17:26:38.013326 24386 solver.cpp:228] Iteration 7200, loss = 8781.51
I0831 17:26:38.013376 24386 solver.cpp:244]     Train net output #0: accuracy = 0.912445
I0831 17:26:38.013386 24386 solver.cpp:244]     Train net output #1: loss = 8781.52 (* 1 = 8781.52 loss)
I0831 17:26:38.013406 24386 sgd_solver.cpp:106] Iteration 7200, lr = 1e-06
I0831 17:28:28.618300 24386 solver.cpp:228] Iteration 7250, loss = 5523.59
I0831 17:28:28.618420 24386 solver.cpp:244]     Train net output #0: accuracy = 0.948366
I0831 17:28:28.618432 24386 solver.cpp:244]     Train net output #1: loss = 5523.59 (* 1 = 5523.59 loss)
I0831 17:28:28.618439 24386 sgd_solver.cpp:106] Iteration 7250, lr = 1e-06
I0831 17:30:22.841133 24386 solver.cpp:228] Iteration 7300, loss = 11190.3
I0831 17:30:22.841236 24386 solver.cpp:244]     Train net output #0: accuracy = 0.889198
I0831 17:30:22.841253 24386 solver.cpp:244]     Train net output #1: loss = 11190.3 (* 1 = 11190.3 loss)
I0831 17:30:22.841264 24386 sgd_solver.cpp:106] Iteration 7300, lr = 1e-06
I0831 17:32:02.594656 24386 solver.cpp:228] Iteration 7350, loss = 10948.4
I0831 17:32:02.594748 24386 solver.cpp:244]     Train net output #0: accuracy = 0.898979
I0831 17:32:02.594758 24386 solver.cpp:244]     Train net output #1: loss = 10948.4 (* 1 = 10948.4 loss)
I0831 17:32:02.594765 24386 sgd_solver.cpp:106] Iteration 7350, lr = 1e-06
I0831 17:33:53.682893 24386 solver.cpp:337] Iteration 7400, Testing net (#0)
I0831 17:34:03.074097 24386 solver.cpp:404]     Test net output #0: accuracy = 0.914549
I0831 17:34:03.074147 24386 solver.cpp:404]     Test net output #1: loss = 8726.26 (* 1 = 8726.26 loss)
I0831 17:34:05.235962 24386 solver.cpp:228] Iteration 7400, loss = 6335.55
I0831 17:34:05.236004 24386 solver.cpp:244]     Train net output #0: accuracy = 0.939197
I0831 17:34:05.236013 24386 solver.cpp:244]     Train net output #1: loss = 6335.55 (* 1 = 6335.55 loss)
I0831 17:34:05.236021 24386 sgd_solver.cpp:106] Iteration 7400, lr = 1e-06
I0831 17:35:56.550837 24386 solver.cpp:228] Iteration 7450, loss = 5112.2
I0831 17:35:56.551077 24386 solver.cpp:244]     Train net output #0: accuracy = 0.949794
I0831 17:35:56.551090 24386 solver.cpp:244]     Train net output #1: loss = 5112.2 (* 1 = 5112.2 loss)
I0831 17:35:56.551096 24386 sgd_solver.cpp:106] Iteration 7450, lr = 1e-06
I0831 17:37:49.461794 24386 solver.cpp:228] Iteration 7500, loss = 4891.54
I0831 17:37:49.461892 24386 solver.cpp:244]     Train net output #0: accuracy = 0.952645
I0831 17:37:49.461905 24386 solver.cpp:244]     Train net output #1: loss = 4891.54 (* 1 = 4891.54 loss)
I0831 17:37:49.461912 24386 sgd_solver.cpp:106] Iteration 7500, lr = 1e-06
I0831 17:39:42.133955 24386 solver.cpp:228] Iteration 7550, loss = 9066.06
I0831 17:39:42.134057 24386 solver.cpp:244]     Train net output #0: accuracy = 0.91461
I0831 17:39:42.134074 24386 solver.cpp:244]     Train net output #1: loss = 9066.06 (* 1 = 9066.06 loss)
I0831 17:39:42.134083 24386 sgd_solver.cpp:106] Iteration 7550, lr = 1e-06
I0831 17:41:33.022294 24386 solver.cpp:337] Iteration 7600, Testing net (#0)
I0831 17:41:42.262892 24386 solver.cpp:404]     Test net output #0: accuracy = 0.913116
I0831 17:41:42.262938 24386 solver.cpp:404]     Test net output #1: loss = 8901.33 (* 1 = 8901.33 loss)
I0831 17:41:44.176755 24386 solver.cpp:228] Iteration 7600, loss = 5213.41
I0831 17:41:44.176803 24386 solver.cpp:244]     Train net output #0: accuracy = 0.947321
I0831 17:41:44.176813 24386 solver.cpp:244]     Train net output #1: loss = 5213.41 (* 1 = 5213.41 loss)
I0831 17:41:44.176820 24386 sgd_solver.cpp:106] Iteration 7600, lr = 1e-06
I0831 17:43:37.701894 24386 solver.cpp:228] Iteration 7650, loss = 7032.2
I0831 17:43:37.701985 24386 solver.cpp:244]     Train net output #0: accuracy = 0.93225
I0831 17:43:37.701997 24386 solver.cpp:244]     Train net output #1: loss = 7032.2 (* 1 = 7032.2 loss)
I0831 17:43:37.702004 24386 sgd_solver.cpp:106] Iteration 7650, lr = 1e-06
I0831 17:45:30.754789 24386 solver.cpp:228] Iteration 7700, loss = 8063.46
I0831 17:45:30.754874 24386 solver.cpp:244]     Train net output #0: accuracy = 0.922139
I0831 17:45:30.754886 24386 solver.cpp:244]     Train net output #1: loss = 8063.46 (* 1 = 8063.46 loss)
I0831 17:45:30.754894 24386 sgd_solver.cpp:106] Iteration 7700, lr = 1e-06
I0831 17:47:26.825314 24386 solver.cpp:228] Iteration 7750, loss = 9121.98
I0831 17:47:26.825454 24386 solver.cpp:244]     Train net output #0: accuracy = 0.911206
I0831 17:47:26.825470 24386 solver.cpp:244]     Train net output #1: loss = 9121.98 (* 1 = 9121.98 loss)
I0831 17:47:26.825479 24386 sgd_solver.cpp:106] Iteration 7750, lr = 1e-06
I0831 17:49:18.858556 24386 solver.cpp:337] Iteration 7800, Testing net (#0)
I0831 17:49:28.026780 24386 solver.cpp:404]     Test net output #0: accuracy = 0.914229
I0831 17:49:28.026824 24386 solver.cpp:404]     Test net output #1: loss = 8783.43 (* 1 = 8783.43 loss)
I0831 17:49:30.034467 24386 solver.cpp:228] Iteration 7800, loss = 272.036
I0831 17:49:30.034513 24386 solver.cpp:244]     Train net output #0: accuracy = 0.999297
I0831 17:49:30.034524 24386 solver.cpp:244]     Train net output #1: loss = 272.036 (* 1 = 272.036 loss)
I0831 17:49:30.034531 24386 sgd_solver.cpp:106] Iteration 7800, lr = 1e-06
I0831 17:51:22.240085 24386 solver.cpp:228] Iteration 7850, loss = 6275.9
I0831 17:51:22.240206 24386 solver.cpp:244]     Train net output #0: accuracy = 0.939411
I0831 17:51:22.240219 24386 solver.cpp:244]     Train net output #1: loss = 6275.9 (* 1 = 6275.9 loss)
I0831 17:51:22.240227 24386 sgd_solver.cpp:106] Iteration 7850, lr = 1e-06
I0831 17:53:15.331598 24386 solver.cpp:228] Iteration 7900, loss = 11130.4
I0831 17:53:15.331696 24386 solver.cpp:244]     Train net output #0: accuracy = 0.891537
I0831 17:53:15.331708 24386 solver.cpp:244]     Train net output #1: loss = 11130.4 (* 1 = 11130.4 loss)
I0831 17:53:15.331715 24386 sgd_solver.cpp:106] Iteration 7900, lr = 1e-06
I0831 17:55:09.074229 24386 solver.cpp:228] Iteration 7950, loss = 7994.86
I0831 17:55:09.074349 24386 solver.cpp:244]     Train net output #0: accuracy = 0.923882
I0831 17:55:09.074384 24386 solver.cpp:244]     Train net output #1: loss = 7994.86 (* 1 = 7994.86 loss)
I0831 17:55:09.074398 24386 sgd_solver.cpp:106] Iteration 7950, lr = 1e-06
I0831 17:56:58.531774 24386 solver.cpp:454] Snapshotting to binary proto file portrait_wb_one_stage3_iter_8000.caffemodel
I0831 17:56:58.542503 24386 sgd_solver.cpp:273] Snapshotting solver state to binary proto file portrait_wb_one_stage3_iter_8000.solverstate
I0831 17:56:58.543722 24386 solver.cpp:337] Iteration 8000, Testing net (#0)
I0831 17:57:07.609498 24386 solver.cpp:404]     Test net output #0: accuracy = 0.915887
I0831 17:57:07.609546 24386 solver.cpp:404]     Test net output #1: loss = 8621.44 (* 1 = 8621.44 loss)
I0831 17:57:09.500730 24386 solver.cpp:228] Iteration 8000, loss = 5162.65
I0831 17:57:09.500777 24386 solver.cpp:244]     Train net output #0: accuracy = 0.948896
I0831 17:57:09.500787 24386 solver.cpp:244]     Train net output #1: loss = 5162.65 (* 1 = 5162.65 loss)
I0831 17:57:09.500794 24386 sgd_solver.cpp:106] Iteration 8000, lr = 1e-07
I0831 17:59:04.005010 24386 solver.cpp:228] Iteration 8050, loss = 5393.72
I0831 17:59:04.005089 24386 solver.cpp:244]     Train net output #0: accuracy = 0.946499
I0831 17:59:04.005100 24386 solver.cpp:244]     Train net output #1: loss = 5393.72 (* 1 = 5393.72 loss)
I0831 17:59:04.005107 24386 sgd_solver.cpp:106] Iteration 8050, lr = 1e-07
I0831 18:00:55.591881 24386 solver.cpp:228] Iteration 8100, loss = 9629.94
I0831 18:00:55.591970 24386 solver.cpp:244]     Train net output #0: accuracy = 0.905617
I0831 18:00:55.591982 24386 solver.cpp:244]     Train net output #1: loss = 9629.94 (* 1 = 9629.94 loss)
I0831 18:00:55.591989 24386 sgd_solver.cpp:106] Iteration 8100, lr = 1e-07
I0831 18:02:49.058265 24386 solver.cpp:228] Iteration 8150, loss = 10082.7
I0831 18:02:49.058338 24386 solver.cpp:244]     Train net output #0: accuracy = 0.902597
I0831 18:02:49.058351 24386 solver.cpp:244]     Train net output #1: loss = 10082.7 (* 1 = 10082.7 loss)
I0831 18:02:49.058357 24386 sgd_solver.cpp:106] Iteration 8150, lr = 1e-07
I0831 18:04:40.366724 24386 solver.cpp:337] Iteration 8200, Testing net (#0)
I0831 18:04:49.333884 24386 solver.cpp:404]     Test net output #0: accuracy = 0.91633
I0831 18:04:49.333935 24386 solver.cpp:404]     Test net output #1: loss = 8559.5 (* 1 = 8559.5 loss)
I0831 18:04:51.160594 24386 solver.cpp:228] Iteration 8200, loss = 6362.18
I0831 18:04:51.160636 24386 solver.cpp:244]     Train net output #0: accuracy = 0.936784
I0831 18:04:51.160646 24386 solver.cpp:244]     Train net output #1: loss = 6362.18 (* 1 = 6362.18 loss)
I0831 18:04:51.160653 24386 sgd_solver.cpp:106] Iteration 8200, lr = 1e-07
I0831 18:06:47.694852 24386 solver.cpp:228] Iteration 8250, loss = 5198.57
I0831 18:06:47.694936 24386 solver.cpp:244]     Train net output #0: accuracy = 0.949399
I0831 18:06:47.694947 24386 solver.cpp:244]     Train net output #1: loss = 5198.57 (* 1 = 5198.57 loss)
I0831 18:06:47.694954 24386 sgd_solver.cpp:106] Iteration 8250, lr = 1e-07
I0831 18:08:41.413323 24386 solver.cpp:228] Iteration 8300, loss = 7841.83
I0831 18:08:41.413414 24386 solver.cpp:244]     Train net output #0: accuracy = 0.92326
I0831 18:08:41.413425 24386 solver.cpp:244]     Train net output #1: loss = 7841.82 (* 1 = 7841.82 loss)
I0831 18:08:41.413434 24386 sgd_solver.cpp:106] Iteration 8300, lr = 1e-07
I0831 18:10:34.043457 24386 solver.cpp:228] Iteration 8350, loss = 288.45
I0831 18:10:34.043560 24386 solver.cpp:244]     Train net output #0: accuracy = 0.999327
I0831 18:10:34.043572 24386 solver.cpp:244]     Train net output #1: loss = 288.45 (* 1 = 288.45 loss)
I0831 18:10:34.043578 24386 sgd_solver.cpp:106] Iteration 8350, lr = 1e-07
I0831 18:12:23.301668 24386 solver.cpp:337] Iteration 8400, Testing net (#0)
I0831 18:12:32.497409 24386 solver.cpp:404]     Test net output #0: accuracy = 0.916538
I0831 18:12:32.497468 24386 solver.cpp:404]     Test net output #1: loss = 8538.9 (* 1 = 8538.9 loss)
I0831 18:12:34.477074 24386 solver.cpp:228] Iteration 8400, loss = 5886.56
I0831 18:12:34.477113 24386 solver.cpp:244]     Train net output #0: accuracy = 0.943502
I0831 18:12:34.477123 24386 solver.cpp:244]     Train net output #1: loss = 5886.56 (* 1 = 5886.56 loss)
I0831 18:12:34.477129 24386 sgd_solver.cpp:106] Iteration 8400, lr = 1e-07
I0831 18:14:26.847425 24386 solver.cpp:228] Iteration 8450, loss = 6704.72
I0831 18:14:26.847522 24386 solver.cpp:244]     Train net output #0: accuracy = 0.933343
I0831 18:14:26.847534 24386 solver.cpp:244]     Train net output #1: loss = 6704.72 (* 1 = 6704.72 loss)
I0831 18:14:26.847543 24386 sgd_solver.cpp:106] Iteration 8450, lr = 1e-07
I0831 18:16:17.315578 24386 solver.cpp:228] Iteration 8500, loss = 6981.17
I0831 18:16:17.315671 24386 solver.cpp:244]     Train net output #0: accuracy = 0.930385
I0831 18:16:17.315685 24386 solver.cpp:244]     Train net output #1: loss = 6981.17 (* 1 = 6981.17 loss)
I0831 18:16:17.315692 24386 sgd_solver.cpp:106] Iteration 8500, lr = 1e-07
I0831 18:18:09.123561 24386 solver.cpp:228] Iteration 8550, loss = 8557.58
I0831 18:18:09.123638 24386 solver.cpp:244]     Train net output #0: accuracy = 0.914414
I0831 18:18:09.123649 24386 solver.cpp:244]     Train net output #1: loss = 8557.58 (* 1 = 8557.58 loss)
I0831 18:18:09.123656 24386 sgd_solver.cpp:106] Iteration 8550, lr = 1e-07
I0831 18:20:01.416241 24386 solver.cpp:337] Iteration 8600, Testing net (#0)
I0831 18:20:10.644791 24386 solver.cpp:404]     Test net output #0: accuracy = 0.915371
I0831 18:20:10.644835 24386 solver.cpp:404]     Test net output #1: loss = 8650.29 (* 1 = 8650.29 loss)
I0831 18:20:12.778836 24386 solver.cpp:228] Iteration 8600, loss = 6137.5
I0831 18:20:12.778877 24386 solver.cpp:244]     Train net output #0: accuracy = 0.939594
I0831 18:20:12.778887 24386 solver.cpp:244]     Train net output #1: loss = 6137.5 (* 1 = 6137.5 loss)
I0831 18:20:12.778893 24386 sgd_solver.cpp:106] Iteration 8600, lr = 1e-07
I0831 18:22:08.676221 24386 solver.cpp:228] Iteration 8650, loss = 9779.47
I0831 18:22:08.676303 24386 solver.cpp:244]     Train net output #0: accuracy = 0.906214
I0831 18:22:08.676316 24386 solver.cpp:244]     Train net output #1: loss = 9779.47 (* 1 = 9779.47 loss)
I0831 18:22:08.676322 24386 sgd_solver.cpp:106] Iteration 8650, lr = 1e-07
I0831 18:24:01.144379 24386 solver.cpp:228] Iteration 8700, loss = 10214.2
I0831 18:24:01.144525 24386 solver.cpp:244]     Train net output #0: accuracy = 0.903509
I0831 18:24:01.144539 24386 solver.cpp:244]     Train net output #1: loss = 10214.2 (* 1 = 10214.2 loss)
I0831 18:24:01.144548 24386 sgd_solver.cpp:106] Iteration 8700, lr = 1e-07
I0831 18:25:53.851207 24386 solver.cpp:228] Iteration 8750, loss = 7580.5
I0831 18:25:53.851301 24386 solver.cpp:244]     Train net output #0: accuracy = 0.925904
I0831 18:25:53.851312 24386 solver.cpp:244]     Train net output #1: loss = 7580.5 (* 1 = 7580.5 loss)
I0831 18:25:53.851320 24386 sgd_solver.cpp:106] Iteration 8750, lr = 1e-07
I0831 18:27:46.896119 24386 solver.cpp:337] Iteration 8800, Testing net (#0)
I0831 18:27:56.452600 24386 solver.cpp:404]     Test net output #0: accuracy = 0.915297
I0831 18:27:56.452649 24386 solver.cpp:404]     Test net output #1: loss = 8679.16 (* 1 = 8679.16 loss)
I0831 18:27:58.527412 24386 solver.cpp:228] Iteration 8800, loss = 4980.77
I0831 18:27:58.527462 24386 solver.cpp:244]     Train net output #0: accuracy = 0.951472
I0831 18:27:58.527473 24386 solver.cpp:244]     Train net output #1: loss = 4980.77 (* 1 = 4980.77 loss)
I0831 18:27:58.527482 24386 sgd_solver.cpp:106] Iteration 8800, lr = 1e-07
I0831 18:29:52.975242 24386 solver.cpp:228] Iteration 8850, loss = 5348.83
I0831 18:29:52.975546 24386 solver.cpp:244]     Train net output #0: accuracy = 0.946679
I0831 18:29:52.975563 24386 solver.cpp:244]     Train net output #1: loss = 5348.83 (* 1 = 5348.83 loss)
I0831 18:29:52.975571 24386 sgd_solver.cpp:106] Iteration 8850, lr = 1e-07
I0831 18:31:48.541970 24386 solver.cpp:228] Iteration 8900, loss = 9093.13
I0831 18:31:48.542078 24386 solver.cpp:244]     Train net output #0: accuracy = 0.909649
I0831 18:31:48.542094 24386 solver.cpp:244]     Train net output #1: loss = 9093.13 (* 1 = 9093.13 loss)
I0831 18:31:48.542104 24386 sgd_solver.cpp:106] Iteration 8900, lr = 1e-07
I0831 18:33:44.231340 24386 solver.cpp:228] Iteration 8950, loss = 5352.16
I0831 18:33:44.231416 24386 solver.cpp:244]     Train net output #0: accuracy = 0.948907
I0831 18:33:44.231428 24386 solver.cpp:244]     Train net output #1: loss = 5352.16 (* 1 = 5352.16 loss)
I0831 18:33:44.231436 24386 sgd_solver.cpp:106] Iteration 8950, lr = 1e-07
I0831 18:35:34.824826 24386 solver.cpp:337] Iteration 9000, Testing net (#0)
I0831 18:35:43.772337 24386 solver.cpp:404]     Test net output #0: accuracy = 0.915226
I0831 18:35:43.772382 24386 solver.cpp:404]     Test net output #1: loss = 8664.79 (* 1 = 8664.79 loss)
I0831 18:35:45.728159 24386 solver.cpp:228] Iteration 9000, loss = 6070.26
I0831 18:35:45.728199 24386 solver.cpp:244]     Train net output #0: accuracy = 0.940017
I0831 18:35:45.728209 24386 solver.cpp:244]     Train net output #1: loss = 6070.26 (* 1 = 6070.26 loss)
I0831 18:35:45.728215 24386 sgd_solver.cpp:106] Iteration 9000, lr = 1e-07
I0831 18:37:38.309393 24386 solver.cpp:228] Iteration 9050, loss = 5196.51
I0831 18:37:38.309497 24386 solver.cpp:244]     Train net output #0: accuracy = 0.950457
I0831 18:37:38.309509 24386 solver.cpp:244]     Train net output #1: loss = 5196.51 (* 1 = 5196.51 loss)
I0831 18:37:38.309517 24386 sgd_solver.cpp:106] Iteration 9050, lr = 1e-07
I0831 18:39:32.675230 24386 solver.cpp:228] Iteration 9100, loss = 8313.38
I0831 18:39:32.675317 24386 solver.cpp:244]     Train net output #0: accuracy = 0.916399
I0831 18:39:32.675329 24386 solver.cpp:244]     Train net output #1: loss = 8313.38 (* 1 = 8313.38 loss)
I0831 18:39:32.675336 24386 sgd_solver.cpp:106] Iteration 9100, lr = 1e-07
I0831 18:41:25.017189 24386 solver.cpp:228] Iteration 9150, loss = 438.975
I0831 18:41:25.017287 24386 solver.cpp:244]     Train net output #0: accuracy = 0.999021
I0831 18:41:25.017302 24386 solver.cpp:244]     Train net output #1: loss = 438.975 (* 1 = 438.975 loss)
I0831 18:41:25.017312 24386 sgd_solver.cpp:106] Iteration 9150, lr = 1e-07
I0831 18:43:17.523526 24386 solver.cpp:337] Iteration 9200, Testing net (#0)
I0831 18:43:26.144564 24386 solver.cpp:404]     Test net output #0: accuracy = 0.915089
I0831 18:43:26.144608 24386 solver.cpp:404]     Test net output #1: loss = 8685.93 (* 1 = 8685.93 loss)
I0831 18:43:27.826829 24386 solver.cpp:228] Iteration 9200, loss = 5477.7
I0831 18:43:27.826867 24386 solver.cpp:244]     Train net output #0: accuracy = 0.948122
I0831 18:43:27.826876 24386 solver.cpp:244]     Train net output #1: loss = 5477.7 (* 1 = 5477.7 loss)
I0831 18:43:27.826884 24386 sgd_solver.cpp:106] Iteration 9200, lr = 1e-07
I0831 18:45:22.211376 24386 solver.cpp:228] Iteration 9250, loss = 10622.8
I0831 18:45:22.211495 24386 solver.cpp:244]     Train net output #0: accuracy = 0.897335
I0831 18:45:22.211513 24386 solver.cpp:244]     Train net output #1: loss = 10622.8 (* 1 = 10622.8 loss)
I0831 18:45:22.211520 24386 sgd_solver.cpp:106] Iteration 9250, lr = 1e-07
I0831 18:47:17.033150 24386 solver.cpp:228] Iteration 9300, loss = 8223.6
I0831 18:47:17.033248 24386 solver.cpp:244]     Train net output #0: accuracy = 0.922002
I0831 18:47:17.033260 24386 solver.cpp:244]     Train net output #1: loss = 8223.6 (* 1 = 8223.6 loss)
I0831 18:47:17.033267 24386 sgd_solver.cpp:106] Iteration 9300, lr = 1e-07
I0831 18:49:11.707759 24386 solver.cpp:228] Iteration 9350, loss = 8710.65
I0831 18:49:11.707861 24386 solver.cpp:244]     Train net output #0: accuracy = 0.912861
I0831 18:49:11.707877 24386 solver.cpp:244]     Train net output #1: loss = 8710.65 (* 1 = 8710.65 loss)
I0831 18:49:11.707886 24386 sgd_solver.cpp:106] Iteration 9350, lr = 1e-07
I0831 18:51:00.811255 24386 solver.cpp:337] Iteration 9400, Testing net (#0)
I0831 18:51:09.505421 24386 solver.cpp:404]     Test net output #0: accuracy = 0.915392
I0831 18:51:09.505467 24386 solver.cpp:404]     Test net output #1: loss = 8647.78 (* 1 = 8647.78 loss)
I0831 18:51:11.438817 24386 solver.cpp:228] Iteration 9400, loss = 5450.1
I0831 18:51:11.438861 24386 solver.cpp:244]     Train net output #0: accuracy = 0.949495
I0831 18:51:11.438871 24386 solver.cpp:244]     Train net output #1: loss = 5450.1 (* 1 = 5450.1 loss)
I0831 18:51:11.438879 24386 sgd_solver.cpp:106] Iteration 9400, lr = 1e-07
I0831 18:53:05.762945 24386 solver.cpp:228] Iteration 9450, loss = 10769.2
I0831 18:53:05.763056 24386 solver.cpp:244]     Train net output #0: accuracy = 0.894458
I0831 18:53:05.763072 24386 solver.cpp:244]     Train net output #1: loss = 10769.2 (* 1 = 10769.2 loss)
I0831 18:53:05.763082 24386 sgd_solver.cpp:106] Iteration 9450, lr = 1e-07
I0831 18:54:57.391247 24386 solver.cpp:228] Iteration 9500, loss = 11322.7
I0831 18:54:57.391372 24386 solver.cpp:244]     Train net output #0: accuracy = 0.895648
I0831 18:54:57.391391 24386 solver.cpp:244]     Train net output #1: loss = 11322.7 (* 1 = 11322.7 loss)
I0831 18:54:57.391402 24386 sgd_solver.cpp:106] Iteration 9500, lr = 1e-07
I0831 18:56:52.173199 24386 solver.cpp:228] Iteration 9550, loss = 6515.17
I0831 18:56:52.173287 24386 solver.cpp:244]     Train net output #0: accuracy = 0.937352
I0831 18:56:52.173300 24386 solver.cpp:244]     Train net output #1: loss = 6515.17 (* 1 = 6515.17 loss)
I0831 18:56:52.173307 24386 sgd_solver.cpp:106] Iteration 9550, lr = 1e-07
I0831 18:58:43.917803 24386 solver.cpp:337] Iteration 9600, Testing net (#0)
I0831 18:58:53.188474 24386 solver.cpp:404]     Test net output #0: accuracy = 0.916046
I0831 18:58:53.188532 24386 solver.cpp:404]     Test net output #1: loss = 8593.84 (* 1 = 8593.84 loss)
I0831 18:58:55.268041 24386 solver.cpp:228] Iteration 9600, loss = 5018.29
I0831 18:58:55.268091 24386 solver.cpp:244]     Train net output #0: accuracy = 0.951204
I0831 18:58:55.268105 24386 solver.cpp:244]     Train net output #1: loss = 5018.29 (* 1 = 5018.29 loss)
I0831 18:58:55.268115 24386 sgd_solver.cpp:106] Iteration 9600, lr = 1e-07
I0831 19:00:46.512655 24386 solver.cpp:228] Iteration 9650, loss = 4854.28
I0831 19:00:46.512735 24386 solver.cpp:244]     Train net output #0: accuracy = 0.953057
I0831 19:00:46.512749 24386 solver.cpp:244]     Train net output #1: loss = 4854.28 (* 1 = 4854.28 loss)
I0831 19:00:46.512756 24386 sgd_solver.cpp:106] Iteration 9650, lr = 1e-07
I0831 19:02:39.507676 24386 solver.cpp:228] Iteration 9700, loss = 9245.83
I0831 19:02:39.507791 24386 solver.cpp:244]     Train net output #0: accuracy = 0.911965
I0831 19:02:39.507804 24386 solver.cpp:244]     Train net output #1: loss = 9245.83 (* 1 = 9245.83 loss)
I0831 19:02:39.507810 24386 sgd_solver.cpp:106] Iteration 9700, lr = 1e-07
I0831 19:04:31.454793 24386 solver.cpp:228] Iteration 9750, loss = 5130.89
I0831 19:04:31.454880 24386 solver.cpp:244]     Train net output #0: accuracy = 0.948312
I0831 19:04:31.454891 24386 solver.cpp:244]     Train net output #1: loss = 5130.89 (* 1 = 5130.89 loss)
I0831 19:04:31.454900 24386 sgd_solver.cpp:106] Iteration 9750, lr = 1e-07
I0831 19:06:22.502578 24386 solver.cpp:337] Iteration 9800, Testing net (#0)
I0831 19:06:31.295644 24386 solver.cpp:404]     Test net output #0: accuracy = 0.916261
I0831 19:06:31.295702 24386 solver.cpp:404]     Test net output #1: loss = 8582.9 (* 1 = 8582.9 loss)
I0831 19:06:33.146365 24386 solver.cpp:228] Iteration 9800, loss = 6732.3
I0831 19:06:33.146421 24386 solver.cpp:244]     Train net output #0: accuracy = 0.934863
I0831 19:06:33.146430 24386 solver.cpp:244]     Train net output #1: loss = 6732.3 (* 1 = 6732.3 loss)
I0831 19:06:33.146438 24386 sgd_solver.cpp:106] Iteration 9800, lr = 1e-07
I0831 19:08:29.451025 24386 solver.cpp:228] Iteration 9850, loss = 8024.44
I0831 19:08:29.451128 24386 solver.cpp:244]     Train net output #0: accuracy = 0.923871
I0831 19:08:29.451144 24386 solver.cpp:244]     Train net output #1: loss = 8024.43 (* 1 = 8024.43 loss)
I0831 19:08:29.451154 24386 sgd_solver.cpp:106] Iteration 9850, lr = 1e-07
I0831 19:10:22.053252 24386 solver.cpp:228] Iteration 9900, loss = 8959.15
I0831 19:10:22.053364 24386 solver.cpp:244]     Train net output #0: accuracy = 0.912064
I0831 19:10:22.053380 24386 solver.cpp:244]     Train net output #1: loss = 8959.15 (* 1 = 8959.15 loss)
I0831 19:10:22.053390 24386 sgd_solver.cpp:106] Iteration 9900, lr = 1e-07
I0831 19:12:17.257339 24386 solver.cpp:228] Iteration 9950, loss = 353.783
I0831 19:12:17.257437 24386 solver.cpp:244]     Train net output #0: accuracy = 0.99882
I0831 19:12:17.257449 24386 solver.cpp:244]     Train net output #1: loss = 353.783 (* 1 = 353.783 loss)
I0831 19:12:17.257457 24386 sgd_solver.cpp:106] Iteration 9950, lr = 1e-07
I0831 19:14:07.788573 24386 solver.cpp:337] Iteration 10000, Testing net (#0)
I0831 19:14:17.251617 24386 solver.cpp:404]     Test net output #0: accuracy = 0.916197
I0831 19:14:17.251674 24386 solver.cpp:404]     Test net output #1: loss = 8587.14 (* 1 = 8587.14 loss)
I0831 19:14:19.207774 24386 solver.cpp:228] Iteration 10000, loss = 5863.89
I0831 19:14:19.207813 24386 solver.cpp:244]     Train net output #0: accuracy = 0.943
I0831 19:14:19.207823 24386 solver.cpp:244]     Train net output #1: loss = 5863.89 (* 1 = 5863.89 loss)
I0831 19:14:19.207829 24386 sgd_solver.cpp:106] Iteration 10000, lr = 1e-07
I0831 19:16:13.457154 24386 solver.cpp:228] Iteration 10050, loss = 10642.3
I0831 19:16:13.457242 24386 solver.cpp:244]     Train net output #0: accuracy = 0.895983
I0831 19:16:13.457254 24386 solver.cpp:244]     Train net output #1: loss = 10642.3 (* 1 = 10642.3 loss)
I0831 19:16:13.457262 24386 sgd_solver.cpp:106] Iteration 10050, lr = 1e-07
I0831 19:18:06.955521 24386 solver.cpp:228] Iteration 10100, loss = 7893.78
I0831 19:18:06.955627 24386 solver.cpp:244]     Train net output #0: accuracy = 0.924528
I0831 19:18:06.955642 24386 solver.cpp:244]     Train net output #1: loss = 7893.78 (* 1 = 7893.78 loss)
I0831 19:18:06.955651 24386 sgd_solver.cpp:106] Iteration 10100, lr = 1e-07
I0831 19:20:00.489965 24386 solver.cpp:228] Iteration 10150, loss = 5322.33
I0831 19:20:00.490051 24386 solver.cpp:244]     Train net output #0: accuracy = 0.94836
I0831 19:20:00.490061 24386 solver.cpp:244]     Train net output #1: loss = 5322.33 (* 1 = 5322.33 loss)
I0831 19:20:00.490069 24386 sgd_solver.cpp:106] Iteration 10150, lr = 1e-07
I0831 19:21:50.101945 24386 solver.cpp:337] Iteration 10200, Testing net (#0)
I0831 19:21:59.461417 24386 solver.cpp:404]     Test net output #0: accuracy = 0.916332
I0831 19:21:59.461467 24386 solver.cpp:404]     Test net output #1: loss = 8567.66 (* 1 = 8567.66 loss)
I0831 19:22:01.505339 24386 solver.cpp:228] Iteration 10200, loss = 5441.14
I0831 19:22:01.505379 24386 solver.cpp:244]     Train net output #0: accuracy = 0.946334
I0831 19:22:01.505388 24386 solver.cpp:244]     Train net output #1: loss = 5441.14 (* 1 = 5441.14 loss)
I0831 19:22:01.505395 24386 sgd_solver.cpp:106] Iteration 10200, lr = 1e-07
I0831 19:23:56.990566 24386 solver.cpp:228] Iteration 10250, loss = 9755.08
I0831 19:23:56.990670 24386 solver.cpp:244]     Train net output #0: accuracy = 0.904138
I0831 19:23:56.990684 24386 solver.cpp:244]     Train net output #1: loss = 9755.08 (* 1 = 9755.08 loss)
I0831 19:23:56.990691 24386 sgd_solver.cpp:106] Iteration 10250, lr = 1e-07
I0831 19:25:50.076711 24386 solver.cpp:228] Iteration 10300, loss = 10258.5
I0831 19:25:50.076817 24386 solver.cpp:244]     Train net output #0: accuracy = 0.901032
I0831 19:25:50.076834 24386 solver.cpp:244]     Train net output #1: loss = 10258.5 (* 1 = 10258.5 loss)
I0831 19:25:50.076845 24386 sgd_solver.cpp:106] Iteration 10300, lr = 1e-07
I0831 19:27:44.705519 24386 solver.cpp:228] Iteration 10350, loss = 6243.39
I0831 19:27:44.705626 24386 solver.cpp:244]     Train net output #0: accuracy = 0.938554
I0831 19:27:44.705643 24386 solver.cpp:244]     Train net output #1: loss = 6243.39 (* 1 = 6243.39 loss)
I0831 19:27:44.705653 24386 sgd_solver.cpp:106] Iteration 10350, lr = 1e-07
I0831 19:29:36.426084 24386 solver.cpp:337] Iteration 10400, Testing net (#0)
I0831 19:29:45.573910 24386 solver.cpp:404]     Test net output #0: accuracy = 0.916131
I0831 19:29:45.573956 24386 solver.cpp:404]     Test net output #1: loss = 8593.88 (* 1 = 8593.88 loss)
I0831 19:29:47.427597 24386 solver.cpp:228] Iteration 10400, loss = 5083.21
I0831 19:29:47.427641 24386 solver.cpp:244]     Train net output #0: accuracy = 0.950619
I0831 19:29:47.427651 24386 solver.cpp:244]     Train net output #1: loss = 5083.21 (* 1 = 5083.21 loss)
I0831 19:29:47.427660 24386 sgd_solver.cpp:106] Iteration 10400, lr = 1e-07
I0831 19:31:39.764539 24386 solver.cpp:228] Iteration 10450, loss = 7800.71
I0831 19:31:39.764639 24386 solver.cpp:244]     Train net output #0: accuracy = 0.922978
I0831 19:31:39.764657 24386 solver.cpp:244]     Train net output #1: loss = 7800.71 (* 1 = 7800.71 loss)
I0831 19:31:39.764669 24386 sgd_solver.cpp:106] Iteration 10450, lr = 1e-07
I0831 19:33:32.821816 24386 solver.cpp:228] Iteration 10500, loss = 296.81
I0831 19:33:32.821902 24386 solver.cpp:244]     Train net output #0: accuracy = 0.999075
I0831 19:33:32.821914 24386 solver.cpp:244]     Train net output #1: loss = 296.811 (* 1 = 296.811 loss)
I0831 19:33:32.821921 24386 sgd_solver.cpp:106] Iteration 10500, lr = 1e-07
I0831 19:35:25.601704 24386 solver.cpp:228] Iteration 10550, loss = 5778.79
I0831 19:35:25.601811 24386 solver.cpp:244]     Train net output #0: accuracy = 0.944248
I0831 19:35:25.601827 24386 solver.cpp:244]     Train net output #1: loss = 5778.79 (* 1 = 5778.79 loss)
I0831 19:35:25.601837 24386 sgd_solver.cpp:106] Iteration 10550, lr = 1e-07
I0831 19:37:16.885849 24386 solver.cpp:337] Iteration 10600, Testing net (#0)
I0831 19:37:25.958166 24386 solver.cpp:404]     Test net output #0: accuracy = 0.915074
I0831 19:37:25.958212 24386 solver.cpp:404]     Test net output #1: loss = 8695.92 (* 1 = 8695.92 loss)
I0831 19:37:27.814991 24386 solver.cpp:228] Iteration 10600, loss = 6789.55
I0831 19:37:27.815032 24386 solver.cpp:244]     Train net output #0: accuracy = 0.932441
I0831 19:37:27.815042 24386 solver.cpp:244]     Train net output #1: loss = 6789.55 (* 1 = 6789.55 loss)
I0831 19:37:27.815049 24386 sgd_solver.cpp:106] Iteration 10600, lr = 1e-07
I0831 19:39:19.635465 24386 solver.cpp:228] Iteration 10650, loss = 6871.25
I0831 19:39:19.635547 24386 solver.cpp:244]     Train net output #0: accuracy = 0.93162
I0831 19:39:19.635560 24386 solver.cpp:244]     Train net output #1: loss = 6871.25 (* 1 = 6871.25 loss)
I0831 19:39:19.635567 24386 sgd_solver.cpp:106] Iteration 10650, lr = 1e-07
I0831 19:41:10.912865 24386 solver.cpp:228] Iteration 10700, loss = 8766.43
I0831 19:41:10.913031 24386 solver.cpp:244]     Train net output #0: accuracy = 0.911924
I0831 19:41:10.913054 24386 solver.cpp:244]     Train net output #1: loss = 8766.43 (* 1 = 8766.43 loss)
I0831 19:41:10.913066 24386 sgd_solver.cpp:106] Iteration 10700, lr = 1e-07
I0831 19:43:02.549826 24386 solver.cpp:228] Iteration 10750, loss = 6256.44
I0831 19:43:02.549931 24386 solver.cpp:244]     Train net output #0: accuracy = 0.938369
I0831 19:43:02.549947 24386 solver.cpp:244]     Train net output #1: loss = 6256.44 (* 1 = 6256.44 loss)
I0831 19:43:02.549958 24386 sgd_solver.cpp:106] Iteration 10750, lr = 1e-07
I0831 19:44:46.347754 24386 solver.cpp:337] Iteration 10800, Testing net (#0)
I0831 19:44:56.049655 24386 solver.cpp:404]     Test net output #0: accuracy = 0.915692
I0831 19:44:56.049710 24386 solver.cpp:404]     Test net output #1: loss = 8629.44 (* 1 = 8629.44 loss)
I0831 19:44:57.836990 24386 solver.cpp:228] Iteration 10800, loss = 9648.07
I0831 19:44:57.837049 24386 solver.cpp:244]     Train net output #0: accuracy = 0.906956
I0831 19:44:57.838536 24386 solver.cpp:244]     Train net output #1: loss = 9648.07 (* 1 = 9648.07 loss)
I0831 19:44:57.838551 24386 sgd_solver.cpp:106] Iteration 10800, lr = 1e-07
I0831 19:46:52.182968 24386 solver.cpp:228] Iteration 10850, loss = 10211.7
I0831 19:46:52.183053 24386 solver.cpp:244]     Train net output #0: accuracy = 0.903967
I0831 19:46:52.183064 24386 solver.cpp:244]     Train net output #1: loss = 10211.7 (* 1 = 10211.7 loss)
I0831 19:46:52.183073 24386 sgd_solver.cpp:106] Iteration 10850, lr = 1e-07
I0831 19:48:50.069669 24386 solver.cpp:228] Iteration 10900, loss = 7772.65
I0831 19:48:50.069769 24386 solver.cpp:244]     Train net output #0: accuracy = 0.923128
I0831 19:48:50.069785 24386 solver.cpp:244]     Train net output #1: loss = 7772.65 (* 1 = 7772.65 loss)
I0831 19:48:50.069795 24386 sgd_solver.cpp:106] Iteration 10900, lr = 1e-07
I0831 19:50:45.766566 24386 solver.cpp:228] Iteration 10950, loss = 5035.03
I0831 19:50:45.766649 24386 solver.cpp:244]     Train net output #0: accuracy = 0.951188
I0831 19:50:45.766661 24386 solver.cpp:244]     Train net output #1: loss = 5035.03 (* 1 = 5035.03 loss)
I0831 19:50:45.766669 24386 sgd_solver.cpp:106] Iteration 10950, lr = 1e-07
I0831 19:52:37.893813 24386 solver.cpp:337] Iteration 11000, Testing net (#0)
I0831 19:52:47.216516 24386 solver.cpp:404]     Test net output #0: accuracy = 0.915859
I0831 19:52:47.216578 24386 solver.cpp:404]     Test net output #1: loss = 8612.72 (* 1 = 8612.72 loss)
I0831 19:52:49.185643 24386 solver.cpp:228] Iteration 11000, loss = 5434.72
I0831 19:52:49.185693 24386 solver.cpp:244]     Train net output #0: accuracy = 0.94607
I0831 19:52:49.185704 24386 solver.cpp:244]     Train net output #1: loss = 5434.72 (* 1 = 5434.72 loss)
I0831 19:52:49.185714 24386 sgd_solver.cpp:106] Iteration 11000, lr = 1e-07
I0831 19:54:42.536821 24386 solver.cpp:228] Iteration 11050, loss = 8987.62
I0831 19:54:42.536905 24386 solver.cpp:244]     Train net output #0: accuracy = 0.911275
I0831 19:54:42.536916 24386 solver.cpp:244]     Train net output #1: loss = 8987.62 (* 1 = 8987.62 loss)
I0831 19:54:42.536923 24386 sgd_solver.cpp:106] Iteration 11050, lr = 1e-07
I0831 19:56:36.264497 24386 solver.cpp:228] Iteration 11100, loss = 5292.34
I0831 19:56:36.264617 24386 solver.cpp:244]     Train net output #0: accuracy = 0.949872
I0831 19:56:36.264638 24386 solver.cpp:244]     Train net output #1: loss = 5292.34 (* 1 = 5292.34 loss)
I0831 19:56:36.264649 24386 sgd_solver.cpp:106] Iteration 11100, lr = 1e-07
I0831 19:58:29.681351 24386 solver.cpp:228] Iteration 11150, loss = 6126.84
I0831 19:58:29.681442 24386 solver.cpp:244]     Train net output #0: accuracy = 0.939777
I0831 19:58:29.681454 24386 solver.cpp:244]     Train net output #1: loss = 6126.84 (* 1 = 6126.84 loss)
I0831 19:58:29.681462 24386 sgd_solver.cpp:106] Iteration 11150, lr = 1e-07
I0831 20:00:21.777070 24386 solver.cpp:337] Iteration 11200, Testing net (#0)
I0831 20:00:31.162022 24386 solver.cpp:404]     Test net output #0: accuracy = 0.915712
I0831 20:00:31.162080 24386 solver.cpp:404]     Test net output #1: loss = 8638.74 (* 1 = 8638.74 loss)
I0831 20:00:33.035598 24386 solver.cpp:228] Iteration 11200, loss = 5211.37
I0831 20:00:33.035640 24386 solver.cpp:244]     Train net output #0: accuracy = 0.950896
I0831 20:00:33.035650 24386 solver.cpp:244]     Train net output #1: loss = 5211.37 (* 1 = 5211.37 loss)
I0831 20:00:33.035656 24386 sgd_solver.cpp:106] Iteration 11200, lr = 1e-07
I0831 20:02:26.939263 24386 solver.cpp:228] Iteration 11250, loss = 8251.91
I0831 20:02:26.939385 24386 solver.cpp:244]     Train net output #0: accuracy = 0.916435
I0831 20:02:26.939406 24386 solver.cpp:244]     Train net output #1: loss = 8251.91 (* 1 = 8251.91 loss)
I0831 20:02:26.939417 24386 sgd_solver.cpp:106] Iteration 11250, lr = 1e-07
I0831 20:04:21.917181 24386 solver.cpp:228] Iteration 11300, loss = 409.435
I0831 20:04:21.917269 24386 solver.cpp:244]     Train net output #0: accuracy = 0.999209
I0831 20:04:21.917282 24386 solver.cpp:244]     Train net output #1: loss = 409.437 (* 1 = 409.437 loss)
I0831 20:04:21.917290 24386 sgd_solver.cpp:106] Iteration 11300, lr = 1e-07
I0831 20:06:16.653074 24386 solver.cpp:228] Iteration 11350, loss = 5395.06
I0831 20:06:16.653178 24386 solver.cpp:244]     Train net output #0: accuracy = 0.949481
I0831 20:06:16.653194 24386 solver.cpp:244]     Train net output #1: loss = 5395.06 (* 1 = 5395.06 loss)
I0831 20:06:16.653204 24386 sgd_solver.cpp:106] Iteration 11350, lr = 1e-07
I0831 20:08:09.413770 24386 solver.cpp:337] Iteration 11400, Testing net (#0)
I0831 20:08:18.040977 24386 solver.cpp:404]     Test net output #0: accuracy = 0.915955
I0831 20:08:18.041019 24386 solver.cpp:404]     Test net output #1: loss = 8611.54 (* 1 = 8611.54 loss)
I0831 20:08:19.992852 24386 solver.cpp:228] Iteration 11400, loss = 10514.7
I0831 20:08:19.992895 24386 solver.cpp:244]     Train net output #0: accuracy = 0.897213
I0831 20:08:19.992905 24386 solver.cpp:244]     Train net output #1: loss = 10514.7 (* 1 = 10514.7 loss)
I0831 20:08:19.992913 24386 sgd_solver.cpp:106] Iteration 11400, lr = 1e-07
I0831 20:10:14.197700 24386 solver.cpp:228] Iteration 11450, loss = 7489.58
I0831 20:10:14.197839 24386 solver.cpp:244]     Train net output #0: accuracy = 0.927945
I0831 20:10:14.197857 24386 solver.cpp:244]     Train net output #1: loss = 7489.58 (* 1 = 7489.58 loss)
I0831 20:10:14.197868 24386 sgd_solver.cpp:106] Iteration 11450, lr = 1e-07
I0831 20:12:08.480972 24386 solver.cpp:228] Iteration 11500, loss = 8913.03
I0831 20:12:08.481055 24386 solver.cpp:244]     Train net output #0: accuracy = 0.912315
I0831 20:12:08.481068 24386 solver.cpp:244]     Train net output #1: loss = 8913.03 (* 1 = 8913.03 loss)
I0831 20:12:08.481076 24386 sgd_solver.cpp:106] Iteration 11500, lr = 1e-07
I0831 20:14:05.157582 24386 solver.cpp:228] Iteration 11550, loss = 5496.58
I0831 20:14:05.157714 24386 solver.cpp:244]     Train net output #0: accuracy = 0.949671
I0831 20:14:05.157727 24386 solver.cpp:244]     Train net output #1: loss = 5496.58 (* 1 = 5496.58 loss)
I0831 20:14:05.157737 24386 sgd_solver.cpp:106] Iteration 11550, lr = 1e-07
I0831 20:15:56.544611 24386 solver.cpp:337] Iteration 11600, Testing net (#0)
I0831 20:16:05.591862 24386 solver.cpp:404]     Test net output #0: accuracy = 0.916265
I0831 20:16:05.591905 24386 solver.cpp:404]     Test net output #1: loss = 8579.12 (* 1 = 8579.12 loss)
I0831 20:16:07.674829 24386 solver.cpp:228] Iteration 11600, loss = 10555
I0831 20:16:07.674876 24386 solver.cpp:244]     Train net output #0: accuracy = 0.895074
I0831 20:16:07.674890 24386 solver.cpp:244]     Train net output #1: loss = 10555 (* 1 = 10555 loss)
I0831 20:16:07.674899 24386 sgd_solver.cpp:106] Iteration 11600, lr = 1e-07
I0831 20:18:04.523103 24386 solver.cpp:228] Iteration 11650, loss = 11337.6
I0831 20:18:04.523197 24386 solver.cpp:244]     Train net output #0: accuracy = 0.895081
I0831 20:18:04.523210 24386 solver.cpp:244]     Train net output #1: loss = 11337.6 (* 1 = 11337.6 loss)
I0831 20:18:04.523224 24386 sgd_solver.cpp:106] Iteration 11650, lr = 1e-07
I0831 20:19:58.985309 24386 solver.cpp:228] Iteration 11700, loss = 6314.05
I0831 20:19:58.985451 24386 solver.cpp:244]     Train net output #0: accuracy = 0.939332
I0831 20:19:58.985469 24386 solver.cpp:244]     Train net output #1: loss = 6314.05 (* 1 = 6314.05 loss)
I0831 20:19:58.985479 24386 sgd_solver.cpp:106] Iteration 11700, lr = 1e-07
I0831 20:21:53.651553 24386 solver.cpp:228] Iteration 11750, loss = 4994.73
I0831 20:21:53.651640 24386 solver.cpp:244]     Train net output #0: accuracy = 0.952075
I0831 20:21:53.651654 24386 solver.cpp:244]     Train net output #1: loss = 4994.73 (* 1 = 4994.73 loss)
I0831 20:21:53.651662 24386 sgd_solver.cpp:106] Iteration 11750, lr = 1e-07
I0831 20:23:46.096961 24386 solver.cpp:337] Iteration 11800, Testing net (#0)
I0831 20:23:55.613569 24386 solver.cpp:404]     Test net output #0: accuracy = 0.916087
I0831 20:23:55.613626 24386 solver.cpp:404]     Test net output #1: loss = 8593.99 (* 1 = 8593.99 loss)
I0831 20:23:57.706059 24386 solver.cpp:228] Iteration 11800, loss = 4810.24
I0831 20:23:57.706099 24386 solver.cpp:244]     Train net output #0: accuracy = 0.953229
I0831 20:23:57.706109 24386 solver.cpp:244]     Train net output #1: loss = 4810.24 (* 1 = 4810.24 loss)
I0831 20:23:57.706115 24386 sgd_solver.cpp:106] Iteration 11800, lr = 1e-07
I0831 20:25:51.625484 24386 solver.cpp:228] Iteration 11850, loss = 9037.98
I0831 20:25:51.625574 24386 solver.cpp:244]     Train net output #0: accuracy = 0.91522
I0831 20:25:51.625592 24386 solver.cpp:244]     Train net output #1: loss = 9037.98 (* 1 = 9037.98 loss)
I0831 20:25:51.625600 24386 sgd_solver.cpp:106] Iteration 11850, lr = 1e-07
I0831 20:27:48.385006 24386 solver.cpp:228] Iteration 11900, loss = 5025.91
I0831 20:27:48.385115 24386 solver.cpp:244]     Train net output #0: accuracy = 0.949277
I0831 20:27:48.385135 24386 solver.cpp:244]     Train net output #1: loss = 5025.91 (* 1 = 5025.91 loss)
I0831 20:27:48.385145 24386 sgd_solver.cpp:106] Iteration 11900, lr = 1e-07
I0831 20:29:45.313143 24386 solver.cpp:228] Iteration 11950, loss = 7033.86
I0831 20:29:45.313247 24386 solver.cpp:244]     Train net output #0: accuracy = 0.931722
I0831 20:29:45.313271 24386 solver.cpp:244]     Train net output #1: loss = 7033.87 (* 1 = 7033.87 loss)
I0831 20:29:45.313282 24386 sgd_solver.cpp:106] Iteration 11950, lr = 1e-07
I0831 20:31:37.659695 24386 solver.cpp:454] Snapshotting to binary proto file portrait_wb_one_stage3_iter_12000.caffemodel
I0831 20:31:37.683871 24386 sgd_solver.cpp:273] Snapshotting solver state to binary proto file portrait_wb_one_stage3_iter_12000.solverstate
I0831 20:31:37.685057 24386 solver.cpp:337] Iteration 12000, Testing net (#0)
I0831 20:31:46.668229 24386 solver.cpp:404]     Test net output #0: accuracy = 0.916127
I0831 20:31:46.668275 24386 solver.cpp:404]     Test net output #1: loss = 8591.13 (* 1 = 8591.13 loss)
I0831 20:31:48.837509 24386 solver.cpp:228] Iteration 12000, loss = 7992.4
I0831 20:31:48.837559 24386 solver.cpp:244]     Train net output #0: accuracy = 0.924375
I0831 20:31:48.837574 24386 solver.cpp:244]     Train net output #1: loss = 7992.41 (* 1 = 7992.41 loss)
I0831 20:31:48.839277 24386 sgd_solver.cpp:106] Iteration 12000, lr = 1e-08
I0831 20:33:44.062351 24386 solver.cpp:228] Iteration 12050, loss = 9011.24
I0831 20:33:44.062463 24386 solver.cpp:244]     Train net output #0: accuracy = 0.911207
I0831 20:33:44.062479 24386 solver.cpp:244]     Train net output #1: loss = 9011.24 (* 1 = 9011.24 loss)
I0831 20:33:44.062489 24386 sgd_solver.cpp:106] Iteration 12050, lr = 1e-08
I0831 20:35:39.699810 24386 solver.cpp:228] Iteration 12100, loss = 338.967
I0831 20:35:39.699897 24386 solver.cpp:244]     Train net output #0: accuracy = 0.998865
I0831 20:35:39.699908 24386 solver.cpp:244]     Train net output #1: loss = 338.969 (* 1 = 338.969 loss)
I0831 20:35:39.699915 24386 sgd_solver.cpp:106] Iteration 12100, lr = 1e-08
I0831 20:37:34.267199 24386 solver.cpp:228] Iteration 12150, loss = 5920.3
I0831 20:37:34.267292 24386 solver.cpp:244]     Train net output #0: accuracy = 0.943239
I0831 20:37:34.267307 24386 solver.cpp:244]     Train net output #1: loss = 5920.3 (* 1 = 5920.3 loss)
I0831 20:37:34.267315 24386 sgd_solver.cpp:106] Iteration 12150, lr = 1e-08
I0831 20:39:28.939623 24386 solver.cpp:337] Iteration 12200, Testing net (#0)
I0831 20:39:38.625569 24386 solver.cpp:404]     Test net output #0: accuracy = 0.916041
I0831 20:39:38.625612 24386 solver.cpp:404]     Test net output #1: loss = 8599.13 (* 1 = 8599.13 loss)
I0831 20:39:40.721690 24386 solver.cpp:228] Iteration 12200, loss = 10664.5
I0831 20:39:40.721742 24386 solver.cpp:244]     Train net output #0: accuracy = 0.895876
I0831 20:39:40.721761 24386 solver.cpp:244]     Train net output #1: loss = 10664.5 (* 1 = 10664.5 loss)
I0831 20:39:40.721773 24386 sgd_solver.cpp:106] Iteration 12200, lr = 1e-08
I0831 20:41:36.183106 24386 solver.cpp:228] Iteration 12250, loss = 7905.94
I0831 20:41:36.183202 24386 solver.cpp:244]     Train net output #0: accuracy = 0.924454
I0831 20:41:36.183215 24386 solver.cpp:244]     Train net output #1: loss = 7905.94 (* 1 = 7905.94 loss)
I0831 20:41:36.183223 24386 sgd_solver.cpp:106] Iteration 12250, lr = 1e-08
I0831 20:43:31.661036 24386 solver.cpp:228] Iteration 12300, loss = 5552.11
I0831 20:43:31.661140 24386 solver.cpp:244]     Train net output #0: accuracy = 0.944971
I0831 20:43:31.661155 24386 solver.cpp:244]     Train net output #1: loss = 5552.11 (* 1 = 5552.11 loss)
I0831 20:43:31.661165 24386 sgd_solver.cpp:106] Iteration 12300, lr = 1e-08
I0831 20:45:25.647994 24386 solver.cpp:228] Iteration 12350, loss = 5451.12
I0831 20:45:25.648075 24386 solver.cpp:244]     Train net output #0: accuracy = 0.945395
I0831 20:45:25.648087 24386 solver.cpp:244]     Train net output #1: loss = 5451.12 (* 1 = 5451.12 loss)
I0831 20:45:25.648094 24386 sgd_solver.cpp:106] Iteration 12350, lr = 1e-08
I0831 20:47:19.441990 24386 solver.cpp:337] Iteration 12400, Testing net (#0)
I0831 20:47:28.934608 24386 solver.cpp:404]     Test net output #0: accuracy = 0.914942
I0831 20:47:28.934653 24386 solver.cpp:404]     Test net output #1: loss = 8735.65 (* 1 = 8735.65 loss)
I0831 20:47:30.991068 24386 solver.cpp:228] Iteration 12400, loss = 9604.72
I0831 20:47:30.991118 24386 solver.cpp:244]     Train net output #0: accuracy = 0.905279
I0831 20:47:30.991132 24386 solver.cpp:244]     Train net output #1: loss = 9604.72 (* 1 = 9604.72 loss)
I0831 20:47:30.991142 24386 sgd_solver.cpp:106] Iteration 12400, lr = 1e-08
I0831 20:49:24.972688 24386 solver.cpp:228] Iteration 12450, loss = 10323.8
I0831 20:49:24.972808 24386 solver.cpp:244]     Train net output #0: accuracy = 0.899639
I0831 20:49:24.972826 24386 solver.cpp:244]     Train net output #1: loss = 10323.8 (* 1 = 10323.8 loss)
I0831 20:49:24.972836 24386 sgd_solver.cpp:106] Iteration 12450, lr = 1e-08
I0831 20:51:21.225402 24386 solver.cpp:228] Iteration 12500, loss = 6246.57
I0831 20:51:21.225533 24386 solver.cpp:244]     Train net output #0: accuracy = 0.937892
I0831 20:51:21.225549 24386 solver.cpp:244]     Train net output #1: loss = 6246.57 (* 1 = 6246.57 loss)
I0831 20:51:21.225561 24386 sgd_solver.cpp:106] Iteration 12500, lr = 1e-08
I0831 20:53:17.186192 24386 solver.cpp:228] Iteration 12550, loss = 5217.56
I0831 20:53:17.186280 24386 solver.cpp:244]     Train net output #0: accuracy = 0.948996
I0831 20:53:17.186291 24386 solver.cpp:244]     Train net output #1: loss = 5217.56 (* 1 = 5217.56 loss)
I0831 20:53:17.186300 24386 sgd_solver.cpp:106] Iteration 12550, lr = 1e-08
I0831 20:55:09.409651 24386 solver.cpp:337] Iteration 12600, Testing net (#0)
I0831 20:55:18.399050 24386 solver.cpp:404]     Test net output #0: accuracy = 0.914657
I0831 20:55:18.399092 24386 solver.cpp:404]     Test net output #1: loss = 8739.22 (* 1 = 8739.22 loss)
I0831 20:55:20.240777 24386 solver.cpp:228] Iteration 12600, loss = 7804.63
I0831 20:55:20.240828 24386 solver.cpp:244]     Train net output #0: accuracy = 0.922357
I0831 20:55:20.240842 24386 solver.cpp:244]     Train net output #1: loss = 7804.64 (* 1 = 7804.64 loss)
I0831 20:55:20.240866 24386 sgd_solver.cpp:106] Iteration 12600, lr = 1e-08
I0831 20:57:17.134860 24386 solver.cpp:228] Iteration 12650, loss = 375.174
I0831 20:57:17.135010 24386 solver.cpp:244]     Train net output #0: accuracy = 0.998671
I0831 20:57:17.135028 24386 solver.cpp:244]     Train net output #1: loss = 375.176 (* 1 = 375.176 loss)
I0831 20:57:17.135040 24386 sgd_solver.cpp:106] Iteration 12650, lr = 1e-08
I0831 20:59:11.414158 24386 solver.cpp:228] Iteration 12700, loss = 5796.85
I0831 20:59:11.414242 24386 solver.cpp:244]     Train net output #0: accuracy = 0.943951
I0831 20:59:11.414254 24386 solver.cpp:244]     Train net output #1: loss = 5796.85 (* 1 = 5796.85 loss)
I0831 20:59:11.414261 24386 sgd_solver.cpp:106] Iteration 12700, lr = 1e-08
I0831 21:01:06.436085 24386 solver.cpp:228] Iteration 12750, loss = 6594.05
I0831 21:01:06.436200 24386 solver.cpp:244]     Train net output #0: accuracy = 0.935827
I0831 21:01:06.436216 24386 solver.cpp:244]     Train net output #1: loss = 6594.05 (* 1 = 6594.05 loss)
I0831 21:01:06.436228 24386 sgd_solver.cpp:106] Iteration 12750, lr = 1e-08
I0831 21:02:56.065960 24386 solver.cpp:337] Iteration 12800, Testing net (#0)
I0831 21:03:05.255870 24386 solver.cpp:404]     Test net output #0: accuracy = 0.915165
I0831 21:03:05.255914 24386 solver.cpp:404]     Test net output #1: loss = 8695.27 (* 1 = 8695.27 loss)
I0831 21:03:07.213174 24386 solver.cpp:228] Iteration 12800, loss = 6902.5
I0831 21:03:07.213214 24386 solver.cpp:244]     Train net output #0: accuracy = 0.931289
I0831 21:03:07.213223 24386 solver.cpp:244]     Train net output #1: loss = 6902.5 (* 1 = 6902.5 loss)
I0831 21:03:07.213232 24386 sgd_solver.cpp:106] Iteration 12800, lr = 1e-08
I0831 21:05:03.131494 24386 solver.cpp:228] Iteration 12850, loss = 8474.17
I0831 21:05:03.131595 24386 solver.cpp:244]     Train net output #0: accuracy = 0.914783
I0831 21:05:03.131608 24386 solver.cpp:244]     Train net output #1: loss = 8474.17 (* 1 = 8474.17 loss)
I0831 21:05:03.131615 24386 sgd_solver.cpp:106] Iteration 12850, lr = 1e-08
I0831 21:06:57.226848 24386 solver.cpp:228] Iteration 12900, loss = 6363.43
I0831 21:06:57.226956 24386 solver.cpp:244]     Train net output #0: accuracy = 0.938323
I0831 21:06:57.226975 24386 solver.cpp:244]     Train net output #1: loss = 6363.44 (* 1 = 6363.44 loss)
I0831 21:06:57.226985 24386 sgd_solver.cpp:106] Iteration 12900, lr = 1e-08
I0831 21:08:52.874837 24386 solver.cpp:228] Iteration 12950, loss = 9726.01
I0831 21:08:52.874930 24386 solver.cpp:244]     Train net output #0: accuracy = 0.906352
I0831 21:08:52.874941 24386 solver.cpp:244]     Train net output #1: loss = 9726.01 (* 1 = 9726.01 loss)
I0831 21:08:52.874948 24386 sgd_solver.cpp:106] Iteration 12950, lr = 1e-08
I0831 21:10:44.646805 24386 solver.cpp:337] Iteration 13000, Testing net (#0)
I0831 21:10:53.968864 24386 solver.cpp:404]     Test net output #0: accuracy = 0.914548
I0831 21:10:53.968909 24386 solver.cpp:404]     Test net output #1: loss = 8754.86 (* 1 = 8754.86 loss)
I0831 21:10:55.910637 24386 solver.cpp:228] Iteration 13000, loss = 10294.6
I0831 21:10:55.910686 24386 solver.cpp:244]     Train net output #0: accuracy = 0.904007
I0831 21:10:55.910701 24386 solver.cpp:244]     Train net output #1: loss = 10294.6 (* 1 = 10294.6 loss)
I0831 21:10:55.910711 24386 sgd_solver.cpp:106] Iteration 13000, lr = 1e-08
I0831 21:12:46.287194 24386 solver.cpp:228] Iteration 13050, loss = 7510.45
I0831 21:12:46.287308 24386 solver.cpp:244]     Train net output #0: accuracy = 0.926459
I0831 21:12:46.287325 24386 solver.cpp:244]     Train net output #1: loss = 7510.45 (* 1 = 7510.45 loss)
I0831 21:12:46.287336 24386 sgd_solver.cpp:106] Iteration 13050, lr = 1e-08
I0831 21:14:41.750664 24386 solver.cpp:228] Iteration 13100, loss = 5011.31
I0831 21:14:41.750746 24386 solver.cpp:244]     Train net output #0: accuracy = 0.951556
I0831 21:14:41.750757 24386 solver.cpp:244]     Train net output #1: loss = 5011.31 (* 1 = 5011.31 loss)
I0831 21:14:41.750764 24386 sgd_solver.cpp:106] Iteration 13100, lr = 1e-08
I0831 21:16:34.440768 24386 solver.cpp:228] Iteration 13150, loss = 5370.52
I0831 21:16:34.440913 24386 solver.cpp:244]     Train net output #0: accuracy = 0.946477
I0831 21:16:34.440934 24386 solver.cpp:244]     Train net output #1: loss = 5370.52 (* 1 = 5370.52 loss)
I0831 21:16:34.440944 24386 sgd_solver.cpp:106] Iteration 13150, lr = 1e-08
I0831 21:18:27.690321 24386 solver.cpp:337] Iteration 13200, Testing net (#0)
I0831 21:18:36.576721 24386 solver.cpp:404]     Test net output #0: accuracy = 0.915058
I0831 21:18:36.576781 24386 solver.cpp:404]     Test net output #1: loss = 8714.38 (* 1 = 8714.38 loss)
I0831 21:18:38.747050 24386 solver.cpp:228] Iteration 13200, loss = 9100.13
I0831 21:18:38.747089 24386 solver.cpp:244]     Train net output #0: accuracy = 0.909459
I0831 21:18:38.747098 24386 solver.cpp:244]     Train net output #1: loss = 9100.13 (* 1 = 9100.13 loss)
I0831 21:18:38.747105 24386 sgd_solver.cpp:106] Iteration 13200, lr = 1e-08
I0831 21:20:32.615705 24386 solver.cpp:228] Iteration 13250, loss = 5343.4
I0831 21:20:32.615795 24386 solver.cpp:244]     Train net output #0: accuracy = 0.949094
I0831 21:20:32.615808 24386 solver.cpp:244]     Train net output #1: loss = 5343.4 (* 1 = 5343.4 loss)
I0831 21:20:32.615818 24386 sgd_solver.cpp:106] Iteration 13250, lr = 1e-08
I0831 21:22:26.787360 24386 solver.cpp:228] Iteration 13300, loss = 5924.99
I0831 21:22:26.787443 24386 solver.cpp:244]     Train net output #0: accuracy = 0.941398
I0831 21:22:26.787454 24386 solver.cpp:244]     Train net output #1: loss = 5924.99 (* 1 = 5924.99 loss)
I0831 21:22:26.787461 24386 sgd_solver.cpp:106] Iteration 13300, lr = 1e-08
I0831 21:24:18.416390 24386 solver.cpp:228] Iteration 13350, loss = 5215.51
I0831 21:24:18.416493 24386 solver.cpp:244]     Train net output #0: accuracy = 0.95121
I0831 21:24:18.416510 24386 solver.cpp:244]     Train net output #1: loss = 5215.51 (* 1 = 5215.51 loss)
I0831 21:24:18.416520 24386 sgd_solver.cpp:106] Iteration 13350, lr = 1e-08
I0831 21:26:11.993614 24386 solver.cpp:337] Iteration 13400, Testing net (#0)
I0831 21:26:21.194381 24386 solver.cpp:404]     Test net output #0: accuracy = 0.916129
I0831 21:26:21.194429 24386 solver.cpp:404]     Test net output #1: loss = 8594.08 (* 1 = 8594.08 loss)
I0831 21:26:23.252326 24386 solver.cpp:228] Iteration 13400, loss = 8165.93
I0831 21:26:23.252380 24386 solver.cpp:244]     Train net output #0: accuracy = 0.917507
I0831 21:26:23.252398 24386 solver.cpp:244]     Train net output #1: loss = 8165.93 (* 1 = 8165.93 loss)
I0831 21:26:23.252408 24386 sgd_solver.cpp:106] Iteration 13400, lr = 1e-08
I0831 21:28:18.681066 24386 solver.cpp:228] Iteration 13450, loss = 521.331
I0831 21:28:18.681170 24386 solver.cpp:244]     Train net output #0: accuracy = 0.998603
I0831 21:28:18.681185 24386 solver.cpp:244]     Train net output #1: loss = 521.332 (* 1 = 521.332 loss)
I0831 21:28:18.681196 24386 sgd_solver.cpp:106] Iteration 13450, lr = 1e-08
I0831 21:30:14.731232 24386 solver.cpp:228] Iteration 13500, loss = 5411.58
I0831 21:30:14.731319 24386 solver.cpp:244]     Train net output #0: accuracy = 0.94879
I0831 21:30:14.731333 24386 solver.cpp:244]     Train net output #1: loss = 5411.58 (* 1 = 5411.58 loss)
I0831 21:30:14.731340 24386 sgd_solver.cpp:106] Iteration 13500, lr = 1e-08
I0831 21:32:09.831146 24386 solver.cpp:228] Iteration 13550, loss = 10567.1
I0831 21:32:09.831234 24386 solver.cpp:244]     Train net output #0: accuracy = 0.897071
I0831 21:32:09.831246 24386 solver.cpp:244]     Train net output #1: loss = 10567.1 (* 1 = 10567.1 loss)
I0831 21:32:09.831254 24386 sgd_solver.cpp:106] Iteration 13550, lr = 1e-08
I0831 21:34:00.133249 24386 solver.cpp:337] Iteration 13600, Testing net (#0)
I0831 21:34:09.793956 24386 solver.cpp:404]     Test net output #0: accuracy = 0.916101
I0831 21:34:09.794013 24386 solver.cpp:404]     Test net output #1: loss = 8598.61 (* 1 = 8598.61 loss)
I0831 21:34:12.103945 24386 solver.cpp:228] Iteration 13600, loss = 7450.83
I0831 21:34:12.103996 24386 solver.cpp:244]     Train net output #0: accuracy = 0.928237
I0831 21:34:12.104009 24386 solver.cpp:244]     Train net output #1: loss = 7450.83 (* 1 = 7450.83 loss)
I0831 21:34:12.104035 24386 sgd_solver.cpp:106] Iteration 13600, lr = 1e-08
I0831 21:36:12.641770 24386 solver.cpp:228] Iteration 13650, loss = 8796.08
I0831 21:36:12.641901 24386 solver.cpp:244]     Train net output #0: accuracy = 0.913834
I0831 21:36:12.641913 24386 solver.cpp:244]     Train net output #1: loss = 8796.08 (* 1 = 8796.08 loss)
I0831 21:36:12.641922 24386 sgd_solver.cpp:106] Iteration 13650, lr = 1e-08
I0831 21:38:09.271322 24386 solver.cpp:228] Iteration 13700, loss = 5690.51
I0831 21:38:09.271438 24386 solver.cpp:244]     Train net output #0: accuracy = 0.947567
I0831 21:38:09.271455 24386 solver.cpp:244]     Train net output #1: loss = 5690.51 (* 1 = 5690.51 loss)
I0831 21:38:09.271466 24386 sgd_solver.cpp:106] Iteration 13700, lr = 1e-08
I0831 21:40:04.550940 24386 solver.cpp:228] Iteration 13750, loss = 10716.9
I0831 21:40:04.551110 24386 solver.cpp:244]     Train net output #0: accuracy = 0.893328
I0831 21:40:04.551123 24386 solver.cpp:244]     Train net output #1: loss = 10716.9 (* 1 = 10716.9 loss)
I0831 21:40:04.551131 24386 sgd_solver.cpp:106] Iteration 13750, lr = 1e-08
I0831 21:41:57.197674 24386 solver.cpp:337] Iteration 13800, Testing net (#0)
I0831 21:42:06.915704 24386 solver.cpp:404]     Test net output #0: accuracy = 0.916182
I0831 21:42:06.915747 24386 solver.cpp:404]     Test net output #1: loss = 8590.36 (* 1 = 8590.36 loss)
I0831 21:42:08.643489 24386 solver.cpp:228] Iteration 13800, loss = 11301.1
I0831 21:42:08.643532 24386 solver.cpp:244]     Train net output #0: accuracy = 0.894995
I0831 21:42:08.643543 24386 solver.cpp:244]     Train net output #1: loss = 11301.1 (* 1 = 11301.1 loss)
I0831 21:42:08.643550 24386 sgd_solver.cpp:106] Iteration 13800, lr = 1e-08
I0831 21:44:02.728019 24386 solver.cpp:228] Iteration 13850, loss = 6345.97
I0831 21:44:02.728103 24386 solver.cpp:244]     Train net output #0: accuracy = 0.938226
I0831 21:44:02.728114 24386 solver.cpp:244]     Train net output #1: loss = 6345.97 (* 1 = 6345.97 loss)
I0831 21:44:02.728122 24386 sgd_solver.cpp:106] Iteration 13850, lr = 1e-08
I0831 21:45:59.170735 24386 solver.cpp:228] Iteration 13900, loss = 5020.01
I0831 21:45:59.170821 24386 solver.cpp:244]     Train net output #0: accuracy = 0.950983
I0831 21:45:59.170833 24386 solver.cpp:244]     Train net output #1: loss = 5020.01 (* 1 = 5020.01 loss)
I0831 21:45:59.170840 24386 sgd_solver.cpp:106] Iteration 13900, lr = 1e-08
I0831 21:47:52.257844 24386 solver.cpp:228] Iteration 13950, loss = 4673.2
I0831 21:47:52.257930 24386 solver.cpp:244]     Train net output #0: accuracy = 0.95464
I0831 21:47:52.257942 24386 solver.cpp:244]     Train net output #1: loss = 4673.2 (* 1 = 4673.2 loss)
I0831 21:47:52.257951 24386 sgd_solver.cpp:106] Iteration 13950, lr = 1e-08
I0831 21:49:43.650275 24386 solver.cpp:337] Iteration 14000, Testing net (#0)
I0831 21:49:52.870515 24386 solver.cpp:404]     Test net output #0: accuracy = 0.916396
I0831 21:49:52.870573 24386 solver.cpp:404]     Test net output #1: loss = 8567.81 (* 1 = 8567.81 loss)
I0831 21:49:54.929253 24386 solver.cpp:228] Iteration 14000, loss = 9405.07
I0831 21:49:54.929296 24386 solver.cpp:244]     Train net output #0: accuracy = 0.909581
I0831 21:49:54.929306 24386 solver.cpp:244]     Train net output #1: loss = 9405.07 (* 1 = 9405.07 loss)
I0831 21:49:54.929314 24386 sgd_solver.cpp:106] Iteration 14000, lr = 1e-08
I0831 21:51:50.901495 24386 solver.cpp:228] Iteration 14050, loss = 5099.98
I0831 21:51:50.901582 24386 solver.cpp:244]     Train net output #0: accuracy = 0.948796
I0831 21:51:50.901598 24386 solver.cpp:244]     Train net output #1: loss = 5099.98 (* 1 = 5099.98 loss)
I0831 21:51:50.901608 24386 sgd_solver.cpp:106] Iteration 14050, lr = 1e-08
I0831 21:53:49.279086 24386 solver.cpp:228] Iteration 14100, loss = 6672.31
I0831 21:53:49.279188 24386 solver.cpp:244]     Train net output #0: accuracy = 0.934905
I0831 21:53:49.279204 24386 solver.cpp:244]     Train net output #1: loss = 6672.31 (* 1 = 6672.31 loss)
I0831 21:53:49.279214 24386 sgd_solver.cpp:106] Iteration 14100, lr = 1e-08
I0831 21:55:45.371886 24386 solver.cpp:228] Iteration 14150, loss = 7907.98
I0831 21:55:45.371999 24386 solver.cpp:244]     Train net output #0: accuracy = 0.925259
I0831 21:55:45.372011 24386 solver.cpp:244]     Train net output #1: loss = 7907.98 (* 1 = 7907.98 loss)
I0831 21:55:45.372019 24386 sgd_solver.cpp:106] Iteration 14150, lr = 1e-08
I0831 21:57:38.037256 24386 solver.cpp:337] Iteration 14200, Testing net (#0)
I0831 21:57:47.578363 24386 solver.cpp:404]     Test net output #0: accuracy = 0.914996
I0831 21:57:47.578424 24386 solver.cpp:404]     Test net output #1: loss = 8697.43 (* 1 = 8697.43 loss)
I0831 21:57:49.730628 24386 solver.cpp:228] Iteration 14200, loss = 8711.48
I0831 21:57:49.730682 24386 solver.cpp:244]     Train net output #0: accuracy = 0.913579
I0831 21:57:49.730700 24386 solver.cpp:244]     Train net output #1: loss = 8711.48 (* 1 = 8711.48 loss)
I0831 21:57:49.730711 24386 sgd_solver.cpp:106] Iteration 14200, lr = 1e-08
I0831 21:59:43.169401 24386 solver.cpp:228] Iteration 14250, loss = 304.443
I0831 21:59:43.169493 24386 solver.cpp:244]     Train net output #0: accuracy = 0.999223
I0831 21:59:43.169505 24386 solver.cpp:244]     Train net output #1: loss = 304.443 (* 1 = 304.443 loss)
I0831 21:59:43.169512 24386 sgd_solver.cpp:106] Iteration 14250, lr = 1e-08
I0831 22:01:35.816587 24386 solver.cpp:228] Iteration 14300, loss = 5469.22
I0831 22:01:35.816694 24386 solver.cpp:244]     Train net output #0: accuracy = 0.946859
I0831 22:01:35.816709 24386 solver.cpp:244]     Train net output #1: loss = 5469.22 (* 1 = 5469.22 loss)
I0831 22:01:35.816720 24386 sgd_solver.cpp:106] Iteration 14300, lr = 1e-08
I0831 22:03:33.057132 24386 solver.cpp:228] Iteration 14350, loss = 10679.5
I0831 22:03:33.057250 24386 solver.cpp:244]     Train net output #0: accuracy = 0.894937
I0831 22:03:33.057276 24386 solver.cpp:244]     Train net output #1: loss = 10679.5 (* 1 = 10679.5 loss)
I0831 22:03:33.057289 24386 sgd_solver.cpp:106] Iteration 14350, lr = 1e-08
I0831 22:05:29.253087 24386 solver.cpp:337] Iteration 14400, Testing net (#0)
I0831 22:05:39.447118 24386 solver.cpp:404]     Test net output #0: accuracy = 0.91497
I0831 22:05:39.447180 24386 solver.cpp:404]     Test net output #1: loss = 8712.12 (* 1 = 8712.12 loss)
I0831 22:05:41.508409 24386 solver.cpp:228] Iteration 14400, loss = 7937.23
I0831 22:05:41.508462 24386 solver.cpp:244]     Train net output #0: accuracy = 0.923807
I0831 22:05:41.508473 24386 solver.cpp:244]     Train net output #1: loss = 7937.23 (* 1 = 7937.23 loss)
I0831 22:05:41.508483 24386 sgd_solver.cpp:106] Iteration 14400, lr = 1e-08
I0831 22:07:37.390743 24386 solver.cpp:228] Iteration 14450, loss = 5705.73
I0831 22:07:37.390841 24386 solver.cpp:244]     Train net output #0: accuracy = 0.944199
I0831 22:07:37.390853 24386 solver.cpp:244]     Train net output #1: loss = 5705.73 (* 1 = 5705.73 loss)
I0831 22:07:37.390861 24386 sgd_solver.cpp:106] Iteration 14450, lr = 1e-08
I0831 22:09:32.584883 24386 solver.cpp:228] Iteration 14500, loss = 5497.51
I0831 22:09:32.584975 24386 solver.cpp:244]     Train net output #0: accuracy = 0.945211
I0831 22:09:32.584986 24386 solver.cpp:244]     Train net output #1: loss = 5497.51 (* 1 = 5497.51 loss)
I0831 22:09:32.584995 24386 sgd_solver.cpp:106] Iteration 14500, lr = 1e-08
I0831 22:11:28.963038 24386 solver.cpp:228] Iteration 14550, loss = 9490.84
I0831 22:11:28.963125 24386 solver.cpp:244]     Train net output #0: accuracy = 0.907013
I0831 22:11:28.963137 24386 solver.cpp:244]     Train net output #1: loss = 9490.84 (* 1 = 9490.84 loss)
I0831 22:11:28.963145 24386 sgd_solver.cpp:106] Iteration 14550, lr = 1e-08
I0831 22:13:23.149504 24386 solver.cpp:337] Iteration 14600, Testing net (#0)
I0831 22:13:32.140118 24386 solver.cpp:404]     Test net output #0: accuracy = 0.914978
I0831 22:13:32.140167 24386 solver.cpp:404]     Test net output #1: loss = 8702.81 (* 1 = 8702.81 loss)
I0831 22:13:34.224306 24386 solver.cpp:228] Iteration 14600, loss = 10027.2
I0831 22:13:34.224370 24386 solver.cpp:244]     Train net output #0: accuracy = 0.904201
I0831 22:13:34.224403 24386 solver.cpp:244]     Train net output #1: loss = 10027.2 (* 1 = 10027.2 loss)
I0831 22:13:34.224419 24386 sgd_solver.cpp:106] Iteration 14600, lr = 1e-08
I0831 22:15:27.927850 24386 solver.cpp:228] Iteration 14650, loss = 6308.85
I0831 22:15:27.927968 24386 solver.cpp:244]     Train net output #0: accuracy = 0.937748
I0831 22:15:27.927980 24386 solver.cpp:244]     Train net output #1: loss = 6308.85 (* 1 = 6308.85 loss)
I0831 22:15:27.927989 24386 sgd_solver.cpp:106] Iteration 14650, lr = 1e-08
I0831 22:17:22.001807 24386 solver.cpp:228] Iteration 14700, loss = 5080.01
I0831 22:17:22.001894 24386 solver.cpp:244]     Train net output #0: accuracy = 0.951243
I0831 22:17:22.001905 24386 solver.cpp:244]     Train net output #1: loss = 5080.01 (* 1 = 5080.01 loss)
I0831 22:17:22.001914 24386 sgd_solver.cpp:106] Iteration 14700, lr = 1e-08
I0831 22:19:12.555902 24386 solver.cpp:228] Iteration 14750, loss = 7650.79
I0831 22:19:12.556006 24386 solver.cpp:244]     Train net output #0: accuracy = 0.925669
I0831 22:19:12.556028 24386 solver.cpp:244]     Train net output #1: loss = 7650.79 (* 1 = 7650.79 loss)
I0831 22:19:12.556041 24386 sgd_solver.cpp:106] Iteration 14750, lr = 1e-08
I0831 22:21:07.664257 24386 solver.cpp:337] Iteration 14800, Testing net (#0)
I0831 22:21:16.911065 24386 solver.cpp:404]     Test net output #0: accuracy = 0.915228
I0831 22:21:16.911114 24386 solver.cpp:404]     Test net output #1: loss = 8680.49 (* 1 = 8680.49 loss)
I0831 22:21:18.595090 24386 solver.cpp:228] Iteration 14800, loss = 250.73
I0831 22:21:18.595134 24386 solver.cpp:244]     Train net output #0: accuracy = 0.999473
I0831 22:21:18.595144 24386 solver.cpp:244]     Train net output #1: loss = 250.73 (* 1 = 250.73 loss)
I0831 22:21:18.595152 24386 sgd_solver.cpp:106] Iteration 14800, lr = 1e-08
I0831 22:23:13.780207 24386 solver.cpp:228] Iteration 14850, loss = 5701.79
I0831 22:23:13.780318 24386 solver.cpp:244]     Train net output #0: accuracy = 0.94442
I0831 22:23:13.780336 24386 solver.cpp:244]     Train net output #1: loss = 5701.79 (* 1 = 5701.79 loss)
I0831 22:23:13.780349 24386 sgd_solver.cpp:106] Iteration 14850, lr = 1e-08
I0831 22:25:10.991348 24386 solver.cpp:228] Iteration 14900, loss = 6441.63
I0831 22:25:10.991451 24386 solver.cpp:244]     Train net output #0: accuracy = 0.936708
I0831 22:25:10.991464 24386 solver.cpp:244]     Train net output #1: loss = 6441.63 (* 1 = 6441.63 loss)
I0831 22:25:10.991472 24386 sgd_solver.cpp:106] Iteration 14900, lr = 1e-08
I0831 22:27:03.992203 24386 solver.cpp:228] Iteration 14950, loss = 6895.7
I0831 22:27:03.992296 24386 solver.cpp:244]     Train net output #0: accuracy = 0.931606
I0831 22:27:03.992308 24386 solver.cpp:244]     Train net output #1: loss = 6895.7 (* 1 = 6895.7 loss)
I0831 22:27:03.992316 24386 sgd_solver.cpp:106] Iteration 14950, lr = 1e-08
I0831 22:28:54.590522 24386 solver.cpp:337] Iteration 15000, Testing net (#0)
I0831 22:29:03.546723 24386 solver.cpp:404]     Test net output #0: accuracy = 0.915268
I0831 22:29:03.546772 24386 solver.cpp:404]     Test net output #1: loss = 8678.11 (* 1 = 8678.11 loss)
I0831 22:29:05.472626 24386 solver.cpp:228] Iteration 15000, loss = 8460.01
I0831 22:29:05.472666 24386 solver.cpp:244]     Train net output #0: accuracy = 0.914729
I0831 22:29:05.472676 24386 solver.cpp:244]     Train net output #1: loss = 8460.01 (* 1 = 8460.01 loss)
I0831 22:29:05.472683 24386 sgd_solver.cpp:106] Iteration 15000, lr = 1e-08
I0831 22:30:58.300915 24386 solver.cpp:228] Iteration 15050, loss = 5804.81
I0831 22:30:58.301005 24386 solver.cpp:244]     Train net output #0: accuracy = 0.942143
I0831 22:30:58.301018 24386 solver.cpp:244]     Train net output #1: loss = 5804.81 (* 1 = 5804.81 loss)
I0831 22:30:58.301026 24386 sgd_solver.cpp:106] Iteration 15050, lr = 1e-08
I0831 22:32:54.966045 24386 solver.cpp:228] Iteration 15100, loss = 9486.07
I0831 22:32:54.966147 24386 solver.cpp:244]     Train net output #0: accuracy = 0.908595
I0831 22:32:54.966159 24386 solver.cpp:244]     Train net output #1: loss = 9486.07 (* 1 = 9486.07 loss)
I0831 22:32:54.966174 24386 sgd_solver.cpp:106] Iteration 15100, lr = 1e-08
I0831 22:34:43.602583 24386 solver.cpp:228] Iteration 15150, loss = 10357.8
I0831 22:34:43.602705 24386 solver.cpp:244]     Train net output #0: accuracy = 0.903285
I0831 22:34:43.602718 24386 solver.cpp:244]     Train net output #1: loss = 10357.8 (* 1 = 10357.8 loss)
I0831 22:34:43.602726 24386 sgd_solver.cpp:106] Iteration 15150, lr = 1e-08
I0831 22:36:34.572486 24386 solver.cpp:337] Iteration 15200, Testing net (#0)
I0831 22:36:43.675498 24386 solver.cpp:404]     Test net output #0: accuracy = 0.914126
I0831 22:36:43.675544 24386 solver.cpp:404]     Test net output #1: loss = 8758.32 (* 1 = 8758.32 loss)
I0831 22:36:45.787540 24386 solver.cpp:228] Iteration 15200, loss = 7477.31
I0831 22:36:45.787582 24386 solver.cpp:244]     Train net output #0: accuracy = 0.926767
I0831 22:36:45.787592 24386 solver.cpp:244]     Train net output #1: loss = 7477.31 (* 1 = 7477.31 loss)
I0831 22:36:45.787600 24386 sgd_solver.cpp:106] Iteration 15200, lr = 1e-08
I0831 22:38:42.098083 24386 solver.cpp:228] Iteration 15250, loss = 4898.43
I0831 22:38:42.098173 24386 solver.cpp:244]     Train net output #0: accuracy = 0.95297
I0831 22:38:42.098186 24386 solver.cpp:244]     Train net output #1: loss = 4898.43 (* 1 = 4898.43 loss)
I0831 22:38:42.098193 24386 sgd_solver.cpp:106] Iteration 15250, lr = 1e-08
I0831 22:40:37.729603 24386 solver.cpp:228] Iteration 15300, loss = 5432.73
I0831 22:40:37.729686 24386 solver.cpp:244]     Train net output #0: accuracy = 0.945791
I0831 22:40:37.729697 24386 solver.cpp:244]     Train net output #1: loss = 5432.73 (* 1 = 5432.73 loss)
I0831 22:40:37.729706 24386 sgd_solver.cpp:106] Iteration 15300, lr = 1e-08
I0831 22:42:34.027421 24386 solver.cpp:228] Iteration 15350, loss = 9168.82
I0831 22:42:34.027530 24386 solver.cpp:244]     Train net output #0: accuracy = 0.90884
I0831 22:42:34.027544 24386 solver.cpp:244]     Train net output #1: loss = 9168.82 (* 1 = 9168.82 loss)
I0831 22:42:34.027551 24386 sgd_solver.cpp:106] Iteration 15350, lr = 1e-08
I0831 22:44:27.992779 24386 solver.cpp:337] Iteration 15400, Testing net (#0)
I0831 22:44:37.478417 24386 solver.cpp:404]     Test net output #0: accuracy = 0.914582
I0831 22:44:37.478453 24386 solver.cpp:404]     Test net output #1: loss = 8763.14 (* 1 = 8763.14 loss)
I0831 22:44:39.489166 24386 solver.cpp:228] Iteration 15400, loss = 5365.37
I0831 22:44:39.489220 24386 solver.cpp:244]     Train net output #0: accuracy = 0.94894
I0831 22:44:39.489234 24386 solver.cpp:244]     Train net output #1: loss = 5365.37 (* 1 = 5365.37 loss)
I0831 22:44:39.489245 24386 sgd_solver.cpp:106] Iteration 15400, lr = 1e-08
I0831 22:46:34.410910 24386 solver.cpp:228] Iteration 15450, loss = 6100.73
I0831 22:46:34.410996 24386 solver.cpp:244]     Train net output #0: accuracy = 0.939775
I0831 22:46:34.411008 24386 solver.cpp:244]     Train net output #1: loss = 6100.73 (* 1 = 6100.73 loss)
I0831 22:46:34.411016 24386 sgd_solver.cpp:106] Iteration 15450, lr = 1e-08
I0831 22:48:30.205355 24386 solver.cpp:228] Iteration 15500, loss = 5311.73
I0831 22:48:30.205461 24386 solver.cpp:244]     Train net output #0: accuracy = 0.949696
I0831 22:48:30.205478 24386 solver.cpp:244]     Train net output #1: loss = 5311.73 (* 1 = 5311.73 loss)
I0831 22:48:30.205490 24386 sgd_solver.cpp:106] Iteration 15500, lr = 1e-08
I0831 22:50:23.762660 24386 solver.cpp:228] Iteration 15550, loss = 8123.65
I0831 22:50:23.762761 24386 solver.cpp:244]     Train net output #0: accuracy = 0.917745
I0831 22:50:23.762778 24386 solver.cpp:244]     Train net output #1: loss = 8123.65 (* 1 = 8123.65 loss)
I0831 22:50:23.762787 24386 sgd_solver.cpp:106] Iteration 15550, lr = 1e-08
I0831 22:52:13.023530 24386 solver.cpp:337] Iteration 15600, Testing net (#0)
I0831 22:52:22.191269 24386 solver.cpp:404]     Test net output #0: accuracy = 0.914168
I0831 22:52:22.191313 24386 solver.cpp:404]     Test net output #1: loss = 8797.04 (* 1 = 8797.04 loss)
I0831 22:52:24.269454 24386 solver.cpp:228] Iteration 15600, loss = 493.045
I0831 22:52:24.269503 24386 solver.cpp:244]     Train net output #0: accuracy = 0.998754
I0831 22:52:24.269513 24386 solver.cpp:244]     Train net output #1: loss = 493.045 (* 1 = 493.045 loss)
I0831 22:52:24.269520 24386 sgd_solver.cpp:106] Iteration 15600, lr = 1e-08
I0831 22:54:18.332100 24386 solver.cpp:228] Iteration 15650, loss = 5461.58
I0831 22:54:18.332227 24386 solver.cpp:244]     Train net output #0: accuracy = 0.948043
I0831 22:54:18.332242 24386 solver.cpp:244]     Train net output #1: loss = 5461.58 (* 1 = 5461.58 loss)
I0831 22:54:18.332248 24386 sgd_solver.cpp:106] Iteration 15650, lr = 1e-08
I0831 22:56:09.677006 24386 solver.cpp:228] Iteration 15700, loss = 10598.9
I0831 22:56:09.677103 24386 solver.cpp:244]     Train net output #0: accuracy = 0.896417
I0831 22:56:09.677115 24386 solver.cpp:244]     Train net output #1: loss = 10598.9 (* 1 = 10598.9 loss)
I0831 22:56:09.677127 24386 sgd_solver.cpp:106] Iteration 15700, lr = 1e-08
I0831 22:58:02.176458 24386 solver.cpp:228] Iteration 15750, loss = 7494.91
I0831 22:58:02.176549 24386 solver.cpp:244]     Train net output #0: accuracy = 0.927645
I0831 22:58:02.176561 24386 solver.cpp:244]     Train net output #1: loss = 7494.91 (* 1 = 7494.91 loss)
I0831 22:58:02.176569 24386 sgd_solver.cpp:106] Iteration 15750, lr = 1e-08
I0831 22:59:53.922334 24386 solver.cpp:337] Iteration 15800, Testing net (#0)
I0831 23:00:03.363921 24386 solver.cpp:404]     Test net output #0: accuracy = 0.916076
I0831 23:00:03.363966 24386 solver.cpp:404]     Test net output #1: loss = 8616.39 (* 1 = 8616.39 loss)
I0831 23:00:05.370195 24386 solver.cpp:228] Iteration 15800, loss = 8761.99
I0831 23:00:05.370237 24386 solver.cpp:244]     Train net output #0: accuracy = 0.913674
I0831 23:00:05.370247 24386 solver.cpp:244]     Train net output #1: loss = 8761.99 (* 1 = 8761.99 loss)
I0831 23:00:05.370256 24386 sgd_solver.cpp:106] Iteration 15800, lr = 1e-08
I0831 23:02:02.480572 24386 solver.cpp:228] Iteration 15850, loss = 5594.48
I0831 23:02:02.480670 24386 solver.cpp:244]     Train net output #0: accuracy = 0.948021
I0831 23:02:02.480686 24386 solver.cpp:244]     Train net output #1: loss = 5594.48 (* 1 = 5594.48 loss)
I0831 23:02:02.480696 24386 sgd_solver.cpp:106] Iteration 15850, lr = 1e-08
I0831 23:03:54.030122 24386 solver.cpp:228] Iteration 15900, loss = 10689.4
I0831 23:03:54.030202 24386 solver.cpp:244]     Train net output #0: accuracy = 0.893532
I0831 23:03:54.030215 24386 solver.cpp:244]     Train net output #1: loss = 10689.4 (* 1 = 10689.4 loss)
I0831 23:03:54.030222 24386 sgd_solver.cpp:106] Iteration 15900, lr = 1e-08
I0831 23:05:49.759636 24386 solver.cpp:228] Iteration 15950, loss = 11144.2
I0831 23:05:49.759718 24386 solver.cpp:244]     Train net output #0: accuracy = 0.895289
I0831 23:05:49.759732 24386 solver.cpp:244]     Train net output #1: loss = 11144.2 (* 1 = 11144.2 loss)
I0831 23:05:49.759739 24386 sgd_solver.cpp:106] Iteration 15950, lr = 1e-08
I0831 23:07:41.570904 24386 solver.cpp:454] Snapshotting to binary proto file portrait_wb_one_stage3_iter_16000.caffemodel
I0831 23:07:41.583708 24386 sgd_solver.cpp:273] Snapshotting solver state to binary proto file portrait_wb_one_stage3_iter_16000.solverstate
I0831 23:07:42.814342 24386 solver.cpp:317] Iteration 16000, loss = 6358.01
I0831 23:07:42.814388 24386 solver.cpp:337] Iteration 16000, Testing net (#0)
I0831 23:07:52.406785 24386 solver.cpp:404]     Test net output #0: accuracy = 0.916363
I0831 23:07:52.406828 24386 solver.cpp:404]     Test net output #1: loss = 8573.65 (* 1 = 8573.65 loss)
I0831 23:07:52.406834 24386 solver.cpp:322] Optimization Done.
I0831 23:07:52.408816 24386 caffe.cpp:254] Optimization Done.
