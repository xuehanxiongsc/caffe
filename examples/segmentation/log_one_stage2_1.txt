I0823 17:41:14.091743 15833 caffe.cpp:217] Using GPUs 1
I0823 17:41:14.114521 15833 caffe.cpp:222] GPU 1: GeForce GTX TITAN X
I0823 17:41:14.313338 15833 solver.cpp:48] Initializing solver from parameters: 
test_iter: 15
test_interval: 200
base_lr: 1e-05
display: 50
max_iter: 12000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 1e-05
stepsize: 3000
snapshot: 3000
snapshot_prefix: "portrait_one_stage2_1"
solver_mode: GPU
device_id: 1
net: "portrait_train_test_one_stage.prototxt2"
train_state {
  level: 0
  stage: ""
}
I0823 17:41:14.313442 15833 solver.cpp:91] Creating training net from net file: portrait_train_test_one_stage.prototxt2
I0823 17:41:14.314005 15833 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0823 17:41:14.314165 15833 net.cpp:58] Initializing net from parameters: 
name: "segmentation"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "SegData"
  top: "image"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 200
  }
  data_param {
    source: "/raid/xuehan/segmentation_train_split"
    batch_size: 128
    backend: LMDB
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "image"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 50
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv1_1_bn"
  type: "BatchNorm"
  bottom: "conv1_1"
  top: "conv1_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv1_1_bn_scale"
  type: "Scale"
  bottom: "conv1_1_bn"
  top: "conv1_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_1_relu"
  type: "ReLU"
  bottom: "conv1_1_bn"
  top: "conv1_1_bn"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_1_bn"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv2_1_bn"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv2_1_bn_scale"
  type: "Scale"
  bottom: "conv2_1_bn"
  top: "conv2_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1_relu"
  type: "ReLU"
  bottom: "conv2_1_bn"
  top: "conv2_1_bn"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_1_bn"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv3_1_bn"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv3_1_bn_scale"
  type: "Scale"
  bottom: "conv3_1_bn"
  top: "conv3_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1_relu"
  type: "ReLU"
  bottom: "conv3_1_bn"
  top: "conv3_1_bn"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_1_bn"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv4_1_bn"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv4_1_bn_scale"
  type: "Scale"
  bottom: "conv4_1_bn"
  top: "conv4_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1_relu"
  type: "ReLU"
  bottom: "conv4_1_bn"
  top: "conv4_1_bn"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_1_bn"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv5_1_bn"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv5_1_bn_scale"
  type: "Scale"
  bottom: "conv5_1_bn"
  top: "conv5_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_1_relu"
  type: "ReLU"
  bottom: "conv5_1_bn"
  top: "conv5_1_bn"
}
layer {
  name: "conv6_1"
  type: "Convolution"
  bottom: "conv5_1_bn"
  top: "conv6_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv6_1_bn"
  type: "BatchNorm"
  bottom: "conv6_1"
  top: "conv6_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv6_1_bn_scale"
  type: "Scale"
  bottom: "conv6_1_bn"
  top: "conv6_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv6_1_relu"
  type: "ReLU"
  bottom: "conv6_1_bn"
  top: "conv6_1_bn"
}
layer {
  name: "conv7_1"
  type: "Convolution"
  bottom: "conv6_1_bn"
  top: "conv7_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv7_1_bn"
  type: "BatchNorm"
  bottom: "conv7_1"
  top: "conv7_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv7_1_bn_scale"
  type: "Scale"
  bottom: "conv7_1_bn"
  top: "conv7_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv7_1_relu"
  type: "ReLU"
  bottom: "conv7_1_bn"
  top: "conv7_1_bn"
}
layer {
  name: "score"
  type: "Convolution"
  bottom: "conv7_1_bn"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 4
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "upscore"
  type: "Deconvolution"
  bottom: "score"
  top: "upscore"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 4
    bias_term: false
    pad: 0
    kernel_size: 32
    stride: 16
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "cropscore"
  type: "Crop"
  bottom: "upscore"
  bottom: "image"
  top: "cropscore"
  crop_param {
    axis: 2
    offset: 12
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "cropscore"
  bottom: "label"
  top: "loss"
  loss_weight: 1
  loss_param {
    normalize: false
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "cropscore"
  bottom: "label"
  top: "accuracy"
}
I0823 17:41:14.314311 15833 layer_factory.hpp:77] Creating layer data
I0823 17:41:14.314756 15833 net.cpp:100] Creating Layer data
I0823 17:41:14.314766 15833 net.cpp:408] data -> image
I0823 17:41:14.314795 15833 net.cpp:408] data -> label
I0823 17:41:14.315749 15839 db_lmdb.cpp:35] Opened lmdb /raid/xuehan/segmentation_train_split
I0823 17:41:14.315943 15833 seg_data_layer.cpp:38] 200 200 4
I0823 17:41:14.324391 15833 seg_data_layer.cpp:51] output data size: 128,3,200,200
I0823 17:41:14.324467 15833 seg_data_layer.cpp:63] output label size: 128,1,200,200
I0823 17:41:14.440307 15833 net.cpp:150] Setting up data
I0823 17:41:14.440336 15833 net.cpp:157] Top shape: 128 3 200 200 (15360000)
I0823 17:41:14.440341 15833 net.cpp:157] Top shape: 128 1 200 200 (5120000)
I0823 17:41:14.440343 15833 net.cpp:165] Memory required for data: 81920000
I0823 17:41:14.440353 15833 layer_factory.hpp:77] Creating layer image_data_0_split
I0823 17:41:14.440368 15833 net.cpp:100] Creating Layer image_data_0_split
I0823 17:41:14.440372 15833 net.cpp:434] image_data_0_split <- image
I0823 17:41:14.440383 15833 net.cpp:408] image_data_0_split -> image_data_0_split_0
I0823 17:41:14.440392 15833 net.cpp:408] image_data_0_split -> image_data_0_split_1
I0823 17:41:14.440433 15833 net.cpp:150] Setting up image_data_0_split
I0823 17:41:14.440439 15833 net.cpp:157] Top shape: 128 3 200 200 (15360000)
I0823 17:41:14.440443 15833 net.cpp:157] Top shape: 128 3 200 200 (15360000)
I0823 17:41:14.440445 15833 net.cpp:165] Memory required for data: 204800000
I0823 17:41:14.440448 15833 layer_factory.hpp:77] Creating layer label_data_1_split
I0823 17:41:14.440453 15833 net.cpp:100] Creating Layer label_data_1_split
I0823 17:41:14.440455 15833 net.cpp:434] label_data_1_split <- label
I0823 17:41:14.440460 15833 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0823 17:41:14.440464 15833 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0823 17:41:14.440486 15833 net.cpp:150] Setting up label_data_1_split
I0823 17:41:14.440491 15833 net.cpp:157] Top shape: 128 1 200 200 (5120000)
I0823 17:41:14.440495 15833 net.cpp:157] Top shape: 128 1 200 200 (5120000)
I0823 17:41:14.440497 15833 net.cpp:165] Memory required for data: 245760000
I0823 17:41:14.440500 15833 layer_factory.hpp:77] Creating layer conv1_1
I0823 17:41:14.440512 15833 net.cpp:100] Creating Layer conv1_1
I0823 17:41:14.440515 15833 net.cpp:434] conv1_1 <- image_data_0_split_0
I0823 17:41:14.440521 15833 net.cpp:408] conv1_1 -> conv1_1
I0823 17:41:14.440670 15833 net.cpp:150] Setting up conv1_1
I0823 17:41:14.440675 15833 net.cpp:157] Top shape: 128 8 298 298 (90935296)
I0823 17:41:14.440678 15833 net.cpp:165] Memory required for data: 609501184
I0823 17:41:14.440688 15833 layer_factory.hpp:77] Creating layer conv1_1_bn
I0823 17:41:14.440696 15833 net.cpp:100] Creating Layer conv1_1_bn
I0823 17:41:14.440698 15833 net.cpp:434] conv1_1_bn <- conv1_1
I0823 17:41:14.440702 15833 net.cpp:408] conv1_1_bn -> conv1_1_bn
I0823 17:41:14.441243 15833 net.cpp:150] Setting up conv1_1_bn
I0823 17:41:14.441253 15833 net.cpp:157] Top shape: 128 8 298 298 (90935296)
I0823 17:41:14.441256 15833 net.cpp:165] Memory required for data: 973242368
I0823 17:41:14.441265 15833 layer_factory.hpp:77] Creating layer conv1_1_bn_scale
I0823 17:41:14.441275 15833 net.cpp:100] Creating Layer conv1_1_bn_scale
I0823 17:41:14.441279 15833 net.cpp:434] conv1_1_bn_scale <- conv1_1_bn
I0823 17:41:14.441283 15833 net.cpp:395] conv1_1_bn_scale -> conv1_1_bn (in-place)
I0823 17:41:14.441311 15833 layer_factory.hpp:77] Creating layer conv1_1_bn_scale
I0823 17:41:14.441871 15833 net.cpp:150] Setting up conv1_1_bn_scale
I0823 17:41:14.441882 15833 net.cpp:157] Top shape: 128 8 298 298 (90935296)
I0823 17:41:14.441885 15833 net.cpp:165] Memory required for data: 1336983552
I0823 17:41:14.441893 15833 layer_factory.hpp:77] Creating layer conv1_1_relu
I0823 17:41:14.441900 15833 net.cpp:100] Creating Layer conv1_1_relu
I0823 17:41:14.441905 15833 net.cpp:434] conv1_1_relu <- conv1_1_bn
I0823 17:41:14.441908 15833 net.cpp:395] conv1_1_relu -> conv1_1_bn (in-place)
I0823 17:41:14.441915 15833 net.cpp:150] Setting up conv1_1_relu
I0823 17:41:14.441918 15833 net.cpp:157] Top shape: 128 8 298 298 (90935296)
I0823 17:41:14.441920 15833 net.cpp:165] Memory required for data: 1700724736
I0823 17:41:14.441923 15833 layer_factory.hpp:77] Creating layer pool1
I0823 17:41:14.441936 15833 net.cpp:100] Creating Layer pool1
I0823 17:41:14.441946 15833 net.cpp:434] pool1 <- conv1_1_bn
I0823 17:41:14.441951 15833 net.cpp:408] pool1 -> pool1
I0823 17:41:14.448492 15833 net.cpp:150] Setting up pool1
I0823 17:41:14.448500 15833 net.cpp:157] Top shape: 128 8 149 149 (22733824)
I0823 17:41:14.448503 15833 net.cpp:165] Memory required for data: 1791660032
I0823 17:41:14.448506 15833 layer_factory.hpp:77] Creating layer conv2_1
I0823 17:41:14.448516 15833 net.cpp:100] Creating Layer conv2_1
I0823 17:41:14.448519 15833 net.cpp:434] conv2_1 <- pool1
I0823 17:41:14.448524 15833 net.cpp:408] conv2_1 -> conv2_1
I0823 17:41:14.449046 15833 net.cpp:150] Setting up conv2_1
I0823 17:41:14.449055 15833 net.cpp:157] Top shape: 128 16 149 149 (45467648)
I0823 17:41:14.449059 15833 net.cpp:165] Memory required for data: 1973530624
I0823 17:41:14.449062 15833 layer_factory.hpp:77] Creating layer conv2_1_bn
I0823 17:41:14.449069 15833 net.cpp:100] Creating Layer conv2_1_bn
I0823 17:41:14.449071 15833 net.cpp:434] conv2_1_bn <- conv2_1
I0823 17:41:14.449075 15833 net.cpp:408] conv2_1_bn -> conv2_1_bn
I0823 17:41:14.449604 15833 net.cpp:150] Setting up conv2_1_bn
I0823 17:41:14.449612 15833 net.cpp:157] Top shape: 128 16 149 149 (45467648)
I0823 17:41:14.449615 15833 net.cpp:165] Memory required for data: 2155401216
I0823 17:41:14.449625 15833 layer_factory.hpp:77] Creating layer conv2_1_bn_scale
I0823 17:41:14.449631 15833 net.cpp:100] Creating Layer conv2_1_bn_scale
I0823 17:41:14.449633 15833 net.cpp:434] conv2_1_bn_scale <- conv2_1_bn
I0823 17:41:14.449638 15833 net.cpp:395] conv2_1_bn_scale -> conv2_1_bn (in-place)
I0823 17:41:14.449663 15833 layer_factory.hpp:77] Creating layer conv2_1_bn_scale
I0823 17:41:14.449770 15833 net.cpp:150] Setting up conv2_1_bn_scale
I0823 17:41:14.449779 15833 net.cpp:157] Top shape: 128 16 149 149 (45467648)
I0823 17:41:14.449781 15833 net.cpp:165] Memory required for data: 2337271808
I0823 17:41:14.449786 15833 layer_factory.hpp:77] Creating layer conv2_1_relu
I0823 17:41:14.449791 15833 net.cpp:100] Creating Layer conv2_1_relu
I0823 17:41:14.449795 15833 net.cpp:434] conv2_1_relu <- conv2_1_bn
I0823 17:41:14.449800 15833 net.cpp:395] conv2_1_relu -> conv2_1_bn (in-place)
I0823 17:41:14.449805 15833 net.cpp:150] Setting up conv2_1_relu
I0823 17:41:14.449810 15833 net.cpp:157] Top shape: 128 16 149 149 (45467648)
I0823 17:41:14.449811 15833 net.cpp:165] Memory required for data: 2519142400
I0823 17:41:14.449815 15833 layer_factory.hpp:77] Creating layer pool2
I0823 17:41:14.449818 15833 net.cpp:100] Creating Layer pool2
I0823 17:41:14.449821 15833 net.cpp:434] pool2 <- conv2_1_bn
I0823 17:41:14.449826 15833 net.cpp:408] pool2 -> pool2
I0823 17:41:14.449851 15833 net.cpp:150] Setting up pool2
I0823 17:41:14.449856 15833 net.cpp:157] Top shape: 128 16 75 75 (11520000)
I0823 17:41:14.449858 15833 net.cpp:165] Memory required for data: 2565222400
I0823 17:41:14.449862 15833 layer_factory.hpp:77] Creating layer conv3_1
I0823 17:41:14.449868 15833 net.cpp:100] Creating Layer conv3_1
I0823 17:41:14.449872 15833 net.cpp:434] conv3_1 <- pool2
I0823 17:41:14.449875 15833 net.cpp:408] conv3_1 -> conv3_1
I0823 17:41:14.450520 15833 net.cpp:150] Setting up conv3_1
I0823 17:41:14.450530 15833 net.cpp:157] Top shape: 128 32 75 75 (23040000)
I0823 17:41:14.450532 15833 net.cpp:165] Memory required for data: 2657382400
I0823 17:41:14.450536 15833 layer_factory.hpp:77] Creating layer conv3_1_bn
I0823 17:41:14.450543 15833 net.cpp:100] Creating Layer conv3_1_bn
I0823 17:41:14.450546 15833 net.cpp:434] conv3_1_bn <- conv3_1
I0823 17:41:14.450551 15833 net.cpp:408] conv3_1_bn -> conv3_1_bn
I0823 17:41:14.450675 15833 net.cpp:150] Setting up conv3_1_bn
I0823 17:41:14.450680 15833 net.cpp:157] Top shape: 128 32 75 75 (23040000)
I0823 17:41:14.450682 15833 net.cpp:165] Memory required for data: 2749542400
I0823 17:41:14.450687 15833 layer_factory.hpp:77] Creating layer conv3_1_bn_scale
I0823 17:41:14.450692 15833 net.cpp:100] Creating Layer conv3_1_bn_scale
I0823 17:41:14.450695 15833 net.cpp:434] conv3_1_bn_scale <- conv3_1_bn
I0823 17:41:14.450709 15833 net.cpp:395] conv3_1_bn_scale -> conv3_1_bn (in-place)
I0823 17:41:14.450736 15833 layer_factory.hpp:77] Creating layer conv3_1_bn_scale
I0823 17:41:14.450812 15833 net.cpp:150] Setting up conv3_1_bn_scale
I0823 17:41:14.450817 15833 net.cpp:157] Top shape: 128 32 75 75 (23040000)
I0823 17:41:14.450820 15833 net.cpp:165] Memory required for data: 2841702400
I0823 17:41:14.450829 15833 layer_factory.hpp:77] Creating layer conv3_1_relu
I0823 17:41:14.450835 15833 net.cpp:100] Creating Layer conv3_1_relu
I0823 17:41:14.450839 15833 net.cpp:434] conv3_1_relu <- conv3_1_bn
I0823 17:41:14.450842 15833 net.cpp:395] conv3_1_relu -> conv3_1_bn (in-place)
I0823 17:41:14.450846 15833 net.cpp:150] Setting up conv3_1_relu
I0823 17:41:14.450850 15833 net.cpp:157] Top shape: 128 32 75 75 (23040000)
I0823 17:41:14.450852 15833 net.cpp:165] Memory required for data: 2933862400
I0823 17:41:14.450855 15833 layer_factory.hpp:77] Creating layer pool3
I0823 17:41:14.450861 15833 net.cpp:100] Creating Layer pool3
I0823 17:41:14.450863 15833 net.cpp:434] pool3 <- conv3_1_bn
I0823 17:41:14.450867 15833 net.cpp:408] pool3 -> pool3
I0823 17:41:14.450894 15833 net.cpp:150] Setting up pool3
I0823 17:41:14.450899 15833 net.cpp:157] Top shape: 128 32 38 38 (5914624)
I0823 17:41:14.450901 15833 net.cpp:165] Memory required for data: 2957520896
I0823 17:41:14.450904 15833 layer_factory.hpp:77] Creating layer conv4_1
I0823 17:41:14.450911 15833 net.cpp:100] Creating Layer conv4_1
I0823 17:41:14.450913 15833 net.cpp:434] conv4_1 <- pool3
I0823 17:41:14.450917 15833 net.cpp:408] conv4_1 -> conv4_1
I0823 17:41:14.451442 15833 net.cpp:150] Setting up conv4_1
I0823 17:41:14.451448 15833 net.cpp:157] Top shape: 128 64 38 38 (11829248)
I0823 17:41:14.451450 15833 net.cpp:165] Memory required for data: 3004837888
I0823 17:41:14.451454 15833 layer_factory.hpp:77] Creating layer conv4_1_bn
I0823 17:41:14.451462 15833 net.cpp:100] Creating Layer conv4_1_bn
I0823 17:41:14.451464 15833 net.cpp:434] conv4_1_bn <- conv4_1
I0823 17:41:14.451468 15833 net.cpp:408] conv4_1_bn -> conv4_1_bn
I0823 17:41:14.451596 15833 net.cpp:150] Setting up conv4_1_bn
I0823 17:41:14.451601 15833 net.cpp:157] Top shape: 128 64 38 38 (11829248)
I0823 17:41:14.451604 15833 net.cpp:165] Memory required for data: 3052154880
I0823 17:41:14.451611 15833 layer_factory.hpp:77] Creating layer conv4_1_bn_scale
I0823 17:41:14.451614 15833 net.cpp:100] Creating Layer conv4_1_bn_scale
I0823 17:41:14.451617 15833 net.cpp:434] conv4_1_bn_scale <- conv4_1_bn
I0823 17:41:14.451620 15833 net.cpp:395] conv4_1_bn_scale -> conv4_1_bn (in-place)
I0823 17:41:14.451644 15833 layer_factory.hpp:77] Creating layer conv4_1_bn_scale
I0823 17:41:14.451719 15833 net.cpp:150] Setting up conv4_1_bn_scale
I0823 17:41:14.451725 15833 net.cpp:157] Top shape: 128 64 38 38 (11829248)
I0823 17:41:14.451727 15833 net.cpp:165] Memory required for data: 3099471872
I0823 17:41:14.451731 15833 layer_factory.hpp:77] Creating layer conv4_1_relu
I0823 17:41:14.451736 15833 net.cpp:100] Creating Layer conv4_1_relu
I0823 17:41:14.451738 15833 net.cpp:434] conv4_1_relu <- conv4_1_bn
I0823 17:41:14.451742 15833 net.cpp:395] conv4_1_relu -> conv4_1_bn (in-place)
I0823 17:41:14.451746 15833 net.cpp:150] Setting up conv4_1_relu
I0823 17:41:14.451750 15833 net.cpp:157] Top shape: 128 64 38 38 (11829248)
I0823 17:41:14.451752 15833 net.cpp:165] Memory required for data: 3146788864
I0823 17:41:14.451755 15833 layer_factory.hpp:77] Creating layer pool4
I0823 17:41:14.451761 15833 net.cpp:100] Creating Layer pool4
I0823 17:41:14.451764 15833 net.cpp:434] pool4 <- conv4_1_bn
I0823 17:41:14.451768 15833 net.cpp:408] pool4 -> pool4
I0823 17:41:14.451793 15833 net.cpp:150] Setting up pool4
I0823 17:41:14.451798 15833 net.cpp:157] Top shape: 128 64 19 19 (2957312)
I0823 17:41:14.451800 15833 net.cpp:165] Memory required for data: 3158618112
I0823 17:41:14.451803 15833 layer_factory.hpp:77] Creating layer conv5_1
I0823 17:41:14.451809 15833 net.cpp:100] Creating Layer conv5_1
I0823 17:41:14.451815 15833 net.cpp:434] conv5_1 <- pool4
I0823 17:41:14.451824 15833 net.cpp:408] conv5_1 -> conv5_1
I0823 17:41:14.452739 15833 net.cpp:150] Setting up conv5_1
I0823 17:41:14.452744 15833 net.cpp:157] Top shape: 128 64 17 17 (2367488)
I0823 17:41:14.452747 15833 net.cpp:165] Memory required for data: 3168088064
I0823 17:41:14.452751 15833 layer_factory.hpp:77] Creating layer conv5_1_bn
I0823 17:41:14.452756 15833 net.cpp:100] Creating Layer conv5_1_bn
I0823 17:41:14.452759 15833 net.cpp:434] conv5_1_bn <- conv5_1
I0823 17:41:14.452764 15833 net.cpp:408] conv5_1_bn -> conv5_1_bn
I0823 17:41:14.453348 15833 net.cpp:150] Setting up conv5_1_bn
I0823 17:41:14.453358 15833 net.cpp:157] Top shape: 128 64 17 17 (2367488)
I0823 17:41:14.453361 15833 net.cpp:165] Memory required for data: 3177558016
I0823 17:41:14.453367 15833 layer_factory.hpp:77] Creating layer conv5_1_bn_scale
I0823 17:41:14.453373 15833 net.cpp:100] Creating Layer conv5_1_bn_scale
I0823 17:41:14.453377 15833 net.cpp:434] conv5_1_bn_scale <- conv5_1_bn
I0823 17:41:14.453382 15833 net.cpp:395] conv5_1_bn_scale -> conv5_1_bn (in-place)
I0823 17:41:14.453408 15833 layer_factory.hpp:77] Creating layer conv5_1_bn_scale
I0823 17:41:14.453483 15833 net.cpp:150] Setting up conv5_1_bn_scale
I0823 17:41:14.453488 15833 net.cpp:157] Top shape: 128 64 17 17 (2367488)
I0823 17:41:14.453491 15833 net.cpp:165] Memory required for data: 3187027968
I0823 17:41:14.453496 15833 layer_factory.hpp:77] Creating layer conv5_1_relu
I0823 17:41:14.453500 15833 net.cpp:100] Creating Layer conv5_1_relu
I0823 17:41:14.453503 15833 net.cpp:434] conv5_1_relu <- conv5_1_bn
I0823 17:41:14.453507 15833 net.cpp:395] conv5_1_relu -> conv5_1_bn (in-place)
I0823 17:41:14.453511 15833 net.cpp:150] Setting up conv5_1_relu
I0823 17:41:14.453516 15833 net.cpp:157] Top shape: 128 64 17 17 (2367488)
I0823 17:41:14.453517 15833 net.cpp:165] Memory required for data: 3196497920
I0823 17:41:14.453521 15833 layer_factory.hpp:77] Creating layer conv6_1
I0823 17:41:14.453527 15833 net.cpp:100] Creating Layer conv6_1
I0823 17:41:14.453531 15833 net.cpp:434] conv6_1 <- conv5_1_bn
I0823 17:41:14.453536 15833 net.cpp:408] conv6_1 -> conv6_1
I0823 17:41:14.454445 15833 net.cpp:150] Setting up conv6_1
I0823 17:41:14.454453 15833 net.cpp:157] Top shape: 128 64 15 15 (1843200)
I0823 17:41:14.454455 15833 net.cpp:165] Memory required for data: 3203870720
I0823 17:41:14.454459 15833 layer_factory.hpp:77] Creating layer conv6_1_bn
I0823 17:41:14.454464 15833 net.cpp:100] Creating Layer conv6_1_bn
I0823 17:41:14.454468 15833 net.cpp:434] conv6_1_bn <- conv6_1
I0823 17:41:14.454473 15833 net.cpp:408] conv6_1_bn -> conv6_1_bn
I0823 17:41:14.454597 15833 net.cpp:150] Setting up conv6_1_bn
I0823 17:41:14.454602 15833 net.cpp:157] Top shape: 128 64 15 15 (1843200)
I0823 17:41:14.454604 15833 net.cpp:165] Memory required for data: 3211243520
I0823 17:41:14.454615 15833 layer_factory.hpp:77] Creating layer conv6_1_bn_scale
I0823 17:41:14.454620 15833 net.cpp:100] Creating Layer conv6_1_bn_scale
I0823 17:41:14.454623 15833 net.cpp:434] conv6_1_bn_scale <- conv6_1_bn
I0823 17:41:14.454627 15833 net.cpp:395] conv6_1_bn_scale -> conv6_1_bn (in-place)
I0823 17:41:14.454651 15833 layer_factory.hpp:77] Creating layer conv6_1_bn_scale
I0823 17:41:14.454735 15833 net.cpp:150] Setting up conv6_1_bn_scale
I0823 17:41:14.454741 15833 net.cpp:157] Top shape: 128 64 15 15 (1843200)
I0823 17:41:14.454756 15833 net.cpp:165] Memory required for data: 3218616320
I0823 17:41:14.454761 15833 layer_factory.hpp:77] Creating layer conv6_1_relu
I0823 17:41:14.454764 15833 net.cpp:100] Creating Layer conv6_1_relu
I0823 17:41:14.454767 15833 net.cpp:434] conv6_1_relu <- conv6_1_bn
I0823 17:41:14.454771 15833 net.cpp:395] conv6_1_relu -> conv6_1_bn (in-place)
I0823 17:41:14.454774 15833 net.cpp:150] Setting up conv6_1_relu
I0823 17:41:14.454777 15833 net.cpp:157] Top shape: 128 64 15 15 (1843200)
I0823 17:41:14.454780 15833 net.cpp:165] Memory required for data: 3225989120
I0823 17:41:14.454783 15833 layer_factory.hpp:77] Creating layer conv7_1
I0823 17:41:14.454797 15833 net.cpp:100] Creating Layer conv7_1
I0823 17:41:14.454807 15833 net.cpp:434] conv7_1 <- conv6_1_bn
I0823 17:41:14.454810 15833 net.cpp:408] conv7_1 -> conv7_1
I0823 17:41:14.456502 15833 net.cpp:150] Setting up conv7_1
I0823 17:41:14.456509 15833 net.cpp:157] Top shape: 128 128 13 13 (2768896)
I0823 17:41:14.456511 15833 net.cpp:165] Memory required for data: 3237064704
I0823 17:41:14.456516 15833 layer_factory.hpp:77] Creating layer conv7_1_bn
I0823 17:41:14.456524 15833 net.cpp:100] Creating Layer conv7_1_bn
I0823 17:41:14.456527 15833 net.cpp:434] conv7_1_bn <- conv7_1
I0823 17:41:14.456532 15833 net.cpp:408] conv7_1_bn -> conv7_1_bn
I0823 17:41:14.456653 15833 net.cpp:150] Setting up conv7_1_bn
I0823 17:41:14.456658 15833 net.cpp:157] Top shape: 128 128 13 13 (2768896)
I0823 17:41:14.456661 15833 net.cpp:165] Memory required for data: 3248140288
I0823 17:41:14.456667 15833 layer_factory.hpp:77] Creating layer conv7_1_bn_scale
I0823 17:41:14.456672 15833 net.cpp:100] Creating Layer conv7_1_bn_scale
I0823 17:41:14.456676 15833 net.cpp:434] conv7_1_bn_scale <- conv7_1_bn
I0823 17:41:14.456679 15833 net.cpp:395] conv7_1_bn_scale -> conv7_1_bn (in-place)
I0823 17:41:14.456701 15833 layer_factory.hpp:77] Creating layer conv7_1_bn_scale
I0823 17:41:14.456789 15833 net.cpp:150] Setting up conv7_1_bn_scale
I0823 17:41:14.456794 15833 net.cpp:157] Top shape: 128 128 13 13 (2768896)
I0823 17:41:14.456796 15833 net.cpp:165] Memory required for data: 3259215872
I0823 17:41:14.456801 15833 layer_factory.hpp:77] Creating layer conv7_1_relu
I0823 17:41:14.456805 15833 net.cpp:100] Creating Layer conv7_1_relu
I0823 17:41:14.456809 15833 net.cpp:434] conv7_1_relu <- conv7_1_bn
I0823 17:41:14.456815 15833 net.cpp:395] conv7_1_relu -> conv7_1_bn (in-place)
I0823 17:41:14.456820 15833 net.cpp:150] Setting up conv7_1_relu
I0823 17:41:14.456822 15833 net.cpp:157] Top shape: 128 128 13 13 (2768896)
I0823 17:41:14.456825 15833 net.cpp:165] Memory required for data: 3270291456
I0823 17:41:14.456828 15833 layer_factory.hpp:77] Creating layer score
I0823 17:41:14.456835 15833 net.cpp:100] Creating Layer score
I0823 17:41:14.456838 15833 net.cpp:434] score <- conv7_1_bn
I0823 17:41:14.456842 15833 net.cpp:408] score -> score
I0823 17:41:14.457000 15833 net.cpp:150] Setting up score
I0823 17:41:14.457005 15833 net.cpp:157] Top shape: 128 4 13 13 (86528)
I0823 17:41:14.457007 15833 net.cpp:165] Memory required for data: 3270637568
I0823 17:41:14.457012 15833 layer_factory.hpp:77] Creating layer upscore
I0823 17:41:14.457018 15833 net.cpp:100] Creating Layer upscore
I0823 17:41:14.457021 15833 net.cpp:434] upscore <- score
I0823 17:41:14.457027 15833 net.cpp:408] upscore -> upscore
I0823 17:41:14.457504 15833 net.cpp:150] Setting up upscore
I0823 17:41:14.457509 15833 net.cpp:157] Top shape: 128 4 224 224 (25690112)
I0823 17:41:14.457511 15833 net.cpp:165] Memory required for data: 3373398016
I0823 17:41:14.457515 15833 layer_factory.hpp:77] Creating layer cropscore
I0823 17:41:14.457520 15833 net.cpp:100] Creating Layer cropscore
I0823 17:41:14.457523 15833 net.cpp:434] cropscore <- upscore
I0823 17:41:14.457527 15833 net.cpp:434] cropscore <- image_data_0_split_1
I0823 17:41:14.457531 15833 net.cpp:408] cropscore -> cropscore
I0823 17:41:14.457550 15833 net.cpp:150] Setting up cropscore
I0823 17:41:14.457554 15833 net.cpp:157] Top shape: 128 4 200 200 (20480000)
I0823 17:41:14.457556 15833 net.cpp:165] Memory required for data: 3455318016
I0823 17:41:14.457559 15833 layer_factory.hpp:77] Creating layer cropscore_cropscore_0_split
I0823 17:41:14.457566 15833 net.cpp:100] Creating Layer cropscore_cropscore_0_split
I0823 17:41:14.457568 15833 net.cpp:434] cropscore_cropscore_0_split <- cropscore
I0823 17:41:14.457572 15833 net.cpp:408] cropscore_cropscore_0_split -> cropscore_cropscore_0_split_0
I0823 17:41:14.457576 15833 net.cpp:408] cropscore_cropscore_0_split -> cropscore_cropscore_0_split_1
I0823 17:41:14.457598 15833 net.cpp:150] Setting up cropscore_cropscore_0_split
I0823 17:41:14.457603 15833 net.cpp:157] Top shape: 128 4 200 200 (20480000)
I0823 17:41:14.457617 15833 net.cpp:157] Top shape: 128 4 200 200 (20480000)
I0823 17:41:14.457618 15833 net.cpp:165] Memory required for data: 3619158016
I0823 17:41:14.457622 15833 layer_factory.hpp:77] Creating layer loss
I0823 17:41:14.457628 15833 net.cpp:100] Creating Layer loss
I0823 17:41:14.457631 15833 net.cpp:434] loss <- cropscore_cropscore_0_split_0
I0823 17:41:14.457634 15833 net.cpp:434] loss <- label_data_1_split_0
I0823 17:41:14.457638 15833 net.cpp:408] loss -> loss
I0823 17:41:14.457646 15833 layer_factory.hpp:77] Creating layer loss
I0823 17:41:14.497987 15833 net.cpp:150] Setting up loss
I0823 17:41:14.498018 15833 net.cpp:157] Top shape: (1)
I0823 17:41:14.498021 15833 net.cpp:160]     with loss weight 1
I0823 17:41:14.498040 15833 net.cpp:165] Memory required for data: 3619158020
I0823 17:41:14.498044 15833 layer_factory.hpp:77] Creating layer accuracy
I0823 17:41:14.498062 15833 net.cpp:100] Creating Layer accuracy
I0823 17:41:14.498069 15833 net.cpp:434] accuracy <- cropscore_cropscore_0_split_1
I0823 17:41:14.498073 15833 net.cpp:434] accuracy <- label_data_1_split_1
I0823 17:41:14.498080 15833 net.cpp:408] accuracy -> accuracy
I0823 17:41:14.498088 15833 net.cpp:150] Setting up accuracy
I0823 17:41:14.498092 15833 net.cpp:157] Top shape: (1)
I0823 17:41:14.498095 15833 net.cpp:165] Memory required for data: 3619158024
I0823 17:41:14.498097 15833 net.cpp:228] accuracy does not need backward computation.
I0823 17:41:14.498100 15833 net.cpp:226] loss needs backward computation.
I0823 17:41:14.498103 15833 net.cpp:226] cropscore_cropscore_0_split needs backward computation.
I0823 17:41:14.498106 15833 net.cpp:226] cropscore needs backward computation.
I0823 17:41:14.498111 15833 net.cpp:226] upscore needs backward computation.
I0823 17:41:14.498112 15833 net.cpp:226] score needs backward computation.
I0823 17:41:14.498116 15833 net.cpp:226] conv7_1_relu needs backward computation.
I0823 17:41:14.498118 15833 net.cpp:226] conv7_1_bn_scale needs backward computation.
I0823 17:41:14.498121 15833 net.cpp:226] conv7_1_bn needs backward computation.
I0823 17:41:14.498123 15833 net.cpp:226] conv7_1 needs backward computation.
I0823 17:41:14.498126 15833 net.cpp:226] conv6_1_relu needs backward computation.
I0823 17:41:14.498129 15833 net.cpp:226] conv6_1_bn_scale needs backward computation.
I0823 17:41:14.498132 15833 net.cpp:226] conv6_1_bn needs backward computation.
I0823 17:41:14.498134 15833 net.cpp:226] conv6_1 needs backward computation.
I0823 17:41:14.498137 15833 net.cpp:226] conv5_1_relu needs backward computation.
I0823 17:41:14.498141 15833 net.cpp:226] conv5_1_bn_scale needs backward computation.
I0823 17:41:14.498142 15833 net.cpp:226] conv5_1_bn needs backward computation.
I0823 17:41:14.498145 15833 net.cpp:226] conv5_1 needs backward computation.
I0823 17:41:14.498148 15833 net.cpp:226] pool4 needs backward computation.
I0823 17:41:14.498152 15833 net.cpp:226] conv4_1_relu needs backward computation.
I0823 17:41:14.498154 15833 net.cpp:226] conv4_1_bn_scale needs backward computation.
I0823 17:41:14.498157 15833 net.cpp:226] conv4_1_bn needs backward computation.
I0823 17:41:14.498159 15833 net.cpp:226] conv4_1 needs backward computation.
I0823 17:41:14.498162 15833 net.cpp:226] pool3 needs backward computation.
I0823 17:41:14.498165 15833 net.cpp:226] conv3_1_relu needs backward computation.
I0823 17:41:14.498167 15833 net.cpp:226] conv3_1_bn_scale needs backward computation.
I0823 17:41:14.498170 15833 net.cpp:226] conv3_1_bn needs backward computation.
I0823 17:41:14.498173 15833 net.cpp:226] conv3_1 needs backward computation.
I0823 17:41:14.498175 15833 net.cpp:226] pool2 needs backward computation.
I0823 17:41:14.498178 15833 net.cpp:226] conv2_1_relu needs backward computation.
I0823 17:41:14.498181 15833 net.cpp:226] conv2_1_bn_scale needs backward computation.
I0823 17:41:14.498183 15833 net.cpp:226] conv2_1_bn needs backward computation.
I0823 17:41:14.498186 15833 net.cpp:226] conv2_1 needs backward computation.
I0823 17:41:14.498189 15833 net.cpp:226] pool1 needs backward computation.
I0823 17:41:14.498206 15833 net.cpp:226] conv1_1_relu needs backward computation.
I0823 17:41:14.498209 15833 net.cpp:226] conv1_1_bn_scale needs backward computation.
I0823 17:41:14.498211 15833 net.cpp:226] conv1_1_bn needs backward computation.
I0823 17:41:14.498214 15833 net.cpp:226] conv1_1 needs backward computation.
I0823 17:41:14.498217 15833 net.cpp:228] label_data_1_split does not need backward computation.
I0823 17:41:14.498221 15833 net.cpp:228] image_data_0_split does not need backward computation.
I0823 17:41:14.498225 15833 net.cpp:228] data does not need backward computation.
I0823 17:41:14.498229 15833 net.cpp:270] This network produces output accuracy
I0823 17:41:14.498230 15833 net.cpp:270] This network produces output loss
I0823 17:41:14.498255 15833 net.cpp:283] Network initialization done.
I0823 17:41:14.498817 15833 solver.cpp:181] Creating test net (#0) specified by net file: portrait_train_test_one_stage.prototxt2
I0823 17:41:14.498855 15833 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0823 17:41:14.499003 15833 net.cpp:58] Initializing net from parameters: 
name: "segmentation"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "SegData"
  top: "image"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 200
  }
  data_param {
    source: "/raid/xuehan/segmentation_test_split"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "image"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 50
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv1_1_bn"
  type: "BatchNorm"
  bottom: "conv1_1"
  top: "conv1_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv1_1_bn_scale"
  type: "Scale"
  bottom: "conv1_1_bn"
  top: "conv1_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_1_relu"
  type: "ReLU"
  bottom: "conv1_1_bn"
  top: "conv1_1_bn"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_1_bn"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv2_1_bn"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv2_1_bn_scale"
  type: "Scale"
  bottom: "conv2_1_bn"
  top: "conv2_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1_relu"
  type: "ReLU"
  bottom: "conv2_1_bn"
  top: "conv2_1_bn"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_1_bn"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv3_1_bn"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv3_1_bn_scale"
  type: "Scale"
  bottom: "conv3_1_bn"
  top: "conv3_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1_relu"
  type: "ReLU"
  bottom: "conv3_1_bn"
  top: "conv3_1_bn"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_1_bn"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv4_1_bn"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv4_1_bn_scale"
  type: "Scale"
  bottom: "conv4_1_bn"
  top: "conv4_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1_relu"
  type: "ReLU"
  bottom: "conv4_1_bn"
  top: "conv4_1_bn"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_1_bn"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv5_1_bn"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv5_1_bn_scale"
  type: "Scale"
  bottom: "conv5_1_bn"
  top: "conv5_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_1_relu"
  type: "ReLU"
  bottom: "conv5_1_bn"
  top: "conv5_1_bn"
}
layer {
  name: "conv6_1"
  type: "Convolution"
  bottom: "conv5_1_bn"
  top: "conv6_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv6_1_bn"
  type: "BatchNorm"
  bottom: "conv6_1"
  top: "conv6_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv6_1_bn_scale"
  type: "Scale"
  bottom: "conv6_1_bn"
  top: "conv6_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv6_1_relu"
  type: "ReLU"
  bottom: "conv6_1_bn"
  top: "conv6_1_bn"
}
layer {
  name: "conv7_1"
  type: "Convolution"
  bottom: "conv6_1_bn"
  top: "conv7_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv7_1_bn"
  type: "BatchNorm"
  bottom: "conv7_1"
  top: "conv7_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv7_1_bn_scale"
  type: "Scale"
  bottom: "conv7_1_bn"
  top: "conv7_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv7_1_relu"
  type: "ReLU"
  bottom: "conv7_1_bn"
  top: "conv7_1_bn"
}
layer {
  name: "score"
  type: "Convolution"
  bottom: "conv7_1_bn"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 4
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "upscore"
  type: "Deconvolution"
  bottom: "score"
  top: "upscore"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 4
    bias_term: false
    pad: 0
    kernel_size: 32
    stride: 16
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "cropscore"
  type: "Crop"
  bottom: "upscore"
  bottom: "image"
  top: "cropscore"
  crop_param {
    axis: 2
    offset: 12
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "cropscore"
  bottom: "label"
  top: "loss"
  loss_weight: 1
  loss_param {
    normalize: false
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "cropscore"
  bottom: "label"
  top: "accuracy"
}
I0823 17:41:14.499115 15833 layer_factory.hpp:77] Creating layer data
I0823 17:41:14.499212 15833 net.cpp:100] Creating Layer data
I0823 17:41:14.499220 15833 net.cpp:408] data -> image
I0823 17:41:14.499228 15833 net.cpp:408] data -> label
I0823 17:41:14.500263 15841 db_lmdb.cpp:35] Opened lmdb /raid/xuehan/segmentation_test_split
I0823 17:41:14.500438 15833 seg_data_layer.cpp:38] 200 200 4
I0823 17:41:14.500512 15833 seg_data_layer.cpp:51] output data size: 64,3,200,200
I0823 17:41:14.500555 15833 seg_data_layer.cpp:63] output label size: 64,1,200,200
I0823 17:41:14.566807 15833 net.cpp:150] Setting up data
I0823 17:41:14.566833 15833 net.cpp:157] Top shape: 64 3 200 200 (7680000)
I0823 17:41:14.566839 15833 net.cpp:157] Top shape: 64 1 200 200 (2560000)
I0823 17:41:14.566843 15833 net.cpp:165] Memory required for data: 40960000
I0823 17:41:14.566848 15833 layer_factory.hpp:77] Creating layer image_data_0_split
I0823 17:41:14.566860 15833 net.cpp:100] Creating Layer image_data_0_split
I0823 17:41:14.566864 15833 net.cpp:434] image_data_0_split <- image
I0823 17:41:14.566870 15833 net.cpp:408] image_data_0_split -> image_data_0_split_0
I0823 17:41:14.566881 15833 net.cpp:408] image_data_0_split -> image_data_0_split_1
I0823 17:41:14.571903 15833 net.cpp:150] Setting up image_data_0_split
I0823 17:41:14.571918 15833 net.cpp:157] Top shape: 64 3 200 200 (7680000)
I0823 17:41:14.571923 15833 net.cpp:157] Top shape: 64 3 200 200 (7680000)
I0823 17:41:14.571925 15833 net.cpp:165] Memory required for data: 102400000
I0823 17:41:14.571929 15833 layer_factory.hpp:77] Creating layer label_data_1_split
I0823 17:41:14.571938 15833 net.cpp:100] Creating Layer label_data_1_split
I0823 17:41:14.571940 15833 net.cpp:434] label_data_1_split <- label
I0823 17:41:14.571945 15833 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0823 17:41:14.571951 15833 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0823 17:41:14.573637 15833 net.cpp:150] Setting up label_data_1_split
I0823 17:41:14.573650 15833 net.cpp:157] Top shape: 64 1 200 200 (2560000)
I0823 17:41:14.573654 15833 net.cpp:157] Top shape: 64 1 200 200 (2560000)
I0823 17:41:14.573657 15833 net.cpp:165] Memory required for data: 122880000
I0823 17:41:14.573660 15833 layer_factory.hpp:77] Creating layer conv1_1
I0823 17:41:14.573671 15833 net.cpp:100] Creating Layer conv1_1
I0823 17:41:14.573674 15833 net.cpp:434] conv1_1 <- image_data_0_split_0
I0823 17:41:14.573684 15833 net.cpp:408] conv1_1 -> conv1_1
I0823 17:41:14.573838 15833 net.cpp:150] Setting up conv1_1
I0823 17:41:14.573845 15833 net.cpp:157] Top shape: 64 8 298 298 (45467648)
I0823 17:41:14.573848 15833 net.cpp:165] Memory required for data: 304750592
I0823 17:41:14.573855 15833 layer_factory.hpp:77] Creating layer conv1_1_bn
I0823 17:41:14.573861 15833 net.cpp:100] Creating Layer conv1_1_bn
I0823 17:41:14.573864 15833 net.cpp:434] conv1_1_bn <- conv1_1
I0823 17:41:14.573869 15833 net.cpp:408] conv1_1_bn -> conv1_1_bn
I0823 17:41:14.574071 15833 net.cpp:150] Setting up conv1_1_bn
I0823 17:41:14.574079 15833 net.cpp:157] Top shape: 64 8 298 298 (45467648)
I0823 17:41:14.574081 15833 net.cpp:165] Memory required for data: 486621184
I0823 17:41:14.574090 15833 layer_factory.hpp:77] Creating layer conv1_1_bn_scale
I0823 17:41:14.574096 15833 net.cpp:100] Creating Layer conv1_1_bn_scale
I0823 17:41:14.574100 15833 net.cpp:434] conv1_1_bn_scale <- conv1_1_bn
I0823 17:41:14.574103 15833 net.cpp:395] conv1_1_bn_scale -> conv1_1_bn (in-place)
I0823 17:41:14.574133 15833 layer_factory.hpp:77] Creating layer conv1_1_bn_scale
I0823 17:41:14.574774 15833 net.cpp:150] Setting up conv1_1_bn_scale
I0823 17:41:14.574786 15833 net.cpp:157] Top shape: 64 8 298 298 (45467648)
I0823 17:41:14.574790 15833 net.cpp:165] Memory required for data: 668491776
I0823 17:41:14.574797 15833 layer_factory.hpp:77] Creating layer conv1_1_relu
I0823 17:41:14.574805 15833 net.cpp:100] Creating Layer conv1_1_relu
I0823 17:41:14.574807 15833 net.cpp:434] conv1_1_relu <- conv1_1_bn
I0823 17:41:14.574811 15833 net.cpp:395] conv1_1_relu -> conv1_1_bn (in-place)
I0823 17:41:14.574825 15833 net.cpp:150] Setting up conv1_1_relu
I0823 17:41:14.574836 15833 net.cpp:157] Top shape: 64 8 298 298 (45467648)
I0823 17:41:14.574838 15833 net.cpp:165] Memory required for data: 850362368
I0823 17:41:14.574841 15833 layer_factory.hpp:77] Creating layer pool1
I0823 17:41:14.574848 15833 net.cpp:100] Creating Layer pool1
I0823 17:41:14.574851 15833 net.cpp:434] pool1 <- conv1_1_bn
I0823 17:41:14.574856 15833 net.cpp:408] pool1 -> pool1
I0823 17:41:14.578133 15833 net.cpp:150] Setting up pool1
I0823 17:41:14.578151 15833 net.cpp:157] Top shape: 64 8 149 149 (11366912)
I0823 17:41:14.578155 15833 net.cpp:165] Memory required for data: 895830016
I0823 17:41:14.578158 15833 layer_factory.hpp:77] Creating layer conv2_1
I0823 17:41:14.578169 15833 net.cpp:100] Creating Layer conv2_1
I0823 17:41:14.578173 15833 net.cpp:434] conv2_1 <- pool1
I0823 17:41:14.578183 15833 net.cpp:408] conv2_1 -> conv2_1
I0823 17:41:14.578358 15833 net.cpp:150] Setting up conv2_1
I0823 17:41:14.578366 15833 net.cpp:157] Top shape: 64 16 149 149 (22733824)
I0823 17:41:14.578367 15833 net.cpp:165] Memory required for data: 986765312
I0823 17:41:14.578372 15833 layer_factory.hpp:77] Creating layer conv2_1_bn
I0823 17:41:14.578379 15833 net.cpp:100] Creating Layer conv2_1_bn
I0823 17:41:14.578382 15833 net.cpp:434] conv2_1_bn <- conv2_1
I0823 17:41:14.578387 15833 net.cpp:408] conv2_1_bn -> conv2_1_bn
I0823 17:41:14.578544 15833 net.cpp:150] Setting up conv2_1_bn
I0823 17:41:14.578550 15833 net.cpp:157] Top shape: 64 16 149 149 (22733824)
I0823 17:41:14.578553 15833 net.cpp:165] Memory required for data: 1077700608
I0823 17:41:14.578562 15833 layer_factory.hpp:77] Creating layer conv2_1_bn_scale
I0823 17:41:14.578567 15833 net.cpp:100] Creating Layer conv2_1_bn_scale
I0823 17:41:14.578570 15833 net.cpp:434] conv2_1_bn_scale <- conv2_1_bn
I0823 17:41:14.578574 15833 net.cpp:395] conv2_1_bn_scale -> conv2_1_bn (in-place)
I0823 17:41:14.578605 15833 layer_factory.hpp:77] Creating layer conv2_1_bn_scale
I0823 17:41:14.578713 15833 net.cpp:150] Setting up conv2_1_bn_scale
I0823 17:41:14.578719 15833 net.cpp:157] Top shape: 64 16 149 149 (22733824)
I0823 17:41:14.578722 15833 net.cpp:165] Memory required for data: 1168635904
I0823 17:41:14.578727 15833 layer_factory.hpp:77] Creating layer conv2_1_relu
I0823 17:41:14.578732 15833 net.cpp:100] Creating Layer conv2_1_relu
I0823 17:41:14.578734 15833 net.cpp:434] conv2_1_relu <- conv2_1_bn
I0823 17:41:14.578739 15833 net.cpp:395] conv2_1_relu -> conv2_1_bn (in-place)
I0823 17:41:14.578744 15833 net.cpp:150] Setting up conv2_1_relu
I0823 17:41:14.578748 15833 net.cpp:157] Top shape: 64 16 149 149 (22733824)
I0823 17:41:14.578750 15833 net.cpp:165] Memory required for data: 1259571200
I0823 17:41:14.578753 15833 layer_factory.hpp:77] Creating layer pool2
I0823 17:41:14.578758 15833 net.cpp:100] Creating Layer pool2
I0823 17:41:14.578761 15833 net.cpp:434] pool2 <- conv2_1_bn
I0823 17:41:14.578766 15833 net.cpp:408] pool2 -> pool2
I0823 17:41:14.578794 15833 net.cpp:150] Setting up pool2
I0823 17:41:14.578797 15833 net.cpp:157] Top shape: 64 16 75 75 (5760000)
I0823 17:41:14.578800 15833 net.cpp:165] Memory required for data: 1282611200
I0823 17:41:14.578804 15833 layer_factory.hpp:77] Creating layer conv3_1
I0823 17:41:14.578809 15833 net.cpp:100] Creating Layer conv3_1
I0823 17:41:14.578811 15833 net.cpp:434] conv3_1 <- pool2
I0823 17:41:14.578817 15833 net.cpp:408] conv3_1 -> conv3_1
I0823 17:41:14.579041 15833 net.cpp:150] Setting up conv3_1
I0823 17:41:14.579046 15833 net.cpp:157] Top shape: 64 32 75 75 (11520000)
I0823 17:41:14.579049 15833 net.cpp:165] Memory required for data: 1328691200
I0823 17:41:14.579053 15833 layer_factory.hpp:77] Creating layer conv3_1_bn
I0823 17:41:14.579059 15833 net.cpp:100] Creating Layer conv3_1_bn
I0823 17:41:14.579062 15833 net.cpp:434] conv3_1_bn <- conv3_1
I0823 17:41:14.579066 15833 net.cpp:408] conv3_1_bn -> conv3_1_bn
I0823 17:41:14.579221 15833 net.cpp:150] Setting up conv3_1_bn
I0823 17:41:14.579228 15833 net.cpp:157] Top shape: 64 32 75 75 (11520000)
I0823 17:41:14.579244 15833 net.cpp:165] Memory required for data: 1374771200
I0823 17:41:14.579251 15833 layer_factory.hpp:77] Creating layer conv3_1_bn_scale
I0823 17:41:14.579255 15833 net.cpp:100] Creating Layer conv3_1_bn_scale
I0823 17:41:14.579258 15833 net.cpp:434] conv3_1_bn_scale <- conv3_1_bn
I0823 17:41:14.579262 15833 net.cpp:395] conv3_1_bn_scale -> conv3_1_bn (in-place)
I0823 17:41:14.579293 15833 layer_factory.hpp:77] Creating layer conv3_1_bn_scale
I0823 17:41:14.579380 15833 net.cpp:150] Setting up conv3_1_bn_scale
I0823 17:41:14.579386 15833 net.cpp:157] Top shape: 64 32 75 75 (11520000)
I0823 17:41:14.579388 15833 net.cpp:165] Memory required for data: 1420851200
I0823 17:41:14.579396 15833 layer_factory.hpp:77] Creating layer conv3_1_relu
I0823 17:41:14.579402 15833 net.cpp:100] Creating Layer conv3_1_relu
I0823 17:41:14.579406 15833 net.cpp:434] conv3_1_relu <- conv3_1_bn
I0823 17:41:14.579409 15833 net.cpp:395] conv3_1_relu -> conv3_1_bn (in-place)
I0823 17:41:14.579414 15833 net.cpp:150] Setting up conv3_1_relu
I0823 17:41:14.579418 15833 net.cpp:157] Top shape: 64 32 75 75 (11520000)
I0823 17:41:14.579421 15833 net.cpp:165] Memory required for data: 1466931200
I0823 17:41:14.579423 15833 layer_factory.hpp:77] Creating layer pool3
I0823 17:41:14.579427 15833 net.cpp:100] Creating Layer pool3
I0823 17:41:14.579430 15833 net.cpp:434] pool3 <- conv3_1_bn
I0823 17:41:14.579435 15833 net.cpp:408] pool3 -> pool3
I0823 17:41:14.579463 15833 net.cpp:150] Setting up pool3
I0823 17:41:14.579466 15833 net.cpp:157] Top shape: 64 32 38 38 (2957312)
I0823 17:41:14.579469 15833 net.cpp:165] Memory required for data: 1478760448
I0823 17:41:14.579473 15833 layer_factory.hpp:77] Creating layer conv4_1
I0823 17:41:14.579479 15833 net.cpp:100] Creating Layer conv4_1
I0823 17:41:14.579483 15833 net.cpp:434] conv4_1 <- pool3
I0823 17:41:14.579488 15833 net.cpp:408] conv4_1 -> conv4_1
I0823 17:41:14.580020 15833 net.cpp:150] Setting up conv4_1
I0823 17:41:14.580027 15833 net.cpp:157] Top shape: 64 64 38 38 (5914624)
I0823 17:41:14.580029 15833 net.cpp:165] Memory required for data: 1502418944
I0823 17:41:14.580034 15833 layer_factory.hpp:77] Creating layer conv4_1_bn
I0823 17:41:14.580039 15833 net.cpp:100] Creating Layer conv4_1_bn
I0823 17:41:14.580041 15833 net.cpp:434] conv4_1_bn <- conv4_1
I0823 17:41:14.580045 15833 net.cpp:408] conv4_1_bn -> conv4_1_bn
I0823 17:41:14.580179 15833 net.cpp:150] Setting up conv4_1_bn
I0823 17:41:14.580185 15833 net.cpp:157] Top shape: 64 64 38 38 (5914624)
I0823 17:41:14.580188 15833 net.cpp:165] Memory required for data: 1526077440
I0823 17:41:14.580193 15833 layer_factory.hpp:77] Creating layer conv4_1_bn_scale
I0823 17:41:14.580199 15833 net.cpp:100] Creating Layer conv4_1_bn_scale
I0823 17:41:14.580200 15833 net.cpp:434] conv4_1_bn_scale <- conv4_1_bn
I0823 17:41:14.580206 15833 net.cpp:395] conv4_1_bn_scale -> conv4_1_bn (in-place)
I0823 17:41:14.580232 15833 layer_factory.hpp:77] Creating layer conv4_1_bn_scale
I0823 17:41:14.580312 15833 net.cpp:150] Setting up conv4_1_bn_scale
I0823 17:41:14.580317 15833 net.cpp:157] Top shape: 64 64 38 38 (5914624)
I0823 17:41:14.580320 15833 net.cpp:165] Memory required for data: 1549735936
I0823 17:41:14.580324 15833 layer_factory.hpp:77] Creating layer conv4_1_relu
I0823 17:41:14.580329 15833 net.cpp:100] Creating Layer conv4_1_relu
I0823 17:41:14.580332 15833 net.cpp:434] conv4_1_relu <- conv4_1_bn
I0823 17:41:14.580339 15833 net.cpp:395] conv4_1_relu -> conv4_1_bn (in-place)
I0823 17:41:14.580343 15833 net.cpp:150] Setting up conv4_1_relu
I0823 17:41:14.580348 15833 net.cpp:157] Top shape: 64 64 38 38 (5914624)
I0823 17:41:14.580350 15833 net.cpp:165] Memory required for data: 1573394432
I0823 17:41:14.580353 15833 layer_factory.hpp:77] Creating layer pool4
I0823 17:41:14.580358 15833 net.cpp:100] Creating Layer pool4
I0823 17:41:14.580361 15833 net.cpp:434] pool4 <- conv4_1_bn
I0823 17:41:14.580365 15833 net.cpp:408] pool4 -> pool4
I0823 17:41:14.580390 15833 net.cpp:150] Setting up pool4
I0823 17:41:14.580399 15833 net.cpp:157] Top shape: 64 64 19 19 (1478656)
I0823 17:41:14.580406 15833 net.cpp:165] Memory required for data: 1579309056
I0823 17:41:14.580410 15833 layer_factory.hpp:77] Creating layer conv5_1
I0823 17:41:14.580415 15833 net.cpp:100] Creating Layer conv5_1
I0823 17:41:14.580418 15833 net.cpp:434] conv5_1 <- pool4
I0823 17:41:14.580423 15833 net.cpp:408] conv5_1 -> conv5_1
I0823 17:41:14.581879 15833 net.cpp:150] Setting up conv5_1
I0823 17:41:14.581900 15833 net.cpp:157] Top shape: 64 64 17 17 (1183744)
I0823 17:41:14.581903 15833 net.cpp:165] Memory required for data: 1584044032
I0823 17:41:14.581908 15833 layer_factory.hpp:77] Creating layer conv5_1_bn
I0823 17:41:14.581915 15833 net.cpp:100] Creating Layer conv5_1_bn
I0823 17:41:14.581919 15833 net.cpp:434] conv5_1_bn <- conv5_1
I0823 17:41:14.581926 15833 net.cpp:408] conv5_1_bn -> conv5_1_bn
I0823 17:41:14.582072 15833 net.cpp:150] Setting up conv5_1_bn
I0823 17:41:14.582078 15833 net.cpp:157] Top shape: 64 64 17 17 (1183744)
I0823 17:41:14.582082 15833 net.cpp:165] Memory required for data: 1588779008
I0823 17:41:14.582087 15833 layer_factory.hpp:77] Creating layer conv5_1_bn_scale
I0823 17:41:14.582093 15833 net.cpp:100] Creating Layer conv5_1_bn_scale
I0823 17:41:14.582098 15833 net.cpp:434] conv5_1_bn_scale <- conv5_1_bn
I0823 17:41:14.582100 15833 net.cpp:395] conv5_1_bn_scale -> conv5_1_bn (in-place)
I0823 17:41:14.582129 15833 layer_factory.hpp:77] Creating layer conv5_1_bn_scale
I0823 17:41:14.582217 15833 net.cpp:150] Setting up conv5_1_bn_scale
I0823 17:41:14.582223 15833 net.cpp:157] Top shape: 64 64 17 17 (1183744)
I0823 17:41:14.582226 15833 net.cpp:165] Memory required for data: 1593513984
I0823 17:41:14.582231 15833 layer_factory.hpp:77] Creating layer conv5_1_relu
I0823 17:41:14.582236 15833 net.cpp:100] Creating Layer conv5_1_relu
I0823 17:41:14.582238 15833 net.cpp:434] conv5_1_relu <- conv5_1_bn
I0823 17:41:14.582243 15833 net.cpp:395] conv5_1_relu -> conv5_1_bn (in-place)
I0823 17:41:14.582247 15833 net.cpp:150] Setting up conv5_1_relu
I0823 17:41:14.582252 15833 net.cpp:157] Top shape: 64 64 17 17 (1183744)
I0823 17:41:14.582253 15833 net.cpp:165] Memory required for data: 1598248960
I0823 17:41:14.582257 15833 layer_factory.hpp:77] Creating layer conv6_1
I0823 17:41:14.582263 15833 net.cpp:100] Creating Layer conv6_1
I0823 17:41:14.582265 15833 net.cpp:434] conv6_1 <- conv5_1_bn
I0823 17:41:14.582270 15833 net.cpp:408] conv6_1 -> conv6_1
I0823 17:41:14.583204 15833 net.cpp:150] Setting up conv6_1
I0823 17:41:14.583211 15833 net.cpp:157] Top shape: 64 64 15 15 (921600)
I0823 17:41:14.583214 15833 net.cpp:165] Memory required for data: 1601935360
I0823 17:41:14.583219 15833 layer_factory.hpp:77] Creating layer conv6_1_bn
I0823 17:41:14.583225 15833 net.cpp:100] Creating Layer conv6_1_bn
I0823 17:41:14.583227 15833 net.cpp:434] conv6_1_bn <- conv6_1
I0823 17:41:14.583231 15833 net.cpp:408] conv6_1_bn -> conv6_1_bn
I0823 17:41:14.583369 15833 net.cpp:150] Setting up conv6_1_bn
I0823 17:41:14.583374 15833 net.cpp:157] Top shape: 64 64 15 15 (921600)
I0823 17:41:14.583376 15833 net.cpp:165] Memory required for data: 1605621760
I0823 17:41:14.583389 15833 layer_factory.hpp:77] Creating layer conv6_1_bn_scale
I0823 17:41:14.583394 15833 net.cpp:100] Creating Layer conv6_1_bn_scale
I0823 17:41:14.583396 15833 net.cpp:434] conv6_1_bn_scale <- conv6_1_bn
I0823 17:41:14.583401 15833 net.cpp:395] conv6_1_bn_scale -> conv6_1_bn (in-place)
I0823 17:41:14.583428 15833 layer_factory.hpp:77] Creating layer conv6_1_bn_scale
I0823 17:41:14.583509 15833 net.cpp:150] Setting up conv6_1_bn_scale
I0823 17:41:14.583514 15833 net.cpp:157] Top shape: 64 64 15 15 (921600)
I0823 17:41:14.583518 15833 net.cpp:165] Memory required for data: 1609308160
I0823 17:41:14.583521 15833 layer_factory.hpp:77] Creating layer conv6_1_relu
I0823 17:41:14.583526 15833 net.cpp:100] Creating Layer conv6_1_relu
I0823 17:41:14.583528 15833 net.cpp:434] conv6_1_relu <- conv6_1_bn
I0823 17:41:14.583534 15833 net.cpp:395] conv6_1_relu -> conv6_1_bn (in-place)
I0823 17:41:14.583546 15833 net.cpp:150] Setting up conv6_1_relu
I0823 17:41:14.583559 15833 net.cpp:157] Top shape: 64 64 15 15 (921600)
I0823 17:41:14.583560 15833 net.cpp:165] Memory required for data: 1612994560
I0823 17:41:14.583564 15833 layer_factory.hpp:77] Creating layer conv7_1
I0823 17:41:14.583570 15833 net.cpp:100] Creating Layer conv7_1
I0823 17:41:14.583572 15833 net.cpp:434] conv7_1 <- conv6_1_bn
I0823 17:41:14.583578 15833 net.cpp:408] conv7_1 -> conv7_1
I0823 17:41:14.585353 15833 net.cpp:150] Setting up conv7_1
I0823 17:41:14.585366 15833 net.cpp:157] Top shape: 64 128 13 13 (1384448)
I0823 17:41:14.585369 15833 net.cpp:165] Memory required for data: 1618532352
I0823 17:41:14.585374 15833 layer_factory.hpp:77] Creating layer conv7_1_bn
I0823 17:41:14.585383 15833 net.cpp:100] Creating Layer conv7_1_bn
I0823 17:41:14.585386 15833 net.cpp:434] conv7_1_bn <- conv7_1
I0823 17:41:14.585391 15833 net.cpp:408] conv7_1_bn -> conv7_1_bn
I0823 17:41:14.585530 15833 net.cpp:150] Setting up conv7_1_bn
I0823 17:41:14.585536 15833 net.cpp:157] Top shape: 64 128 13 13 (1384448)
I0823 17:41:14.585538 15833 net.cpp:165] Memory required for data: 1624070144
I0823 17:41:14.585543 15833 layer_factory.hpp:77] Creating layer conv7_1_bn_scale
I0823 17:41:14.585549 15833 net.cpp:100] Creating Layer conv7_1_bn_scale
I0823 17:41:14.585551 15833 net.cpp:434] conv7_1_bn_scale <- conv7_1_bn
I0823 17:41:14.585556 15833 net.cpp:395] conv7_1_bn_scale -> conv7_1_bn (in-place)
I0823 17:41:14.585584 15833 layer_factory.hpp:77] Creating layer conv7_1_bn_scale
I0823 17:41:14.585659 15833 net.cpp:150] Setting up conv7_1_bn_scale
I0823 17:41:14.585664 15833 net.cpp:157] Top shape: 64 128 13 13 (1384448)
I0823 17:41:14.585666 15833 net.cpp:165] Memory required for data: 1629607936
I0823 17:41:14.585672 15833 layer_factory.hpp:77] Creating layer conv7_1_relu
I0823 17:41:14.585676 15833 net.cpp:100] Creating Layer conv7_1_relu
I0823 17:41:14.585680 15833 net.cpp:434] conv7_1_relu <- conv7_1_bn
I0823 17:41:14.585683 15833 net.cpp:395] conv7_1_relu -> conv7_1_bn (in-place)
I0823 17:41:14.585687 15833 net.cpp:150] Setting up conv7_1_relu
I0823 17:41:14.585690 15833 net.cpp:157] Top shape: 64 128 13 13 (1384448)
I0823 17:41:14.585693 15833 net.cpp:165] Memory required for data: 1635145728
I0823 17:41:14.585695 15833 layer_factory.hpp:77] Creating layer score
I0823 17:41:14.585705 15833 net.cpp:100] Creating Layer score
I0823 17:41:14.585707 15833 net.cpp:434] score <- conv7_1_bn
I0823 17:41:14.585713 15833 net.cpp:408] score -> score
I0823 17:41:14.585899 15833 net.cpp:150] Setting up score
I0823 17:41:14.585906 15833 net.cpp:157] Top shape: 64 4 13 13 (43264)
I0823 17:41:14.585909 15833 net.cpp:165] Memory required for data: 1635318784
I0823 17:41:14.585914 15833 layer_factory.hpp:77] Creating layer upscore
I0823 17:41:14.585922 15833 net.cpp:100] Creating Layer upscore
I0823 17:41:14.585924 15833 net.cpp:434] upscore <- score
I0823 17:41:14.585930 15833 net.cpp:408] upscore -> upscore
I0823 17:41:14.586431 15833 net.cpp:150] Setting up upscore
I0823 17:41:14.586436 15833 net.cpp:157] Top shape: 64 4 224 224 (12845056)
I0823 17:41:14.586439 15833 net.cpp:165] Memory required for data: 1686699008
I0823 17:41:14.586443 15833 layer_factory.hpp:77] Creating layer cropscore
I0823 17:41:14.586450 15833 net.cpp:100] Creating Layer cropscore
I0823 17:41:14.586453 15833 net.cpp:434] cropscore <- upscore
I0823 17:41:14.586457 15833 net.cpp:434] cropscore <- image_data_0_split_1
I0823 17:41:14.586462 15833 net.cpp:408] cropscore -> cropscore
I0823 17:41:14.586479 15833 net.cpp:150] Setting up cropscore
I0823 17:41:14.586483 15833 net.cpp:157] Top shape: 64 4 200 200 (10240000)
I0823 17:41:14.586486 15833 net.cpp:165] Memory required for data: 1727659008
I0823 17:41:14.586488 15833 layer_factory.hpp:77] Creating layer cropscore_cropscore_0_split
I0823 17:41:14.586493 15833 net.cpp:100] Creating Layer cropscore_cropscore_0_split
I0823 17:41:14.586496 15833 net.cpp:434] cropscore_cropscore_0_split <- cropscore
I0823 17:41:14.586501 15833 net.cpp:408] cropscore_cropscore_0_split -> cropscore_cropscore_0_split_0
I0823 17:41:14.586521 15833 net.cpp:408] cropscore_cropscore_0_split -> cropscore_cropscore_0_split_1
I0823 17:41:14.586546 15833 net.cpp:150] Setting up cropscore_cropscore_0_split
I0823 17:41:14.586550 15833 net.cpp:157] Top shape: 64 4 200 200 (10240000)
I0823 17:41:14.586555 15833 net.cpp:157] Top shape: 64 4 200 200 (10240000)
I0823 17:41:14.586556 15833 net.cpp:165] Memory required for data: 1809579008
I0823 17:41:14.586560 15833 layer_factory.hpp:77] Creating layer loss
I0823 17:41:14.586565 15833 net.cpp:100] Creating Layer loss
I0823 17:41:14.586568 15833 net.cpp:434] loss <- cropscore_cropscore_0_split_0
I0823 17:41:14.586572 15833 net.cpp:434] loss <- label_data_1_split_0
I0823 17:41:14.586580 15833 net.cpp:408] loss -> loss
I0823 17:41:14.586586 15833 layer_factory.hpp:77] Creating layer loss
I0823 17:41:14.607904 15833 net.cpp:150] Setting up loss
I0823 17:41:14.607934 15833 net.cpp:157] Top shape: (1)
I0823 17:41:14.607939 15833 net.cpp:160]     with loss weight 1
I0823 17:41:14.607950 15833 net.cpp:165] Memory required for data: 1809579012
I0823 17:41:14.607954 15833 layer_factory.hpp:77] Creating layer accuracy
I0823 17:41:14.607962 15833 net.cpp:100] Creating Layer accuracy
I0823 17:41:14.607967 15833 net.cpp:434] accuracy <- cropscore_cropscore_0_split_1
I0823 17:41:14.607974 15833 net.cpp:434] accuracy <- label_data_1_split_1
I0823 17:41:14.607978 15833 net.cpp:408] accuracy -> accuracy
I0823 17:41:14.607986 15833 net.cpp:150] Setting up accuracy
I0823 17:41:14.607990 15833 net.cpp:157] Top shape: (1)
I0823 17:41:14.607992 15833 net.cpp:165] Memory required for data: 1809579016
I0823 17:41:14.607995 15833 net.cpp:228] accuracy does not need backward computation.
I0823 17:41:14.607998 15833 net.cpp:226] loss needs backward computation.
I0823 17:41:14.608001 15833 net.cpp:226] cropscore_cropscore_0_split needs backward computation.
I0823 17:41:14.608006 15833 net.cpp:226] cropscore needs backward computation.
I0823 17:41:14.608008 15833 net.cpp:226] upscore needs backward computation.
I0823 17:41:14.608011 15833 net.cpp:226] score needs backward computation.
I0823 17:41:14.608014 15833 net.cpp:226] conv7_1_relu needs backward computation.
I0823 17:41:14.608017 15833 net.cpp:226] conv7_1_bn_scale needs backward computation.
I0823 17:41:14.608021 15833 net.cpp:226] conv7_1_bn needs backward computation.
I0823 17:41:14.608023 15833 net.cpp:226] conv7_1 needs backward computation.
I0823 17:41:14.608026 15833 net.cpp:226] conv6_1_relu needs backward computation.
I0823 17:41:14.608028 15833 net.cpp:226] conv6_1_bn_scale needs backward computation.
I0823 17:41:14.608031 15833 net.cpp:226] conv6_1_bn needs backward computation.
I0823 17:41:14.608034 15833 net.cpp:226] conv6_1 needs backward computation.
I0823 17:41:14.608037 15833 net.cpp:226] conv5_1_relu needs backward computation.
I0823 17:41:14.608041 15833 net.cpp:226] conv5_1_bn_scale needs backward computation.
I0823 17:41:14.608043 15833 net.cpp:226] conv5_1_bn needs backward computation.
I0823 17:41:14.608047 15833 net.cpp:226] conv5_1 needs backward computation.
I0823 17:41:14.608049 15833 net.cpp:226] pool4 needs backward computation.
I0823 17:41:14.608052 15833 net.cpp:226] conv4_1_relu needs backward computation.
I0823 17:41:14.608054 15833 net.cpp:226] conv4_1_bn_scale needs backward computation.
I0823 17:41:14.608057 15833 net.cpp:226] conv4_1_bn needs backward computation.
I0823 17:41:14.608060 15833 net.cpp:226] conv4_1 needs backward computation.
I0823 17:41:14.608064 15833 net.cpp:226] pool3 needs backward computation.
I0823 17:41:14.608067 15833 net.cpp:226] conv3_1_relu needs backward computation.
I0823 17:41:14.608070 15833 net.cpp:226] conv3_1_bn_scale needs backward computation.
I0823 17:41:14.608073 15833 net.cpp:226] conv3_1_bn needs backward computation.
I0823 17:41:14.608077 15833 net.cpp:226] conv3_1 needs backward computation.
I0823 17:41:14.608079 15833 net.cpp:226] pool2 needs backward computation.
I0823 17:41:14.608083 15833 net.cpp:226] conv2_1_relu needs backward computation.
I0823 17:41:14.608093 15833 net.cpp:226] conv2_1_bn_scale needs backward computation.
I0823 17:41:14.608104 15833 net.cpp:226] conv2_1_bn needs backward computation.
I0823 17:41:14.608108 15833 net.cpp:226] conv2_1 needs backward computation.
I0823 17:41:14.608110 15833 net.cpp:226] pool1 needs backward computation.
I0823 17:41:14.608114 15833 net.cpp:226] conv1_1_relu needs backward computation.
I0823 17:41:14.608115 15833 net.cpp:226] conv1_1_bn_scale needs backward computation.
I0823 17:41:14.608119 15833 net.cpp:226] conv1_1_bn needs backward computation.
I0823 17:41:14.608121 15833 net.cpp:226] conv1_1 needs backward computation.
I0823 17:41:14.608125 15833 net.cpp:228] label_data_1_split does not need backward computation.
I0823 17:41:14.608129 15833 net.cpp:228] image_data_0_split does not need backward computation.
I0823 17:41:14.608131 15833 net.cpp:228] data does not need backward computation.
I0823 17:41:14.608134 15833 net.cpp:270] This network produces output accuracy
I0823 17:41:14.608136 15833 net.cpp:270] This network produces output loss
I0823 17:41:14.608155 15833 net.cpp:283] Network initialization done.
I0823 17:41:14.608258 15833 solver.cpp:60] Solver scaffolding done.
I0823 17:41:14.609344 15833 caffe.cpp:251] Starting Optimization
I0823 17:41:14.609351 15833 solver.cpp:279] Solving segmentation
I0823 17:41:14.609354 15833 solver.cpp:280] Learning Rate Policy: step
I0823 17:41:14.610481 15833 solver.cpp:337] Iteration 0, Testing net (#0)
I0823 17:41:22.266878 15833 solver.cpp:404]     Test net output #0: accuracy = 0.252792
I0823 17:41:22.266918 15833 solver.cpp:404]     Test net output #1: loss = 2.61034e+06 (* 1 = 2.61034e+06 loss)
I0823 17:41:23.946046 15833 solver.cpp:228] Iteration 0, loss = 55449.5
I0823 17:41:23.946079 15833 solver.cpp:244]     Train net output #0: accuracy = 0.259638
I0823 17:41:23.946089 15833 solver.cpp:244]     Train net output #1: loss = 55449.5 (* 1 = 55449.5 loss)
I0823 17:41:23.946100 15833 sgd_solver.cpp:106] Iteration 0, lr = 1e-05
I0823 17:42:49.763429 15833 solver.cpp:228] Iteration 50, loss = 40675.4
I0823 17:42:49.763501 15833 solver.cpp:244]     Train net output #0: accuracy = 0.519093
I0823 17:42:49.763512 15833 solver.cpp:244]     Train net output #1: loss = 40675.4 (* 1 = 40675.4 loss)
I0823 17:42:49.763520 15833 sgd_solver.cpp:106] Iteration 50, lr = 1e-05
I0823 17:44:16.061944 15833 solver.cpp:228] Iteration 100, loss = 31093.8
I0823 17:44:16.062036 15833 solver.cpp:244]     Train net output #0: accuracy = 0.707482
I0823 17:44:16.062048 15833 solver.cpp:244]     Train net output #1: loss = 31093.8 (* 1 = 31093.8 loss)
I0823 17:44:16.062055 15833 sgd_solver.cpp:106] Iteration 100, lr = 1e-05
I0823 17:45:43.103703 15833 solver.cpp:228] Iteration 150, loss = 31107.1
I0823 17:45:43.103775 15833 solver.cpp:244]     Train net output #0: accuracy = 0.665866
I0823 17:45:43.103787 15833 solver.cpp:244]     Train net output #1: loss = 31107.1 (* 1 = 31107.1 loss)
I0823 17:45:43.103795 15833 sgd_solver.cpp:106] Iteration 150, lr = 1e-05
I0823 17:47:08.223493 15833 solver.cpp:337] Iteration 200, Testing net (#0)
I0823 17:47:15.701941 15833 solver.cpp:404]     Test net output #0: accuracy = 0.622173
I0823 17:47:15.701993 15833 solver.cpp:404]     Test net output #1: loss = 67564.2 (* 1 = 67564.2 loss)
I0823 17:47:17.131319 15833 solver.cpp:228] Iteration 200, loss = 22347.6
I0823 17:47:17.131352 15833 solver.cpp:244]     Train net output #0: accuracy = 0.810188
I0823 17:47:17.131362 15833 solver.cpp:244]     Train net output #1: loss = 22347.6 (* 1 = 22347.6 loss)
I0823 17:47:17.131369 15833 sgd_solver.cpp:106] Iteration 200, lr = 1e-05
I0823 17:48:43.858710 15833 solver.cpp:228] Iteration 250, loss = 23050.5
I0823 17:48:43.858805 15833 solver.cpp:244]     Train net output #0: accuracy = 0.748894
I0823 17:48:43.858817 15833 solver.cpp:244]     Train net output #1: loss = 23050.5 (* 1 = 23050.5 loss)
I0823 17:48:43.858824 15833 sgd_solver.cpp:106] Iteration 250, lr = 1e-05
I0823 17:50:10.735019 15833 solver.cpp:228] Iteration 300, loss = 19640.8
I0823 17:50:10.735128 15833 solver.cpp:244]     Train net output #0: accuracy = 0.825495
I0823 17:50:10.735144 15833 solver.cpp:244]     Train net output #1: loss = 19640.8 (* 1 = 19640.8 loss)
I0823 17:50:10.735151 15833 sgd_solver.cpp:106] Iteration 300, lr = 1e-05
I0823 17:51:37.642613 15833 solver.cpp:228] Iteration 350, loss = 21483.3
I0823 17:51:37.642714 15833 solver.cpp:244]     Train net output #0: accuracy = 0.789734
I0823 17:51:37.642727 15833 solver.cpp:244]     Train net output #1: loss = 21483.3 (* 1 = 21483.3 loss)
I0823 17:51:37.642735 15833 sgd_solver.cpp:106] Iteration 350, lr = 1e-05
I0823 17:53:03.165190 15833 solver.cpp:337] Iteration 400, Testing net (#0)
I0823 17:53:10.722532 15833 solver.cpp:404]     Test net output #0: accuracy = 0.68467
I0823 17:53:10.722571 15833 solver.cpp:404]     Test net output #1: loss = 33409.6 (* 1 = 33409.6 loss)
I0823 17:53:12.163852 15833 solver.cpp:228] Iteration 400, loss = 23816.6
I0823 17:53:12.163885 15833 solver.cpp:244]     Train net output #0: accuracy = 0.755639
I0823 17:53:12.163895 15833 solver.cpp:244]     Train net output #1: loss = 23816.6 (* 1 = 23816.6 loss)
I0823 17:53:12.163902 15833 sgd_solver.cpp:106] Iteration 400, lr = 1e-05
I0823 17:54:39.151401 15833 solver.cpp:228] Iteration 450, loss = 20455.8
I0823 17:54:39.151494 15833 solver.cpp:244]     Train net output #0: accuracy = 0.781546
I0823 17:54:39.151505 15833 solver.cpp:244]     Train net output #1: loss = 20455.8 (* 1 = 20455.8 loss)
I0823 17:54:39.151512 15833 sgd_solver.cpp:106] Iteration 450, lr = 1e-05
I0823 17:56:06.107996 15833 solver.cpp:228] Iteration 500, loss = 25602.6
I0823 17:56:06.108088 15833 solver.cpp:244]     Train net output #0: accuracy = 0.74367
I0823 17:56:06.108099 15833 solver.cpp:244]     Train net output #1: loss = 25602.6 (* 1 = 25602.6 loss)
I0823 17:56:06.108106 15833 sgd_solver.cpp:106] Iteration 500, lr = 1e-05
I0823 17:57:33.112493 15833 solver.cpp:228] Iteration 550, loss = 16664.8
I0823 17:57:33.112565 15833 solver.cpp:244]     Train net output #0: accuracy = 0.834633
I0823 17:57:33.112576 15833 solver.cpp:244]     Train net output #1: loss = 16664.8 (* 1 = 16664.8 loss)
I0823 17:57:33.112582 15833 sgd_solver.cpp:106] Iteration 550, lr = 1e-05
I0823 17:58:58.652597 15833 solver.cpp:337] Iteration 600, Testing net (#0)
I0823 17:59:06.158033 15833 solver.cpp:404]     Test net output #0: accuracy = 0.685068
I0823 17:59:06.158073 15833 solver.cpp:404]     Test net output #1: loss = 36525.6 (* 1 = 36525.6 loss)
I0823 17:59:07.597178 15833 solver.cpp:228] Iteration 600, loss = 20179.4
I0823 17:59:07.597210 15833 solver.cpp:244]     Train net output #0: accuracy = 0.802838
I0823 17:59:07.597220 15833 solver.cpp:244]     Train net output #1: loss = 20179.4 (* 1 = 20179.4 loss)
I0823 17:59:07.597228 15833 sgd_solver.cpp:106] Iteration 600, lr = 1e-05
I0823 18:00:34.566684 15833 solver.cpp:228] Iteration 650, loss = 15625.8
I0823 18:00:34.566754 15833 solver.cpp:244]     Train net output #0: accuracy = 0.853078
I0823 18:00:34.566766 15833 solver.cpp:244]     Train net output #1: loss = 15625.8 (* 1 = 15625.8 loss)
I0823 18:00:34.566771 15833 sgd_solver.cpp:106] Iteration 650, lr = 1e-05
I0823 18:02:01.583215 15833 solver.cpp:228] Iteration 700, loss = 14890.5
I0823 18:02:01.583310 15833 solver.cpp:244]     Train net output #0: accuracy = 0.855705
I0823 18:02:01.583323 15833 solver.cpp:244]     Train net output #1: loss = 14890.5 (* 1 = 14890.5 loss)
I0823 18:02:01.583329 15833 sgd_solver.cpp:106] Iteration 700, lr = 1e-05
I0823 18:03:28.579264 15833 solver.cpp:228] Iteration 750, loss = 17163.3
I0823 18:03:28.579344 15833 solver.cpp:244]     Train net output #0: accuracy = 0.840197
I0823 18:03:28.579355 15833 solver.cpp:244]     Train net output #1: loss = 17163.3 (* 1 = 17163.3 loss)
I0823 18:03:28.579362 15833 sgd_solver.cpp:106] Iteration 750, lr = 1e-05
I0823 18:04:54.144968 15833 solver.cpp:337] Iteration 800, Testing net (#0)
I0823 18:05:01.695308 15833 solver.cpp:404]     Test net output #0: accuracy = 0.640571
I0823 18:05:01.695348 15833 solver.cpp:404]     Test net output #1: loss = 36080.7 (* 1 = 36080.7 loss)
I0823 18:05:03.130925 15833 solver.cpp:228] Iteration 800, loss = 16915.6
I0823 18:05:03.130957 15833 solver.cpp:244]     Train net output #0: accuracy = 0.832484
I0823 18:05:03.130967 15833 solver.cpp:244]     Train net output #1: loss = 16915.6 (* 1 = 16915.6 loss)
I0823 18:05:03.130973 15833 sgd_solver.cpp:106] Iteration 800, lr = 1e-05
I0823 18:06:30.078388 15833 solver.cpp:228] Iteration 850, loss = 17789.7
I0823 18:06:30.078508 15833 solver.cpp:244]     Train net output #0: accuracy = 0.818604
I0823 18:06:30.078521 15833 solver.cpp:244]     Train net output #1: loss = 17789.7 (* 1 = 17789.7 loss)
I0823 18:06:30.078527 15833 sgd_solver.cpp:106] Iteration 850, lr = 1e-05
I0823 18:07:57.036110 15833 solver.cpp:228] Iteration 900, loss = 13011.2
I0823 18:07:57.036207 15833 solver.cpp:244]     Train net output #0: accuracy = 0.871312
I0823 18:07:57.036219 15833 solver.cpp:244]     Train net output #1: loss = 13011.2 (* 1 = 13011.2 loss)
I0823 18:07:57.036226 15833 sgd_solver.cpp:106] Iteration 900, lr = 1e-05
I0823 18:09:23.994993 15833 solver.cpp:228] Iteration 950, loss = 15030.6
I0823 18:09:23.995039 15833 solver.cpp:244]     Train net output #0: accuracy = 0.852987
I0823 18:09:23.995049 15833 solver.cpp:244]     Train net output #1: loss = 15030.6 (* 1 = 15030.6 loss)
I0823 18:09:23.995056 15833 sgd_solver.cpp:106] Iteration 950, lr = 1e-05
I0823 18:10:49.542531 15833 solver.cpp:337] Iteration 1000, Testing net (#0)
I0823 18:10:57.101047 15833 solver.cpp:404]     Test net output #0: accuracy = 0.673265
I0823 18:10:57.101086 15833 solver.cpp:404]     Test net output #1: loss = 31299.6 (* 1 = 31299.6 loss)
I0823 18:10:58.533855 15833 solver.cpp:228] Iteration 1000, loss = 9941.79
I0823 18:10:58.533888 15833 solver.cpp:244]     Train net output #0: accuracy = 0.906704
I0823 18:10:58.533898 15833 solver.cpp:244]     Train net output #1: loss = 9941.79 (* 1 = 9941.79 loss)
I0823 18:10:58.533905 15833 sgd_solver.cpp:106] Iteration 1000, lr = 1e-05
I0823 18:12:25.520928 15833 solver.cpp:228] Iteration 1050, loss = 14567.4
I0823 18:12:25.520977 15833 solver.cpp:244]     Train net output #0: accuracy = 0.861044
I0823 18:12:25.520987 15833 solver.cpp:244]     Train net output #1: loss = 14567.4 (* 1 = 14567.4 loss)
I0823 18:12:25.520993 15833 sgd_solver.cpp:106] Iteration 1050, lr = 1e-05
I0823 18:13:52.480468 15833 solver.cpp:228] Iteration 1100, loss = 12632.7
I0823 18:13:52.480541 15833 solver.cpp:244]     Train net output #0: accuracy = 0.881209
I0823 18:13:52.480552 15833 solver.cpp:244]     Train net output #1: loss = 12632.7 (* 1 = 12632.7 loss)
I0823 18:13:52.480559 15833 sgd_solver.cpp:106] Iteration 1100, lr = 1e-05
I0823 18:15:19.471971 15833 solver.cpp:228] Iteration 1150, loss = 10425.8
I0823 18:15:19.472060 15833 solver.cpp:244]     Train net output #0: accuracy = 0.90407
I0823 18:15:19.472071 15833 solver.cpp:244]     Train net output #1: loss = 10425.8 (* 1 = 10425.8 loss)
I0823 18:15:19.472079 15833 sgd_solver.cpp:106] Iteration 1150, lr = 1e-05
I0823 18:16:45.024245 15833 solver.cpp:337] Iteration 1200, Testing net (#0)
I0823 18:16:52.606986 15833 solver.cpp:404]     Test net output #0: accuracy = 0.675191
I0823 18:16:52.607028 15833 solver.cpp:404]     Test net output #1: loss = 31388.4 (* 1 = 31388.4 loss)
I0823 18:16:54.045820 15833 solver.cpp:228] Iteration 1200, loss = 11846.5
I0823 18:16:54.045852 15833 solver.cpp:244]     Train net output #0: accuracy = 0.882381
I0823 18:16:54.045862 15833 solver.cpp:244]     Train net output #1: loss = 11846.5 (* 1 = 11846.5 loss)
I0823 18:16:54.045869 15833 sgd_solver.cpp:106] Iteration 1200, lr = 1e-05
I0823 18:18:21.056998 15833 solver.cpp:228] Iteration 1250, loss = 9716.74
I0823 18:18:21.057085 15833 solver.cpp:244]     Train net output #0: accuracy = 0.907499
I0823 18:18:21.057097 15833 solver.cpp:244]     Train net output #1: loss = 9716.74 (* 1 = 9716.74 loss)
I0823 18:18:21.057104 15833 sgd_solver.cpp:106] Iteration 1250, lr = 1e-05
I0823 18:19:48.022892 15833 solver.cpp:228] Iteration 1300, loss = 11275.7
I0823 18:19:48.022989 15833 solver.cpp:244]     Train net output #0: accuracy = 0.889559
I0823 18:19:48.023005 15833 solver.cpp:244]     Train net output #1: loss = 11275.7 (* 1 = 11275.7 loss)
I0823 18:19:48.023011 15833 sgd_solver.cpp:106] Iteration 1300, lr = 1e-05
I0823 18:21:14.988634 15833 solver.cpp:228] Iteration 1350, loss = 7859.77
I0823 18:21:14.988709 15833 solver.cpp:244]     Train net output #0: accuracy = 0.924965
I0823 18:21:14.988720 15833 solver.cpp:244]     Train net output #1: loss = 7859.77 (* 1 = 7859.77 loss)
I0823 18:21:14.988726 15833 sgd_solver.cpp:106] Iteration 1350, lr = 1e-05
I0823 18:22:40.521543 15833 solver.cpp:337] Iteration 1400, Testing net (#0)
I0823 18:22:48.091693 15833 solver.cpp:404]     Test net output #0: accuracy = 0.706882
I0823 18:22:48.091734 15833 solver.cpp:404]     Test net output #1: loss = 27941.1 (* 1 = 27941.1 loss)
I0823 18:22:49.536582 15833 solver.cpp:228] Iteration 1400, loss = 12410
I0823 18:22:49.536614 15833 solver.cpp:244]     Train net output #0: accuracy = 0.873403
I0823 18:22:49.536625 15833 solver.cpp:244]     Train net output #1: loss = 12410 (* 1 = 12410 loss)
I0823 18:22:49.536631 15833 sgd_solver.cpp:106] Iteration 1400, lr = 1e-05
I0823 18:24:16.494523 15833 solver.cpp:228] Iteration 1450, loss = 7334.79
I0823 18:24:16.494597 15833 solver.cpp:244]     Train net output #0: accuracy = 0.930767
I0823 18:24:16.494609 15833 solver.cpp:244]     Train net output #1: loss = 7334.79 (* 1 = 7334.79 loss)
I0823 18:24:16.494616 15833 sgd_solver.cpp:106] Iteration 1450, lr = 1e-05
I0823 18:25:43.513820 15833 solver.cpp:228] Iteration 1500, loss = 11338.7
I0823 18:25:43.513896 15833 solver.cpp:244]     Train net output #0: accuracy = 0.887152
I0823 18:25:43.513908 15833 solver.cpp:244]     Train net output #1: loss = 11338.7 (* 1 = 11338.7 loss)
I0823 18:25:43.513914 15833 sgd_solver.cpp:106] Iteration 1500, lr = 1e-05
I0823 18:27:10.471947 15833 solver.cpp:228] Iteration 1550, loss = 12815.4
I0823 18:27:10.471989 15833 solver.cpp:244]     Train net output #0: accuracy = 0.876195
I0823 18:27:10.471999 15833 solver.cpp:244]     Train net output #1: loss = 12815.4 (* 1 = 12815.4 loss)
I0823 18:27:10.472007 15833 sgd_solver.cpp:106] Iteration 1550, lr = 1e-05
I0823 18:28:36.030133 15833 solver.cpp:337] Iteration 1600, Testing net (#0)
I0823 18:28:43.641394 15833 solver.cpp:404]     Test net output #0: accuracy = 0.735835
I0823 18:28:43.641433 15833 solver.cpp:404]     Test net output #1: loss = 25698 (* 1 = 25698 loss)
I0823 18:28:45.074126 15833 solver.cpp:228] Iteration 1600, loss = 8226.87
I0823 18:28:45.074159 15833 solver.cpp:244]     Train net output #0: accuracy = 0.922815
I0823 18:28:45.074169 15833 solver.cpp:244]     Train net output #1: loss = 8226.87 (* 1 = 8226.87 loss)
I0823 18:28:45.074177 15833 sgd_solver.cpp:106] Iteration 1600, lr = 1e-05
I0823 18:30:12.075847 15833 solver.cpp:228] Iteration 1650, loss = 8580.86
I0823 18:30:12.075892 15833 solver.cpp:244]     Train net output #0: accuracy = 0.914771
I0823 18:30:12.075903 15833 solver.cpp:244]     Train net output #1: loss = 8580.86 (* 1 = 8580.86 loss)
I0823 18:30:12.075909 15833 sgd_solver.cpp:106] Iteration 1650, lr = 1e-05
I0823 18:31:39.070618 15833 solver.cpp:228] Iteration 1700, loss = 6601.9
I0823 18:31:39.070659 15833 solver.cpp:244]     Train net output #0: accuracy = 0.939199
I0823 18:31:39.070669 15833 solver.cpp:244]     Train net output #1: loss = 6601.9 (* 1 = 6601.9 loss)
I0823 18:31:39.070677 15833 sgd_solver.cpp:106] Iteration 1700, lr = 1e-05
I0823 18:33:06.061622 15833 solver.cpp:228] Iteration 1750, loss = 9033.49
I0823 18:33:06.061668 15833 solver.cpp:244]     Train net output #0: accuracy = 0.908919
I0823 18:33:06.061679 15833 solver.cpp:244]     Train net output #1: loss = 9033.49 (* 1 = 9033.49 loss)
I0823 18:33:06.061686 15833 sgd_solver.cpp:106] Iteration 1750, lr = 1e-05
I0823 18:34:31.605769 15833 solver.cpp:337] Iteration 1800, Testing net (#0)
I0823 18:34:39.164825 15833 solver.cpp:404]     Test net output #0: accuracy = 0.762015
I0823 18:34:39.164867 15833 solver.cpp:404]     Test net output #1: loss = 24923.4 (* 1 = 24923.4 loss)
I0823 18:34:40.598884 15833 solver.cpp:228] Iteration 1800, loss = 5600.68
I0823 18:34:40.598915 15833 solver.cpp:244]     Train net output #0: accuracy = 0.946237
I0823 18:34:40.598925 15833 solver.cpp:244]     Train net output #1: loss = 5600.68 (* 1 = 5600.68 loss)
I0823 18:34:40.598932 15833 sgd_solver.cpp:106] Iteration 1800, lr = 1e-05
I0823 18:36:07.573516 15833 solver.cpp:228] Iteration 1850, loss = 11874.1
I0823 18:36:07.573619 15833 solver.cpp:244]     Train net output #0: accuracy = 0.879856
I0823 18:36:07.573632 15833 solver.cpp:244]     Train net output #1: loss = 11874.1 (* 1 = 11874.1 loss)
I0823 18:36:07.573639 15833 sgd_solver.cpp:106] Iteration 1850, lr = 1e-05
I0823 18:37:34.538771 15833 solver.cpp:228] Iteration 1900, loss = 11059.8
I0823 18:37:34.538822 15833 solver.cpp:244]     Train net output #0: accuracy = 0.892638
I0823 18:37:34.538832 15833 solver.cpp:244]     Train net output #1: loss = 11059.8 (* 1 = 11059.8 loss)
I0823 18:37:34.538839 15833 sgd_solver.cpp:106] Iteration 1900, lr = 1e-05
I0823 18:39:01.552644 15833 solver.cpp:228] Iteration 1950, loss = 6785.59
I0823 18:39:01.552737 15833 solver.cpp:244]     Train net output #0: accuracy = 0.937302
I0823 18:39:01.552748 15833 solver.cpp:244]     Train net output #1: loss = 6785.59 (* 1 = 6785.59 loss)
I0823 18:39:01.552755 15833 sgd_solver.cpp:106] Iteration 1950, lr = 1e-05
I0823 18:40:27.095397 15833 solver.cpp:337] Iteration 2000, Testing net (#0)
I0823 18:40:34.669844 15833 solver.cpp:404]     Test net output #0: accuracy = 0.816721
I0823 18:40:34.669885 15833 solver.cpp:404]     Test net output #1: loss = 18605.3 (* 1 = 18605.3 loss)
I0823 18:40:36.109890 15833 solver.cpp:228] Iteration 2000, loss = 11801.3
I0823 18:40:36.109923 15833 solver.cpp:244]     Train net output #0: accuracy = 0.882837
I0823 18:40:36.109933 15833 solver.cpp:244]     Train net output #1: loss = 11801.3 (* 1 = 11801.3 loss)
I0823 18:40:36.109941 15833 sgd_solver.cpp:106] Iteration 2000, lr = 1e-05
I0823 18:42:03.092207 15833 solver.cpp:228] Iteration 2050, loss = 6705.92
I0823 18:42:03.092255 15833 solver.cpp:244]     Train net output #0: accuracy = 0.937111
I0823 18:42:03.092265 15833 solver.cpp:244]     Train net output #1: loss = 6705.92 (* 1 = 6705.92 loss)
I0823 18:42:03.092273 15833 sgd_solver.cpp:106] Iteration 2050, lr = 1e-05
I0823 18:43:30.070297 15833 solver.cpp:228] Iteration 2100, loss = 9575.31
I0823 18:43:30.070343 15833 solver.cpp:244]     Train net output #0: accuracy = 0.906523
I0823 18:43:30.070354 15833 solver.cpp:244]     Train net output #1: loss = 9575.31 (* 1 = 9575.31 loss)
I0823 18:43:30.070361 15833 sgd_solver.cpp:106] Iteration 2100, lr = 1e-05
I0823 18:44:57.033524 15833 solver.cpp:228] Iteration 2150, loss = 5277.47
I0823 18:44:57.033571 15833 solver.cpp:244]     Train net output #0: accuracy = 0.95038
I0823 18:44:57.033581 15833 solver.cpp:244]     Train net output #1: loss = 5277.47 (* 1 = 5277.47 loss)
I0823 18:44:57.033587 15833 sgd_solver.cpp:106] Iteration 2150, lr = 1e-05
I0823 18:46:22.583446 15833 solver.cpp:337] Iteration 2200, Testing net (#0)
I0823 18:46:30.135424 15833 solver.cpp:404]     Test net output #0: accuracy = 0.782483
I0823 18:46:30.135464 15833 solver.cpp:404]     Test net output #1: loss = 22622.9 (* 1 = 22622.9 loss)
I0823 18:46:31.579840 15833 solver.cpp:228] Iteration 2200, loss = 10254.8
I0823 18:46:31.579875 15833 solver.cpp:244]     Train net output #0: accuracy = 0.899033
I0823 18:46:31.579885 15833 solver.cpp:244]     Train net output #1: loss = 10254.8 (* 1 = 10254.8 loss)
I0823 18:46:31.579892 15833 sgd_solver.cpp:106] Iteration 2200, lr = 1e-05
I0823 18:47:58.505870 15833 solver.cpp:228] Iteration 2250, loss = 8794.82
I0823 18:47:58.505916 15833 solver.cpp:244]     Train net output #0: accuracy = 0.912736
I0823 18:47:58.505928 15833 solver.cpp:244]     Train net output #1: loss = 8794.82 (* 1 = 8794.82 loss)
I0823 18:47:58.505934 15833 sgd_solver.cpp:106] Iteration 2250, lr = 1e-05
I0823 18:49:25.490558 15833 solver.cpp:228] Iteration 2300, loss = 6321.06
I0823 18:49:25.490634 15833 solver.cpp:244]     Train net output #0: accuracy = 0.939242
I0823 18:49:25.490645 15833 solver.cpp:244]     Train net output #1: loss = 6321.06 (* 1 = 6321.06 loss)
I0823 18:49:25.490653 15833 sgd_solver.cpp:106] Iteration 2300, lr = 1e-05
I0823 18:50:52.452296 15833 solver.cpp:228] Iteration 2350, loss = 10605.8
I0823 18:50:52.452392 15833 solver.cpp:244]     Train net output #0: accuracy = 0.894874
I0823 18:50:52.452404 15833 solver.cpp:244]     Train net output #1: loss = 10605.8 (* 1 = 10605.8 loss)
I0823 18:50:52.452411 15833 sgd_solver.cpp:106] Iteration 2350, lr = 1e-05
I0823 18:52:17.995987 15833 solver.cpp:337] Iteration 2400, Testing net (#0)
I0823 18:52:25.531183 15833 solver.cpp:404]     Test net output #0: accuracy = 0.827952
I0823 18:52:25.531224 15833 solver.cpp:404]     Test net output #1: loss = 17640.8 (* 1 = 17640.8 loss)
I0823 18:52:26.963434 15833 solver.cpp:228] Iteration 2400, loss = 6122.32
I0823 18:52:26.963467 15833 solver.cpp:244]     Train net output #0: accuracy = 0.941245
I0823 18:52:26.963477 15833 solver.cpp:244]     Train net output #1: loss = 6122.32 (* 1 = 6122.32 loss)
I0823 18:52:26.963485 15833 sgd_solver.cpp:106] Iteration 2400, lr = 1e-05
I0823 18:53:53.933751 15833 solver.cpp:228] Iteration 2450, loss = 11082.4
I0823 18:53:53.933797 15833 solver.cpp:244]     Train net output #0: accuracy = 0.892808
I0823 18:53:53.933807 15833 solver.cpp:244]     Train net output #1: loss = 11082.4 (* 1 = 11082.4 loss)
I0823 18:53:53.933815 15833 sgd_solver.cpp:106] Iteration 2450, lr = 1e-05
I0823 18:55:20.902314 15833 solver.cpp:228] Iteration 2500, loss = 6537.53
I0823 18:55:20.902406 15833 solver.cpp:244]     Train net output #0: accuracy = 0.936597
I0823 18:55:20.902418 15833 solver.cpp:244]     Train net output #1: loss = 6537.53 (* 1 = 6537.53 loss)
I0823 18:55:20.902426 15833 sgd_solver.cpp:106] Iteration 2500, lr = 1e-05
I0823 18:56:47.867455 15833 solver.cpp:228] Iteration 2550, loss = 7311.63
I0823 18:56:47.867501 15833 solver.cpp:244]     Train net output #0: accuracy = 0.928239
I0823 18:56:47.867512 15833 solver.cpp:244]     Train net output #1: loss = 7311.63 (* 1 = 7311.63 loss)
I0823 18:56:47.867518 15833 sgd_solver.cpp:106] Iteration 2550, lr = 1e-05
I0823 18:58:13.379420 15833 solver.cpp:337] Iteration 2600, Testing net (#0)
I0823 18:58:20.925107 15833 solver.cpp:404]     Test net output #0: accuracy = 0.807366
I0823 18:58:20.925148 15833 solver.cpp:404]     Test net output #1: loss = 20262.5 (* 1 = 20262.5 loss)
I0823 18:58:22.357686 15833 solver.cpp:228] Iteration 2600, loss = 4965.51
I0823 18:58:22.357718 15833 solver.cpp:244]     Train net output #0: accuracy = 0.953995
I0823 18:58:22.357733 15833 solver.cpp:244]     Train net output #1: loss = 4965.51 (* 1 = 4965.51 loss)
I0823 18:58:22.357738 15833 sgd_solver.cpp:106] Iteration 2600, lr = 1e-05
I0823 18:59:49.348709 15833 solver.cpp:228] Iteration 2650, loss = 9053.01
I0823 18:59:49.348799 15833 solver.cpp:244]     Train net output #0: accuracy = 0.909045
I0823 18:59:49.348811 15833 solver.cpp:244]     Train net output #1: loss = 9053.01 (* 1 = 9053.01 loss)
I0823 18:59:49.348819 15833 sgd_solver.cpp:106] Iteration 2650, lr = 1e-05
I0823 19:01:16.300549 15833 solver.cpp:228] Iteration 2700, loss = 9608.38
I0823 19:01:16.300642 15833 solver.cpp:244]     Train net output #0: accuracy = 0.90266
I0823 19:01:16.300654 15833 solver.cpp:244]     Train net output #1: loss = 9608.38 (* 1 = 9608.38 loss)
I0823 19:01:16.300660 15833 sgd_solver.cpp:106] Iteration 2700, lr = 1e-05
I0823 19:02:43.247911 15833 solver.cpp:228] Iteration 2750, loss = 5445.19
I0823 19:02:43.247984 15833 solver.cpp:244]     Train net output #0: accuracy = 0.947291
I0823 19:02:43.247995 15833 solver.cpp:244]     Train net output #1: loss = 5445.19 (* 1 = 5445.19 loss)
I0823 19:02:43.248003 15833 sgd_solver.cpp:106] Iteration 2750, lr = 1e-05
I0823 19:04:08.774322 15833 solver.cpp:337] Iteration 2800, Testing net (#0)
I0823 19:04:16.308203 15833 solver.cpp:404]     Test net output #0: accuracy = 0.843528
I0823 19:04:16.308243 15833 solver.cpp:404]     Test net output #1: loss = 16455.4 (* 1 = 16455.4 loss)
I0823 19:04:17.750339 15833 solver.cpp:228] Iteration 2800, loss = 10695.1
I0823 19:04:17.750370 15833 solver.cpp:244]     Train net output #0: accuracy = 0.8935
I0823 19:04:17.750380 15833 solver.cpp:244]     Train net output #1: loss = 10695.1 (* 1 = 10695.1 loss)
I0823 19:04:17.750386 15833 sgd_solver.cpp:106] Iteration 2800, lr = 1e-05
I0823 19:05:44.717991 15833 solver.cpp:228] Iteration 2850, loss = 5698.92
I0823 19:05:44.718089 15833 solver.cpp:244]     Train net output #0: accuracy = 0.945481
I0823 19:05:44.718101 15833 solver.cpp:244]     Train net output #1: loss = 5698.92 (* 1 = 5698.92 loss)
I0823 19:05:44.718108 15833 sgd_solver.cpp:106] Iteration 2850, lr = 1e-05
I0823 19:07:11.704507 15833 solver.cpp:228] Iteration 2900, loss = 10605.8
I0823 19:07:11.704602 15833 solver.cpp:244]     Train net output #0: accuracy = 0.898252
I0823 19:07:11.704613 15833 solver.cpp:244]     Train net output #1: loss = 10605.8 (* 1 = 10605.8 loss)
I0823 19:07:11.704619 15833 sgd_solver.cpp:106] Iteration 2900, lr = 1e-05
I0823 19:08:38.654019 15833 solver.cpp:228] Iteration 2950, loss = 6902.94
I0823 19:08:38.654119 15833 solver.cpp:244]     Train net output #0: accuracy = 0.934357
I0823 19:08:38.654131 15833 solver.cpp:244]     Train net output #1: loss = 6902.94 (* 1 = 6902.94 loss)
I0823 19:08:38.654139 15833 sgd_solver.cpp:106] Iteration 2950, lr = 1e-05
I0823 19:10:04.208997 15833 solver.cpp:454] Snapshotting to binary proto file portrait_one_stage2_1_iter_3000.caffemodel
I0823 19:10:04.213049 15833 sgd_solver.cpp:273] Snapshotting solver state to binary proto file portrait_one_stage2_1_iter_3000.solverstate
I0823 19:10:04.214066 15833 solver.cpp:337] Iteration 3000, Testing net (#0)
I0823 19:10:11.785807 15833 solver.cpp:404]     Test net output #0: accuracy = 0.842776
I0823 19:10:11.785847 15833 solver.cpp:404]     Test net output #1: loss = 16649.4 (* 1 = 16649.4 loss)
I0823 19:10:13.226752 15833 solver.cpp:228] Iteration 3000, loss = 6911.55
I0823 19:10:13.226785 15833 solver.cpp:244]     Train net output #0: accuracy = 0.932568
I0823 19:10:13.226795 15833 solver.cpp:244]     Train net output #1: loss = 6911.55 (* 1 = 6911.55 loss)
I0823 19:10:13.226801 15833 sgd_solver.cpp:106] Iteration 3000, lr = 1e-06
I0823 19:11:40.219169 15833 solver.cpp:228] Iteration 3050, loss = 8048.83
I0823 19:11:40.219257 15833 solver.cpp:244]     Train net output #0: accuracy = 0.922235
I0823 19:11:40.219269 15833 solver.cpp:244]     Train net output #1: loss = 8048.83 (* 1 = 8048.83 loss)
I0823 19:11:40.219276 15833 sgd_solver.cpp:106] Iteration 3050, lr = 1e-06
I0823 19:13:07.213268 15833 solver.cpp:228] Iteration 3100, loss = 4506.26
I0823 19:13:07.213315 15833 solver.cpp:244]     Train net output #0: accuracy = 0.956506
I0823 19:13:07.213327 15833 solver.cpp:244]     Train net output #1: loss = 4506.26 (* 1 = 4506.26 loss)
I0823 19:13:07.213333 15833 sgd_solver.cpp:106] Iteration 3100, lr = 1e-06
I0823 19:14:34.169523 15833 solver.cpp:228] Iteration 3150, loss = 7869.19
I0823 19:14:34.169612 15833 solver.cpp:244]     Train net output #0: accuracy = 0.922359
I0823 19:14:34.169625 15833 solver.cpp:244]     Train net output #1: loss = 7869.19 (* 1 = 7869.19 loss)
I0823 19:14:34.169631 15833 sgd_solver.cpp:106] Iteration 3150, lr = 1e-06
I0823 19:15:59.723067 15833 solver.cpp:337] Iteration 3200, Testing net (#0)
I0823 19:16:07.283960 15833 solver.cpp:404]     Test net output #0: accuracy = 0.880209
I0823 19:16:07.284001 15833 solver.cpp:404]     Test net output #1: loss = 12704.8 (* 1 = 12704.8 loss)
I0823 19:16:08.730824 15833 solver.cpp:228] Iteration 3200, loss = 4940.96
I0823 19:16:08.730859 15833 solver.cpp:244]     Train net output #0: accuracy = 0.950609
I0823 19:16:08.730867 15833 solver.cpp:244]     Train net output #1: loss = 4940.96 (* 1 = 4940.96 loss)
I0823 19:16:08.730875 15833 sgd_solver.cpp:106] Iteration 3200, lr = 1e-06
I0823 19:17:35.701975 15833 solver.cpp:228] Iteration 3250, loss = 9009.12
I0823 19:17:35.702097 15833 solver.cpp:244]     Train net output #0: accuracy = 0.911514
I0823 19:17:35.702112 15833 solver.cpp:244]     Train net output #1: loss = 9009.12 (* 1 = 9009.12 loss)
I0823 19:17:35.702119 15833 sgd_solver.cpp:106] Iteration 3250, lr = 1e-06
I0823 19:19:02.686929 15833 solver.cpp:228] Iteration 3300, loss = 5151.74
I0823 19:19:02.687026 15833 solver.cpp:244]     Train net output #0: accuracy = 0.950557
I0823 19:19:02.687037 15833 solver.cpp:244]     Train net output #1: loss = 5151.74 (* 1 = 5151.74 loss)
I0823 19:19:02.687044 15833 sgd_solver.cpp:106] Iteration 3300, lr = 1e-06
I0823 19:20:29.705137 15833 solver.cpp:228] Iteration 3350, loss = 8679.41
I0823 19:20:29.705207 15833 solver.cpp:244]     Train net output #0: accuracy = 0.917683
I0823 19:20:29.705219 15833 solver.cpp:244]     Train net output #1: loss = 8679.41 (* 1 = 8679.41 loss)
I0823 19:20:29.705225 15833 sgd_solver.cpp:106] Iteration 3350, lr = 1e-06
I0823 19:21:55.220052 15833 solver.cpp:337] Iteration 3400, Testing net (#0)
I0823 19:22:02.816704 15833 solver.cpp:404]     Test net output #0: accuracy = 0.884658
I0823 19:22:02.816743 15833 solver.cpp:404]     Test net output #1: loss = 12038.8 (* 1 = 12038.8 loss)
I0823 19:22:04.250833 15833 solver.cpp:228] Iteration 3400, loss = 7345.13
I0823 19:22:04.250865 15833 solver.cpp:244]     Train net output #0: accuracy = 0.930114
I0823 19:22:04.250875 15833 solver.cpp:244]     Train net output #1: loss = 7345.13 (* 1 = 7345.13 loss)
I0823 19:22:04.250881 15833 sgd_solver.cpp:106] Iteration 3400, lr = 1e-06
I0823 19:23:31.237828 15833 solver.cpp:228] Iteration 3450, loss = 5941.34
I0823 19:23:31.237920 15833 solver.cpp:244]     Train net output #0: accuracy = 0.944386
I0823 19:23:31.237931 15833 solver.cpp:244]     Train net output #1: loss = 5941.34 (* 1 = 5941.34 loss)
I0823 19:23:31.237938 15833 sgd_solver.cpp:106] Iteration 3450, lr = 1e-06
I0823 19:24:58.217432 15833 solver.cpp:228] Iteration 3500, loss = 6963.97
I0823 19:24:58.217526 15833 solver.cpp:244]     Train net output #0: accuracy = 0.933101
I0823 19:24:58.217538 15833 solver.cpp:244]     Train net output #1: loss = 6963.97 (* 1 = 6963.97 loss)
I0823 19:24:58.217545 15833 sgd_solver.cpp:106] Iteration 3500, lr = 1e-06
I0823 19:26:25.272402 15833 solver.cpp:228] Iteration 3550, loss = 4551.16
I0823 19:26:25.272493 15833 solver.cpp:244]     Train net output #0: accuracy = 0.956025
I0823 19:26:25.272505 15833 solver.cpp:244]     Train net output #1: loss = 4551.16 (* 1 = 4551.16 loss)
I0823 19:26:25.272511 15833 sgd_solver.cpp:106] Iteration 3550, lr = 1e-06
I0823 19:27:50.800817 15833 solver.cpp:337] Iteration 3600, Testing net (#0)
I0823 19:27:58.371368 15833 solver.cpp:404]     Test net output #0: accuracy = 0.900933
I0823 19:27:58.371408 15833 solver.cpp:404]     Test net output #1: loss = 10369.2 (* 1 = 10369.2 loss)
I0823 19:27:59.814230 15833 solver.cpp:228] Iteration 3600, loss = 8241.38
I0823 19:27:59.814265 15833 solver.cpp:244]     Train net output #0: accuracy = 0.918992
I0823 19:27:59.814275 15833 solver.cpp:244]     Train net output #1: loss = 8241.38 (* 1 = 8241.38 loss)
I0823 19:27:59.814281 15833 sgd_solver.cpp:106] Iteration 3600, lr = 1e-06
I0823 19:29:26.771778 15833 solver.cpp:228] Iteration 3650, loss = 5135.75
I0823 19:29:26.771823 15833 solver.cpp:244]     Train net output #0: accuracy = 0.949149
I0823 19:29:26.771834 15833 solver.cpp:244]     Train net output #1: loss = 5135.75 (* 1 = 5135.75 loss)
I0823 19:29:26.771842 15833 sgd_solver.cpp:106] Iteration 3650, lr = 1e-06
I0823 19:30:53.817713 15833 solver.cpp:228] Iteration 3700, loss = 8643.92
I0823 19:30:53.817809 15833 solver.cpp:244]     Train net output #0: accuracy = 0.912096
I0823 19:30:53.817821 15833 solver.cpp:244]     Train net output #1: loss = 8643.92 (* 1 = 8643.92 loss)
I0823 19:30:53.817827 15833 sgd_solver.cpp:106] Iteration 3700, lr = 1e-06
I0823 19:32:20.768534 15833 solver.cpp:228] Iteration 3750, loss = 4834.74
I0823 19:32:20.768626 15833 solver.cpp:244]     Train net output #0: accuracy = 0.953825
I0823 19:32:20.768638 15833 solver.cpp:244]     Train net output #1: loss = 4834.74 (* 1 = 4834.74 loss)
I0823 19:32:20.768654 15833 sgd_solver.cpp:106] Iteration 3750, lr = 1e-06
I0823 19:33:46.327986 15833 solver.cpp:337] Iteration 3800, Testing net (#0)
I0823 19:33:53.894443 15833 solver.cpp:404]     Test net output #0: accuracy = 0.90441
I0823 19:33:53.894484 15833 solver.cpp:404]     Test net output #1: loss = 9891.51 (* 1 = 9891.51 loss)
I0823 19:33:55.329385 15833 solver.cpp:228] Iteration 3800, loss = 7274.21
I0823 19:33:55.329417 15833 solver.cpp:244]     Train net output #0: accuracy = 0.930918
I0823 19:33:55.329428 15833 solver.cpp:244]     Train net output #1: loss = 7274.21 (* 1 = 7274.21 loss)
I0823 19:33:55.329434 15833 sgd_solver.cpp:106] Iteration 3800, lr = 1e-06
I0823 19:35:22.277179 15833 solver.cpp:228] Iteration 3850, loss = 9564.37
I0823 19:35:22.277279 15833 solver.cpp:244]     Train net output #0: accuracy = 0.907731
I0823 19:35:22.277292 15833 solver.cpp:244]     Train net output #1: loss = 9564.37 (* 1 = 9564.37 loss)
I0823 19:35:22.277298 15833 sgd_solver.cpp:106] Iteration 3850, lr = 1e-06
I0823 19:36:49.278504 15833 solver.cpp:228] Iteration 3900, loss = 5542.37
I0823 19:36:49.278602 15833 solver.cpp:244]     Train net output #0: accuracy = 0.94754
I0823 19:36:49.278614 15833 solver.cpp:244]     Train net output #1: loss = 5542.37 (* 1 = 5542.37 loss)
I0823 19:36:49.278620 15833 sgd_solver.cpp:106] Iteration 3900, lr = 1e-06
I0823 19:38:16.284690 15833 solver.cpp:228] Iteration 3950, loss = 6742.91
I0823 19:38:16.284782 15833 solver.cpp:244]     Train net output #0: accuracy = 0.933787
I0823 19:38:16.284795 15833 solver.cpp:244]     Train net output #1: loss = 6742.91 (* 1 = 6742.91 loss)
I0823 19:38:16.284801 15833 sgd_solver.cpp:106] Iteration 3950, lr = 1e-06
I0823 19:39:41.830420 15833 solver.cpp:337] Iteration 4000, Testing net (#0)
I0823 19:39:49.398234 15833 solver.cpp:404]     Test net output #0: accuracy = 0.913877
I0823 19:39:49.398274 15833 solver.cpp:404]     Test net output #1: loss = 8934.38 (* 1 = 8934.38 loss)
I0823 19:39:50.829202 15833 solver.cpp:228] Iteration 4000, loss = 4474.03
I0823 19:39:50.829234 15833 solver.cpp:244]     Train net output #0: accuracy = 0.956509
I0823 19:39:50.829244 15833 solver.cpp:244]     Train net output #1: loss = 4474.03 (* 1 = 4474.03 loss)
I0823 19:39:50.829252 15833 sgd_solver.cpp:106] Iteration 4000, lr = 1e-06
I0823 19:41:17.782352 15833 solver.cpp:228] Iteration 4050, loss = 7617.33
I0823 19:41:17.782444 15833 solver.cpp:244]     Train net output #0: accuracy = 0.925627
I0823 19:41:17.782456 15833 solver.cpp:244]     Train net output #1: loss = 7617.33 (* 1 = 7617.33 loss)
I0823 19:41:17.782462 15833 sgd_solver.cpp:106] Iteration 4050, lr = 1e-06
I0823 19:42:44.701669 15833 solver.cpp:228] Iteration 4100, loss = 4311.38
I0823 19:42:44.701761 15833 solver.cpp:244]     Train net output #0: accuracy = 0.958097
I0823 19:42:44.701773 15833 solver.cpp:244]     Train net output #1: loss = 4311.38 (* 1 = 4311.38 loss)
I0823 19:42:44.701779 15833 sgd_solver.cpp:106] Iteration 4100, lr = 1e-06
I0823 19:44:11.672830 15833 solver.cpp:228] Iteration 4150, loss = 9004.76
I0823 19:44:11.672927 15833 solver.cpp:244]     Train net output #0: accuracy = 0.912299
I0823 19:44:11.672940 15833 solver.cpp:244]     Train net output #1: loss = 9004.76 (* 1 = 9004.76 loss)
I0823 19:44:11.672946 15833 sgd_solver.cpp:106] Iteration 4150, lr = 1e-06
I0823 19:45:37.145745 15833 solver.cpp:337] Iteration 4200, Testing net (#0)
I0823 19:45:44.701215 15833 solver.cpp:404]     Test net output #0: accuracy = 0.920389
I0823 19:45:44.701256 15833 solver.cpp:404]     Test net output #1: loss = 8317.95 (* 1 = 8317.95 loss)
I0823 19:45:46.143146 15833 solver.cpp:228] Iteration 4200, loss = 9263.46
I0823 19:45:46.143179 15833 solver.cpp:244]     Train net output #0: accuracy = 0.909686
I0823 19:45:46.143189 15833 solver.cpp:244]     Train net output #1: loss = 9263.46 (* 1 = 9263.46 loss)
I0823 19:45:46.143196 15833 sgd_solver.cpp:106] Iteration 4200, lr = 1e-06
I0823 19:47:13.097026 15833 solver.cpp:228] Iteration 4250, loss = 4917.24
I0823 19:47:13.097146 15833 solver.cpp:244]     Train net output #0: accuracy = 0.952314
I0823 19:47:13.097162 15833 solver.cpp:244]     Train net output #1: loss = 4917.24 (* 1 = 4917.24 loss)
I0823 19:47:13.097168 15833 sgd_solver.cpp:106] Iteration 4250, lr = 1e-06
I0823 19:48:40.045430 15833 solver.cpp:228] Iteration 4300, loss = 10125.4
I0823 19:48:40.045533 15833 solver.cpp:244]     Train net output #0: accuracy = 0.89951
I0823 19:48:40.045545 15833 solver.cpp:244]     Train net output #1: loss = 10125.4 (* 1 = 10125.4 loss)
I0823 19:48:40.045552 15833 sgd_solver.cpp:106] Iteration 4300, lr = 1e-06
I0823 19:50:07.018678 15833 solver.cpp:228] Iteration 4350, loss = 5370.18
I0823 19:50:07.018724 15833 solver.cpp:244]     Train net output #0: accuracy = 0.947841
I0823 19:50:07.018734 15833 solver.cpp:244]     Train net output #1: loss = 5370.18 (* 1 = 5370.18 loss)
I0823 19:50:07.018741 15833 sgd_solver.cpp:106] Iteration 4350, lr = 1e-06
I0823 19:51:32.555151 15833 solver.cpp:337] Iteration 4400, Testing net (#0)
I0823 19:51:40.119282 15833 solver.cpp:404]     Test net output #0: accuracy = 0.920055
I0823 19:51:40.119324 15833 solver.cpp:404]     Test net output #1: loss = 8288.86 (* 1 = 8288.86 loss)
I0823 19:51:41.559334 15833 solver.cpp:228] Iteration 4400, loss = 8125.08
I0823 19:51:41.559370 15833 solver.cpp:244]     Train net output #0: accuracy = 0.923486
I0823 19:51:41.559378 15833 solver.cpp:244]     Train net output #1: loss = 8125.08 (* 1 = 8125.08 loss)
I0823 19:51:41.559386 15833 sgd_solver.cpp:106] Iteration 4400, lr = 1e-06
I0823 19:52:32.297082 15833 solver.cpp:454] Snapshotting to binary proto file portrait_one_stage2_1_iter_4430.caffemodel
I0823 19:52:32.299684 15833 sgd_solver.cpp:273] Snapshotting solver state to binary proto file portrait_one_stage2_1_iter_4430.solverstate
I0823 19:53:08.536231 15833 solver.cpp:228] Iteration 4450, loss = 4186.73
I0823 19:53:08.536319 15833 solver.cpp:244]     Train net output #0: accuracy = 0.959484
I0823 19:53:08.536330 15833 solver.cpp:244]     Train net output #1: loss = 4186.73 (* 1 = 4186.73 loss)
I0823 19:53:08.536337 15833 sgd_solver.cpp:106] Iteration 4450, lr = 1e-06
I0823 19:54:35.574106 15833 solver.cpp:228] Iteration 4500, loss = 7784.79
I0823 19:54:35.574198 15833 solver.cpp:244]     Train net output #0: accuracy = 0.924945
I0823 19:54:35.574208 15833 solver.cpp:244]     Train net output #1: loss = 7784.79 (* 1 = 7784.79 loss)
I0823 19:54:35.574215 15833 sgd_solver.cpp:106] Iteration 4500, lr = 1e-06
I0823 19:56:02.496312 15833 solver.cpp:228] Iteration 4550, loss = 6025.34
I0823 19:56:02.496404 15833 solver.cpp:244]     Train net output #0: accuracy = 0.940534
I0823 19:56:02.496415 15833 solver.cpp:244]     Train net output #1: loss = 6025.34 (* 1 = 6025.34 loss)
I0823 19:56:02.496423 15833 sgd_solver.cpp:106] Iteration 4550, lr = 1e-06
I0823 19:57:28.047502 15833 solver.cpp:337] Iteration 4600, Testing net (#0)
I0823 19:57:35.612447 15833 solver.cpp:404]     Test net output #0: accuracy = 0.925481
I0823 19:57:35.612488 15833 solver.cpp:404]     Test net output #1: loss = 7782.61 (* 1 = 7782.61 loss)
I0823 19:57:37.046159 15833 solver.cpp:228] Iteration 4600, loss = 4994.16
I0823 19:57:37.046191 15833 solver.cpp:244]     Train net output #0: accuracy = 0.95197
I0823 19:57:37.046201 15833 solver.cpp:244]     Train net output #1: loss = 4994.16 (* 1 = 4994.16 loss)
I0823 19:57:37.046208 15833 sgd_solver.cpp:106] Iteration 4600, lr = 1e-06
I0823 19:59:03.977449 15833 solver.cpp:228] Iteration 4650, loss = 8848.8
I0823 19:59:03.977495 15833 solver.cpp:244]     Train net output #0: accuracy = 0.912632
I0823 19:59:03.977505 15833 solver.cpp:244]     Train net output #1: loss = 8848.8 (* 1 = 8848.8 loss)
I0823 19:59:03.977512 15833 sgd_solver.cpp:106] Iteration 4650, lr = 1e-06
I0823 20:00:30.974395 15833 solver.cpp:228] Iteration 4700, loss = 4915.06
I0823 20:00:30.974468 15833 solver.cpp:244]     Train net output #0: accuracy = 0.951456
I0823 20:00:30.974479 15833 solver.cpp:244]     Train net output #1: loss = 4915.06 (* 1 = 4915.06 loss)
I0823 20:00:30.974486 15833 sgd_solver.cpp:106] Iteration 4700, lr = 1e-06
I0823 20:01:57.936877 15833 solver.cpp:228] Iteration 4750, loss = 9854.41
I0823 20:01:57.936993 15833 solver.cpp:244]     Train net output #0: accuracy = 0.906899
I0823 20:01:57.937005 15833 solver.cpp:244]     Train net output #1: loss = 9854.41 (* 1 = 9854.41 loss)
I0823 20:01:57.937012 15833 sgd_solver.cpp:106] Iteration 4750, lr = 1e-06
I0823 20:03:23.458564 15833 solver.cpp:337] Iteration 4800, Testing net (#0)
I0823 20:03:31.056398 15833 solver.cpp:404]     Test net output #0: accuracy = 0.924584
I0823 20:03:31.056442 15833 solver.cpp:404]     Test net output #1: loss = 7863.23 (* 1 = 7863.23 loss)
I0823 20:03:32.491009 15833 solver.cpp:228] Iteration 4800, loss = 5643.47
I0823 20:03:32.491042 15833 solver.cpp:244]     Train net output #0: accuracy = 0.945119
I0823 20:03:32.491052 15833 solver.cpp:244]     Train net output #1: loss = 5643.47 (* 1 = 5643.47 loss)
I0823 20:03:32.491060 15833 sgd_solver.cpp:106] Iteration 4800, lr = 1e-06
I0823 20:04:59.461587 15833 solver.cpp:228] Iteration 4850, loss = 6636.78
I0823 20:04:59.461678 15833 solver.cpp:244]     Train net output #0: accuracy = 0.936943
I0823 20:04:59.461689 15833 solver.cpp:244]     Train net output #1: loss = 6636.78 (* 1 = 6636.78 loss)
I0823 20:04:59.461696 15833 sgd_solver.cpp:106] Iteration 4850, lr = 1e-06
I0823 20:06:26.448554 15833 solver.cpp:228] Iteration 4900, loss = 4281.95
I0823 20:06:26.448642 15833 solver.cpp:244]     Train net output #0: accuracy = 0.959187
I0823 20:06:26.448653 15833 solver.cpp:244]     Train net output #1: loss = 4281.95 (* 1 = 4281.95 loss)
I0823 20:06:26.448660 15833 sgd_solver.cpp:106] Iteration 4900, lr = 1e-06
I0823 20:07:53.484940 15833 solver.cpp:228] Iteration 4950, loss = 6136.16
I0823 20:07:53.485035 15833 solver.cpp:244]     Train net output #0: accuracy = 0.940688
I0823 20:07:53.485046 15833 solver.cpp:244]     Train net output #1: loss = 6136.16 (* 1 = 6136.16 loss)
I0823 20:07:53.485054 15833 sgd_solver.cpp:106] Iteration 4950, lr = 1e-06
I0823 20:09:18.959290 15833 solver.cpp:337] Iteration 5000, Testing net (#0)
I0823 20:09:26.520433 15833 solver.cpp:404]     Test net output #0: accuracy = 0.927241
I0823 20:09:26.520475 15833 solver.cpp:404]     Test net output #1: loss = 7571.92 (* 1 = 7571.92 loss)
I0823 20:09:27.982528 15833 solver.cpp:228] Iteration 5000, loss = 7583.35
I0823 20:09:27.982559 15833 solver.cpp:244]     Train net output #0: accuracy = 0.923985
I0823 20:09:27.982569 15833 solver.cpp:244]     Train net output #1: loss = 7583.35 (* 1 = 7583.35 loss)
I0823 20:09:27.982576 15833 sgd_solver.cpp:106] Iteration 5000, lr = 1e-06
I0823 20:10:54.961168 15833 solver.cpp:228] Iteration 5050, loss = 4497.11
I0823 20:10:54.961263 15833 solver.cpp:244]     Train net output #0: accuracy = 0.956695
I0823 20:10:54.961275 15833 solver.cpp:244]     Train net output #1: loss = 4497.11 (* 1 = 4497.11 loss)
I0823 20:10:54.961282 15833 sgd_solver.cpp:106] Iteration 5050, lr = 1e-06
I0823 20:12:21.904391 15833 solver.cpp:228] Iteration 5100, loss = 9913.38
I0823 20:12:21.904489 15833 solver.cpp:244]     Train net output #0: accuracy = 0.901433
I0823 20:12:21.904501 15833 solver.cpp:244]     Train net output #1: loss = 9913.38 (* 1 = 9913.38 loss)
I0823 20:12:21.904508 15833 sgd_solver.cpp:106] Iteration 5100, lr = 1e-06
I0823 20:13:48.862601 15833 solver.cpp:228] Iteration 5150, loss = 5490.81
I0823 20:13:48.862694 15833 solver.cpp:244]     Train net output #0: accuracy = 0.947508
I0823 20:13:48.862706 15833 solver.cpp:244]     Train net output #1: loss = 5490.81 (* 1 = 5490.81 loss)
I0823 20:13:48.862714 15833 sgd_solver.cpp:106] Iteration 5150, lr = 1e-06
I0823 20:15:14.402567 15833 solver.cpp:337] Iteration 5200, Testing net (#0)
I0823 20:15:21.983242 15833 solver.cpp:404]     Test net output #0: accuracy = 0.92824
I0823 20:15:21.983285 15833 solver.cpp:404]     Test net output #1: loss = 7468.94 (* 1 = 7468.94 loss)
I0823 20:15:23.423749 15833 solver.cpp:228] Iteration 5200, loss = 9792.11
I0823 20:15:23.423784 15833 solver.cpp:244]     Train net output #0: accuracy = 0.90631
I0823 20:15:23.423801 15833 solver.cpp:244]     Train net output #1: loss = 9792.11 (* 1 = 9792.11 loss)
I0823 20:15:23.423809 15833 sgd_solver.cpp:106] Iteration 5200, lr = 1e-06
I0823 20:16:50.387291 15833 solver.cpp:228] Iteration 5250, loss = 5844.12
I0823 20:16:50.387414 15833 solver.cpp:244]     Train net output #0: accuracy = 0.944339
I0823 20:16:50.387428 15833 solver.cpp:244]     Train net output #1: loss = 5844.12 (* 1 = 5844.12 loss)
I0823 20:16:50.387434 15833 sgd_solver.cpp:106] Iteration 5250, lr = 1e-06
I0823 20:18:17.389328 15833 solver.cpp:228] Iteration 5300, loss = 6368.61
I0823 20:18:17.389430 15833 solver.cpp:244]     Train net output #0: accuracy = 0.938008
I0823 20:18:17.389441 15833 solver.cpp:244]     Train net output #1: loss = 6368.61 (* 1 = 6368.61 loss)
I0823 20:18:17.389447 15833 sgd_solver.cpp:106] Iteration 5300, lr = 1e-06
I0823 20:19:44.325654 15833 solver.cpp:228] Iteration 5350, loss = 7442.5
I0823 20:19:44.325743 15833 solver.cpp:244]     Train net output #0: accuracy = 0.929071
I0823 20:19:44.325755 15833 solver.cpp:244]     Train net output #1: loss = 7442.5 (* 1 = 7442.5 loss)
I0823 20:19:44.325762 15833 sgd_solver.cpp:106] Iteration 5350, lr = 1e-06
I0823 20:21:09.892454 15833 solver.cpp:337] Iteration 5400, Testing net (#0)
I0823 20:21:17.452178 15833 solver.cpp:404]     Test net output #0: accuracy = 0.925798
I0823 20:21:17.452219 15833 solver.cpp:404]     Test net output #1: loss = 7684.4 (* 1 = 7684.4 loss)
I0823 20:21:18.884516 15833 solver.cpp:228] Iteration 5400, loss = 4390.75
I0823 20:21:18.884549 15833 solver.cpp:244]     Train net output #0: accuracy = 0.958427
I0823 20:21:18.884559 15833 solver.cpp:244]     Train net output #1: loss = 4390.75 (* 1 = 4390.75 loss)
I0823 20:21:18.884567 15833 sgd_solver.cpp:106] Iteration 5400, lr = 1e-06
I0823 20:22:45.820655 15833 solver.cpp:228] Iteration 5450, loss = 7295.38
I0823 20:22:45.820703 15833 solver.cpp:244]     Train net output #0: accuracy = 0.926912
I0823 20:22:45.820713 15833 solver.cpp:244]     Train net output #1: loss = 7295.38 (* 1 = 7295.38 loss)
I0823 20:22:45.820719 15833 sgd_solver.cpp:106] Iteration 5450, lr = 1e-06
I0823 20:24:12.762688 15833 solver.cpp:228] Iteration 5500, loss = 4675.21
I0823 20:24:12.762761 15833 solver.cpp:244]     Train net output #0: accuracy = 0.952924
I0823 20:24:12.762773 15833 solver.cpp:244]     Train net output #1: loss = 4675.21 (* 1 = 4675.21 loss)
I0823 20:24:12.762779 15833 sgd_solver.cpp:106] Iteration 5500, lr = 1e-06
I0823 20:25:39.726155 15833 solver.cpp:228] Iteration 5550, loss = 8984.62
I0823 20:25:39.726250 15833 solver.cpp:244]     Train net output #0: accuracy = 0.911788
I0823 20:25:39.726261 15833 solver.cpp:244]     Train net output #1: loss = 8984.62 (* 1 = 8984.62 loss)
I0823 20:25:39.726269 15833 sgd_solver.cpp:106] Iteration 5550, lr = 1e-06
I0823 20:27:05.235817 15833 solver.cpp:337] Iteration 5600, Testing net (#0)
I0823 20:27:12.801259 15833 solver.cpp:404]     Test net output #0: accuracy = 0.927987
I0823 20:27:12.801301 15833 solver.cpp:404]     Test net output #1: loss = 7481.1 (* 1 = 7481.1 loss)
I0823 20:27:14.235093 15833 solver.cpp:228] Iteration 5600, loss = 4738.61
I0823 20:27:14.235126 15833 solver.cpp:244]     Train net output #0: accuracy = 0.954158
I0823 20:27:14.235136 15833 solver.cpp:244]     Train net output #1: loss = 4738.61 (* 1 = 4738.61 loss)
I0823 20:27:14.235142 15833 sgd_solver.cpp:106] Iteration 5600, lr = 1e-06
I0823 20:28:41.212658 15833 solver.cpp:228] Iteration 5650, loss = 8253.03
I0823 20:28:41.212720 15833 solver.cpp:244]     Train net output #0: accuracy = 0.920623
I0823 20:28:41.212731 15833 solver.cpp:244]     Train net output #1: loss = 8253.03 (* 1 = 8253.03 loss)
I0823 20:28:41.212738 15833 sgd_solver.cpp:106] Iteration 5650, lr = 1e-06
I0823 20:30:08.143055 15833 solver.cpp:228] Iteration 5700, loss = 7763.18
I0823 20:30:08.143100 15833 solver.cpp:244]     Train net output #0: accuracy = 0.926871
I0823 20:30:08.143117 15833 solver.cpp:244]     Train net output #1: loss = 7763.18 (* 1 = 7763.18 loss)
I0823 20:30:08.143124 15833 sgd_solver.cpp:106] Iteration 5700, lr = 1e-06
I0823 20:31:35.136831 15833 solver.cpp:228] Iteration 5750, loss = 5422.96
I0823 20:31:35.136917 15833 solver.cpp:244]     Train net output #0: accuracy = 0.948692
I0823 20:31:35.136930 15833 solver.cpp:244]     Train net output #1: loss = 5422.96 (* 1 = 5422.96 loss)
I0823 20:31:35.136937 15833 sgd_solver.cpp:106] Iteration 5750, lr = 1e-06
I0823 20:33:00.666394 15833 solver.cpp:337] Iteration 5800, Testing net (#0)
I0823 20:33:08.231652 15833 solver.cpp:404]     Test net output #0: accuracy = 0.927331
I0823 20:33:08.231691 15833 solver.cpp:404]     Test net output #1: loss = 7566.67 (* 1 = 7566.67 loss)
I0823 20:33:09.671301 15833 solver.cpp:228] Iteration 5800, loss = 6400.23
I0823 20:33:09.671334 15833 solver.cpp:244]     Train net output #0: accuracy = 0.937899
I0823 20:33:09.671344 15833 solver.cpp:244]     Train net output #1: loss = 6400.23 (* 1 = 6400.23 loss)
I0823 20:33:09.671350 15833 sgd_solver.cpp:106] Iteration 5800, lr = 1e-06
I0823 20:34:36.650032 15833 solver.cpp:228] Iteration 5850, loss = 4313.63
I0823 20:34:36.650104 15833 solver.cpp:244]     Train net output #0: accuracy = 0.958763
I0823 20:34:36.650115 15833 solver.cpp:244]     Train net output #1: loss = 4313.63 (* 1 = 4313.63 loss)
I0823 20:34:36.650122 15833 sgd_solver.cpp:106] Iteration 5850, lr = 1e-06
I0823 20:36:03.644827 15833 solver.cpp:228] Iteration 5900, loss = 8026.02
I0823 20:36:03.644917 15833 solver.cpp:244]     Train net output #0: accuracy = 0.921143
I0823 20:36:03.644927 15833 solver.cpp:244]     Train net output #1: loss = 8026.02 (* 1 = 8026.02 loss)
I0823 20:36:03.644934 15833 sgd_solver.cpp:106] Iteration 5900, lr = 1e-06
I0823 20:37:30.590342 15833 solver.cpp:228] Iteration 5950, loss = 4751.04
I0823 20:37:30.590386 15833 solver.cpp:244]     Train net output #0: accuracy = 0.953193
I0823 20:37:30.590397 15833 solver.cpp:244]     Train net output #1: loss = 4751.04 (* 1 = 4751.04 loss)
I0823 20:37:30.590404 15833 sgd_solver.cpp:106] Iteration 5950, lr = 1e-06
I0823 20:38:56.127324 15833 solver.cpp:454] Snapshotting to binary proto file portrait_one_stage2_1_iter_6000.caffemodel
I0823 20:38:56.129802 15833 sgd_solver.cpp:273] Snapshotting solver state to binary proto file portrait_one_stage2_1_iter_6000.solverstate
I0823 20:38:56.130800 15833 solver.cpp:337] Iteration 6000, Testing net (#0)
I0823 20:39:03.701169 15833 solver.cpp:404]     Test net output #0: accuracy = 0.929075
I0823 20:39:03.701210 15833 solver.cpp:404]     Test net output #1: loss = 7385.47 (* 1 = 7385.47 loss)
I0823 20:39:05.144474 15833 solver.cpp:228] Iteration 6000, loss = 8012.86
I0823 20:39:05.144510 15833 solver.cpp:244]     Train net output #0: accuracy = 0.9192
I0823 20:39:05.144520 15833 solver.cpp:244]     Train net output #1: loss = 8012.86 (* 1 = 8012.86 loss)
I0823 20:39:05.144526 15833 sgd_solver.cpp:106] Iteration 6000, lr = 1e-07
I0823 20:40:32.076697 15833 solver.cpp:228] Iteration 6050, loss = 4494.71
I0823 20:40:32.076769 15833 solver.cpp:244]     Train net output #0: accuracy = 0.955378
I0823 20:40:32.076781 15833 solver.cpp:244]     Train net output #1: loss = 4494.71 (* 1 = 4494.71 loss)
I0823 20:40:32.076787 15833 sgd_solver.cpp:106] Iteration 6050, lr = 1e-07
I0823 20:41:59.093611 15833 solver.cpp:228] Iteration 6100, loss = 5508.81
I0823 20:41:59.093700 15833 solver.cpp:244]     Train net output #0: accuracy = 0.946889
I0823 20:41:59.093713 15833 solver.cpp:244]     Train net output #1: loss = 5508.81 (* 1 = 5508.81 loss)
I0823 20:41:59.093719 15833 sgd_solver.cpp:106] Iteration 6100, lr = 1e-07
I0823 20:43:26.042619 15833 solver.cpp:228] Iteration 6150, loss = 9726.04
I0823 20:43:26.042695 15833 solver.cpp:244]     Train net output #0: accuracy = 0.906013
I0823 20:43:26.042707 15833 solver.cpp:244]     Train net output #1: loss = 9726.04 (* 1 = 9726.04 loss)
I0823 20:43:26.042714 15833 sgd_solver.cpp:106] Iteration 6150, lr = 1e-07
I0823 20:44:51.603148 15833 solver.cpp:337] Iteration 6200, Testing net (#0)
I0823 20:44:59.181629 15833 solver.cpp:404]     Test net output #0: accuracy = 0.93154
I0823 20:44:59.181680 15833 solver.cpp:404]     Test net output #1: loss = 7134.56 (* 1 = 7134.56 loss)
I0823 20:45:00.620839 15833 solver.cpp:228] Iteration 6200, loss = 5252.66
I0823 20:45:00.620870 15833 solver.cpp:244]     Train net output #0: accuracy = 0.949575
I0823 20:45:00.620880 15833 solver.cpp:244]     Train net output #1: loss = 5252.66 (* 1 = 5252.66 loss)
I0823 20:45:00.620887 15833 sgd_solver.cpp:106] Iteration 6200, lr = 1e-07
I0823 20:46:27.603826 15833 solver.cpp:228] Iteration 6250, loss = 6316.18
I0823 20:46:27.603905 15833 solver.cpp:244]     Train net output #0: accuracy = 0.938992
I0823 20:46:27.603917 15833 solver.cpp:244]     Train net output #1: loss = 6316.18 (* 1 = 6316.18 loss)
I0823 20:46:27.603924 15833 sgd_solver.cpp:106] Iteration 6250, lr = 1e-07
I0823 20:47:54.611629 15833 solver.cpp:228] Iteration 6300, loss = 4300.04
I0823 20:47:54.611676 15833 solver.cpp:244]     Train net output #0: accuracy = 0.957852
I0823 20:47:54.611686 15833 solver.cpp:244]     Train net output #1: loss = 4300.04 (* 1 = 4300.04 loss)
I0823 20:47:54.611693 15833 sgd_solver.cpp:106] Iteration 6300, lr = 1e-07
I0823 20:49:21.596465 15833 solver.cpp:228] Iteration 6350, loss = 7247.3
I0823 20:49:21.596537 15833 solver.cpp:244]     Train net output #0: accuracy = 0.928933
I0823 20:49:21.596549 15833 solver.cpp:244]     Train net output #1: loss = 7247.3 (* 1 = 7247.3 loss)
I0823 20:49:21.596555 15833 sgd_solver.cpp:106] Iteration 6350, lr = 1e-07
I0823 20:50:47.136339 15833 solver.cpp:337] Iteration 6400, Testing net (#0)
I0823 20:50:54.698264 15833 solver.cpp:404]     Test net output #0: accuracy = 0.928846
I0823 20:50:54.698307 15833 solver.cpp:404]     Test net output #1: loss = 7420.89 (* 1 = 7420.89 loss)
I0823 20:50:56.132617 15833 solver.cpp:228] Iteration 6400, loss = 4082.07
I0823 20:50:56.132652 15833 solver.cpp:244]     Train net output #0: accuracy = 0.959894
I0823 20:50:56.132661 15833 solver.cpp:244]     Train net output #1: loss = 4082.07 (* 1 = 4082.07 loss)
I0823 20:50:56.132668 15833 sgd_solver.cpp:106] Iteration 6400, lr = 1e-07
I0823 20:52:23.131693 15833 solver.cpp:228] Iteration 6450, loss = 7945.2
I0823 20:52:23.131738 15833 solver.cpp:244]     Train net output #0: accuracy = 0.923161
I0823 20:52:23.131749 15833 solver.cpp:244]     Train net output #1: loss = 7945.2 (* 1 = 7945.2 loss)
I0823 20:52:23.131757 15833 sgd_solver.cpp:106] Iteration 6450, lr = 1e-07
I0823 20:53:50.076104 15833 solver.cpp:228] Iteration 6500, loss = 8536.51
I0823 20:53:50.076150 15833 solver.cpp:244]     Train net output #0: accuracy = 0.91619
I0823 20:53:50.076161 15833 solver.cpp:244]     Train net output #1: loss = 8536.51 (* 1 = 8536.51 loss)
I0823 20:53:50.076169 15833 sgd_solver.cpp:106] Iteration 6500, lr = 1e-07
I0823 20:55:17.067311 15833 solver.cpp:228] Iteration 6550, loss = 4685.94
I0823 20:55:17.067387 15833 solver.cpp:244]     Train net output #0: accuracy = 0.954328
I0823 20:55:17.067399 15833 solver.cpp:244]     Train net output #1: loss = 4685.94 (* 1 = 4685.94 loss)
I0823 20:55:17.067405 15833 sgd_solver.cpp:106] Iteration 6550, lr = 1e-07
I0823 20:56:42.593789 15833 solver.cpp:337] Iteration 6600, Testing net (#0)
I0823 20:56:50.156121 15833 solver.cpp:404]     Test net output #0: accuracy = 0.931506
I0823 20:56:50.156160 15833 solver.cpp:404]     Test net output #1: loss = 7138.58 (* 1 = 7138.58 loss)
I0823 20:56:51.595991 15833 solver.cpp:228] Iteration 6600, loss = 9610.41
I0823 20:56:51.596026 15833 solver.cpp:244]     Train net output #0: accuracy = 0.904104
I0823 20:56:51.596035 15833 solver.cpp:244]     Train net output #1: loss = 9610.41 (* 1 = 9610.41 loss)
I0823 20:56:51.596042 15833 sgd_solver.cpp:106] Iteration 6600, lr = 1e-07
I0823 20:58:18.567066 15833 solver.cpp:228] Iteration 6650, loss = 5093.87
I0823 20:58:18.567157 15833 solver.cpp:244]     Train net output #0: accuracy = 0.950034
I0823 20:58:18.567169 15833 solver.cpp:244]     Train net output #1: loss = 5093.87 (* 1 = 5093.87 loss)
I0823 20:58:18.567176 15833 sgd_solver.cpp:106] Iteration 6650, lr = 1e-07
I0823 20:59:45.522796 15833 solver.cpp:228] Iteration 6700, loss = 7764.18
I0823 20:59:45.522905 15833 solver.cpp:244]     Train net output #0: accuracy = 0.925243
I0823 20:59:45.522918 15833 solver.cpp:244]     Train net output #1: loss = 7764.18 (* 1 = 7764.18 loss)
I0823 20:59:45.522925 15833 sgd_solver.cpp:106] Iteration 6700, lr = 1e-07
I0823 21:01:12.496608 15833 solver.cpp:228] Iteration 6750, loss = 3998.61
I0823 21:01:12.496680 15833 solver.cpp:244]     Train net output #0: accuracy = 0.961064
I0823 21:01:12.496690 15833 solver.cpp:244]     Train net output #1: loss = 3998.61 (* 1 = 3998.61 loss)
I0823 21:01:12.496697 15833 sgd_solver.cpp:106] Iteration 6750, lr = 1e-07
I0823 21:02:38.049621 15833 solver.cpp:337] Iteration 6800, Testing net (#0)
I0823 21:02:45.615718 15833 solver.cpp:404]     Test net output #0: accuracy = 0.930089
I0823 21:02:45.615759 15833 solver.cpp:404]     Test net output #1: loss = 7286.78 (* 1 = 7286.78 loss)
I0823 21:02:47.060523 15833 solver.cpp:228] Iteration 6800, loss = 7666.03
I0823 21:02:47.060556 15833 solver.cpp:244]     Train net output #0: accuracy = 0.924506
I0823 21:02:47.060566 15833 solver.cpp:244]     Train net output #1: loss = 7666.03 (* 1 = 7666.03 loss)
I0823 21:02:47.060573 15833 sgd_solver.cpp:106] Iteration 6800, lr = 1e-07
I0823 21:04:13.974602 15833 solver.cpp:228] Iteration 6850, loss = 6284.32
I0823 21:04:13.974647 15833 solver.cpp:244]     Train net output #0: accuracy = 0.938265
I0823 21:04:13.974656 15833 solver.cpp:244]     Train net output #1: loss = 6284.32 (* 1 = 6284.32 loss)
I0823 21:04:13.974663 15833 sgd_solver.cpp:106] Iteration 6850, lr = 1e-07
I0823 21:05:40.927635 15833 solver.cpp:228] Iteration 6900, loss = 4591.48
I0823 21:05:40.927726 15833 solver.cpp:244]     Train net output #0: accuracy = 0.955809
I0823 21:05:40.927738 15833 solver.cpp:244]     Train net output #1: loss = 4591.48 (* 1 = 4591.48 loss)
I0823 21:05:40.927745 15833 sgd_solver.cpp:106] Iteration 6900, lr = 1e-07
I0823 21:07:07.870885 15833 solver.cpp:228] Iteration 6950, loss = 8596.36
I0823 21:07:07.870959 15833 solver.cpp:244]     Train net output #0: accuracy = 0.912639
I0823 21:07:07.870970 15833 solver.cpp:244]     Train net output #1: loss = 8596.36 (* 1 = 8596.36 loss)
I0823 21:07:07.870977 15833 sgd_solver.cpp:106] Iteration 6950, lr = 1e-07
I0823 21:08:33.387811 15833 solver.cpp:337] Iteration 7000, Testing net (#0)
I0823 21:08:40.959645 15833 solver.cpp:404]     Test net output #0: accuracy = 0.931378
I0823 21:08:40.959686 15833 solver.cpp:404]     Test net output #1: loss = 7153.15 (* 1 = 7153.15 loss)
I0823 21:08:42.392570 15833 solver.cpp:228] Iteration 7000, loss = 4426.88
I0823 21:08:42.392601 15833 solver.cpp:244]     Train net output #0: accuracy = 0.95607
I0823 21:08:42.392611 15833 solver.cpp:244]     Train net output #1: loss = 4426.88 (* 1 = 4426.88 loss)
I0823 21:08:42.392618 15833 sgd_solver.cpp:106] Iteration 7000, lr = 1e-07
I0823 21:10:09.330152 15833 solver.cpp:228] Iteration 7050, loss = 8693.33
I0823 21:10:09.330227 15833 solver.cpp:244]     Train net output #0: accuracy = 0.917428
I0823 21:10:09.330240 15833 solver.cpp:244]     Train net output #1: loss = 8693.33 (* 1 = 8693.33 loss)
I0823 21:10:09.330246 15833 sgd_solver.cpp:106] Iteration 7050, lr = 1e-07
I0823 21:11:36.265832 15833 solver.cpp:228] Iteration 7100, loss = 5469.5
I0823 21:11:36.265879 15833 solver.cpp:244]     Train net output #0: accuracy = 0.946305
I0823 21:11:36.265889 15833 solver.cpp:244]     Train net output #1: loss = 5469.5 (* 1 = 5469.5 loss)
I0823 21:11:36.265897 15833 sgd_solver.cpp:106] Iteration 7100, lr = 1e-07
I0823 21:13:03.236902 15833 solver.cpp:228] Iteration 7150, loss = 6566.18
I0823 21:13:03.236968 15833 solver.cpp:244]     Train net output #0: accuracy = 0.936511
I0823 21:13:03.236980 15833 solver.cpp:244]     Train net output #1: loss = 6566.18 (* 1 = 6566.18 loss)
I0823 21:13:03.236987 15833 sgd_solver.cpp:106] Iteration 7150, lr = 1e-07
I0823 21:14:28.765106 15833 solver.cpp:337] Iteration 7200, Testing net (#0)
I0823 21:14:36.326594 15833 solver.cpp:404]     Test net output #0: accuracy = 0.932373
I0823 21:14:36.326642 15833 solver.cpp:404]     Test net output #1: loss = 7049.09 (* 1 = 7049.09 loss)
I0823 21:14:37.757232 15833 solver.cpp:228] Iteration 7200, loss = 4011.94
I0823 21:14:37.757266 15833 solver.cpp:244]     Train net output #0: accuracy = 0.961089
I0823 21:14:37.757274 15833 solver.cpp:244]     Train net output #1: loss = 4011.94 (* 1 = 4011.94 loss)
I0823 21:14:37.757282 15833 sgd_solver.cpp:106] Iteration 7200, lr = 1e-07
I0823 21:16:04.744103 15833 solver.cpp:228] Iteration 7250, loss = 5292.21
I0823 21:16:04.744199 15833 solver.cpp:244]     Train net output #0: accuracy = 0.948536
I0823 21:16:04.744210 15833 solver.cpp:244]     Train net output #1: loss = 5292.21 (* 1 = 5292.21 loss)
I0823 21:16:04.744218 15833 sgd_solver.cpp:106] Iteration 7250, lr = 1e-07
I0823 21:17:31.678609 15833 solver.cpp:228] Iteration 7300, loss = 7300.3
I0823 21:17:31.678701 15833 solver.cpp:244]     Train net output #0: accuracy = 0.926466
I0823 21:17:31.678712 15833 solver.cpp:244]     Train net output #1: loss = 7300.3 (* 1 = 7300.3 loss)
I0823 21:17:31.678720 15833 sgd_solver.cpp:106] Iteration 7300, lr = 1e-07
I0823 21:18:58.634590 15833 solver.cpp:228] Iteration 7350, loss = 4650.95
I0823 21:18:58.634636 15833 solver.cpp:244]     Train net output #0: accuracy = 0.955169
I0823 21:18:58.634646 15833 solver.cpp:244]     Train net output #1: loss = 4650.95 (* 1 = 4650.95 loss)
I0823 21:18:58.634654 15833 sgd_solver.cpp:106] Iteration 7350, lr = 1e-07
I0823 21:20:24.156462 15833 solver.cpp:337] Iteration 7400, Testing net (#0)
I0823 21:20:31.740046 15833 solver.cpp:404]     Test net output #0: accuracy = 0.92934
I0823 21:20:31.740088 15833 solver.cpp:404]     Test net output #1: loss = 7366.74 (* 1 = 7366.74 loss)
I0823 21:20:33.205140 15833 solver.cpp:228] Iteration 7400, loss = 8610.07
I0823 21:20:33.205174 15833 solver.cpp:244]     Train net output #0: accuracy = 0.914073
I0823 21:20:33.205184 15833 solver.cpp:244]     Train net output #1: loss = 8610.07 (* 1 = 8610.07 loss)
I0823 21:20:33.205191 15833 sgd_solver.cpp:106] Iteration 7400, lr = 1e-07
I0823 21:22:00.160704 15833 solver.cpp:228] Iteration 7450, loss = 5242.66
I0823 21:22:00.160748 15833 solver.cpp:244]     Train net output #0: accuracy = 0.950276
I0823 21:22:00.160758 15833 solver.cpp:244]     Train net output #1: loss = 5242.66 (* 1 = 5242.66 loss)
I0823 21:22:00.160765 15833 sgd_solver.cpp:106] Iteration 7450, lr = 1e-07
I0823 21:23:27.167387 15833 solver.cpp:228] Iteration 7500, loss = 9980.49
I0823 21:23:27.167455 15833 solver.cpp:244]     Train net output #0: accuracy = 0.906491
I0823 21:23:27.167467 15833 solver.cpp:244]     Train net output #1: loss = 9980.49 (* 1 = 9980.49 loss)
I0823 21:23:27.167474 15833 sgd_solver.cpp:106] Iteration 7500, lr = 1e-07
I0823 21:24:54.113072 15833 solver.cpp:228] Iteration 7550, loss = 5609.28
I0823 21:24:54.113116 15833 solver.cpp:244]     Train net output #0: accuracy = 0.945998
I0823 21:24:54.113126 15833 solver.cpp:244]     Train net output #1: loss = 5609.28 (* 1 = 5609.28 loss)
I0823 21:24:54.113133 15833 sgd_solver.cpp:106] Iteration 7550, lr = 1e-07
I0823 21:26:19.724097 15833 solver.cpp:337] Iteration 7600, Testing net (#0)
I0823 21:26:27.286324 15833 solver.cpp:404]     Test net output #0: accuracy = 0.931725
I0823 21:26:27.286362 15833 solver.cpp:404]     Test net output #1: loss = 7112.1 (* 1 = 7112.1 loss)
I0823 21:26:28.723553 15833 solver.cpp:228] Iteration 7600, loss = 6251.2
I0823 21:26:28.723583 15833 solver.cpp:244]     Train net output #0: accuracy = 0.939355
I0823 21:26:28.723593 15833 solver.cpp:244]     Train net output #1: loss = 6251.2 (* 1 = 6251.2 loss)
I0823 21:26:28.723600 15833 sgd_solver.cpp:106] Iteration 7600, lr = 1e-07
I0823 21:27:55.682534 15833 solver.cpp:228] Iteration 7650, loss = 7165.34
I0823 21:27:55.682607 15833 solver.cpp:244]     Train net output #0: accuracy = 0.931789
I0823 21:27:55.682618 15833 solver.cpp:244]     Train net output #1: loss = 7165.34 (* 1 = 7165.34 loss)
I0823 21:27:55.682626 15833 sgd_solver.cpp:106] Iteration 7650, lr = 1e-07
I0823 21:29:22.667536 15833 solver.cpp:228] Iteration 7700, loss = 4190.51
I0823 21:29:22.667634 15833 solver.cpp:244]     Train net output #0: accuracy = 0.959982
I0823 21:29:22.667646 15833 solver.cpp:244]     Train net output #1: loss = 4190.51 (* 1 = 4190.51 loss)
I0823 21:29:22.667654 15833 sgd_solver.cpp:106] Iteration 7700, lr = 1e-07
I0823 21:30:49.631841 15833 solver.cpp:228] Iteration 7750, loss = 7418.86
I0823 21:30:49.631892 15833 solver.cpp:244]     Train net output #0: accuracy = 0.924855
I0823 21:30:49.631903 15833 solver.cpp:244]     Train net output #1: loss = 7418.86 (* 1 = 7418.86 loss)
I0823 21:30:49.631909 15833 sgd_solver.cpp:106] Iteration 7750, lr = 1e-07
I0823 21:32:15.176695 15833 solver.cpp:337] Iteration 7800, Testing net (#0)
I0823 21:32:22.737821 15833 solver.cpp:404]     Test net output #0: accuracy = 0.931304
I0823 21:32:22.737864 15833 solver.cpp:404]     Test net output #1: loss = 7170.91 (* 1 = 7170.91 loss)
I0823 21:32:24.172513 15833 solver.cpp:228] Iteration 7800, loss = 4540.84
I0823 21:32:24.172544 15833 solver.cpp:244]     Train net output #0: accuracy = 0.954638
I0823 21:32:24.172554 15833 solver.cpp:244]     Train net output #1: loss = 4540.84 (* 1 = 4540.84 loss)
I0823 21:32:24.172560 15833 sgd_solver.cpp:106] Iteration 7800, lr = 1e-07
I0823 21:33:51.144318 15833 solver.cpp:228] Iteration 7850, loss = 8867.23
I0823 21:33:51.144385 15833 solver.cpp:244]     Train net output #0: accuracy = 0.910047
I0823 21:33:51.144397 15833 solver.cpp:244]     Train net output #1: loss = 8867.23 (* 1 = 8867.23 loss)
I0823 21:33:51.144403 15833 sgd_solver.cpp:106] Iteration 7850, lr = 1e-07
I0823 21:35:18.112558 15833 solver.cpp:228] Iteration 7900, loss = 4586.66
I0823 21:35:18.112644 15833 solver.cpp:244]     Train net output #0: accuracy = 0.955839
I0823 21:35:18.112655 15833 solver.cpp:244]     Train net output #1: loss = 4586.66 (* 1 = 4586.66 loss)
I0823 21:35:18.112663 15833 sgd_solver.cpp:106] Iteration 7900, lr = 1e-07
I0823 21:36:45.107666 15833 solver.cpp:228] Iteration 7950, loss = 8567.1
I0823 21:36:45.107713 15833 solver.cpp:244]     Train net output #0: accuracy = 0.917222
I0823 21:36:45.107723 15833 solver.cpp:244]     Train net output #1: loss = 8567.1 (* 1 = 8567.1 loss)
I0823 21:36:45.107730 15833 sgd_solver.cpp:106] Iteration 7950, lr = 1e-07
I0823 21:38:10.615278 15833 solver.cpp:337] Iteration 8000, Testing net (#0)
I0823 21:38:18.208144 15833 solver.cpp:404]     Test net output #0: accuracy = 0.931359
I0823 21:38:18.208184 15833 solver.cpp:404]     Test net output #1: loss = 7147.17 (* 1 = 7147.17 loss)
I0823 21:38:19.644920 15833 solver.cpp:228] Iteration 8000, loss = 7725.19
I0823 21:38:19.644953 15833 solver.cpp:244]     Train net output #0: accuracy = 0.927571
I0823 21:38:19.644963 15833 solver.cpp:244]     Train net output #1: loss = 7725.19 (* 1 = 7725.19 loss)
I0823 21:38:19.644970 15833 sgd_solver.cpp:106] Iteration 8000, lr = 1e-07
I0823 21:39:46.661350 15833 solver.cpp:228] Iteration 8050, loss = 4847.24
I0823 21:39:46.661396 15833 solver.cpp:244]     Train net output #0: accuracy = 0.953391
I0823 21:39:46.661407 15833 solver.cpp:244]     Train net output #1: loss = 4847.24 (* 1 = 4847.24 loss)
I0823 21:39:46.661414 15833 sgd_solver.cpp:106] Iteration 8050, lr = 1e-07
I0823 21:41:13.615489 15833 solver.cpp:228] Iteration 8100, loss = 6242.74
I0823 21:41:13.615562 15833 solver.cpp:244]     Train net output #0: accuracy = 0.939634
I0823 21:41:13.615572 15833 solver.cpp:244]     Train net output #1: loss = 6242.74 (* 1 = 6242.74 loss)
I0823 21:41:13.615579 15833 sgd_solver.cpp:106] Iteration 8100, lr = 1e-07
I0823 21:42:40.600039 15833 solver.cpp:228] Iteration 8150, loss = 4108.29
I0823 21:42:40.600085 15833 solver.cpp:244]     Train net output #0: accuracy = 0.96048
I0823 21:42:40.600095 15833 solver.cpp:244]     Train net output #1: loss = 4108.29 (* 1 = 4108.29 loss)
I0823 21:42:40.600101 15833 sgd_solver.cpp:106] Iteration 8150, lr = 1e-07
I0823 21:44:06.133810 15833 solver.cpp:337] Iteration 8200, Testing net (#0)
I0823 21:44:13.697475 15833 solver.cpp:404]     Test net output #0: accuracy = 0.932619
I0823 21:44:13.697525 15833 solver.cpp:404]     Test net output #1: loss = 7023.26 (* 1 = 7023.26 loss)
I0823 21:44:15.139379 15833 solver.cpp:228] Iteration 8200, loss = 7782.06
I0823 21:44:15.139410 15833 solver.cpp:244]     Train net output #0: accuracy = 0.923257
I0823 21:44:15.139420 15833 solver.cpp:244]     Train net output #1: loss = 7782.06 (* 1 = 7782.06 loss)
I0823 21:44:15.139425 15833 sgd_solver.cpp:106] Iteration 8200, lr = 1e-07
I0823 21:45:42.059336 15833 solver.cpp:228] Iteration 8250, loss = 4584.03
I0823 21:45:42.059432 15833 solver.cpp:244]     Train net output #0: accuracy = 0.954652
I0823 21:45:42.059443 15833 solver.cpp:244]     Train net output #1: loss = 4584.03 (* 1 = 4584.03 loss)
I0823 21:45:42.059450 15833 sgd_solver.cpp:106] Iteration 8250, lr = 1e-07
I0823 21:47:09.039808 15833 solver.cpp:228] Iteration 8300, loss = 7899.1
I0823 21:47:09.039880 15833 solver.cpp:244]     Train net output #0: accuracy = 0.921015
I0823 21:47:09.039891 15833 solver.cpp:244]     Train net output #1: loss = 7899.1 (* 1 = 7899.1 loss)
I0823 21:47:09.039898 15833 sgd_solver.cpp:106] Iteration 8300, lr = 1e-07
I0823 21:48:35.962445 15833 solver.cpp:228] Iteration 8350, loss = 4779.05
I0823 21:48:35.962515 15833 solver.cpp:244]     Train net output #0: accuracy = 0.953084
I0823 21:48:35.962527 15833 solver.cpp:244]     Train net output #1: loss = 4779.05 (* 1 = 4779.05 loss)
I0823 21:48:35.962533 15833 sgd_solver.cpp:106] Iteration 8350, lr = 1e-07
I0823 21:50:01.505321 15833 solver.cpp:337] Iteration 8400, Testing net (#0)
I0823 21:50:09.064633 15833 solver.cpp:404]     Test net output #0: accuracy = 0.928774
I0823 21:50:09.064671 15833 solver.cpp:404]     Test net output #1: loss = 7412.57 (* 1 = 7412.57 loss)
I0823 21:50:10.497617 15833 solver.cpp:228] Iteration 8400, loss = 4789.9
I0823 21:50:10.497651 15833 solver.cpp:244]     Train net output #0: accuracy = 0.953045
I0823 21:50:10.497661 15833 solver.cpp:244]     Train net output #1: loss = 4789.9 (* 1 = 4789.9 loss)
I0823 21:50:10.497668 15833 sgd_solver.cpp:106] Iteration 8400, lr = 1e-07
I0823 21:51:37.424787 15833 solver.cpp:228] Iteration 8450, loss = 9715.7
I0823 21:51:37.424832 15833 solver.cpp:244]     Train net output #0: accuracy = 0.905907
I0823 21:51:37.424842 15833 solver.cpp:244]     Train net output #1: loss = 9715.7 (* 1 = 9715.7 loss)
I0823 21:51:37.424849 15833 sgd_solver.cpp:106] Iteration 8450, lr = 1e-07
I0823 21:53:04.388761 15833 solver.cpp:228] Iteration 8500, loss = 5170.49
I0823 21:53:04.388846 15833 solver.cpp:244]     Train net output #0: accuracy = 0.950432
I0823 21:53:04.388859 15833 solver.cpp:244]     Train net output #1: loss = 5170.49 (* 1 = 5170.49 loss)
I0823 21:53:04.388865 15833 sgd_solver.cpp:106] Iteration 8500, lr = 1e-07
I0823 21:54:31.358019 15833 solver.cpp:228] Iteration 8550, loss = 6385.8
I0823 21:54:31.358088 15833 solver.cpp:244]     Train net output #0: accuracy = 0.938592
I0823 21:54:31.358099 15833 solver.cpp:244]     Train net output #1: loss = 6385.8 (* 1 = 6385.8 loss)
I0823 21:54:31.358106 15833 sgd_solver.cpp:106] Iteration 8550, lr = 1e-07
I0823 21:55:56.878929 15833 solver.cpp:337] Iteration 8600, Testing net (#0)
I0823 21:56:04.439575 15833 solver.cpp:404]     Test net output #0: accuracy = 0.931825
I0823 21:56:04.439615 15833 solver.cpp:404]     Test net output #1: loss = 7105.52 (* 1 = 7105.52 loss)
I0823 21:56:05.870115 15833 solver.cpp:228] Iteration 8600, loss = 4236.04
I0823 21:56:05.870149 15833 solver.cpp:244]     Train net output #0: accuracy = 0.958532
I0823 21:56:05.870160 15833 solver.cpp:244]     Train net output #1: loss = 4236.04 (* 1 = 4236.04 loss)
I0823 21:56:05.870167 15833 sgd_solver.cpp:106] Iteration 8600, lr = 1e-07
I0823 21:57:32.851214 15833 solver.cpp:228] Iteration 8650, loss = 7263.01
I0823 21:57:32.851287 15833 solver.cpp:244]     Train net output #0: accuracy = 0.928406
I0823 21:57:32.851299 15833 solver.cpp:244]     Train net output #1: loss = 7263.01 (* 1 = 7263.01 loss)
I0823 21:57:32.851305 15833 sgd_solver.cpp:106] Iteration 8650, lr = 1e-07
I0823 21:58:59.776945 15833 solver.cpp:228] Iteration 8700, loss = 4064.93
I0823 21:58:59.777066 15833 solver.cpp:244]     Train net output #0: accuracy = 0.960638
I0823 21:58:59.777079 15833 solver.cpp:244]     Train net output #1: loss = 4064.93 (* 1 = 4064.93 loss)
I0823 21:58:59.777086 15833 sgd_solver.cpp:106] Iteration 8700, lr = 1e-07
I0823 22:00:26.769680 15833 solver.cpp:228] Iteration 8750, loss = 7523.7
I0823 22:00:26.769736 15833 solver.cpp:244]     Train net output #0: accuracy = 0.927825
I0823 22:00:26.769747 15833 solver.cpp:244]     Train net output #1: loss = 7523.7 (* 1 = 7523.7 loss)
I0823 22:00:26.769753 15833 sgd_solver.cpp:106] Iteration 8750, lr = 1e-07
I0823 22:01:52.256053 15833 solver.cpp:337] Iteration 8800, Testing net (#0)
I0823 22:01:59.818266 15833 solver.cpp:404]     Test net output #0: accuracy = 0.931746
I0823 22:01:59.818307 15833 solver.cpp:404]     Test net output #1: loss = 7127.43 (* 1 = 7127.43 loss)
I0823 22:02:01.261039 15833 solver.cpp:228] Iteration 8800, loss = 8731.54
I0823 22:02:01.261070 15833 solver.cpp:244]     Train net output #0: accuracy = 0.914986
I0823 22:02:01.261080 15833 solver.cpp:244]     Train net output #1: loss = 8731.54 (* 1 = 8731.54 loss)
I0823 22:02:01.261088 15833 sgd_solver.cpp:106] Iteration 8800, lr = 1e-07
I0823 22:03:28.255220 15833 solver.cpp:228] Iteration 8850, loss = 4552.99
I0823 22:03:28.255296 15833 solver.cpp:244]     Train net output #0: accuracy = 0.955776
I0823 22:03:28.255308 15833 solver.cpp:244]     Train net output #1: loss = 4552.99 (* 1 = 4552.99 loss)
I0823 22:03:28.255316 15833 sgd_solver.cpp:106] Iteration 8850, lr = 1e-07
I0823 22:04:55.232725 15833 solver.cpp:228] Iteration 8900, loss = 9325.19
I0823 22:04:55.232800 15833 solver.cpp:244]     Train net output #0: accuracy = 0.909068
I0823 22:04:55.232811 15833 solver.cpp:244]     Train net output #1: loss = 9325.19 (* 1 = 9325.19 loss)
I0823 22:04:55.232818 15833 sgd_solver.cpp:106] Iteration 8900, lr = 1e-07
I0823 22:06:22.188356 15833 solver.cpp:228] Iteration 8950, loss = 5050.49
I0823 22:06:22.188447 15833 solver.cpp:244]     Train net output #0: accuracy = 0.95112
I0823 22:06:22.188459 15833 solver.cpp:244]     Train net output #1: loss = 5050.49 (* 1 = 5050.49 loss)
I0823 22:06:22.188467 15833 sgd_solver.cpp:106] Iteration 8950, lr = 1e-07
I0823 22:07:47.719476 15833 solver.cpp:454] Snapshotting to binary proto file portrait_one_stage2_1_iter_9000.caffemodel
I0823 22:07:47.721946 15833 sgd_solver.cpp:273] Snapshotting solver state to binary proto file portrait_one_stage2_1_iter_9000.solverstate
I0823 22:07:47.722909 15833 solver.cpp:337] Iteration 9000, Testing net (#0)
I0823 22:07:55.286612 15833 solver.cpp:404]     Test net output #0: accuracy = 0.931797
I0823 22:07:55.286653 15833 solver.cpp:404]     Test net output #1: loss = 7100.86 (* 1 = 7100.86 loss)
I0823 22:07:56.727011 15833 solver.cpp:228] Iteration 9000, loss = 7362.22
I0823 22:07:56.727046 15833 solver.cpp:244]     Train net output #0: accuracy = 0.930371
I0823 22:07:56.727056 15833 solver.cpp:244]     Train net output #1: loss = 7362.22 (* 1 = 7362.22 loss)
I0823 22:07:56.727063 15833 sgd_solver.cpp:106] Iteration 9000, lr = 1e-08
I0823 22:09:23.709880 15833 solver.cpp:228] Iteration 9050, loss = 3970
I0823 22:09:23.709929 15833 solver.cpp:244]     Train net output #0: accuracy = 0.961446
I0823 22:09:23.709939 15833 solver.cpp:244]     Train net output #1: loss = 3970 (* 1 = 3970 loss)
I0823 22:09:23.709946 15833 sgd_solver.cpp:106] Iteration 9050, lr = 1e-08
I0823 22:10:50.731945 15833 solver.cpp:228] Iteration 9100, loss = 7630.98
I0823 22:10:50.731992 15833 solver.cpp:244]     Train net output #0: accuracy = 0.924202
I0823 22:10:50.732002 15833 solver.cpp:244]     Train net output #1: loss = 7630.98 (* 1 = 7630.98 loss)
I0823 22:10:50.732009 15833 sgd_solver.cpp:106] Iteration 9100, lr = 1e-08
I0823 22:12:17.646904 15833 solver.cpp:228] Iteration 9150, loss = 6682.62
I0823 22:12:17.647002 15833 solver.cpp:244]     Train net output #0: accuracy = 0.934031
I0823 22:12:17.647014 15833 solver.cpp:244]     Train net output #1: loss = 6682.62 (* 1 = 6682.62 loss)
I0823 22:12:17.647025 15833 sgd_solver.cpp:106] Iteration 9150, lr = 1e-08
I0823 22:13:43.199178 15833 solver.cpp:337] Iteration 9200, Testing net (#0)
I0823 22:13:50.758690 15833 solver.cpp:404]     Test net output #0: accuracy = 0.932636
I0823 22:13:50.758733 15833 solver.cpp:404]     Test net output #1: loss = 7022.9 (* 1 = 7022.9 loss)
I0823 22:13:52.193385 15833 solver.cpp:228] Iteration 9200, loss = 4587.25
I0823 22:13:52.193419 15833 solver.cpp:244]     Train net output #0: accuracy = 0.955823
I0823 22:13:52.193429 15833 solver.cpp:244]     Train net output #1: loss = 4587.25 (* 1 = 4587.25 loss)
I0823 22:13:52.193436 15833 sgd_solver.cpp:106] Iteration 9200, lr = 1e-08
I0823 22:15:19.157618 15833 solver.cpp:228] Iteration 9250, loss = 8859.54
I0823 22:15:19.157711 15833 solver.cpp:244]     Train net output #0: accuracy = 0.909885
I0823 22:15:19.157727 15833 solver.cpp:244]     Train net output #1: loss = 8859.54 (* 1 = 8859.54 loss)
I0823 22:15:19.157735 15833 sgd_solver.cpp:106] Iteration 9250, lr = 1e-08
I0823 22:16:46.162677 15833 solver.cpp:228] Iteration 9300, loss = 4372.99
I0823 22:16:46.162751 15833 solver.cpp:244]     Train net output #0: accuracy = 0.955896
I0823 22:16:46.162762 15833 solver.cpp:244]     Train net output #1: loss = 4372.99 (* 1 = 4372.99 loss)
I0823 22:16:46.162770 15833 sgd_solver.cpp:106] Iteration 9300, lr = 1e-08
I0823 22:18:13.137029 15833 solver.cpp:228] Iteration 9350, loss = 8507.94
I0823 22:18:13.137125 15833 solver.cpp:244]     Train net output #0: accuracy = 0.919558
I0823 22:18:13.137135 15833 solver.cpp:244]     Train net output #1: loss = 8507.94 (* 1 = 8507.94 loss)
I0823 22:18:13.137143 15833 sgd_solver.cpp:106] Iteration 9350, lr = 1e-08
I0823 22:19:38.683665 15833 solver.cpp:337] Iteration 9400, Testing net (#0)
I0823 22:19:46.248564 15833 solver.cpp:404]     Test net output #0: accuracy = 0.927997
I0823 22:19:46.248606 15833 solver.cpp:404]     Test net output #1: loss = 7494.83 (* 1 = 7494.83 loss)
I0823 22:19:47.681596 15833 solver.cpp:228] Iteration 9400, loss = 5731.38
I0823 22:19:47.681628 15833 solver.cpp:244]     Train net output #0: accuracy = 0.944586
I0823 22:19:47.681638 15833 solver.cpp:244]     Train net output #1: loss = 5731.38 (* 1 = 5731.38 loss)
I0823 22:19:47.681645 15833 sgd_solver.cpp:106] Iteration 9400, lr = 1e-08
I0823 22:21:14.671576 15833 solver.cpp:228] Iteration 9450, loss = 6684.04
I0823 22:21:14.671624 15833 solver.cpp:244]     Train net output #0: accuracy = 0.934598
I0823 22:21:14.671634 15833 solver.cpp:244]     Train net output #1: loss = 6684.04 (* 1 = 6684.04 loss)
I0823 22:21:14.671643 15833 sgd_solver.cpp:106] Iteration 9450, lr = 1e-08
I0823 22:22:41.620143 15833 solver.cpp:228] Iteration 9500, loss = 4605
I0823 22:22:41.620213 15833 solver.cpp:244]     Train net output #0: accuracy = 0.955812
I0823 22:22:41.620225 15833 solver.cpp:244]     Train net output #1: loss = 4605 (* 1 = 4605 loss)
I0823 22:22:41.620232 15833 sgd_solver.cpp:106] Iteration 9500, lr = 1e-08
I0823 22:24:08.639806 15833 solver.cpp:228] Iteration 9550, loss = 4630.95
I0823 22:24:08.639880 15833 solver.cpp:244]     Train net output #0: accuracy = 0.955546
I0823 22:24:08.639891 15833 solver.cpp:244]     Train net output #1: loss = 4630.95 (* 1 = 4630.95 loss)
I0823 22:24:08.639899 15833 sgd_solver.cpp:106] Iteration 9550, lr = 1e-08
I0823 22:25:34.135679 15833 solver.cpp:337] Iteration 9600, Testing net (#0)
I0823 22:25:41.695775 15833 solver.cpp:404]     Test net output #0: accuracy = 0.931802
I0823 22:25:41.695817 15833 solver.cpp:404]     Test net output #1: loss = 7098.98 (* 1 = 7098.98 loss)
I0823 22:25:43.139703 15833 solver.cpp:228] Iteration 9600, loss = 7283.06
I0823 22:25:43.139737 15833 solver.cpp:244]     Train net output #0: accuracy = 0.926865
I0823 22:25:43.139747 15833 solver.cpp:244]     Train net output #1: loss = 7283.06 (* 1 = 7283.06 loss)
I0823 22:25:43.139755 15833 sgd_solver.cpp:106] Iteration 9600, lr = 1e-08
I0823 22:27:10.080133 15833 solver.cpp:228] Iteration 9650, loss = 4660.79
I0823 22:27:10.080227 15833 solver.cpp:244]     Train net output #0: accuracy = 0.955548
I0823 22:27:10.080240 15833 solver.cpp:244]     Train net output #1: loss = 4660.79 (* 1 = 4660.79 loss)
I0823 22:27:10.080246 15833 sgd_solver.cpp:106] Iteration 9650, lr = 1e-08
I0823 22:28:37.009006 15833 solver.cpp:228] Iteration 9700, loss = 8395.32
I0823 22:28:37.009084 15833 solver.cpp:244]     Train net output #0: accuracy = 0.91623
I0823 22:28:37.009095 15833 solver.cpp:244]     Train net output #1: loss = 8395.32 (* 1 = 8395.32 loss)
I0823 22:28:37.009102 15833 sgd_solver.cpp:106] Iteration 9700, lr = 1e-08
I0823 22:30:03.934365 15833 solver.cpp:228] Iteration 9750, loss = 4970.02
I0823 22:30:03.934407 15833 solver.cpp:244]     Train net output #0: accuracy = 0.952163
I0823 22:30:03.934417 15833 solver.cpp:244]     Train net output #1: loss = 4970.02 (* 1 = 4970.02 loss)
I0823 22:30:03.934424 15833 sgd_solver.cpp:106] Iteration 9750, lr = 1e-08
I0823 22:31:29.472206 15833 solver.cpp:337] Iteration 9800, Testing net (#0)
I0823 22:31:37.035373 15833 solver.cpp:404]     Test net output #0: accuracy = 0.932158
I0823 22:31:37.035410 15833 solver.cpp:404]     Test net output #1: loss = 7082.3 (* 1 = 7082.3 loss)
I0823 22:31:38.475982 15833 solver.cpp:228] Iteration 9800, loss = 9912.67
I0823 22:31:38.476016 15833 solver.cpp:244]     Train net output #0: accuracy = 0.906047
I0823 22:31:38.476027 15833 solver.cpp:244]     Train net output #1: loss = 9912.67 (* 1 = 9912.67 loss)
I0823 22:31:38.476033 15833 sgd_solver.cpp:106] Iteration 9800, lr = 1e-08
I0823 22:33:05.416432 15833 solver.cpp:228] Iteration 9850, loss = 5796.79
I0823 22:33:05.416507 15833 solver.cpp:244]     Train net output #0: accuracy = 0.943772
I0823 22:33:05.416517 15833 solver.cpp:244]     Train net output #1: loss = 5796.79 (* 1 = 5796.79 loss)
I0823 22:33:05.416525 15833 sgd_solver.cpp:106] Iteration 9850, lr = 1e-08
I0823 22:34:32.412199 15833 solver.cpp:228] Iteration 9900, loss = 6016
I0823 22:34:32.412271 15833 solver.cpp:244]     Train net output #0: accuracy = 0.941456
I0823 22:34:32.412282 15833 solver.cpp:244]     Train net output #1: loss = 6016 (* 1 = 6016 loss)
I0823 22:34:32.412289 15833 sgd_solver.cpp:106] Iteration 9900, lr = 1e-08
I0823 22:35:59.386385 15833 solver.cpp:228] Iteration 9950, loss = 7128.48
I0823 22:35:59.386476 15833 solver.cpp:244]     Train net output #0: accuracy = 0.931606
I0823 22:35:59.386487 15833 solver.cpp:244]     Train net output #1: loss = 7128.48 (* 1 = 7128.48 loss)
I0823 22:35:59.386494 15833 sgd_solver.cpp:106] Iteration 9950, lr = 1e-08
I0823 22:37:24.950400 15833 solver.cpp:337] Iteration 10000, Testing net (#0)
I0823 22:37:32.511662 15833 solver.cpp:404]     Test net output #0: accuracy = 0.932158
I0823 22:37:32.511703 15833 solver.cpp:404]     Test net output #1: loss = 7072.77 (* 1 = 7072.77 loss)
I0823 22:37:33.942999 15833 solver.cpp:228] Iteration 10000, loss = 4013.01
I0823 22:37:33.943032 15833 solver.cpp:244]     Train net output #0: accuracy = 0.960774
I0823 22:37:33.943042 15833 solver.cpp:244]     Train net output #1: loss = 4013.01 (* 1 = 4013.01 loss)
I0823 22:37:33.943049 15833 sgd_solver.cpp:106] Iteration 10000, lr = 1e-08
I0823 22:39:00.894496 15833 solver.cpp:228] Iteration 10050, loss = 7174.97
I0823 22:39:00.894544 15833 solver.cpp:244]     Train net output #0: accuracy = 0.927717
I0823 22:39:00.894554 15833 solver.cpp:244]     Train net output #1: loss = 7174.97 (* 1 = 7174.97 loss)
I0823 22:39:00.894562 15833 sgd_solver.cpp:106] Iteration 10050, lr = 1e-08
I0823 22:40:27.842416 15833 solver.cpp:228] Iteration 10100, loss = 4629.39
I0823 22:40:27.842489 15833 solver.cpp:244]     Train net output #0: accuracy = 0.953435
I0823 22:40:27.842500 15833 solver.cpp:244]     Train net output #1: loss = 4629.39 (* 1 = 4629.39 loss)
I0823 22:40:27.842507 15833 sgd_solver.cpp:106] Iteration 10100, lr = 1e-08
I0823 22:41:54.817219 15833 solver.cpp:228] Iteration 10150, loss = 8945.09
I0823 22:41:54.817323 15833 solver.cpp:244]     Train net output #0: accuracy = 0.909384
I0823 22:41:54.817338 15833 solver.cpp:244]     Train net output #1: loss = 8945.09 (* 1 = 8945.09 loss)
I0823 22:41:54.817347 15833 sgd_solver.cpp:106] Iteration 10150, lr = 1e-08
I0823 22:43:20.327759 15833 solver.cpp:337] Iteration 10200, Testing net (#0)
I0823 22:43:27.886073 15833 solver.cpp:404]     Test net output #0: accuracy = 0.932663
I0823 22:43:27.886116 15833 solver.cpp:404]     Test net output #1: loss = 7023.41 (* 1 = 7023.41 loss)
I0823 22:43:29.319548 15833 solver.cpp:228] Iteration 10200, loss = 4432.64
I0823 22:43:29.319579 15833 solver.cpp:244]     Train net output #0: accuracy = 0.957149
I0823 22:43:29.319589 15833 solver.cpp:244]     Train net output #1: loss = 4432.64 (* 1 = 4432.64 loss)
I0823 22:43:29.319597 15833 sgd_solver.cpp:106] Iteration 10200, lr = 1e-08
I0823 22:44:56.327760 15833 solver.cpp:228] Iteration 10250, loss = 8427.91
I0823 22:44:56.327807 15833 solver.cpp:244]     Train net output #0: accuracy = 0.918304
I0823 22:44:56.327818 15833 solver.cpp:244]     Train net output #1: loss = 8427.91 (* 1 = 8427.91 loss)
I0823 22:44:56.327826 15833 sgd_solver.cpp:106] Iteration 10250, lr = 1e-08
I0823 22:46:23.269978 15833 solver.cpp:228] Iteration 10300, loss = 8341.81
I0823 22:46:23.270069 15833 solver.cpp:244]     Train net output #0: accuracy = 0.92128
I0823 22:46:23.270081 15833 solver.cpp:244]     Train net output #1: loss = 8341.81 (* 1 = 8341.81 loss)
I0823 22:46:23.270088 15833 sgd_solver.cpp:106] Iteration 10300, lr = 1e-08
I0823 22:47:50.246742 15833 solver.cpp:228] Iteration 10350, loss = 4914.51
I0823 22:47:50.246784 15833 solver.cpp:244]     Train net output #0: accuracy = 0.951837
I0823 22:47:50.246794 15833 solver.cpp:244]     Train net output #1: loss = 4914.51 (* 1 = 4914.51 loss)
I0823 22:47:50.246803 15833 sgd_solver.cpp:106] Iteration 10350, lr = 1e-08
I0823 22:49:15.777251 15833 solver.cpp:337] Iteration 10400, Testing net (#0)
I0823 22:49:23.338469 15833 solver.cpp:404]     Test net output #0: accuracy = 0.928162
I0823 22:49:23.338510 15833 solver.cpp:404]     Test net output #1: loss = 7477.73 (* 1 = 7477.73 loss)
I0823 22:49:24.777926 15833 solver.cpp:228] Iteration 10400, loss = 6165.6
I0823 22:49:24.777959 15833 solver.cpp:244]     Train net output #0: accuracy = 0.939411
I0823 22:49:24.777969 15833 solver.cpp:244]     Train net output #1: loss = 6165.6 (* 1 = 6165.6 loss)
I0823 22:49:24.777976 15833 sgd_solver.cpp:106] Iteration 10400, lr = 1e-08
I0823 22:50:51.758723 15833 solver.cpp:228] Iteration 10450, loss = 4103.33
I0823 22:50:51.758770 15833 solver.cpp:244]     Train net output #0: accuracy = 0.960902
I0823 22:50:51.758781 15833 solver.cpp:244]     Train net output #1: loss = 4103.33 (* 1 = 4103.33 loss)
I0823 22:50:51.758788 15833 sgd_solver.cpp:106] Iteration 10450, lr = 1e-08
I0823 22:52:18.727318 15833 solver.cpp:228] Iteration 10500, loss = 7683.52
I0823 22:52:18.727365 15833 solver.cpp:244]     Train net output #0: accuracy = 0.923802
I0823 22:52:18.727375 15833 solver.cpp:244]     Train net output #1: loss = 7683.52 (* 1 = 7683.52 loss)
I0823 22:52:18.727383 15833 sgd_solver.cpp:106] Iteration 10500, lr = 1e-08
I0823 22:53:45.692257 15833 solver.cpp:228] Iteration 10550, loss = 4380.76
I0823 22:53:45.692304 15833 solver.cpp:244]     Train net output #0: accuracy = 0.956656
I0823 22:53:45.692315 15833 solver.cpp:244]     Train net output #1: loss = 4380.76 (* 1 = 4380.76 loss)
I0823 22:53:45.692322 15833 sgd_solver.cpp:106] Iteration 10550, lr = 1e-08
I0823 22:55:11.234787 15833 solver.cpp:337] Iteration 10600, Testing net (#0)
I0823 22:55:18.796416 15833 solver.cpp:404]     Test net output #0: accuracy = 0.931329
I0823 22:55:18.796455 15833 solver.cpp:404]     Test net output #1: loss = 7144.11 (* 1 = 7144.11 loss)
I0823 22:55:20.240396 15833 solver.cpp:228] Iteration 10600, loss = 7928.93
I0823 22:55:20.240427 15833 solver.cpp:244]     Train net output #0: accuracy = 0.921719
I0823 22:55:20.240437 15833 solver.cpp:244]     Train net output #1: loss = 7928.93 (* 1 = 7928.93 loss)
I0823 22:55:20.240444 15833 sgd_solver.cpp:106] Iteration 10600, lr = 1e-08
I0823 22:56:47.169028 15833 solver.cpp:228] Iteration 10650, loss = 5394.64
I0823 22:56:47.169096 15833 solver.cpp:244]     Train net output #0: accuracy = 0.94799
I0823 22:56:47.169108 15833 solver.cpp:244]     Train net output #1: loss = 5394.64 (* 1 = 5394.64 loss)
I0823 22:56:47.169116 15833 sgd_solver.cpp:106] Iteration 10650, lr = 1e-08
I0823 22:58:14.174741 15833 solver.cpp:228] Iteration 10700, loss = 4283.11
I0823 22:58:14.174788 15833 solver.cpp:244]     Train net output #0: accuracy = 0.957668
I0823 22:58:14.174799 15833 solver.cpp:244]     Train net output #1: loss = 4283.11 (* 1 = 4283.11 loss)
I0823 22:58:14.174806 15833 sgd_solver.cpp:106] Iteration 10700, lr = 1e-08
I0823 22:59:41.152061 15833 solver.cpp:228] Iteration 10750, loss = 9653.4
I0823 22:59:41.152134 15833 solver.cpp:244]     Train net output #0: accuracy = 0.906319
I0823 22:59:41.152145 15833 solver.cpp:244]     Train net output #1: loss = 9653.4 (* 1 = 9653.4 loss)
I0823 22:59:41.152153 15833 sgd_solver.cpp:106] Iteration 10750, lr = 1e-08
I0823 23:01:06.718528 15833 solver.cpp:337] Iteration 10800, Testing net (#0)
I0823 23:01:14.279208 15833 solver.cpp:404]     Test net output #0: accuracy = 0.932191
I0823 23:01:14.279248 15833 solver.cpp:404]     Test net output #1: loss = 7085.08 (* 1 = 7085.08 loss)
I0823 23:01:15.711621 15833 solver.cpp:228] Iteration 10800, loss = 5285
I0823 23:01:15.711652 15833 solver.cpp:244]     Train net output #0: accuracy = 0.949287
I0823 23:01:15.711663 15833 solver.cpp:244]     Train net output #1: loss = 5285 (* 1 = 5285 loss)
I0823 23:01:15.711670 15833 sgd_solver.cpp:106] Iteration 10800, lr = 1e-08
I0823 23:02:42.677012 15833 solver.cpp:228] Iteration 10850, loss = 6433.52
I0823 23:02:42.677059 15833 solver.cpp:244]     Train net output #0: accuracy = 0.938195
I0823 23:02:42.677069 15833 solver.cpp:244]     Train net output #1: loss = 6433.52 (* 1 = 6433.52 loss)
I0823 23:02:42.677078 15833 sgd_solver.cpp:106] Iteration 10850, lr = 1e-08
I0823 23:04:09.648186 15833 solver.cpp:228] Iteration 10900, loss = 4198.05
I0823 23:04:09.648234 15833 solver.cpp:244]     Train net output #0: accuracy = 0.958844
I0823 23:04:09.648246 15833 solver.cpp:244]     Train net output #1: loss = 4198.05 (* 1 = 4198.05 loss)
I0823 23:04:09.648253 15833 sgd_solver.cpp:106] Iteration 10900, lr = 1e-08
I0823 23:05:36.641717 15833 solver.cpp:228] Iteration 10950, loss = 7319.47
I0823 23:05:36.641809 15833 solver.cpp:244]     Train net output #0: accuracy = 0.929406
I0823 23:05:36.641821 15833 solver.cpp:244]     Train net output #1: loss = 7319.47 (* 1 = 7319.47 loss)
I0823 23:05:36.641829 15833 sgd_solver.cpp:106] Iteration 10950, lr = 1e-08
I0823 23:07:02.143517 15833 solver.cpp:337] Iteration 11000, Testing net (#0)
I0823 23:07:09.705478 15833 solver.cpp:404]     Test net output #0: accuracy = 0.932676
I0823 23:07:09.705519 15833 solver.cpp:404]     Test net output #1: loss = 7019.83 (* 1 = 7019.83 loss)
I0823 23:07:11.141243 15833 solver.cpp:228] Iteration 11000, loss = 4362.12
I0823 23:07:11.141278 15833 solver.cpp:244]     Train net output #0: accuracy = 0.95817
I0823 23:07:11.141288 15833 solver.cpp:244]     Train net output #1: loss = 4362.12 (* 1 = 4362.12 loss)
I0823 23:07:11.141295 15833 sgd_solver.cpp:106] Iteration 11000, lr = 1e-08
I0823 23:08:38.125248 15833 solver.cpp:228] Iteration 11050, loss = 7039.52
I0823 23:08:38.125294 15833 solver.cpp:244]     Train net output #0: accuracy = 0.932861
I0823 23:08:38.125304 15833 solver.cpp:244]     Train net output #1: loss = 7039.52 (* 1 = 7039.52 loss)
I0823 23:08:38.125313 15833 sgd_solver.cpp:106] Iteration 11050, lr = 1e-08
I0823 23:10:05.071269 15833 solver.cpp:228] Iteration 11100, loss = 8671.64
I0823 23:10:05.071341 15833 solver.cpp:244]     Train net output #0: accuracy = 0.915926
I0823 23:10:05.071352 15833 solver.cpp:244]     Train net output #1: loss = 8671.64 (* 1 = 8671.64 loss)
I0823 23:10:05.071359 15833 sgd_solver.cpp:106] Iteration 11100, lr = 1e-08
I0823 23:11:32.061717 15833 solver.cpp:228] Iteration 11150, loss = 4705.93
I0823 23:11:32.061816 15833 solver.cpp:244]     Train net output #0: accuracy = 0.953525
I0823 23:11:32.061832 15833 solver.cpp:244]     Train net output #1: loss = 4705.93 (* 1 = 4705.93 loss)
I0823 23:11:32.061839 15833 sgd_solver.cpp:106] Iteration 11150, lr = 1e-08
I0823 23:12:57.578181 15833 solver.cpp:337] Iteration 11200, Testing net (#0)
I0823 23:13:05.137990 15833 solver.cpp:404]     Test net output #0: accuracy = 0.931928
I0823 23:13:05.138031 15833 solver.cpp:404]     Test net output #1: loss = 7097.94 (* 1 = 7097.94 loss)
I0823 23:13:06.577741 15833 solver.cpp:228] Iteration 11200, loss = 9791.46
I0823 23:13:06.577775 15833 solver.cpp:244]     Train net output #0: accuracy = 0.904778
I0823 23:13:06.577785 15833 solver.cpp:244]     Train net output #1: loss = 9791.46 (* 1 = 9791.46 loss)
I0823 23:13:06.577793 15833 sgd_solver.cpp:106] Iteration 11200, lr = 1e-08
I0823 23:14:33.528952 15833 solver.cpp:228] Iteration 11250, loss = 5082.66
I0823 23:14:33.529000 15833 solver.cpp:244]     Train net output #0: accuracy = 0.951223
I0823 23:14:33.529011 15833 solver.cpp:244]     Train net output #1: loss = 5082.66 (* 1 = 5082.66 loss)
I0823 23:14:33.529018 15833 sgd_solver.cpp:106] Iteration 11250, lr = 1e-08
I0823 23:16:00.523291 15833 solver.cpp:228] Iteration 11300, loss = 6973.31
I0823 23:16:00.523368 15833 solver.cpp:244]     Train net output #0: accuracy = 0.933858
I0823 23:16:00.523380 15833 solver.cpp:244]     Train net output #1: loss = 6973.31 (* 1 = 6973.31 loss)
I0823 23:16:00.523387 15833 sgd_solver.cpp:106] Iteration 11300, lr = 1e-08
I0823 23:17:27.490550 15833 solver.cpp:228] Iteration 11350, loss = 3867.77
I0823 23:17:27.490640 15833 solver.cpp:244]     Train net output #0: accuracy = 0.962909
I0823 23:17:27.490653 15833 solver.cpp:244]     Train net output #1: loss = 3867.77 (* 1 = 3867.77 loss)
I0823 23:17:27.490660 15833 sgd_solver.cpp:106] Iteration 11350, lr = 1e-08
I0823 23:18:53.049140 15833 solver.cpp:337] Iteration 11400, Testing net (#0)
I0823 23:19:00.633235 15833 solver.cpp:404]     Test net output #0: accuracy = 0.928669
I0823 23:19:00.633276 15833 solver.cpp:404]     Test net output #1: loss = 7438.83 (* 1 = 7438.83 loss)
I0823 23:19:02.077945 15833 solver.cpp:228] Iteration 11400, loss = 7814.14
I0823 23:19:02.077977 15833 solver.cpp:244]     Train net output #0: accuracy = 0.923976
I0823 23:19:02.077988 15833 solver.cpp:244]     Train net output #1: loss = 7814.14 (* 1 = 7814.14 loss)
I0823 23:19:02.077996 15833 sgd_solver.cpp:106] Iteration 11400, lr = 1e-08
I0823 23:20:29.001904 15833 solver.cpp:228] Iteration 11450, loss = 7014.74
I0823 23:20:29.001950 15833 solver.cpp:244]     Train net output #0: accuracy = 0.931296
I0823 23:20:29.003466 15833 solver.cpp:244]     Train net output #1: loss = 7014.74 (* 1 = 7014.74 loss)
I0823 23:20:29.003479 15833 sgd_solver.cpp:106] Iteration 11450, lr = 1e-08
I0823 23:21:56.022327 15833 solver.cpp:228] Iteration 11500, loss = 4565.62
I0823 23:21:56.022421 15833 solver.cpp:244]     Train net output #0: accuracy = 0.956135
I0823 23:21:56.022433 15833 solver.cpp:244]     Train net output #1: loss = 4565.62 (* 1 = 4565.62 loss)
I0823 23:21:56.022440 15833 sgd_solver.cpp:106] Iteration 11500, lr = 1e-08
I0823 23:23:22.988880 15833 solver.cpp:228] Iteration 11550, loss = 9462.51
I0823 23:23:22.988957 15833 solver.cpp:244]     Train net output #0: accuracy = 0.905598
I0823 23:23:22.988970 15833 solver.cpp:244]     Train net output #1: loss = 9462.51 (* 1 = 9462.51 loss)
I0823 23:23:22.988977 15833 sgd_solver.cpp:106] Iteration 11550, lr = 1e-08
I0823 23:24:48.554018 15833 solver.cpp:337] Iteration 11600, Testing net (#0)
I0823 23:24:56.117856 15833 solver.cpp:404]     Test net output #0: accuracy = 0.931031
I0823 23:24:56.117899 15833 solver.cpp:404]     Test net output #1: loss = 7163.18 (* 1 = 7163.18 loss)
I0823 23:24:57.551331 15833 solver.cpp:228] Iteration 11600, loss = 4618.22
I0823 23:24:57.551365 15833 solver.cpp:244]     Train net output #0: accuracy = 0.954904
I0823 23:24:57.551375 15833 solver.cpp:244]     Train net output #1: loss = 4618.22 (* 1 = 4618.22 loss)
I0823 23:24:57.551393 15833 sgd_solver.cpp:106] Iteration 11600, lr = 1e-08
I0823 23:26:24.578382 15833 solver.cpp:228] Iteration 11650, loss = 8597.07
I0823 23:26:24.578505 15833 solver.cpp:244]     Train net output #0: accuracy = 0.917986
I0823 23:26:24.578516 15833 solver.cpp:244]     Train net output #1: loss = 8597.07 (* 1 = 8597.07 loss)
I0823 23:26:24.578524 15833 sgd_solver.cpp:106] Iteration 11650, lr = 1e-08
I0823 23:27:51.597388 15833 solver.cpp:228] Iteration 11700, loss = 5549.38
I0823 23:27:51.597465 15833 solver.cpp:244]     Train net output #0: accuracy = 0.946039
I0823 23:27:51.597476 15833 solver.cpp:244]     Train net output #1: loss = 5549.38 (* 1 = 5549.38 loss)
I0823 23:27:51.597483 15833 sgd_solver.cpp:106] Iteration 11700, lr = 1e-08
I0823 23:29:18.613857 15833 solver.cpp:228] Iteration 11750, loss = 6680.29
I0823 23:29:18.613905 15833 solver.cpp:244]     Train net output #0: accuracy = 0.935127
I0823 23:29:18.613916 15833 solver.cpp:244]     Train net output #1: loss = 6680.29 (* 1 = 6680.29 loss)
I0823 23:29:18.613924 15833 sgd_solver.cpp:106] Iteration 11750, lr = 1e-08
I0823 23:30:44.158406 15833 solver.cpp:337] Iteration 11800, Testing net (#0)
I0823 23:30:51.721201 15833 solver.cpp:404]     Test net output #0: accuracy = 0.932211
I0823 23:30:51.721243 15833 solver.cpp:404]     Test net output #1: loss = 7086.98 (* 1 = 7086.98 loss)
I0823 23:30:53.164747 15833 solver.cpp:228] Iteration 11800, loss = 5152.61
I0823 23:30:53.164783 15833 solver.cpp:244]     Train net output #0: accuracy = 0.950008
I0823 23:30:53.164793 15833 solver.cpp:244]     Train net output #1: loss = 5152.61 (* 1 = 5152.61 loss)
I0823 23:30:53.164800 15833 sgd_solver.cpp:106] Iteration 11800, lr = 1e-08
I0823 23:32:20.260207 15833 solver.cpp:228] Iteration 11850, loss = 3791.14
I0823 23:32:20.260282 15833 solver.cpp:244]     Train net output #0: accuracy = 0.962333
I0823 23:32:20.260293 15833 solver.cpp:244]     Train net output #1: loss = 3791.14 (* 1 = 3791.14 loss)
I0823 23:32:20.260301 15833 sgd_solver.cpp:106] Iteration 11850, lr = 1e-08
I0823 23:33:47.215031 15833 solver.cpp:228] Iteration 11900, loss = 7231.42
I0823 23:33:47.215077 15833 solver.cpp:244]     Train net output #0: accuracy = 0.927085
I0823 23:33:47.215088 15833 solver.cpp:244]     Train net output #1: loss = 7231.42 (* 1 = 7231.42 loss)
I0823 23:33:47.215096 15833 sgd_solver.cpp:106] Iteration 11900, lr = 1e-08
I0823 23:35:14.276247 15833 solver.cpp:228] Iteration 11950, loss = 4796.79
I0823 23:35:14.276331 15833 solver.cpp:244]     Train net output #0: accuracy = 0.952782
I0823 23:35:14.276343 15833 solver.cpp:244]     Train net output #1: loss = 4796.79 (* 1 = 4796.79 loss)
I0823 23:35:14.276351 15833 sgd_solver.cpp:106] Iteration 11950, lr = 1e-08
I0823 23:36:39.806330 15833 solver.cpp:454] Snapshotting to binary proto file portrait_one_stage2_1_iter_12000.caffemodel
I0823 23:36:39.808804 15833 sgd_solver.cpp:273] Snapshotting solver state to binary proto file portrait_one_stage2_1_iter_12000.solverstate
I0823 23:36:40.838119 15833 solver.cpp:317] Iteration 12000, loss = 8501.42
I0823 23:36:40.838155 15833 solver.cpp:337] Iteration 12000, Testing net (#0)
I0823 23:36:49.026610 15833 solver.cpp:404]     Test net output #0: accuracy = 0.933016
I0823 23:36:49.026651 15833 solver.cpp:404]     Test net output #1: loss = 6983.53 (* 1 = 6983.53 loss)
I0823 23:36:49.026657 15833 solver.cpp:322] Optimization Done.
I0823 23:36:49.026660 15833 caffe.cpp:254] Optimization Done.
