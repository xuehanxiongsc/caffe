I0826 16:36:06.356765  4567 caffe.cpp:217] Using GPUs 1
I0826 16:36:06.372581  4567 caffe.cpp:222] GPU 1: GeForce GTX TITAN X
I0826 16:36:06.562274  4567 solver.cpp:48] Initializing solver from parameters: 
test_iter: 15
test_interval: 200
base_lr: 1e-05
display: 50
max_iter: 16000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 1e-05
stepsize: 4000
snapshot: 4000
snapshot_prefix: "portrait_one_stage3"
solver_mode: GPU
device_id: 1
net: "portrait_train_test_one_stage.prototxt3"
train_state {
  level: 0
  stage: ""
}
I0826 16:36:06.562415  4567 solver.cpp:91] Creating training net from net file: portrait_train_test_one_stage.prototxt3
I0826 16:36:06.563293  4567 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0826 16:36:06.563561  4567 net.cpp:58] Initializing net from parameters: 
name: "segmentation"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "SegData"
  top: "image"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 200
  }
  data_param {
    source: "/raid/xuehan/segmentation_train_split"
    batch_size: 128
    backend: LMDB
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "image"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 50
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1_1_bn"
  type: "BatchNorm"
  bottom: "pool1"
  top: "conv1_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv1_1_bn_scale"
  type: "Scale"
  bottom: "conv1_1_bn"
  top: "conv1_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_1_relu"
  type: "ReLU"
  bottom: "conv1_1_bn"
  top: "conv1_1_bn"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv1_1_bn"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_1"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1_bn"
  type: "BatchNorm"
  bottom: "pool2"
  top: "conv2_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv2_1_bn_scale"
  type: "Scale"
  bottom: "conv2_1_bn"
  top: "conv2_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1_relu"
  type: "ReLU"
  bottom: "conv2_1_bn"
  top: "conv2_1_bn"
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv2_1_bn"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_1"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1_bn"
  type: "BatchNorm"
  bottom: "pool3"
  top: "conv3_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv3_1_bn_scale"
  type: "Scale"
  bottom: "conv3_1_bn"
  top: "conv3_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1_relu"
  type: "ReLU"
  bottom: "conv3_1_bn"
  top: "conv3_1_bn"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv3_1_bn"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_1"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1_bn"
  type: "BatchNorm"
  bottom: "pool4"
  top: "conv4_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv4_1_bn_scale"
  type: "Scale"
  bottom: "conv4_1_bn"
  top: "conv4_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1_relu"
  type: "ReLU"
  bottom: "conv4_1_bn"
  top: "conv4_1_bn"
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "conv4_1_bn"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv5_1_bn"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv5_1_bn_scale"
  type: "Scale"
  bottom: "conv5_1_bn"
  top: "conv5_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_1_relu"
  type: "ReLU"
  bottom: "conv5_1_bn"
  top: "conv5_1_bn"
}
layer {
  name: "conv6_1"
  type: "Convolution"
  bottom: "conv5_1_bn"
  top: "conv6_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv6_1_bn"
  type: "BatchNorm"
  bottom: "conv6_1"
  top: "conv6_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv6_1_bn_scale"
  type: "Scale"
  bottom: "conv6_1_bn"
  top: "conv6_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv6_1_relu"
  type: "ReLU"
  bottom: "conv6_1_bn"
  top: "conv6_1_bn"
}
layer {
  name: "conv7_1"
  type: "Convolution"
  bottom: "conv6_1_bn"
  top: "conv7_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv7_1_bn"
  type: "BatchNorm"
  bottom: "conv7_1"
  top: "conv7_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv7_1_bn_scale"
  type: "Scale"
  bottom: "conv7_1_bn"
  top: "conv7_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv7_1_relu"
  type: "ReLU"
  bottom: "conv7_1_bn"
  top: "conv7_1_bn"
}
layer {
  name: "score"
  type: "Convolution"
  bottom: "conv7_1_bn"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 4
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "upscore"
  type: "Deconvolution"
  bottom: "score"
  top: "upscore"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 4
    bias_term: false
    pad: 0
    kernel_size: 32
    stride: 16
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "cropscore"
  type: "Crop"
  bottom: "upscore"
  bottom: "image"
  top: "cropscore"
  crop_param {
    axis: 2
    offset: 12
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "cropscore"
  bottom: "label"
  top: "loss"
  loss_weight: 1
  loss_param {
    normalize: false
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "cropscore"
  bottom: "label"
  top: "accuracy"
}
I0826 16:36:06.563778  4567 layer_factory.hpp:77] Creating layer data
I0826 16:36:06.564384  4567 net.cpp:100] Creating Layer data
I0826 16:36:06.564396  4567 net.cpp:408] data -> image
I0826 16:36:06.564416  4567 net.cpp:408] data -> label
I0826 16:36:06.565361  4571 db_lmdb.cpp:35] Opened lmdb /raid/xuehan/segmentation_train_split
I0826 16:36:06.565510  4567 seg_data_layer.cpp:38] 200 200 4
I0826 16:36:06.572863  4567 seg_data_layer.cpp:51] output data size: 128,3,200,200
I0826 16:36:06.572922  4567 seg_data_layer.cpp:63] output label size: 128,1,200,200
I0826 16:36:06.681324  4567 net.cpp:150] Setting up data
I0826 16:36:06.681363  4567 net.cpp:157] Top shape: 128 3 200 200 (15360000)
I0826 16:36:06.681370  4567 net.cpp:157] Top shape: 128 1 200 200 (5120000)
I0826 16:36:06.681375  4567 net.cpp:165] Memory required for data: 81920000
I0826 16:36:06.681391  4567 layer_factory.hpp:77] Creating layer image_data_0_split
I0826 16:36:06.681408  4567 net.cpp:100] Creating Layer image_data_0_split
I0826 16:36:06.681416  4567 net.cpp:434] image_data_0_split <- image
I0826 16:36:06.681429  4567 net.cpp:408] image_data_0_split -> image_data_0_split_0
I0826 16:36:06.681443  4567 net.cpp:408] image_data_0_split -> image_data_0_split_1
I0826 16:36:06.681498  4567 net.cpp:150] Setting up image_data_0_split
I0826 16:36:06.681505  4567 net.cpp:157] Top shape: 128 3 200 200 (15360000)
I0826 16:36:06.681510  4567 net.cpp:157] Top shape: 128 3 200 200 (15360000)
I0826 16:36:06.681514  4567 net.cpp:165] Memory required for data: 204800000
I0826 16:36:06.681519  4567 layer_factory.hpp:77] Creating layer label_data_1_split
I0826 16:36:06.681530  4567 net.cpp:100] Creating Layer label_data_1_split
I0826 16:36:06.681535  4567 net.cpp:434] label_data_1_split <- label
I0826 16:36:06.681541  4567 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0826 16:36:06.681548  4567 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0826 16:36:06.681582  4567 net.cpp:150] Setting up label_data_1_split
I0826 16:36:06.681591  4567 net.cpp:157] Top shape: 128 1 200 200 (5120000)
I0826 16:36:06.681596  4567 net.cpp:157] Top shape: 128 1 200 200 (5120000)
I0826 16:36:06.681601  4567 net.cpp:165] Memory required for data: 245760000
I0826 16:36:06.681604  4567 layer_factory.hpp:77] Creating layer conv1_1
I0826 16:36:06.681622  4567 net.cpp:100] Creating Layer conv1_1
I0826 16:36:06.681627  4567 net.cpp:434] conv1_1 <- image_data_0_split_0
I0826 16:36:06.681633  4567 net.cpp:408] conv1_1 -> conv1_1
I0826 16:36:06.681846  4567 net.cpp:150] Setting up conv1_1
I0826 16:36:06.681856  4567 net.cpp:157] Top shape: 128 8 298 298 (90935296)
I0826 16:36:06.681860  4567 net.cpp:165] Memory required for data: 609501184
I0826 16:36:06.681874  4567 layer_factory.hpp:77] Creating layer pool1
I0826 16:36:06.681885  4567 net.cpp:100] Creating Layer pool1
I0826 16:36:06.681890  4567 net.cpp:434] pool1 <- conv1_1
I0826 16:36:06.681895  4567 net.cpp:408] pool1 -> pool1
I0826 16:36:06.681937  4567 net.cpp:150] Setting up pool1
I0826 16:36:06.681944  4567 net.cpp:157] Top shape: 128 8 149 149 (22733824)
I0826 16:36:06.681949  4567 net.cpp:165] Memory required for data: 700436480
I0826 16:36:06.681953  4567 layer_factory.hpp:77] Creating layer conv1_1_bn
I0826 16:36:06.681962  4567 net.cpp:100] Creating Layer conv1_1_bn
I0826 16:36:06.681967  4567 net.cpp:434] conv1_1_bn <- pool1
I0826 16:36:06.681972  4567 net.cpp:408] conv1_1_bn -> conv1_1_bn
I0826 16:36:06.682760  4567 net.cpp:150] Setting up conv1_1_bn
I0826 16:36:06.682777  4567 net.cpp:157] Top shape: 128 8 149 149 (22733824)
I0826 16:36:06.682782  4567 net.cpp:165] Memory required for data: 791371776
I0826 16:36:06.682799  4567 layer_factory.hpp:77] Creating layer conv1_1_bn_scale
I0826 16:36:06.682814  4567 net.cpp:100] Creating Layer conv1_1_bn_scale
I0826 16:36:06.682819  4567 net.cpp:434] conv1_1_bn_scale <- conv1_1_bn
I0826 16:36:06.682826  4567 net.cpp:395] conv1_1_bn_scale -> conv1_1_bn (in-place)
I0826 16:36:06.690253  4567 layer_factory.hpp:77] Creating layer conv1_1_bn_scale
I0826 16:36:06.690443  4567 net.cpp:150] Setting up conv1_1_bn_scale
I0826 16:36:06.690457  4567 net.cpp:157] Top shape: 128 8 149 149 (22733824)
I0826 16:36:06.690461  4567 net.cpp:165] Memory required for data: 882307072
I0826 16:36:06.690477  4567 layer_factory.hpp:77] Creating layer conv1_1_relu
I0826 16:36:06.690487  4567 net.cpp:100] Creating Layer conv1_1_relu
I0826 16:36:06.690503  4567 net.cpp:434] conv1_1_relu <- conv1_1_bn
I0826 16:36:06.690523  4567 net.cpp:395] conv1_1_relu -> conv1_1_bn (in-place)
I0826 16:36:06.690531  4567 net.cpp:150] Setting up conv1_1_relu
I0826 16:36:06.690537  4567 net.cpp:157] Top shape: 128 8 149 149 (22733824)
I0826 16:36:06.690541  4567 net.cpp:165] Memory required for data: 973242368
I0826 16:36:06.690546  4567 layer_factory.hpp:77] Creating layer conv2_1
I0826 16:36:06.690560  4567 net.cpp:100] Creating Layer conv2_1
I0826 16:36:06.690564  4567 net.cpp:434] conv2_1 <- conv1_1_bn
I0826 16:36:06.690572  4567 net.cpp:408] conv2_1 -> conv2_1
I0826 16:36:06.691354  4567 net.cpp:150] Setting up conv2_1
I0826 16:36:06.691370  4567 net.cpp:157] Top shape: 128 16 149 149 (45467648)
I0826 16:36:06.691373  4567 net.cpp:165] Memory required for data: 1155112960
I0826 16:36:06.691380  4567 layer_factory.hpp:77] Creating layer pool2
I0826 16:36:06.691390  4567 net.cpp:100] Creating Layer pool2
I0826 16:36:06.691395  4567 net.cpp:434] pool2 <- conv2_1
I0826 16:36:06.691404  4567 net.cpp:408] pool2 -> pool2
I0826 16:36:06.691440  4567 net.cpp:150] Setting up pool2
I0826 16:36:06.691448  4567 net.cpp:157] Top shape: 128 16 75 75 (11520000)
I0826 16:36:06.691452  4567 net.cpp:165] Memory required for data: 1201192960
I0826 16:36:06.691457  4567 layer_factory.hpp:77] Creating layer conv2_1_bn
I0826 16:36:06.691465  4567 net.cpp:100] Creating Layer conv2_1_bn
I0826 16:36:06.691469  4567 net.cpp:434] conv2_1_bn <- pool2
I0826 16:36:06.691476  4567 net.cpp:408] conv2_1_bn -> conv2_1_bn
I0826 16:36:06.692188  4567 net.cpp:150] Setting up conv2_1_bn
I0826 16:36:06.692204  4567 net.cpp:157] Top shape: 128 16 75 75 (11520000)
I0826 16:36:06.692209  4567 net.cpp:165] Memory required for data: 1247272960
I0826 16:36:06.692225  4567 layer_factory.hpp:77] Creating layer conv2_1_bn_scale
I0826 16:36:06.692234  4567 net.cpp:100] Creating Layer conv2_1_bn_scale
I0826 16:36:06.692240  4567 net.cpp:434] conv2_1_bn_scale <- conv2_1_bn
I0826 16:36:06.692246  4567 net.cpp:395] conv2_1_bn_scale -> conv2_1_bn (in-place)
I0826 16:36:06.692283  4567 layer_factory.hpp:77] Creating layer conv2_1_bn_scale
I0826 16:36:06.692404  4567 net.cpp:150] Setting up conv2_1_bn_scale
I0826 16:36:06.692414  4567 net.cpp:157] Top shape: 128 16 75 75 (11520000)
I0826 16:36:06.692416  4567 net.cpp:165] Memory required for data: 1293352960
I0826 16:36:06.692422  4567 layer_factory.hpp:77] Creating layer conv2_1_relu
I0826 16:36:06.692428  4567 net.cpp:100] Creating Layer conv2_1_relu
I0826 16:36:06.692431  4567 net.cpp:434] conv2_1_relu <- conv2_1_bn
I0826 16:36:06.692436  4567 net.cpp:395] conv2_1_relu -> conv2_1_bn (in-place)
I0826 16:36:06.692445  4567 net.cpp:150] Setting up conv2_1_relu
I0826 16:36:06.692448  4567 net.cpp:157] Top shape: 128 16 75 75 (11520000)
I0826 16:36:06.692451  4567 net.cpp:165] Memory required for data: 1339432960
I0826 16:36:06.692453  4567 layer_factory.hpp:77] Creating layer conv3_1
I0826 16:36:06.692461  4567 net.cpp:100] Creating Layer conv3_1
I0826 16:36:06.692464  4567 net.cpp:434] conv3_1 <- conv2_1_bn
I0826 16:36:06.692471  4567 net.cpp:408] conv3_1 -> conv3_1
I0826 16:36:06.692813  4567 net.cpp:150] Setting up conv3_1
I0826 16:36:06.692828  4567 net.cpp:157] Top shape: 128 32 75 75 (23040000)
I0826 16:36:06.692833  4567 net.cpp:165] Memory required for data: 1431592960
I0826 16:36:06.692839  4567 layer_factory.hpp:77] Creating layer pool3
I0826 16:36:06.692848  4567 net.cpp:100] Creating Layer pool3
I0826 16:36:06.692853  4567 net.cpp:434] pool3 <- conv3_1
I0826 16:36:06.692860  4567 net.cpp:408] pool3 -> pool3
I0826 16:36:06.692903  4567 net.cpp:150] Setting up pool3
I0826 16:36:06.692910  4567 net.cpp:157] Top shape: 128 32 38 38 (5914624)
I0826 16:36:06.692914  4567 net.cpp:165] Memory required for data: 1455251456
I0826 16:36:06.692916  4567 layer_factory.hpp:77] Creating layer conv3_1_bn
I0826 16:36:06.692921  4567 net.cpp:100] Creating Layer conv3_1_bn
I0826 16:36:06.692924  4567 net.cpp:434] conv3_1_bn <- pool3
I0826 16:36:06.692939  4567 net.cpp:408] conv3_1_bn -> conv3_1_bn
I0826 16:36:06.693074  4567 net.cpp:150] Setting up conv3_1_bn
I0826 16:36:06.693080  4567 net.cpp:157] Top shape: 128 32 38 38 (5914624)
I0826 16:36:06.693084  4567 net.cpp:165] Memory required for data: 1478909952
I0826 16:36:06.693089  4567 layer_factory.hpp:77] Creating layer conv3_1_bn_scale
I0826 16:36:06.693097  4567 net.cpp:100] Creating Layer conv3_1_bn_scale
I0826 16:36:06.693100  4567 net.cpp:434] conv3_1_bn_scale <- conv3_1_bn
I0826 16:36:06.693104  4567 net.cpp:395] conv3_1_bn_scale -> conv3_1_bn (in-place)
I0826 16:36:06.693128  4567 layer_factory.hpp:77] Creating layer conv3_1_bn_scale
I0826 16:36:06.693228  4567 net.cpp:150] Setting up conv3_1_bn_scale
I0826 16:36:06.693238  4567 net.cpp:157] Top shape: 128 32 38 38 (5914624)
I0826 16:36:06.693243  4567 net.cpp:165] Memory required for data: 1502568448
I0826 16:36:06.693256  4567 layer_factory.hpp:77] Creating layer conv3_1_relu
I0826 16:36:06.693265  4567 net.cpp:100] Creating Layer conv3_1_relu
I0826 16:36:06.693269  4567 net.cpp:434] conv3_1_relu <- conv3_1_bn
I0826 16:36:06.693275  4567 net.cpp:395] conv3_1_relu -> conv3_1_bn (in-place)
I0826 16:36:06.693282  4567 net.cpp:150] Setting up conv3_1_relu
I0826 16:36:06.693289  4567 net.cpp:157] Top shape: 128 32 38 38 (5914624)
I0826 16:36:06.693291  4567 net.cpp:165] Memory required for data: 1526226944
I0826 16:36:06.693295  4567 layer_factory.hpp:77] Creating layer conv4_1
I0826 16:36:06.693305  4567 net.cpp:100] Creating Layer conv4_1
I0826 16:36:06.693310  4567 net.cpp:434] conv4_1 <- conv3_1_bn
I0826 16:36:06.693317  4567 net.cpp:408] conv4_1 -> conv4_1
I0826 16:36:06.693886  4567 net.cpp:150] Setting up conv4_1
I0826 16:36:06.693897  4567 net.cpp:157] Top shape: 128 64 38 38 (11829248)
I0826 16:36:06.693899  4567 net.cpp:165] Memory required for data: 1573543936
I0826 16:36:06.693903  4567 layer_factory.hpp:77] Creating layer pool4
I0826 16:36:06.693909  4567 net.cpp:100] Creating Layer pool4
I0826 16:36:06.693912  4567 net.cpp:434] pool4 <- conv4_1
I0826 16:36:06.693917  4567 net.cpp:408] pool4 -> pool4
I0826 16:36:06.693943  4567 net.cpp:150] Setting up pool4
I0826 16:36:06.693950  4567 net.cpp:157] Top shape: 128 64 19 19 (2957312)
I0826 16:36:06.693953  4567 net.cpp:165] Memory required for data: 1585373184
I0826 16:36:06.693955  4567 layer_factory.hpp:77] Creating layer conv4_1_bn
I0826 16:36:06.693961  4567 net.cpp:100] Creating Layer conv4_1_bn
I0826 16:36:06.693964  4567 net.cpp:434] conv4_1_bn <- pool4
I0826 16:36:06.693969  4567 net.cpp:408] conv4_1_bn -> conv4_1_bn
I0826 16:36:06.694528  4567 net.cpp:150] Setting up conv4_1_bn
I0826 16:36:06.694540  4567 net.cpp:157] Top shape: 128 64 19 19 (2957312)
I0826 16:36:06.694542  4567 net.cpp:165] Memory required for data: 1597202432
I0826 16:36:06.694550  4567 layer_factory.hpp:77] Creating layer conv4_1_bn_scale
I0826 16:36:06.694555  4567 net.cpp:100] Creating Layer conv4_1_bn_scale
I0826 16:36:06.694558  4567 net.cpp:434] conv4_1_bn_scale <- conv4_1_bn
I0826 16:36:06.694563  4567 net.cpp:395] conv4_1_bn_scale -> conv4_1_bn (in-place)
I0826 16:36:06.694591  4567 layer_factory.hpp:77] Creating layer conv4_1_bn_scale
I0826 16:36:06.694667  4567 net.cpp:150] Setting up conv4_1_bn_scale
I0826 16:36:06.694672  4567 net.cpp:157] Top shape: 128 64 19 19 (2957312)
I0826 16:36:06.694675  4567 net.cpp:165] Memory required for data: 1609031680
I0826 16:36:06.694680  4567 layer_factory.hpp:77] Creating layer conv4_1_relu
I0826 16:36:06.694685  4567 net.cpp:100] Creating Layer conv4_1_relu
I0826 16:36:06.694687  4567 net.cpp:434] conv4_1_relu <- conv4_1_bn
I0826 16:36:06.694692  4567 net.cpp:395] conv4_1_relu -> conv4_1_bn (in-place)
I0826 16:36:06.694697  4567 net.cpp:150] Setting up conv4_1_relu
I0826 16:36:06.694701  4567 net.cpp:157] Top shape: 128 64 19 19 (2957312)
I0826 16:36:06.694703  4567 net.cpp:165] Memory required for data: 1620860928
I0826 16:36:06.694706  4567 layer_factory.hpp:77] Creating layer conv5_1
I0826 16:36:06.694715  4567 net.cpp:100] Creating Layer conv5_1
I0826 16:36:06.694717  4567 net.cpp:434] conv5_1 <- conv4_1_bn
I0826 16:36:06.694736  4567 net.cpp:408] conv5_1 -> conv5_1
I0826 16:36:06.695667  4567 net.cpp:150] Setting up conv5_1
I0826 16:36:06.695675  4567 net.cpp:157] Top shape: 128 64 17 17 (2367488)
I0826 16:36:06.695678  4567 net.cpp:165] Memory required for data: 1630330880
I0826 16:36:06.695683  4567 layer_factory.hpp:77] Creating layer conv5_1_bn
I0826 16:36:06.695688  4567 net.cpp:100] Creating Layer conv5_1_bn
I0826 16:36:06.695690  4567 net.cpp:434] conv5_1_bn <- conv5_1
I0826 16:36:06.695695  4567 net.cpp:408] conv5_1_bn -> conv5_1_bn
I0826 16:36:06.695828  4567 net.cpp:150] Setting up conv5_1_bn
I0826 16:36:06.695834  4567 net.cpp:157] Top shape: 128 64 17 17 (2367488)
I0826 16:36:06.695837  4567 net.cpp:165] Memory required for data: 1639800832
I0826 16:36:06.695842  4567 layer_factory.hpp:77] Creating layer conv5_1_bn_scale
I0826 16:36:06.695847  4567 net.cpp:100] Creating Layer conv5_1_bn_scale
I0826 16:36:06.695850  4567 net.cpp:434] conv5_1_bn_scale <- conv5_1_bn
I0826 16:36:06.695854  4567 net.cpp:395] conv5_1_bn_scale -> conv5_1_bn (in-place)
I0826 16:36:06.695879  4567 layer_factory.hpp:77] Creating layer conv5_1_bn_scale
I0826 16:36:06.695960  4567 net.cpp:150] Setting up conv5_1_bn_scale
I0826 16:36:06.695966  4567 net.cpp:157] Top shape: 128 64 17 17 (2367488)
I0826 16:36:06.695967  4567 net.cpp:165] Memory required for data: 1649270784
I0826 16:36:06.695972  4567 layer_factory.hpp:77] Creating layer conv5_1_relu
I0826 16:36:06.695977  4567 net.cpp:100] Creating Layer conv5_1_relu
I0826 16:36:06.695979  4567 net.cpp:434] conv5_1_relu <- conv5_1_bn
I0826 16:36:06.695984  4567 net.cpp:395] conv5_1_relu -> conv5_1_bn (in-place)
I0826 16:36:06.695989  4567 net.cpp:150] Setting up conv5_1_relu
I0826 16:36:06.695992  4567 net.cpp:157] Top shape: 128 64 17 17 (2367488)
I0826 16:36:06.695996  4567 net.cpp:165] Memory required for data: 1658740736
I0826 16:36:06.695997  4567 layer_factory.hpp:77] Creating layer conv6_1
I0826 16:36:06.696004  4567 net.cpp:100] Creating Layer conv6_1
I0826 16:36:06.696007  4567 net.cpp:434] conv6_1 <- conv5_1_bn
I0826 16:36:06.696012  4567 net.cpp:408] conv6_1 -> conv6_1
I0826 16:36:06.696914  4567 net.cpp:150] Setting up conv6_1
I0826 16:36:06.696921  4567 net.cpp:157] Top shape: 128 64 15 15 (1843200)
I0826 16:36:06.696923  4567 net.cpp:165] Memory required for data: 1666113536
I0826 16:36:06.696928  4567 layer_factory.hpp:77] Creating layer conv6_1_bn
I0826 16:36:06.696933  4567 net.cpp:100] Creating Layer conv6_1_bn
I0826 16:36:06.696936  4567 net.cpp:434] conv6_1_bn <- conv6_1
I0826 16:36:06.696939  4567 net.cpp:408] conv6_1_bn -> conv6_1_bn
I0826 16:36:06.697064  4567 net.cpp:150] Setting up conv6_1_bn
I0826 16:36:06.697070  4567 net.cpp:157] Top shape: 128 64 15 15 (1843200)
I0826 16:36:06.697072  4567 net.cpp:165] Memory required for data: 1673486336
I0826 16:36:06.697084  4567 layer_factory.hpp:77] Creating layer conv6_1_bn_scale
I0826 16:36:06.697089  4567 net.cpp:100] Creating Layer conv6_1_bn_scale
I0826 16:36:06.697091  4567 net.cpp:434] conv6_1_bn_scale <- conv6_1_bn
I0826 16:36:06.697096  4567 net.cpp:395] conv6_1_bn_scale -> conv6_1_bn (in-place)
I0826 16:36:06.697119  4567 layer_factory.hpp:77] Creating layer conv6_1_bn_scale
I0826 16:36:06.697192  4567 net.cpp:150] Setting up conv6_1_bn_scale
I0826 16:36:06.697197  4567 net.cpp:157] Top shape: 128 64 15 15 (1843200)
I0826 16:36:06.697201  4567 net.cpp:165] Memory required for data: 1680859136
I0826 16:36:06.697204  4567 layer_factory.hpp:77] Creating layer conv6_1_relu
I0826 16:36:06.697209  4567 net.cpp:100] Creating Layer conv6_1_relu
I0826 16:36:06.697212  4567 net.cpp:434] conv6_1_relu <- conv6_1_bn
I0826 16:36:06.697216  4567 net.cpp:395] conv6_1_relu -> conv6_1_bn (in-place)
I0826 16:36:06.697221  4567 net.cpp:150] Setting up conv6_1_relu
I0826 16:36:06.697224  4567 net.cpp:157] Top shape: 128 64 15 15 (1843200)
I0826 16:36:06.697227  4567 net.cpp:165] Memory required for data: 1688231936
I0826 16:36:06.697229  4567 layer_factory.hpp:77] Creating layer conv7_1
I0826 16:36:06.697243  4567 net.cpp:100] Creating Layer conv7_1
I0826 16:36:06.697252  4567 net.cpp:434] conv7_1 <- conv6_1_bn
I0826 16:36:06.697257  4567 net.cpp:408] conv7_1 -> conv7_1
I0826 16:36:06.699692  4567 net.cpp:150] Setting up conv7_1
I0826 16:36:06.699717  4567 net.cpp:157] Top shape: 128 128 13 13 (2768896)
I0826 16:36:06.699719  4567 net.cpp:165] Memory required for data: 1699307520
I0826 16:36:06.699725  4567 layer_factory.hpp:77] Creating layer conv7_1_bn
I0826 16:36:06.699738  4567 net.cpp:100] Creating Layer conv7_1_bn
I0826 16:36:06.699741  4567 net.cpp:434] conv7_1_bn <- conv7_1
I0826 16:36:06.699748  4567 net.cpp:408] conv7_1_bn -> conv7_1_bn
I0826 16:36:06.699882  4567 net.cpp:150] Setting up conv7_1_bn
I0826 16:36:06.699888  4567 net.cpp:157] Top shape: 128 128 13 13 (2768896)
I0826 16:36:06.699892  4567 net.cpp:165] Memory required for data: 1710383104
I0826 16:36:06.699898  4567 layer_factory.hpp:77] Creating layer conv7_1_bn_scale
I0826 16:36:06.699903  4567 net.cpp:100] Creating Layer conv7_1_bn_scale
I0826 16:36:06.699908  4567 net.cpp:434] conv7_1_bn_scale <- conv7_1_bn
I0826 16:36:06.699911  4567 net.cpp:395] conv7_1_bn_scale -> conv7_1_bn (in-place)
I0826 16:36:06.699937  4567 layer_factory.hpp:77] Creating layer conv7_1_bn_scale
I0826 16:36:06.700008  4567 net.cpp:150] Setting up conv7_1_bn_scale
I0826 16:36:06.700013  4567 net.cpp:157] Top shape: 128 128 13 13 (2768896)
I0826 16:36:06.700016  4567 net.cpp:165] Memory required for data: 1721458688
I0826 16:36:06.700021  4567 layer_factory.hpp:77] Creating layer conv7_1_relu
I0826 16:36:06.700026  4567 net.cpp:100] Creating Layer conv7_1_relu
I0826 16:36:06.700028  4567 net.cpp:434] conv7_1_relu <- conv7_1_bn
I0826 16:36:06.700031  4567 net.cpp:395] conv7_1_relu -> conv7_1_bn (in-place)
I0826 16:36:06.700037  4567 net.cpp:150] Setting up conv7_1_relu
I0826 16:36:06.700040  4567 net.cpp:157] Top shape: 128 128 13 13 (2768896)
I0826 16:36:06.700042  4567 net.cpp:165] Memory required for data: 1732534272
I0826 16:36:06.700045  4567 layer_factory.hpp:77] Creating layer score
I0826 16:36:06.700055  4567 net.cpp:100] Creating Layer score
I0826 16:36:06.700058  4567 net.cpp:434] score <- conv7_1_bn
I0826 16:36:06.700062  4567 net.cpp:408] score -> score
I0826 16:36:06.700243  4567 net.cpp:150] Setting up score
I0826 16:36:06.700253  4567 net.cpp:157] Top shape: 128 4 13 13 (86528)
I0826 16:36:06.700255  4567 net.cpp:165] Memory required for data: 1732880384
I0826 16:36:06.700260  4567 layer_factory.hpp:77] Creating layer upscore
I0826 16:36:06.700268  4567 net.cpp:100] Creating Layer upscore
I0826 16:36:06.700270  4567 net.cpp:434] upscore <- score
I0826 16:36:06.700275  4567 net.cpp:408] upscore -> upscore
I0826 16:36:06.700790  4567 net.cpp:150] Setting up upscore
I0826 16:36:06.700801  4567 net.cpp:157] Top shape: 128 4 224 224 (25690112)
I0826 16:36:06.700804  4567 net.cpp:165] Memory required for data: 1835640832
I0826 16:36:06.700809  4567 layer_factory.hpp:77] Creating layer cropscore
I0826 16:36:06.700815  4567 net.cpp:100] Creating Layer cropscore
I0826 16:36:06.700819  4567 net.cpp:434] cropscore <- upscore
I0826 16:36:06.700822  4567 net.cpp:434] cropscore <- image_data_0_split_1
I0826 16:36:06.700827  4567 net.cpp:408] cropscore -> cropscore
I0826 16:36:06.700855  4567 net.cpp:150] Setting up cropscore
I0826 16:36:06.700862  4567 net.cpp:157] Top shape: 128 4 200 200 (20480000)
I0826 16:36:06.700866  4567 net.cpp:165] Memory required for data: 1917560832
I0826 16:36:06.700871  4567 layer_factory.hpp:77] Creating layer cropscore_cropscore_0_split
I0826 16:36:06.700878  4567 net.cpp:100] Creating Layer cropscore_cropscore_0_split
I0826 16:36:06.700882  4567 net.cpp:434] cropscore_cropscore_0_split <- cropscore
I0826 16:36:06.700891  4567 net.cpp:408] cropscore_cropscore_0_split -> cropscore_cropscore_0_split_0
I0826 16:36:06.700897  4567 net.cpp:408] cropscore_cropscore_0_split -> cropscore_cropscore_0_split_1
I0826 16:36:06.700923  4567 net.cpp:150] Setting up cropscore_cropscore_0_split
I0826 16:36:06.700928  4567 net.cpp:157] Top shape: 128 4 200 200 (20480000)
I0826 16:36:06.700939  4567 net.cpp:157] Top shape: 128 4 200 200 (20480000)
I0826 16:36:06.700947  4567 net.cpp:165] Memory required for data: 2081400832
I0826 16:36:06.700950  4567 layer_factory.hpp:77] Creating layer loss
I0826 16:36:06.700958  4567 net.cpp:100] Creating Layer loss
I0826 16:36:06.700960  4567 net.cpp:434] loss <- cropscore_cropscore_0_split_0
I0826 16:36:06.700963  4567 net.cpp:434] loss <- label_data_1_split_0
I0826 16:36:06.700968  4567 net.cpp:408] loss -> loss
I0826 16:36:06.700978  4567 layer_factory.hpp:77] Creating layer loss
I0826 16:36:06.737442  4567 net.cpp:150] Setting up loss
I0826 16:36:06.737475  4567 net.cpp:157] Top shape: (1)
I0826 16:36:06.737480  4567 net.cpp:160]     with loss weight 1
I0826 16:36:06.737506  4567 net.cpp:165] Memory required for data: 2081400836
I0826 16:36:06.737511  4567 layer_factory.hpp:77] Creating layer accuracy
I0826 16:36:06.737525  4567 net.cpp:100] Creating Layer accuracy
I0826 16:36:06.737530  4567 net.cpp:434] accuracy <- cropscore_cropscore_0_split_1
I0826 16:36:06.737535  4567 net.cpp:434] accuracy <- label_data_1_split_1
I0826 16:36:06.737540  4567 net.cpp:408] accuracy -> accuracy
I0826 16:36:06.737550  4567 net.cpp:150] Setting up accuracy
I0826 16:36:06.737555  4567 net.cpp:157] Top shape: (1)
I0826 16:36:06.737557  4567 net.cpp:165] Memory required for data: 2081400840
I0826 16:36:06.737560  4567 net.cpp:228] accuracy does not need backward computation.
I0826 16:36:06.737563  4567 net.cpp:226] loss needs backward computation.
I0826 16:36:06.737566  4567 net.cpp:226] cropscore_cropscore_0_split needs backward computation.
I0826 16:36:06.737571  4567 net.cpp:226] cropscore needs backward computation.
I0826 16:36:06.737573  4567 net.cpp:226] upscore needs backward computation.
I0826 16:36:06.737576  4567 net.cpp:226] score needs backward computation.
I0826 16:36:06.737579  4567 net.cpp:226] conv7_1_relu needs backward computation.
I0826 16:36:06.737582  4567 net.cpp:226] conv7_1_bn_scale needs backward computation.
I0826 16:36:06.737584  4567 net.cpp:226] conv7_1_bn needs backward computation.
I0826 16:36:06.737587  4567 net.cpp:226] conv7_1 needs backward computation.
I0826 16:36:06.737591  4567 net.cpp:226] conv6_1_relu needs backward computation.
I0826 16:36:06.737593  4567 net.cpp:226] conv6_1_bn_scale needs backward computation.
I0826 16:36:06.737596  4567 net.cpp:226] conv6_1_bn needs backward computation.
I0826 16:36:06.737598  4567 net.cpp:226] conv6_1 needs backward computation.
I0826 16:36:06.737602  4567 net.cpp:226] conv5_1_relu needs backward computation.
I0826 16:36:06.737604  4567 net.cpp:226] conv5_1_bn_scale needs backward computation.
I0826 16:36:06.737607  4567 net.cpp:226] conv5_1_bn needs backward computation.
I0826 16:36:06.737610  4567 net.cpp:226] conv5_1 needs backward computation.
I0826 16:36:06.737613  4567 net.cpp:226] conv4_1_relu needs backward computation.
I0826 16:36:06.737615  4567 net.cpp:226] conv4_1_bn_scale needs backward computation.
I0826 16:36:06.737618  4567 net.cpp:226] conv4_1_bn needs backward computation.
I0826 16:36:06.737620  4567 net.cpp:226] pool4 needs backward computation.
I0826 16:36:06.737623  4567 net.cpp:226] conv4_1 needs backward computation.
I0826 16:36:06.737627  4567 net.cpp:226] conv3_1_relu needs backward computation.
I0826 16:36:06.737629  4567 net.cpp:226] conv3_1_bn_scale needs backward computation.
I0826 16:36:06.737632  4567 net.cpp:226] conv3_1_bn needs backward computation.
I0826 16:36:06.737637  4567 net.cpp:226] pool3 needs backward computation.
I0826 16:36:06.737639  4567 net.cpp:226] conv3_1 needs backward computation.
I0826 16:36:06.737642  4567 net.cpp:226] conv2_1_relu needs backward computation.
I0826 16:36:06.737644  4567 net.cpp:226] conv2_1_bn_scale needs backward computation.
I0826 16:36:06.737648  4567 net.cpp:226] conv2_1_bn needs backward computation.
I0826 16:36:06.737649  4567 net.cpp:226] pool2 needs backward computation.
I0826 16:36:06.737653  4567 net.cpp:226] conv2_1 needs backward computation.
I0826 16:36:06.737655  4567 net.cpp:226] conv1_1_relu needs backward computation.
I0826 16:36:06.737666  4567 net.cpp:226] conv1_1_bn_scale needs backward computation.
I0826 16:36:06.737676  4567 net.cpp:226] conv1_1_bn needs backward computation.
I0826 16:36:06.737679  4567 net.cpp:226] pool1 needs backward computation.
I0826 16:36:06.737682  4567 net.cpp:226] conv1_1 needs backward computation.
I0826 16:36:06.737686  4567 net.cpp:228] label_data_1_split does not need backward computation.
I0826 16:36:06.737689  4567 net.cpp:228] image_data_0_split does not need backward computation.
I0826 16:36:06.737692  4567 net.cpp:228] data does not need backward computation.
I0826 16:36:06.737695  4567 net.cpp:270] This network produces output accuracy
I0826 16:36:06.737697  4567 net.cpp:270] This network produces output loss
I0826 16:36:06.737716  4567 net.cpp:283] Network initialization done.
I0826 16:36:06.738294  4567 solver.cpp:181] Creating test net (#0) specified by net file: portrait_train_test_one_stage.prototxt3
I0826 16:36:06.738335  4567 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0826 16:36:06.738495  4567 net.cpp:58] Initializing net from parameters: 
name: "segmentation"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "SegData"
  top: "image"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 200
  }
  data_param {
    source: "/raid/xuehan/segmentation_test_split"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "image"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 50
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1_1_bn"
  type: "BatchNorm"
  bottom: "pool1"
  top: "conv1_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv1_1_bn_scale"
  type: "Scale"
  bottom: "conv1_1_bn"
  top: "conv1_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_1_relu"
  type: "ReLU"
  bottom: "conv1_1_bn"
  top: "conv1_1_bn"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "conv1_1_bn"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_1"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1_bn"
  type: "BatchNorm"
  bottom: "pool2"
  top: "conv2_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv2_1_bn_scale"
  type: "Scale"
  bottom: "conv2_1_bn"
  top: "conv2_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1_relu"
  type: "ReLU"
  bottom: "conv2_1_bn"
  top: "conv2_1_bn"
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv2_1_bn"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_1"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1_bn"
  type: "BatchNorm"
  bottom: "pool3"
  top: "conv3_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv3_1_bn_scale"
  type: "Scale"
  bottom: "conv3_1_bn"
  top: "conv3_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1_relu"
  type: "ReLU"
  bottom: "conv3_1_bn"
  top: "conv3_1_bn"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv3_1_bn"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_1"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1_bn"
  type: "BatchNorm"
  bottom: "pool4"
  top: "conv4_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv4_1_bn_scale"
  type: "Scale"
  bottom: "conv4_1_bn"
  top: "conv4_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1_relu"
  type: "ReLU"
  bottom: "conv4_1_bn"
  top: "conv4_1_bn"
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "conv4_1_bn"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv5_1_bn"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv5_1_bn_scale"
  type: "Scale"
  bottom: "conv5_1_bn"
  top: "conv5_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_1_relu"
  type: "ReLU"
  bottom: "conv5_1_bn"
  top: "conv5_1_bn"
}
layer {
  name: "conv6_1"
  type: "Convolution"
  bottom: "conv5_1_bn"
  top: "conv6_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv6_1_bn"
  type: "BatchNorm"
  bottom: "conv6_1"
  top: "conv6_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv6_1_bn_scale"
  type: "Scale"
  bottom: "conv6_1_bn"
  top: "conv6_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv6_1_relu"
  type: "ReLU"
  bottom: "conv6_1_bn"
  top: "conv6_1_bn"
}
layer {
  name: "conv7_1"
  type: "Convolution"
  bottom: "conv6_1_bn"
  top: "conv7_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv7_1_bn"
  type: "BatchNorm"
  bottom: "conv7_1"
  top: "conv7_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv7_1_bn_scale"
  type: "Scale"
  bottom: "conv7_1_bn"
  top: "conv7_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv7_1_relu"
  type: "ReLU"
  bottom: "conv7_1_bn"
  top: "conv7_1_bn"
}
layer {
  name: "score"
  type: "Convolution"
  bottom: "conv7_1_bn"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 4
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "upscore"
  type: "Deconvolution"
  bottom: "score"
  top: "upscore"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 4
    bias_term: false
    pad: 0
    kernel_size: 32
    stride: 16
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "cropscore"
  type: "Crop"
  bottom: "upscore"
  bottom: "image"
  top: "cropscore"
  crop_param {
    axis: 2
    offset: 12
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "cropscore"
  bottom: "label"
  top: "loss"
  loss_weight: 1
  loss_param {
    normalize: false
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "cropscore"
  bottom: "label"
  top: "accuracy"
}
I0826 16:36:06.738615  4567 layer_factory.hpp:77] Creating layer data
I0826 16:36:06.738834  4567 net.cpp:100] Creating Layer data
I0826 16:36:06.738842  4567 net.cpp:408] data -> image
I0826 16:36:06.738849  4567 net.cpp:408] data -> label
I0826 16:36:06.739887  4573 db_lmdb.cpp:35] Opened lmdb /raid/xuehan/segmentation_test_split
I0826 16:36:06.740022  4567 seg_data_layer.cpp:38] 200 200 4
I0826 16:36:06.740119  4567 seg_data_layer.cpp:51] output data size: 64,3,200,200
I0826 16:36:06.740171  4567 seg_data_layer.cpp:63] output label size: 64,1,200,200
I0826 16:36:06.808511  4567 net.cpp:150] Setting up data
I0826 16:36:06.808537  4567 net.cpp:157] Top shape: 64 3 200 200 (7680000)
I0826 16:36:06.808542  4567 net.cpp:157] Top shape: 64 1 200 200 (2560000)
I0826 16:36:06.808545  4567 net.cpp:165] Memory required for data: 40960000
I0826 16:36:06.808550  4567 layer_factory.hpp:77] Creating layer image_data_0_split
I0826 16:36:06.808562  4567 net.cpp:100] Creating Layer image_data_0_split
I0826 16:36:06.808564  4567 net.cpp:434] image_data_0_split <- image
I0826 16:36:06.808573  4567 net.cpp:408] image_data_0_split -> image_data_0_split_0
I0826 16:36:06.808580  4567 net.cpp:408] image_data_0_split -> image_data_0_split_1
I0826 16:36:06.808653  4567 net.cpp:150] Setting up image_data_0_split
I0826 16:36:06.808661  4567 net.cpp:157] Top shape: 64 3 200 200 (7680000)
I0826 16:36:06.808665  4567 net.cpp:157] Top shape: 64 3 200 200 (7680000)
I0826 16:36:06.808666  4567 net.cpp:165] Memory required for data: 102400000
I0826 16:36:06.808670  4567 layer_factory.hpp:77] Creating layer label_data_1_split
I0826 16:36:06.808677  4567 net.cpp:100] Creating Layer label_data_1_split
I0826 16:36:06.808681  4567 net.cpp:434] label_data_1_split <- label
I0826 16:36:06.808686  4567 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0826 16:36:06.808691  4567 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0826 16:36:06.808717  4567 net.cpp:150] Setting up label_data_1_split
I0826 16:36:06.808722  4567 net.cpp:157] Top shape: 64 1 200 200 (2560000)
I0826 16:36:06.808727  4567 net.cpp:157] Top shape: 64 1 200 200 (2560000)
I0826 16:36:06.808728  4567 net.cpp:165] Memory required for data: 122880000
I0826 16:36:06.808732  4567 layer_factory.hpp:77] Creating layer conv1_1
I0826 16:36:06.808740  4567 net.cpp:100] Creating Layer conv1_1
I0826 16:36:06.808743  4567 net.cpp:434] conv1_1 <- image_data_0_split_0
I0826 16:36:06.808748  4567 net.cpp:408] conv1_1 -> conv1_1
I0826 16:36:06.808897  4567 net.cpp:150] Setting up conv1_1
I0826 16:36:06.808902  4567 net.cpp:157] Top shape: 64 8 298 298 (45467648)
I0826 16:36:06.808904  4567 net.cpp:165] Memory required for data: 304750592
I0826 16:36:06.808912  4567 layer_factory.hpp:77] Creating layer pool1
I0826 16:36:06.808917  4567 net.cpp:100] Creating Layer pool1
I0826 16:36:06.808920  4567 net.cpp:434] pool1 <- conv1_1
I0826 16:36:06.808923  4567 net.cpp:408] pool1 -> pool1
I0826 16:36:06.808949  4567 net.cpp:150] Setting up pool1
I0826 16:36:06.808954  4567 net.cpp:157] Top shape: 64 8 149 149 (11366912)
I0826 16:36:06.808956  4567 net.cpp:165] Memory required for data: 350218240
I0826 16:36:06.808959  4567 layer_factory.hpp:77] Creating layer conv1_1_bn
I0826 16:36:06.808964  4567 net.cpp:100] Creating Layer conv1_1_bn
I0826 16:36:06.808967  4567 net.cpp:434] conv1_1_bn <- pool1
I0826 16:36:06.808972  4567 net.cpp:408] conv1_1_bn -> conv1_1_bn
I0826 16:36:06.809129  4567 net.cpp:150] Setting up conv1_1_bn
I0826 16:36:06.809136  4567 net.cpp:157] Top shape: 64 8 149 149 (11366912)
I0826 16:36:06.809139  4567 net.cpp:165] Memory required for data: 395685888
I0826 16:36:06.809149  4567 layer_factory.hpp:77] Creating layer conv1_1_bn_scale
I0826 16:36:06.809154  4567 net.cpp:100] Creating Layer conv1_1_bn_scale
I0826 16:36:06.809157  4567 net.cpp:434] conv1_1_bn_scale <- conv1_1_bn
I0826 16:36:06.809160  4567 net.cpp:395] conv1_1_bn_scale -> conv1_1_bn (in-place)
I0826 16:36:06.809190  4567 layer_factory.hpp:77] Creating layer conv1_1_bn_scale
I0826 16:36:06.809298  4567 net.cpp:150] Setting up conv1_1_bn_scale
I0826 16:36:06.809310  4567 net.cpp:157] Top shape: 64 8 149 149 (11366912)
I0826 16:36:06.809319  4567 net.cpp:165] Memory required for data: 441153536
I0826 16:36:06.809325  4567 layer_factory.hpp:77] Creating layer conv1_1_relu
I0826 16:36:06.809332  4567 net.cpp:100] Creating Layer conv1_1_relu
I0826 16:36:06.809335  4567 net.cpp:434] conv1_1_relu <- conv1_1_bn
I0826 16:36:06.809340  4567 net.cpp:395] conv1_1_relu -> conv1_1_bn (in-place)
I0826 16:36:06.809345  4567 net.cpp:150] Setting up conv1_1_relu
I0826 16:36:06.809348  4567 net.cpp:157] Top shape: 64 8 149 149 (11366912)
I0826 16:36:06.809350  4567 net.cpp:165] Memory required for data: 486621184
I0826 16:36:06.809353  4567 layer_factory.hpp:77] Creating layer conv2_1
I0826 16:36:06.809361  4567 net.cpp:100] Creating Layer conv2_1
I0826 16:36:06.809363  4567 net.cpp:434] conv2_1 <- conv1_1_bn
I0826 16:36:06.809367  4567 net.cpp:408] conv2_1 -> conv2_1
I0826 16:36:06.809522  4567 net.cpp:150] Setting up conv2_1
I0826 16:36:06.809528  4567 net.cpp:157] Top shape: 64 16 149 149 (22733824)
I0826 16:36:06.809531  4567 net.cpp:165] Memory required for data: 577556480
I0826 16:36:06.809535  4567 layer_factory.hpp:77] Creating layer pool2
I0826 16:36:06.809540  4567 net.cpp:100] Creating Layer pool2
I0826 16:36:06.809542  4567 net.cpp:434] pool2 <- conv2_1
I0826 16:36:06.809546  4567 net.cpp:408] pool2 -> pool2
I0826 16:36:06.809571  4567 net.cpp:150] Setting up pool2
I0826 16:36:06.809576  4567 net.cpp:157] Top shape: 64 16 75 75 (5760000)
I0826 16:36:06.809577  4567 net.cpp:165] Memory required for data: 600596480
I0826 16:36:06.809581  4567 layer_factory.hpp:77] Creating layer conv2_1_bn
I0826 16:36:06.809586  4567 net.cpp:100] Creating Layer conv2_1_bn
I0826 16:36:06.809587  4567 net.cpp:434] conv2_1_bn <- pool2
I0826 16:36:06.809592  4567 net.cpp:408] conv2_1_bn -> conv2_1_bn
I0826 16:36:06.809727  4567 net.cpp:150] Setting up conv2_1_bn
I0826 16:36:06.809732  4567 net.cpp:157] Top shape: 64 16 75 75 (5760000)
I0826 16:36:06.809736  4567 net.cpp:165] Memory required for data: 623636480
I0826 16:36:06.809744  4567 layer_factory.hpp:77] Creating layer conv2_1_bn_scale
I0826 16:36:06.809749  4567 net.cpp:100] Creating Layer conv2_1_bn_scale
I0826 16:36:06.809752  4567 net.cpp:434] conv2_1_bn_scale <- conv2_1_bn
I0826 16:36:06.809756  4567 net.cpp:395] conv2_1_bn_scale -> conv2_1_bn (in-place)
I0826 16:36:06.809783  4567 layer_factory.hpp:77] Creating layer conv2_1_bn_scale
I0826 16:36:06.809928  4567 net.cpp:150] Setting up conv2_1_bn_scale
I0826 16:36:06.809936  4567 net.cpp:157] Top shape: 64 16 75 75 (5760000)
I0826 16:36:06.809938  4567 net.cpp:165] Memory required for data: 646676480
I0826 16:36:06.809943  4567 layer_factory.hpp:77] Creating layer conv2_1_relu
I0826 16:36:06.809949  4567 net.cpp:100] Creating Layer conv2_1_relu
I0826 16:36:06.809952  4567 net.cpp:434] conv2_1_relu <- conv2_1_bn
I0826 16:36:06.809955  4567 net.cpp:395] conv2_1_relu -> conv2_1_bn (in-place)
I0826 16:36:06.809960  4567 net.cpp:150] Setting up conv2_1_relu
I0826 16:36:06.809963  4567 net.cpp:157] Top shape: 64 16 75 75 (5760000)
I0826 16:36:06.809967  4567 net.cpp:165] Memory required for data: 669716480
I0826 16:36:06.809968  4567 layer_factory.hpp:77] Creating layer conv3_1
I0826 16:36:06.809976  4567 net.cpp:100] Creating Layer conv3_1
I0826 16:36:06.809978  4567 net.cpp:434] conv3_1 <- conv2_1_bn
I0826 16:36:06.809983  4567 net.cpp:408] conv3_1 -> conv3_1
I0826 16:36:06.815151  4567 net.cpp:150] Setting up conv3_1
I0826 16:36:06.815170  4567 net.cpp:157] Top shape: 64 32 75 75 (11520000)
I0826 16:36:06.815174  4567 net.cpp:165] Memory required for data: 715796480
I0826 16:36:06.815181  4567 layer_factory.hpp:77] Creating layer pool3
I0826 16:36:06.815191  4567 net.cpp:100] Creating Layer pool3
I0826 16:36:06.815196  4567 net.cpp:434] pool3 <- conv3_1
I0826 16:36:06.815204  4567 net.cpp:408] pool3 -> pool3
I0826 16:36:06.815251  4567 net.cpp:150] Setting up pool3
I0826 16:36:06.815263  4567 net.cpp:157] Top shape: 64 32 38 38 (2957312)
I0826 16:36:06.815268  4567 net.cpp:165] Memory required for data: 727625728
I0826 16:36:06.815286  4567 layer_factory.hpp:77] Creating layer conv3_1_bn
I0826 16:36:06.815295  4567 net.cpp:100] Creating Layer conv3_1_bn
I0826 16:36:06.815301  4567 net.cpp:434] conv3_1_bn <- pool3
I0826 16:36:06.815309  4567 net.cpp:408] conv3_1_bn -> conv3_1_bn
I0826 16:36:06.815488  4567 net.cpp:150] Setting up conv3_1_bn
I0826 16:36:06.815496  4567 net.cpp:157] Top shape: 64 32 38 38 (2957312)
I0826 16:36:06.815498  4567 net.cpp:165] Memory required for data: 739454976
I0826 16:36:06.815505  4567 layer_factory.hpp:77] Creating layer conv3_1_bn_scale
I0826 16:36:06.815512  4567 net.cpp:100] Creating Layer conv3_1_bn_scale
I0826 16:36:06.815515  4567 net.cpp:434] conv3_1_bn_scale <- conv3_1_bn
I0826 16:36:06.815520  4567 net.cpp:395] conv3_1_bn_scale -> conv3_1_bn (in-place)
I0826 16:36:06.815549  4567 layer_factory.hpp:77] Creating layer conv3_1_bn_scale
I0826 16:36:06.815632  4567 net.cpp:150] Setting up conv3_1_bn_scale
I0826 16:36:06.815640  4567 net.cpp:157] Top shape: 64 32 38 38 (2957312)
I0826 16:36:06.815645  4567 net.cpp:165] Memory required for data: 751284224
I0826 16:36:06.815659  4567 layer_factory.hpp:77] Creating layer conv3_1_relu
I0826 16:36:06.815668  4567 net.cpp:100] Creating Layer conv3_1_relu
I0826 16:36:06.815675  4567 net.cpp:434] conv3_1_relu <- conv3_1_bn
I0826 16:36:06.815681  4567 net.cpp:395] conv3_1_relu -> conv3_1_bn (in-place)
I0826 16:36:06.815692  4567 net.cpp:150] Setting up conv3_1_relu
I0826 16:36:06.815702  4567 net.cpp:157] Top shape: 64 32 38 38 (2957312)
I0826 16:36:06.815708  4567 net.cpp:165] Memory required for data: 763113472
I0826 16:36:06.815713  4567 layer_factory.hpp:77] Creating layer conv4_1
I0826 16:36:06.815723  4567 net.cpp:100] Creating Layer conv4_1
I0826 16:36:06.815727  4567 net.cpp:434] conv4_1 <- conv3_1_bn
I0826 16:36:06.815732  4567 net.cpp:408] conv4_1 -> conv4_1
I0826 16:36:06.823088  4567 net.cpp:150] Setting up conv4_1
I0826 16:36:06.823113  4567 net.cpp:157] Top shape: 64 64 38 38 (5914624)
I0826 16:36:06.823117  4567 net.cpp:165] Memory required for data: 786771968
I0826 16:36:06.823122  4567 layer_factory.hpp:77] Creating layer pool4
I0826 16:36:06.823132  4567 net.cpp:100] Creating Layer pool4
I0826 16:36:06.823137  4567 net.cpp:434] pool4 <- conv4_1
I0826 16:36:06.823150  4567 net.cpp:408] pool4 -> pool4
I0826 16:36:06.823210  4567 net.cpp:150] Setting up pool4
I0826 16:36:06.823218  4567 net.cpp:157] Top shape: 64 64 19 19 (1478656)
I0826 16:36:06.823221  4567 net.cpp:165] Memory required for data: 792686592
I0826 16:36:06.823225  4567 layer_factory.hpp:77] Creating layer conv4_1_bn
I0826 16:36:06.823232  4567 net.cpp:100] Creating Layer conv4_1_bn
I0826 16:36:06.823235  4567 net.cpp:434] conv4_1_bn <- pool4
I0826 16:36:06.823240  4567 net.cpp:408] conv4_1_bn -> conv4_1_bn
I0826 16:36:06.823388  4567 net.cpp:150] Setting up conv4_1_bn
I0826 16:36:06.823395  4567 net.cpp:157] Top shape: 64 64 19 19 (1478656)
I0826 16:36:06.823397  4567 net.cpp:165] Memory required for data: 798601216
I0826 16:36:06.823403  4567 layer_factory.hpp:77] Creating layer conv4_1_bn_scale
I0826 16:36:06.823410  4567 net.cpp:100] Creating Layer conv4_1_bn_scale
I0826 16:36:06.823412  4567 net.cpp:434] conv4_1_bn_scale <- conv4_1_bn
I0826 16:36:06.823416  4567 net.cpp:395] conv4_1_bn_scale -> conv4_1_bn (in-place)
I0826 16:36:06.823448  4567 layer_factory.hpp:77] Creating layer conv4_1_bn_scale
I0826 16:36:06.823593  4567 net.cpp:150] Setting up conv4_1_bn_scale
I0826 16:36:06.823604  4567 net.cpp:157] Top shape: 64 64 19 19 (1478656)
I0826 16:36:06.823608  4567 net.cpp:165] Memory required for data: 804515840
I0826 16:36:06.823616  4567 layer_factory.hpp:77] Creating layer conv4_1_relu
I0826 16:36:06.823623  4567 net.cpp:100] Creating Layer conv4_1_relu
I0826 16:36:06.823628  4567 net.cpp:434] conv4_1_relu <- conv4_1_bn
I0826 16:36:06.823635  4567 net.cpp:395] conv4_1_relu -> conv4_1_bn (in-place)
I0826 16:36:06.823642  4567 net.cpp:150] Setting up conv4_1_relu
I0826 16:36:06.823648  4567 net.cpp:157] Top shape: 64 64 19 19 (1478656)
I0826 16:36:06.823662  4567 net.cpp:165] Memory required for data: 810430464
I0826 16:36:06.823678  4567 layer_factory.hpp:77] Creating layer conv5_1
I0826 16:36:06.823689  4567 net.cpp:100] Creating Layer conv5_1
I0826 16:36:06.823694  4567 net.cpp:434] conv5_1 <- conv4_1_bn
I0826 16:36:06.823700  4567 net.cpp:408] conv5_1 -> conv5_1
I0826 16:36:06.825726  4567 net.cpp:150] Setting up conv5_1
I0826 16:36:06.825752  4567 net.cpp:157] Top shape: 64 64 17 17 (1183744)
I0826 16:36:06.825757  4567 net.cpp:165] Memory required for data: 815165440
I0826 16:36:06.825764  4567 layer_factory.hpp:77] Creating layer conv5_1_bn
I0826 16:36:06.825775  4567 net.cpp:100] Creating Layer conv5_1_bn
I0826 16:36:06.825781  4567 net.cpp:434] conv5_1_bn <- conv5_1
I0826 16:36:06.825788  4567 net.cpp:408] conv5_1_bn -> conv5_1_bn
I0826 16:36:06.826027  4567 net.cpp:150] Setting up conv5_1_bn
I0826 16:36:06.826045  4567 net.cpp:157] Top shape: 64 64 17 17 (1183744)
I0826 16:36:06.826052  4567 net.cpp:165] Memory required for data: 819900416
I0826 16:36:06.826064  4567 layer_factory.hpp:77] Creating layer conv5_1_bn_scale
I0826 16:36:06.826077  4567 net.cpp:100] Creating Layer conv5_1_bn_scale
I0826 16:36:06.826086  4567 net.cpp:434] conv5_1_bn_scale <- conv5_1_bn
I0826 16:36:06.826097  4567 net.cpp:395] conv5_1_bn_scale -> conv5_1_bn (in-place)
I0826 16:36:06.826154  4567 layer_factory.hpp:77] Creating layer conv5_1_bn_scale
I0826 16:36:06.826329  4567 net.cpp:150] Setting up conv5_1_bn_scale
I0826 16:36:06.826339  4567 net.cpp:157] Top shape: 64 64 17 17 (1183744)
I0826 16:36:06.826340  4567 net.cpp:165] Memory required for data: 824635392
I0826 16:36:06.826346  4567 layer_factory.hpp:77] Creating layer conv5_1_relu
I0826 16:36:06.826351  4567 net.cpp:100] Creating Layer conv5_1_relu
I0826 16:36:06.826354  4567 net.cpp:434] conv5_1_relu <- conv5_1_bn
I0826 16:36:06.826359  4567 net.cpp:395] conv5_1_relu -> conv5_1_bn (in-place)
I0826 16:36:06.826364  4567 net.cpp:150] Setting up conv5_1_relu
I0826 16:36:06.826376  4567 net.cpp:157] Top shape: 64 64 17 17 (1183744)
I0826 16:36:06.826380  4567 net.cpp:165] Memory required for data: 829370368
I0826 16:36:06.826383  4567 layer_factory.hpp:77] Creating layer conv6_1
I0826 16:36:06.826391  4567 net.cpp:100] Creating Layer conv6_1
I0826 16:36:06.826395  4567 net.cpp:434] conv6_1 <- conv5_1_bn
I0826 16:36:06.826398  4567 net.cpp:408] conv6_1 -> conv6_1
I0826 16:36:06.827446  4567 net.cpp:150] Setting up conv6_1
I0826 16:36:06.827457  4567 net.cpp:157] Top shape: 64 64 15 15 (921600)
I0826 16:36:06.827460  4567 net.cpp:165] Memory required for data: 833056768
I0826 16:36:06.827464  4567 layer_factory.hpp:77] Creating layer conv6_1_bn
I0826 16:36:06.827469  4567 net.cpp:100] Creating Layer conv6_1_bn
I0826 16:36:06.827472  4567 net.cpp:434] conv6_1_bn <- conv6_1
I0826 16:36:06.827477  4567 net.cpp:408] conv6_1_bn -> conv6_1_bn
I0826 16:36:06.827623  4567 net.cpp:150] Setting up conv6_1_bn
I0826 16:36:06.827630  4567 net.cpp:157] Top shape: 64 64 15 15 (921600)
I0826 16:36:06.827632  4567 net.cpp:165] Memory required for data: 836743168
I0826 16:36:06.827652  4567 layer_factory.hpp:77] Creating layer conv6_1_bn_scale
I0826 16:36:06.827666  4567 net.cpp:100] Creating Layer conv6_1_bn_scale
I0826 16:36:06.827673  4567 net.cpp:434] conv6_1_bn_scale <- conv6_1_bn
I0826 16:36:06.827684  4567 net.cpp:395] conv6_1_bn_scale -> conv6_1_bn (in-place)
I0826 16:36:06.827723  4567 layer_factory.hpp:77] Creating layer conv6_1_bn_scale
I0826 16:36:06.827803  4567 net.cpp:150] Setting up conv6_1_bn_scale
I0826 16:36:06.827810  4567 net.cpp:157] Top shape: 64 64 15 15 (921600)
I0826 16:36:06.827811  4567 net.cpp:165] Memory required for data: 840429568
I0826 16:36:06.827816  4567 layer_factory.hpp:77] Creating layer conv6_1_relu
I0826 16:36:06.827821  4567 net.cpp:100] Creating Layer conv6_1_relu
I0826 16:36:06.827824  4567 net.cpp:434] conv6_1_relu <- conv6_1_bn
I0826 16:36:06.827828  4567 net.cpp:395] conv6_1_relu -> conv6_1_bn (in-place)
I0826 16:36:06.827833  4567 net.cpp:150] Setting up conv6_1_relu
I0826 16:36:06.827846  4567 net.cpp:157] Top shape: 64 64 15 15 (921600)
I0826 16:36:06.827855  4567 net.cpp:165] Memory required for data: 844115968
I0826 16:36:06.827858  4567 layer_factory.hpp:77] Creating layer conv7_1
I0826 16:36:06.827865  4567 net.cpp:100] Creating Layer conv7_1
I0826 16:36:06.827867  4567 net.cpp:434] conv7_1 <- conv6_1_bn
I0826 16:36:06.827873  4567 net.cpp:408] conv7_1 -> conv7_1
I0826 16:36:06.829792  4567 net.cpp:150] Setting up conv7_1
I0826 16:36:06.829813  4567 net.cpp:157] Top shape: 64 128 13 13 (1384448)
I0826 16:36:06.829816  4567 net.cpp:165] Memory required for data: 849653760
I0826 16:36:06.829821  4567 layer_factory.hpp:77] Creating layer conv7_1_bn
I0826 16:36:06.829833  4567 net.cpp:100] Creating Layer conv7_1_bn
I0826 16:36:06.829836  4567 net.cpp:434] conv7_1_bn <- conv7_1
I0826 16:36:06.829841  4567 net.cpp:408] conv7_1_bn -> conv7_1_bn
I0826 16:36:06.829984  4567 net.cpp:150] Setting up conv7_1_bn
I0826 16:36:06.829990  4567 net.cpp:157] Top shape: 64 128 13 13 (1384448)
I0826 16:36:06.829994  4567 net.cpp:165] Memory required for data: 855191552
I0826 16:36:06.830003  4567 layer_factory.hpp:77] Creating layer conv7_1_bn_scale
I0826 16:36:06.830013  4567 net.cpp:100] Creating Layer conv7_1_bn_scale
I0826 16:36:06.830019  4567 net.cpp:434] conv7_1_bn_scale <- conv7_1_bn
I0826 16:36:06.830027  4567 net.cpp:395] conv7_1_bn_scale -> conv7_1_bn (in-place)
I0826 16:36:06.830075  4567 layer_factory.hpp:77] Creating layer conv7_1_bn_scale
I0826 16:36:06.830165  4567 net.cpp:150] Setting up conv7_1_bn_scale
I0826 16:36:06.830173  4567 net.cpp:157] Top shape: 64 128 13 13 (1384448)
I0826 16:36:06.830174  4567 net.cpp:165] Memory required for data: 860729344
I0826 16:36:06.830179  4567 layer_factory.hpp:77] Creating layer conv7_1_relu
I0826 16:36:06.830186  4567 net.cpp:100] Creating Layer conv7_1_relu
I0826 16:36:06.830189  4567 net.cpp:434] conv7_1_relu <- conv7_1_bn
I0826 16:36:06.830193  4567 net.cpp:395] conv7_1_relu -> conv7_1_bn (in-place)
I0826 16:36:06.830198  4567 net.cpp:150] Setting up conv7_1_relu
I0826 16:36:06.830200  4567 net.cpp:157] Top shape: 64 128 13 13 (1384448)
I0826 16:36:06.830204  4567 net.cpp:165] Memory required for data: 866267136
I0826 16:36:06.830206  4567 layer_factory.hpp:77] Creating layer score
I0826 16:36:06.830214  4567 net.cpp:100] Creating Layer score
I0826 16:36:06.830217  4567 net.cpp:434] score <- conv7_1_bn
I0826 16:36:06.830222  4567 net.cpp:408] score -> score
I0826 16:36:06.830441  4567 net.cpp:150] Setting up score
I0826 16:36:06.830449  4567 net.cpp:157] Top shape: 64 4 13 13 (43264)
I0826 16:36:06.830452  4567 net.cpp:165] Memory required for data: 866440192
I0826 16:36:06.830457  4567 layer_factory.hpp:77] Creating layer upscore
I0826 16:36:06.830466  4567 net.cpp:100] Creating Layer upscore
I0826 16:36:06.830468  4567 net.cpp:434] upscore <- score
I0826 16:36:06.830473  4567 net.cpp:408] upscore -> upscore
I0826 16:36:06.831063  4567 net.cpp:150] Setting up upscore
I0826 16:36:06.831071  4567 net.cpp:157] Top shape: 64 4 224 224 (12845056)
I0826 16:36:06.831074  4567 net.cpp:165] Memory required for data: 917820416
I0826 16:36:06.831079  4567 layer_factory.hpp:77] Creating layer cropscore
I0826 16:36:06.831085  4567 net.cpp:100] Creating Layer cropscore
I0826 16:36:06.831089  4567 net.cpp:434] cropscore <- upscore
I0826 16:36:06.831092  4567 net.cpp:434] cropscore <- image_data_0_split_1
I0826 16:36:06.831096  4567 net.cpp:408] cropscore -> cropscore
I0826 16:36:06.831115  4567 net.cpp:150] Setting up cropscore
I0826 16:36:06.831120  4567 net.cpp:157] Top shape: 64 4 200 200 (10240000)
I0826 16:36:06.831122  4567 net.cpp:165] Memory required for data: 958780416
I0826 16:36:06.831125  4567 layer_factory.hpp:77] Creating layer cropscore_cropscore_0_split
I0826 16:36:06.831130  4567 net.cpp:100] Creating Layer cropscore_cropscore_0_split
I0826 16:36:06.831132  4567 net.cpp:434] cropscore_cropscore_0_split <- cropscore
I0826 16:36:06.831137  4567 net.cpp:408] cropscore_cropscore_0_split -> cropscore_cropscore_0_split_0
I0826 16:36:06.831149  4567 net.cpp:408] cropscore_cropscore_0_split -> cropscore_cropscore_0_split_1
I0826 16:36:06.831182  4567 net.cpp:150] Setting up cropscore_cropscore_0_split
I0826 16:36:06.831187  4567 net.cpp:157] Top shape: 64 4 200 200 (10240000)
I0826 16:36:06.831189  4567 net.cpp:157] Top shape: 64 4 200 200 (10240000)
I0826 16:36:06.831192  4567 net.cpp:165] Memory required for data: 1040700416
I0826 16:36:06.831194  4567 layer_factory.hpp:77] Creating layer loss
I0826 16:36:06.831199  4567 net.cpp:100] Creating Layer loss
I0826 16:36:06.831202  4567 net.cpp:434] loss <- cropscore_cropscore_0_split_0
I0826 16:36:06.831207  4567 net.cpp:434] loss <- label_data_1_split_0
I0826 16:36:06.831212  4567 net.cpp:408] loss -> loss
I0826 16:36:06.831217  4567 layer_factory.hpp:77] Creating layer loss
I0826 16:36:06.849395  4567 net.cpp:150] Setting up loss
I0826 16:36:06.849424  4567 net.cpp:157] Top shape: (1)
I0826 16:36:06.849427  4567 net.cpp:160]     with loss weight 1
I0826 16:36:06.849439  4567 net.cpp:165] Memory required for data: 1040700420
I0826 16:36:06.849443  4567 layer_factory.hpp:77] Creating layer accuracy
I0826 16:36:06.849453  4567 net.cpp:100] Creating Layer accuracy
I0826 16:36:06.849458  4567 net.cpp:434] accuracy <- cropscore_cropscore_0_split_1
I0826 16:36:06.849465  4567 net.cpp:434] accuracy <- label_data_1_split_1
I0826 16:36:06.849470  4567 net.cpp:408] accuracy -> accuracy
I0826 16:36:06.849478  4567 net.cpp:150] Setting up accuracy
I0826 16:36:06.849483  4567 net.cpp:157] Top shape: (1)
I0826 16:36:06.849485  4567 net.cpp:165] Memory required for data: 1040700424
I0826 16:36:06.849488  4567 net.cpp:228] accuracy does not need backward computation.
I0826 16:36:06.849491  4567 net.cpp:226] loss needs backward computation.
I0826 16:36:06.849494  4567 net.cpp:226] cropscore_cropscore_0_split needs backward computation.
I0826 16:36:06.849498  4567 net.cpp:226] cropscore needs backward computation.
I0826 16:36:06.849501  4567 net.cpp:226] upscore needs backward computation.
I0826 16:36:06.849504  4567 net.cpp:226] score needs backward computation.
I0826 16:36:06.849508  4567 net.cpp:226] conv7_1_relu needs backward computation.
I0826 16:36:06.849510  4567 net.cpp:226] conv7_1_bn_scale needs backward computation.
I0826 16:36:06.849512  4567 net.cpp:226] conv7_1_bn needs backward computation.
I0826 16:36:06.849515  4567 net.cpp:226] conv7_1 needs backward computation.
I0826 16:36:06.849519  4567 net.cpp:226] conv6_1_relu needs backward computation.
I0826 16:36:06.849521  4567 net.cpp:226] conv6_1_bn_scale needs backward computation.
I0826 16:36:06.849524  4567 net.cpp:226] conv6_1_bn needs backward computation.
I0826 16:36:06.849526  4567 net.cpp:226] conv6_1 needs backward computation.
I0826 16:36:06.849529  4567 net.cpp:226] conv5_1_relu needs backward computation.
I0826 16:36:06.849532  4567 net.cpp:226] conv5_1_bn_scale needs backward computation.
I0826 16:36:06.849534  4567 net.cpp:226] conv5_1_bn needs backward computation.
I0826 16:36:06.849537  4567 net.cpp:226] conv5_1 needs backward computation.
I0826 16:36:06.849540  4567 net.cpp:226] conv4_1_relu needs backward computation.
I0826 16:36:06.849542  4567 net.cpp:226] conv4_1_bn_scale needs backward computation.
I0826 16:36:06.849545  4567 net.cpp:226] conv4_1_bn needs backward computation.
I0826 16:36:06.849548  4567 net.cpp:226] pool4 needs backward computation.
I0826 16:36:06.849551  4567 net.cpp:226] conv4_1 needs backward computation.
I0826 16:36:06.849555  4567 net.cpp:226] conv3_1_relu needs backward computation.
I0826 16:36:06.849558  4567 net.cpp:226] conv3_1_bn_scale needs backward computation.
I0826 16:36:06.849562  4567 net.cpp:226] conv3_1_bn needs backward computation.
I0826 16:36:06.849567  4567 net.cpp:226] pool3 needs backward computation.
I0826 16:36:06.849572  4567 net.cpp:226] conv3_1 needs backward computation.
I0826 16:36:06.849577  4567 net.cpp:226] conv2_1_relu needs backward computation.
I0826 16:36:06.849582  4567 net.cpp:226] conv2_1_bn_scale needs backward computation.
I0826 16:36:06.849588  4567 net.cpp:226] conv2_1_bn needs backward computation.
I0826 16:36:06.849608  4567 net.cpp:226] pool2 needs backward computation.
I0826 16:36:06.849620  4567 net.cpp:226] conv2_1 needs backward computation.
I0826 16:36:06.849624  4567 net.cpp:226] conv1_1_relu needs backward computation.
I0826 16:36:06.849627  4567 net.cpp:226] conv1_1_bn_scale needs backward computation.
I0826 16:36:06.849629  4567 net.cpp:226] conv1_1_bn needs backward computation.
I0826 16:36:06.849632  4567 net.cpp:226] pool1 needs backward computation.
I0826 16:36:06.849635  4567 net.cpp:226] conv1_1 needs backward computation.
I0826 16:36:06.849639  4567 net.cpp:228] label_data_1_split does not need backward computation.
I0826 16:36:06.849642  4567 net.cpp:228] image_data_0_split does not need backward computation.
I0826 16:36:06.849645  4567 net.cpp:228] data does not need backward computation.
I0826 16:36:06.849648  4567 net.cpp:270] This network produces output accuracy
I0826 16:36:06.849652  4567 net.cpp:270] This network produces output loss
I0826 16:36:06.849669  4567 net.cpp:283] Network initialization done.
I0826 16:36:06.849773  4567 solver.cpp:60] Solver scaffolding done.
I0826 16:36:06.851024  4567 caffe.cpp:251] Starting Optimization
I0826 16:36:06.851042  4567 solver.cpp:279] Solving segmentation
I0826 16:36:06.851049  4567 solver.cpp:280] Learning Rate Policy: step
I0826 16:36:06.852334  4567 solver.cpp:337] Iteration 0, Testing net (#0)
I0826 16:36:15.037377  4567 solver.cpp:404]     Test net output #0: accuracy = 0.244512
I0826 16:36:15.037416  4567 solver.cpp:404]     Test net output #1: loss = 2.63927e+06 (* 1 = 2.63927e+06 loss)
I0826 16:36:16.596364  4567 solver.cpp:228] Iteration 0, loss = 55451.7
I0826 16:36:16.596397  4567 solver.cpp:244]     Train net output #0: accuracy = 0.251837
I0826 16:36:16.596406  4567 solver.cpp:244]     Train net output #1: loss = 55451.7 (* 1 = 55451.7 loss)
I0826 16:36:16.596420  4567 sgd_solver.cpp:106] Iteration 0, lr = 1e-05
I0826 16:37:31.957048  4567 solver.cpp:228] Iteration 50, loss = 39702.8
I0826 16:37:31.957137  4567 solver.cpp:244]     Train net output #0: accuracy = 0.52007
I0826 16:37:31.957152  4567 solver.cpp:244]     Train net output #1: loss = 39702.8 (* 1 = 39702.8 loss)
I0826 16:37:31.957162  4567 sgd_solver.cpp:106] Iteration 50, lr = 1e-05
I0826 16:38:48.012248  4567 solver.cpp:228] Iteration 100, loss = 27790
I0826 16:38:48.012338  4567 solver.cpp:244]     Train net output #0: accuracy = 0.745267
I0826 16:38:48.012351  4567 solver.cpp:244]     Train net output #1: loss = 27790 (* 1 = 27790 loss)
I0826 16:38:48.012357  4567 sgd_solver.cpp:106] Iteration 100, lr = 1e-05
I0826 16:40:03.962875  4567 solver.cpp:228] Iteration 150, loss = 29860.9
I0826 16:40:03.962980  4567 solver.cpp:244]     Train net output #0: accuracy = 0.692366
I0826 16:40:03.962995  4567 solver.cpp:244]     Train net output #1: loss = 29860.9 (* 1 = 29860.9 loss)
I0826 16:40:03.963001  4567 sgd_solver.cpp:106] Iteration 150, lr = 1e-05
I0826 16:41:19.814003  4567 solver.cpp:337] Iteration 200, Testing net (#0)
I0826 16:41:27.994590  4567 solver.cpp:404]     Test net output #0: accuracy = 0.714364
I0826 16:41:27.994629  4567 solver.cpp:404]     Test net output #1: loss = 33750.9 (* 1 = 33750.9 loss)
I0826 16:41:29.407116  4567 solver.cpp:228] Iteration 200, loss = 21502
I0826 16:41:29.407153  4567 solver.cpp:244]     Train net output #0: accuracy = 0.814628
I0826 16:41:29.407162  4567 solver.cpp:244]     Train net output #1: loss = 21502 (* 1 = 21502 loss)
I0826 16:41:29.407169  4567 sgd_solver.cpp:106] Iteration 200, lr = 1e-05
I0826 16:42:47.090322  4567 solver.cpp:228] Iteration 250, loss = 22623.4
I0826 16:42:47.090420  4567 solver.cpp:244]     Train net output #0: accuracy = 0.756865
I0826 16:42:47.090430  4567 solver.cpp:244]     Train net output #1: loss = 22623.4 (* 1 = 22623.4 loss)
I0826 16:42:47.090437  4567 sgd_solver.cpp:106] Iteration 250, lr = 1e-05
I0826 16:44:02.686779  4567 solver.cpp:228] Iteration 300, loss = 18316
I0826 16:44:02.686892  4567 solver.cpp:244]     Train net output #0: accuracy = 0.839601
I0826 16:44:02.686902  4567 solver.cpp:244]     Train net output #1: loss = 18316 (* 1 = 18316 loss)
I0826 16:44:02.686913  4567 sgd_solver.cpp:106] Iteration 300, lr = 1e-05
I0826 16:45:20.044086  4567 solver.cpp:228] Iteration 350, loss = 21187
I0826 16:45:20.044178  4567 solver.cpp:244]     Train net output #0: accuracy = 0.789257
I0826 16:45:20.044193  4567 solver.cpp:244]     Train net output #1: loss = 21187 (* 1 = 21187 loss)
I0826 16:45:20.044200  4567 sgd_solver.cpp:106] Iteration 350, lr = 1e-05
I0826 16:46:49.816201  4567 solver.cpp:337] Iteration 400, Testing net (#0)
I0826 16:47:00.249043  4567 solver.cpp:404]     Test net output #0: accuracy = 0.750133
I0826 16:47:00.249095  4567 solver.cpp:404]     Test net output #1: loss = 29128.5 (* 1 = 29128.5 loss)
I0826 16:47:01.950001  4567 solver.cpp:228] Iteration 400, loss = 21209.3
I0826 16:47:01.950049  4567 solver.cpp:244]     Train net output #0: accuracy = 0.786057
I0826 16:47:01.950062  4567 solver.cpp:244]     Train net output #1: loss = 21209.3 (* 1 = 21209.3 loss)
I0826 16:47:01.950073  4567 sgd_solver.cpp:106] Iteration 400, lr = 1e-05
I0826 16:48:32.668395  4567 solver.cpp:228] Iteration 450, loss = 20728.3
I0826 16:48:32.668483  4567 solver.cpp:244]     Train net output #0: accuracy = 0.77434
I0826 16:48:32.668503  4567 solver.cpp:244]     Train net output #1: loss = 20728.3 (* 1 = 20728.3 loss)
I0826 16:48:32.668514  4567 sgd_solver.cpp:106] Iteration 450, lr = 1e-05
I0826 16:49:57.425869  4567 solver.cpp:228] Iteration 500, loss = 26658.7
I0826 16:49:57.425963  4567 solver.cpp:244]     Train net output #0: accuracy = 0.734969
I0826 16:49:57.425974  4567 solver.cpp:244]     Train net output #1: loss = 26658.7 (* 1 = 26658.7 loss)
I0826 16:49:57.425981  4567 sgd_solver.cpp:106] Iteration 500, lr = 1e-05
I0826 16:51:11.929466  4567 solver.cpp:454] Snapshotting to binary proto file portrait_one_stage3_iter_549.caffemodel
I0826 16:51:11.933558  4567 sgd_solver.cpp:273] Snapshotting solver state to binary proto file portrait_one_stage3_iter_549.solverstate
I0826 16:51:14.991890  4567 solver.cpp:228] Iteration 550, loss = 15518.2
I0826 16:51:14.991931  4567 solver.cpp:244]     Train net output #0: accuracy = 0.847764
I0826 16:51:14.991947  4567 solver.cpp:244]     Train net output #1: loss = 15518.2 (* 1 = 15518.2 loss)
I0826 16:51:14.991960  4567 sgd_solver.cpp:106] Iteration 550, lr = 1e-05
I0826 16:52:31.392592  4567 solver.cpp:337] Iteration 600, Testing net (#0)
I0826 16:52:39.611616  4567 solver.cpp:404]     Test net output #0: accuracy = 0.778814
I0826 16:52:39.611657  4567 solver.cpp:404]     Test net output #1: loss = 25127.2 (* 1 = 25127.2 loss)
I0826 16:52:41.048426  4567 solver.cpp:228] Iteration 600, loss = 18749.1
I0826 16:52:41.048472  4567 solver.cpp:244]     Train net output #0: accuracy = 0.818941
I0826 16:52:41.048486  4567 solver.cpp:244]     Train net output #1: loss = 18749.1 (* 1 = 18749.1 loss)
I0826 16:52:41.048496  4567 sgd_solver.cpp:106] Iteration 600, lr = 1e-05
I0826 16:53:59.928395  4567 solver.cpp:228] Iteration 650, loss = 14687.4
I0826 16:53:59.928493  4567 solver.cpp:244]     Train net output #0: accuracy = 0.862997
I0826 16:53:59.928508  4567 solver.cpp:244]     Train net output #1: loss = 14687.4 (* 1 = 14687.4 loss)
I0826 16:53:59.928519  4567 sgd_solver.cpp:106] Iteration 650, lr = 1e-05
I0826 16:55:17.015609  4567 solver.cpp:228] Iteration 700, loss = 13340.8
I0826 16:55:17.015697  4567 solver.cpp:244]     Train net output #0: accuracy = 0.873475
I0826 16:55:17.015717  4567 solver.cpp:244]     Train net output #1: loss = 13340.8 (* 1 = 13340.8 loss)
I0826 16:55:17.015727  4567 sgd_solver.cpp:106] Iteration 700, lr = 1e-05
I0826 16:56:35.434305  4567 solver.cpp:228] Iteration 750, loss = 16761.9
I0826 16:56:35.434401  4567 solver.cpp:244]     Train net output #0: accuracy = 0.844328
I0826 16:56:35.434413  4567 solver.cpp:244]     Train net output #1: loss = 16761.9 (* 1 = 16761.9 loss)
I0826 16:56:35.434420  4567 sgd_solver.cpp:106] Iteration 750, lr = 1e-05
I0826 16:57:53.030648  4567 solver.cpp:337] Iteration 800, Testing net (#0)
I0826 16:58:01.045894  4567 solver.cpp:404]     Test net output #0: accuracy = 0.738057
I0826 16:58:01.045935  4567 solver.cpp:404]     Test net output #1: loss = 26265.2 (* 1 = 26265.2 loss)
I0826 16:58:02.466732  4567 solver.cpp:228] Iteration 800, loss = 15050.8
I0826 16:58:02.466769  4567 solver.cpp:244]     Train net output #0: accuracy = 0.853495
I0826 16:58:02.466778  4567 solver.cpp:244]     Train net output #1: loss = 15050.8 (* 1 = 15050.8 loss)
I0826 16:58:02.466784  4567 sgd_solver.cpp:106] Iteration 800, lr = 1e-05
I0826 16:59:20.886920  4567 solver.cpp:228] Iteration 850, loss = 14450.3
I0826 16:59:20.887001  4567 solver.cpp:244]     Train net output #0: accuracy = 0.856472
I0826 16:59:20.887012  4567 solver.cpp:244]     Train net output #1: loss = 14450.3 (* 1 = 14450.3 loss)
I0826 16:59:20.887019  4567 sgd_solver.cpp:106] Iteration 850, lr = 1e-05
I0826 17:00:39.150204  4567 solver.cpp:228] Iteration 900, loss = 11599
I0826 17:00:39.150295  4567 solver.cpp:244]     Train net output #0: accuracy = 0.887378
I0826 17:00:39.150307  4567 solver.cpp:244]     Train net output #1: loss = 11599 (* 1 = 11599 loss)
I0826 17:00:39.150315  4567 sgd_solver.cpp:106] Iteration 900, lr = 1e-05
I0826 17:01:58.138193  4567 solver.cpp:228] Iteration 950, loss = 14016
I0826 17:01:58.138298  4567 solver.cpp:244]     Train net output #0: accuracy = 0.863396
I0826 17:01:58.138312  4567 solver.cpp:244]     Train net output #1: loss = 14016 (* 1 = 14016 loss)
I0826 17:01:58.138322  4567 sgd_solver.cpp:106] Iteration 950, lr = 1e-05
I0826 17:03:14.031910  4567 solver.cpp:337] Iteration 1000, Testing net (#0)
I0826 17:03:22.103518  4567 solver.cpp:404]     Test net output #0: accuracy = 0.82012
I0826 17:03:22.103572  4567 solver.cpp:404]     Test net output #1: loss = 18924.5 (* 1 = 18924.5 loss)
I0826 17:03:23.537823  4567 solver.cpp:228] Iteration 1000, loss = 8977.19
I0826 17:03:23.537860  4567 solver.cpp:244]     Train net output #0: accuracy = 0.917299
I0826 17:03:23.537870  4567 solver.cpp:244]     Train net output #1: loss = 8977.19 (* 1 = 8977.19 loss)
I0826 17:03:23.537878  4567 sgd_solver.cpp:106] Iteration 1000, lr = 1e-05
I0826 17:04:41.417086  4567 solver.cpp:228] Iteration 1050, loss = 13396.5
I0826 17:04:41.417194  4567 solver.cpp:244]     Train net output #0: accuracy = 0.873915
I0826 17:04:41.417212  4567 solver.cpp:244]     Train net output #1: loss = 13396.5 (* 1 = 13396.5 loss)
I0826 17:04:41.417220  4567 sgd_solver.cpp:106] Iteration 1050, lr = 1e-05
I0826 17:06:00.980273  4567 solver.cpp:228] Iteration 1100, loss = 11451.3
I0826 17:06:00.980382  4567 solver.cpp:244]     Train net output #0: accuracy = 0.891156
I0826 17:06:00.980399  4567 solver.cpp:244]     Train net output #1: loss = 11451.3 (* 1 = 11451.3 loss)
I0826 17:06:00.980408  4567 sgd_solver.cpp:106] Iteration 1100, lr = 1e-05
I0826 17:07:19.162833  4567 solver.cpp:228] Iteration 1150, loss = 9754.45
I0826 17:07:19.162909  4567 solver.cpp:244]     Train net output #0: accuracy = 0.909993
I0826 17:07:19.162919  4567 solver.cpp:244]     Train net output #1: loss = 9754.45 (* 1 = 9754.45 loss)
I0826 17:07:19.162926  4567 sgd_solver.cpp:106] Iteration 1150, lr = 1e-05
I0826 17:08:35.835722  4567 solver.cpp:337] Iteration 1200, Testing net (#0)
I0826 17:08:44.061731  4567 solver.cpp:404]     Test net output #0: accuracy = 0.797252
I0826 17:08:44.061771  4567 solver.cpp:404]     Test net output #1: loss = 20378.8 (* 1 = 20378.8 loss)
I0826 17:08:45.395123  4567 solver.cpp:228] Iteration 1200, loss = 11264.8
I0826 17:08:45.395162  4567 solver.cpp:244]     Train net output #0: accuracy = 0.888097
I0826 17:08:45.395171  4567 solver.cpp:244]     Train net output #1: loss = 11264.8 (* 1 = 11264.8 loss)
I0826 17:08:45.395179  4567 sgd_solver.cpp:106] Iteration 1200, lr = 1e-05
I0826 17:10:04.147933  4567 solver.cpp:228] Iteration 1250, loss = 8807.73
I0826 17:10:04.148025  4567 solver.cpp:244]     Train net output #0: accuracy = 0.91601
I0826 17:10:04.148036  4567 solver.cpp:244]     Train net output #1: loss = 8807.73 (* 1 = 8807.73 loss)
I0826 17:10:04.148043  4567 sgd_solver.cpp:106] Iteration 1250, lr = 1e-05
I0826 17:11:21.044222  4567 solver.cpp:228] Iteration 1300, loss = 10442.5
I0826 17:11:21.044348  4567 solver.cpp:244]     Train net output #0: accuracy = 0.899755
I0826 17:11:21.044359  4567 solver.cpp:244]     Train net output #1: loss = 10442.5 (* 1 = 10442.5 loss)
I0826 17:11:21.044366  4567 sgd_solver.cpp:106] Iteration 1300, lr = 1e-05
I0826 17:12:39.753144  4567 solver.cpp:228] Iteration 1350, loss = 6986.14
I0826 17:12:39.753226  4567 solver.cpp:244]     Train net output #0: accuracy = 0.93263
I0826 17:12:39.753237  4567 solver.cpp:244]     Train net output #1: loss = 6986.14 (* 1 = 6986.14 loss)
I0826 17:12:39.753243  4567 sgd_solver.cpp:106] Iteration 1350, lr = 1e-05
I0826 17:13:56.386850  4567 solver.cpp:337] Iteration 1400, Testing net (#0)
I0826 17:14:04.521855  4567 solver.cpp:404]     Test net output #0: accuracy = 0.763171
I0826 17:14:04.521898  4567 solver.cpp:404]     Test net output #1: loss = 24384.3 (* 1 = 24384.3 loss)
I0826 17:14:05.940649  4567 solver.cpp:228] Iteration 1400, loss = 11737.3
I0826 17:14:05.940696  4567 solver.cpp:244]     Train net output #0: accuracy = 0.87949
I0826 17:14:05.940709  4567 solver.cpp:244]     Train net output #1: loss = 11737.3 (* 1 = 11737.3 loss)
I0826 17:14:05.940718  4567 sgd_solver.cpp:106] Iteration 1400, lr = 1e-05
I0826 17:15:23.231125  4567 solver.cpp:228] Iteration 1450, loss = 6810.89
I0826 17:15:23.231221  4567 solver.cpp:244]     Train net output #0: accuracy = 0.935886
I0826 17:15:23.231237  4567 solver.cpp:244]     Train net output #1: loss = 6810.89 (* 1 = 6810.89 loss)
I0826 17:15:23.231246  4567 sgd_solver.cpp:106] Iteration 1450, lr = 1e-05
I0826 17:16:42.390233  4567 solver.cpp:228] Iteration 1500, loss = 9825.04
I0826 17:16:42.390311  4567 solver.cpp:244]     Train net output #0: accuracy = 0.906634
I0826 17:16:42.390321  4567 solver.cpp:244]     Train net output #1: loss = 9825.04 (* 1 = 9825.04 loss)
I0826 17:16:42.390328  4567 sgd_solver.cpp:106] Iteration 1500, lr = 1e-05
I0826 17:18:00.961210  4567 solver.cpp:228] Iteration 1550, loss = 12408.8
I0826 17:18:00.961297  4567 solver.cpp:244]     Train net output #0: accuracy = 0.879074
I0826 17:18:00.961309  4567 solver.cpp:244]     Train net output #1: loss = 12408.8 (* 1 = 12408.8 loss)
I0826 17:18:00.961315  4567 sgd_solver.cpp:106] Iteration 1550, lr = 1e-05
I0826 17:19:18.298225  4567 solver.cpp:337] Iteration 1600, Testing net (#0)
I0826 17:19:26.647816  4567 solver.cpp:404]     Test net output #0: accuracy = 0.807033
I0826 17:19:26.647851  4567 solver.cpp:404]     Test net output #1: loss = 19075.1 (* 1 = 19075.1 loss)
I0826 17:19:28.075305  4567 solver.cpp:228] Iteration 1600, loss = 7517.5
I0826 17:19:28.075353  4567 solver.cpp:244]     Train net output #0: accuracy = 0.928062
I0826 17:19:28.075369  4567 solver.cpp:244]     Train net output #1: loss = 7517.5 (* 1 = 7517.5 loss)
I0826 17:19:28.075379  4567 sgd_solver.cpp:106] Iteration 1600, lr = 1e-05
I0826 17:20:46.269490  4567 solver.cpp:228] Iteration 1650, loss = 8157.77
I0826 17:20:46.269574  4567 solver.cpp:244]     Train net output #0: accuracy = 0.918951
I0826 17:20:46.269585  4567 solver.cpp:244]     Train net output #1: loss = 8157.77 (* 1 = 8157.77 loss)
I0826 17:20:46.269593  4567 sgd_solver.cpp:106] Iteration 1650, lr = 1e-05
I0826 17:22:04.789532  4567 solver.cpp:228] Iteration 1700, loss = 5843.35
I0826 17:22:04.789662  4567 solver.cpp:244]     Train net output #0: accuracy = 0.945627
I0826 17:22:04.789680  4567 solver.cpp:244]     Train net output #1: loss = 5843.35 (* 1 = 5843.35 loss)
I0826 17:22:04.789690  4567 sgd_solver.cpp:106] Iteration 1700, lr = 1e-05
I0826 17:23:22.577069  4567 solver.cpp:228] Iteration 1750, loss = 8674.19
I0826 17:23:22.577147  4567 solver.cpp:244]     Train net output #0: accuracy = 0.914006
I0826 17:23:22.577162  4567 solver.cpp:244]     Train net output #1: loss = 8674.19 (* 1 = 8674.19 loss)
I0826 17:23:22.577170  4567 sgd_solver.cpp:106] Iteration 1750, lr = 1e-05
I0826 17:24:39.652508  4567 solver.cpp:337] Iteration 1800, Testing net (#0)
I0826 17:24:47.639312  4567 solver.cpp:404]     Test net output #0: accuracy = 0.835054
I0826 17:24:47.639369  4567 solver.cpp:404]     Test net output #1: loss = 18479.7 (* 1 = 18479.7 loss)
I0826 17:24:49.040787  4567 solver.cpp:228] Iteration 1800, loss = 5073.52
I0826 17:24:49.040833  4567 solver.cpp:244]     Train net output #0: accuracy = 0.950425
I0826 17:24:49.040846  4567 solver.cpp:244]     Train net output #1: loss = 5073.52 (* 1 = 5073.52 loss)
I0826 17:24:49.040855  4567 sgd_solver.cpp:106] Iteration 1800, lr = 1e-05
I0826 17:26:07.436617  4567 solver.cpp:228] Iteration 1850, loss = 12137.4
I0826 17:26:07.436714  4567 solver.cpp:244]     Train net output #0: accuracy = 0.876089
I0826 17:26:07.436730  4567 solver.cpp:244]     Train net output #1: loss = 12137.4 (* 1 = 12137.4 loss)
I0826 17:26:07.436741  4567 sgd_solver.cpp:106] Iteration 1850, lr = 1e-05
I0826 17:27:26.068207  4567 solver.cpp:228] Iteration 1900, loss = 9790.23
I0826 17:27:26.068275  4567 solver.cpp:244]     Train net output #0: accuracy = 0.903922
I0826 17:27:26.068286  4567 solver.cpp:244]     Train net output #1: loss = 9790.23 (* 1 = 9790.23 loss)
I0826 17:27:26.068294  4567 sgd_solver.cpp:106] Iteration 1900, lr = 1e-05
I0826 17:28:43.869966  4567 solver.cpp:228] Iteration 1950, loss = 6148.98
I0826 17:28:43.870069  4567 solver.cpp:244]     Train net output #0: accuracy = 0.942975
I0826 17:28:43.870080  4567 solver.cpp:244]     Train net output #1: loss = 6148.98 (* 1 = 6148.98 loss)
I0826 17:28:43.870087  4567 sgd_solver.cpp:106] Iteration 1950, lr = 1e-05
I0826 17:30:03.777606  4567 solver.cpp:337] Iteration 2000, Testing net (#0)
I0826 17:30:11.909713  4567 solver.cpp:404]     Test net output #0: accuracy = 0.868348
I0826 17:30:11.909754  4567 solver.cpp:404]     Test net output #1: loss = 14444 (* 1 = 14444 loss)
I0826 17:30:13.344916  4567 solver.cpp:228] Iteration 2000, loss = 11596.5
I0826 17:30:13.344952  4567 solver.cpp:244]     Train net output #0: accuracy = 0.886312
I0826 17:30:13.344962  4567 solver.cpp:244]     Train net output #1: loss = 11596.5 (* 1 = 11596.5 loss)
I0826 17:30:13.344969  4567 sgd_solver.cpp:106] Iteration 2000, lr = 1e-05
I0826 17:31:31.138535  4567 solver.cpp:228] Iteration 2050, loss = 6369.66
I0826 17:31:31.138633  4567 solver.cpp:244]     Train net output #0: accuracy = 0.93971
I0826 17:31:31.138644  4567 solver.cpp:244]     Train net output #1: loss = 6369.66 (* 1 = 6369.66 loss)
I0826 17:31:31.138650  4567 sgd_solver.cpp:106] Iteration 2050, lr = 1e-05
I0826 17:32:49.581902  4567 solver.cpp:228] Iteration 2100, loss = 8849.74
I0826 17:32:49.582003  4567 solver.cpp:244]     Train net output #0: accuracy = 0.913545
I0826 17:32:49.582018  4567 solver.cpp:244]     Train net output #1: loss = 8849.74 (* 1 = 8849.74 loss)
I0826 17:32:49.582029  4567 sgd_solver.cpp:106] Iteration 2100, lr = 1e-05
I0826 17:34:07.803576  4567 solver.cpp:228] Iteration 2150, loss = 4897.87
I0826 17:34:07.803659  4567 solver.cpp:244]     Train net output #0: accuracy = 0.953071
I0826 17:34:07.803670  4567 solver.cpp:244]     Train net output #1: loss = 4897.87 (* 1 = 4897.87 loss)
I0826 17:34:07.803678  4567 sgd_solver.cpp:106] Iteration 2150, lr = 1e-05
I0826 17:35:24.036873  4567 solver.cpp:337] Iteration 2200, Testing net (#0)
I0826 17:35:31.914043  4567 solver.cpp:404]     Test net output #0: accuracy = 0.855967
I0826 17:35:31.914083  4567 solver.cpp:404]     Test net output #1: loss = 15644.7 (* 1 = 15644.7 loss)
I0826 17:35:33.290225  4567 solver.cpp:228] Iteration 2200, loss = 9258.46
I0826 17:35:33.290268  4567 solver.cpp:244]     Train net output #0: accuracy = 0.9087
I0826 17:35:33.290284  4567 solver.cpp:244]     Train net output #1: loss = 9258.46 (* 1 = 9258.46 loss)
I0826 17:35:33.290294  4567 sgd_solver.cpp:106] Iteration 2200, lr = 1e-05
I0826 17:36:51.803197  4567 solver.cpp:228] Iteration 2250, loss = 6552.97
I0826 17:36:51.803262  4567 solver.cpp:244]     Train net output #0: accuracy = 0.935763
I0826 17:36:51.803273  4567 solver.cpp:244]     Train net output #1: loss = 6552.97 (* 1 = 6552.97 loss)
I0826 17:36:51.803292  4567 sgd_solver.cpp:106] Iteration 2250, lr = 1e-05
I0826 17:38:09.762192  4567 solver.cpp:228] Iteration 2300, loss = 5765.2
I0826 17:38:09.762327  4567 solver.cpp:244]     Train net output #0: accuracy = 0.946875
I0826 17:38:09.762343  4567 solver.cpp:244]     Train net output #1: loss = 5765.2 (* 1 = 5765.2 loss)
I0826 17:38:09.762352  4567 sgd_solver.cpp:106] Iteration 2300, lr = 1e-05
I0826 17:39:27.394152  4567 solver.cpp:228] Iteration 2350, loss = 10003
I0826 17:39:27.394233  4567 solver.cpp:244]     Train net output #0: accuracy = 0.90199
I0826 17:39:27.394244  4567 solver.cpp:244]     Train net output #1: loss = 10003 (* 1 = 10003 loss)
I0826 17:39:27.394251  4567 sgd_solver.cpp:106] Iteration 2350, lr = 1e-05
I0826 17:40:44.032142  4567 solver.cpp:337] Iteration 2400, Testing net (#0)
I0826 17:40:52.221766  4567 solver.cpp:404]     Test net output #0: accuracy = 0.842919
I0826 17:40:52.221825  4567 solver.cpp:404]     Test net output #1: loss = 16828.2 (* 1 = 16828.2 loss)
I0826 17:40:53.627102  4567 solver.cpp:228] Iteration 2400, loss = 5381.79
I0826 17:40:53.627140  4567 solver.cpp:244]     Train net output #0: accuracy = 0.947783
I0826 17:40:53.627149  4567 solver.cpp:244]     Train net output #1: loss = 5381.79 (* 1 = 5381.79 loss)
I0826 17:40:53.627156  4567 sgd_solver.cpp:106] Iteration 2400, lr = 1e-05
I0826 17:42:11.836191  4567 solver.cpp:228] Iteration 2450, loss = 10529.8
I0826 17:42:11.836277  4567 solver.cpp:244]     Train net output #0: accuracy = 0.898458
I0826 17:42:11.836288  4567 solver.cpp:244]     Train net output #1: loss = 10529.8 (* 1 = 10529.8 loss)
I0826 17:42:11.836295  4567 sgd_solver.cpp:106] Iteration 2450, lr = 1e-05
I0826 17:43:30.146019  4567 solver.cpp:228] Iteration 2500, loss = 6011.7
I0826 17:43:30.146111  4567 solver.cpp:244]     Train net output #0: accuracy = 0.942029
I0826 17:43:30.146126  4567 solver.cpp:244]     Train net output #1: loss = 6011.7 (* 1 = 6011.7 loss)
I0826 17:43:30.146134  4567 sgd_solver.cpp:106] Iteration 2500, lr = 1e-05
I0826 17:44:48.419253  4567 solver.cpp:228] Iteration 2550, loss = 7078.59
I0826 17:44:48.419334  4567 solver.cpp:244]     Train net output #0: accuracy = 0.931908
I0826 17:44:48.419347  4567 solver.cpp:244]     Train net output #1: loss = 7078.59 (* 1 = 7078.59 loss)
I0826 17:44:48.419353  4567 sgd_solver.cpp:106] Iteration 2550, lr = 1e-05
I0826 17:46:05.201131  4567 solver.cpp:337] Iteration 2600, Testing net (#0)
I0826 17:46:13.841186  4567 solver.cpp:404]     Test net output #0: accuracy = 0.869326
I0826 17:46:13.841225  4567 solver.cpp:404]     Test net output #1: loss = 13994.4 (* 1 = 13994.4 loss)
I0826 17:46:15.173817  4567 solver.cpp:228] Iteration 2600, loss = 4964.54
I0826 17:46:15.173852  4567 solver.cpp:244]     Train net output #0: accuracy = 0.953688
I0826 17:46:15.173861  4567 solver.cpp:244]     Train net output #1: loss = 4964.54 (* 1 = 4964.54 loss)
I0826 17:46:15.173868  4567 sgd_solver.cpp:106] Iteration 2600, lr = 1e-05
I0826 17:47:32.890178  4567 solver.cpp:228] Iteration 2650, loss = 7768.42
I0826 17:47:32.890272  4567 solver.cpp:244]     Train net output #0: accuracy = 0.924255
I0826 17:47:32.890288  4567 solver.cpp:244]     Train net output #1: loss = 7768.42 (* 1 = 7768.42 loss)
I0826 17:47:32.890297  4567 sgd_solver.cpp:106] Iteration 2650, lr = 1e-05
I0826 17:48:49.614595  4567 solver.cpp:228] Iteration 2700, loss = 8301.45
I0826 17:48:49.614660  4567 solver.cpp:244]     Train net output #0: accuracy = 0.914924
I0826 17:48:49.614670  4567 solver.cpp:244]     Train net output #1: loss = 8301.45 (* 1 = 8301.45 loss)
I0826 17:48:49.614676  4567 sgd_solver.cpp:106] Iteration 2700, lr = 1e-05
I0826 17:50:07.827878  4567 solver.cpp:228] Iteration 2750, loss = 5068.11
I0826 17:50:07.827956  4567 solver.cpp:244]     Train net output #0: accuracy = 0.951171
I0826 17:50:07.827967  4567 solver.cpp:244]     Train net output #1: loss = 5068.11 (* 1 = 5068.11 loss)
I0826 17:50:07.827975  4567 sgd_solver.cpp:106] Iteration 2750, lr = 1e-05
I0826 17:51:24.052369  4567 solver.cpp:337] Iteration 2800, Testing net (#0)
I0826 17:51:32.279805  4567 solver.cpp:404]     Test net output #0: accuracy = 0.879767
I0826 17:51:32.279844  4567 solver.cpp:404]     Test net output #1: loss = 13322.9 (* 1 = 13322.9 loss)
I0826 17:51:33.769104  4567 solver.cpp:228] Iteration 2800, loss = 10191.9
I0826 17:51:33.769135  4567 solver.cpp:244]     Train net output #0: accuracy = 0.898473
I0826 17:51:33.769145  4567 solver.cpp:244]     Train net output #1: loss = 10191.9 (* 1 = 10191.9 loss)
I0826 17:51:33.769151  4567 sgd_solver.cpp:106] Iteration 2800, lr = 1e-05
I0826 17:52:50.611541  4567 solver.cpp:228] Iteration 2850, loss = 5373.25
I0826 17:52:50.611624  4567 solver.cpp:244]     Train net output #0: accuracy = 0.948815
I0826 17:52:50.611634  4567 solver.cpp:244]     Train net output #1: loss = 5373.25 (* 1 = 5373.25 loss)
I0826 17:52:50.611640  4567 sgd_solver.cpp:106] Iteration 2850, lr = 1e-05
I0826 17:54:08.648924  4567 solver.cpp:228] Iteration 2900, loss = 9910.7
I0826 17:54:08.649020  4567 solver.cpp:244]     Train net output #0: accuracy = 0.904699
I0826 17:54:08.649032  4567 solver.cpp:244]     Train net output #1: loss = 9910.7 (* 1 = 9910.7 loss)
I0826 17:54:08.649039  4567 sgd_solver.cpp:106] Iteration 2900, lr = 1e-05
I0826 17:55:28.017871  4567 solver.cpp:228] Iteration 2950, loss = 6052.14
I0826 17:55:28.017956  4567 solver.cpp:244]     Train net output #0: accuracy = 0.940802
I0826 17:55:28.017967  4567 solver.cpp:244]     Train net output #1: loss = 6052.14 (* 1 = 6052.14 loss)
I0826 17:55:28.017973  4567 sgd_solver.cpp:106] Iteration 2950, lr = 1e-05
I0826 17:56:45.050405  4567 solver.cpp:337] Iteration 3000, Testing net (#0)
I0826 17:56:55.092998  4567 solver.cpp:404]     Test net output #0: accuracy = 0.884261
I0826 17:56:55.093049  4567 solver.cpp:404]     Test net output #1: loss = 12025.3 (* 1 = 12025.3 loss)
I0826 17:56:56.867081  4567 solver.cpp:228] Iteration 3000, loss = 6462.64
I0826 17:56:56.867136  4567 solver.cpp:244]     Train net output #0: accuracy = 0.937271
I0826 17:56:56.867152  4567 solver.cpp:244]     Train net output #1: loss = 6462.64 (* 1 = 6462.64 loss)
I0826 17:56:56.867164  4567 sgd_solver.cpp:106] Iteration 3000, lr = 1e-05
I0826 17:58:15.313999  4567 solver.cpp:228] Iteration 3050, loss = 7390.29
I0826 17:58:15.314152  4567 solver.cpp:244]     Train net output #0: accuracy = 0.928746
I0826 17:58:15.314172  4567 solver.cpp:244]     Train net output #1: loss = 7390.29 (* 1 = 7390.29 loss)
I0826 17:58:15.314182  4567 sgd_solver.cpp:106] Iteration 3050, lr = 1e-05
I0826 17:59:32.705685  4567 solver.cpp:228] Iteration 3100, loss = 4371.28
I0826 17:59:32.705781  4567 solver.cpp:244]     Train net output #0: accuracy = 0.957174
I0826 17:59:32.705796  4567 solver.cpp:244]     Train net output #1: loss = 4371.28 (* 1 = 4371.28 loss)
I0826 17:59:32.705806  4567 sgd_solver.cpp:106] Iteration 3100, lr = 1e-05
I0826 18:00:49.692651  4567 solver.cpp:228] Iteration 3150, loss = 7259.38
I0826 18:00:49.692729  4567 solver.cpp:244]     Train net output #0: accuracy = 0.926462
I0826 18:00:49.692742  4567 solver.cpp:244]     Train net output #1: loss = 7259.38 (* 1 = 7259.38 loss)
I0826 18:00:49.692749  4567 sgd_solver.cpp:106] Iteration 3150, lr = 1e-05
I0826 18:02:06.794214  4567 solver.cpp:337] Iteration 3200, Testing net (#0)
I0826 18:02:14.903149  4567 solver.cpp:404]     Test net output #0: accuracy = 0.884779
I0826 18:02:14.903200  4567 solver.cpp:404]     Test net output #1: loss = 12121.5 (* 1 = 12121.5 loss)
I0826 18:02:16.300284  4567 solver.cpp:228] Iteration 3200, loss = 4820.09
I0826 18:02:16.300323  4567 solver.cpp:244]     Train net output #0: accuracy = 0.952322
I0826 18:02:16.300331  4567 solver.cpp:244]     Train net output #1: loss = 4820.09 (* 1 = 4820.09 loss)
I0826 18:02:16.300338  4567 sgd_solver.cpp:106] Iteration 3200, lr = 1e-05
I0826 18:03:34.109854  4567 solver.cpp:228] Iteration 3250, loss = 8895.63
I0826 18:03:34.109947  4567 solver.cpp:244]     Train net output #0: accuracy = 0.912071
I0826 18:03:34.109958  4567 solver.cpp:244]     Train net output #1: loss = 8895.63 (* 1 = 8895.63 loss)
I0826 18:03:34.109975  4567 sgd_solver.cpp:106] Iteration 3250, lr = 1e-05
I0826 18:04:55.525945  4567 solver.cpp:228] Iteration 3300, loss = 4852.27
I0826 18:04:55.527540  4567 solver.cpp:244]     Train net output #0: accuracy = 0.953166
I0826 18:04:55.527554  4567 solver.cpp:244]     Train net output #1: loss = 4852.27 (* 1 = 4852.27 loss)
I0826 18:04:55.527560  4567 sgd_solver.cpp:106] Iteration 3300, lr = 1e-05
I0826 18:06:13.608057  4567 solver.cpp:228] Iteration 3350, loss = 8522.1
I0826 18:06:13.608160  4567 solver.cpp:244]     Train net output #0: accuracy = 0.920402
I0826 18:06:13.608183  4567 solver.cpp:244]     Train net output #1: loss = 8522.1 (* 1 = 8522.1 loss)
I0826 18:06:13.608196  4567 sgd_solver.cpp:106] Iteration 3350, lr = 1e-05
I0826 18:07:33.617843  4567 solver.cpp:337] Iteration 3400, Testing net (#0)
I0826 18:07:41.437111  4567 solver.cpp:404]     Test net output #0: accuracy = 0.912998
I0826 18:07:41.437153  4567 solver.cpp:404]     Test net output #1: loss = 9186.5 (* 1 = 9186.5 loss)
I0826 18:07:42.768506  4567 solver.cpp:228] Iteration 3400, loss = 6918.87
I0826 18:07:42.768542  4567 solver.cpp:244]     Train net output #0: accuracy = 0.93191
I0826 18:07:42.768550  4567 solver.cpp:244]     Train net output #1: loss = 6918.87 (* 1 = 6918.87 loss)
I0826 18:07:42.768558  4567 sgd_solver.cpp:106] Iteration 3400, lr = 1e-05
I0826 18:09:01.100896  4567 solver.cpp:228] Iteration 3450, loss = 5216.16
I0826 18:09:01.100975  4567 solver.cpp:244]     Train net output #0: accuracy = 0.948544
I0826 18:09:01.100987  4567 solver.cpp:244]     Train net output #1: loss = 5216.16 (* 1 = 5216.16 loss)
I0826 18:09:01.100996  4567 sgd_solver.cpp:106] Iteration 3450, lr = 1e-05
I0826 18:10:19.413231  4567 solver.cpp:228] Iteration 3500, loss = 6926.96
I0826 18:10:19.413303  4567 solver.cpp:244]     Train net output #0: accuracy = 0.932147
I0826 18:10:19.413316  4567 solver.cpp:244]     Train net output #1: loss = 6926.96 (* 1 = 6926.96 loss)
I0826 18:10:19.413321  4567 sgd_solver.cpp:106] Iteration 3500, lr = 1e-05
I0826 18:11:38.925016  4567 solver.cpp:228] Iteration 3550, loss = 4487.08
I0826 18:11:38.925091  4567 solver.cpp:244]     Train net output #0: accuracy = 0.957321
I0826 18:11:38.925101  4567 solver.cpp:244]     Train net output #1: loss = 4487.08 (* 1 = 4487.08 loss)
I0826 18:11:38.925108  4567 sgd_solver.cpp:106] Iteration 3550, lr = 1e-05
I0826 18:12:55.721354  4567 solver.cpp:337] Iteration 3600, Testing net (#0)
I0826 18:13:03.853466  4567 solver.cpp:404]     Test net output #0: accuracy = 0.911518
I0826 18:13:03.853507  4567 solver.cpp:404]     Test net output #1: loss = 9159.14 (* 1 = 9159.14 loss)
I0826 18:13:05.282426  4567 solver.cpp:228] Iteration 3600, loss = 7756.29
I0826 18:13:05.282457  4567 solver.cpp:244]     Train net output #0: accuracy = 0.923722
I0826 18:13:05.282467  4567 solver.cpp:244]     Train net output #1: loss = 7756.29 (* 1 = 7756.29 loss)
I0826 18:13:05.282474  4567 sgd_solver.cpp:106] Iteration 3600, lr = 1e-05
I0826 18:14:23.888312  4567 solver.cpp:228] Iteration 3650, loss = 4630.82
I0826 18:14:23.888396  4567 solver.cpp:244]     Train net output #0: accuracy = 0.95339
I0826 18:14:23.888407  4567 solver.cpp:244]     Train net output #1: loss = 4630.82 (* 1 = 4630.82 loss)
I0826 18:14:23.888413  4567 sgd_solver.cpp:106] Iteration 3650, lr = 1e-05
I0826 18:15:42.802287  4567 solver.cpp:228] Iteration 3700, loss = 8415.07
I0826 18:15:42.802371  4567 solver.cpp:244]     Train net output #0: accuracy = 0.914021
I0826 18:15:42.802384  4567 solver.cpp:244]     Train net output #1: loss = 8415.07 (* 1 = 8415.07 loss)
I0826 18:15:42.802392  4567 sgd_solver.cpp:106] Iteration 3700, lr = 1e-05
I0826 18:17:02.018530  4567 solver.cpp:228] Iteration 3750, loss = 4479.67
I0826 18:17:02.018625  4567 solver.cpp:244]     Train net output #0: accuracy = 0.95667
I0826 18:17:02.018637  4567 solver.cpp:244]     Train net output #1: loss = 4479.67 (* 1 = 4479.67 loss)
I0826 18:17:02.018646  4567 sgd_solver.cpp:106] Iteration 3750, lr = 1e-05
I0826 18:18:18.660231  4567 solver.cpp:337] Iteration 3800, Testing net (#0)
I0826 18:18:26.741654  4567 solver.cpp:404]     Test net output #0: accuracy = 0.918292
I0826 18:18:26.741705  4567 solver.cpp:404]     Test net output #1: loss = 8591.65 (* 1 = 8591.65 loss)
I0826 18:18:28.169608  4567 solver.cpp:228] Iteration 3800, loss = 6562.45
I0826 18:18:28.169643  4567 solver.cpp:244]     Train net output #0: accuracy = 0.937703
I0826 18:18:28.169652  4567 solver.cpp:244]     Train net output #1: loss = 6562.45 (* 1 = 6562.45 loss)
I0826 18:18:28.169658  4567 sgd_solver.cpp:106] Iteration 3800, lr = 1e-05
I0826 18:19:46.545344  4567 solver.cpp:228] Iteration 3850, loss = 9464.23
I0826 18:19:46.545420  4567 solver.cpp:244]     Train net output #0: accuracy = 0.90812
I0826 18:19:46.545433  4567 solver.cpp:244]     Train net output #1: loss = 9464.23 (* 1 = 9464.23 loss)
I0826 18:19:46.545439  4567 sgd_solver.cpp:106] Iteration 3850, lr = 1e-05
I0826 18:21:08.042613  4567 solver.cpp:228] Iteration 3900, loss = 5006.03
I0826 18:21:08.042688  4567 solver.cpp:244]     Train net output #0: accuracy = 0.9513
I0826 18:21:08.042701  4567 solver.cpp:244]     Train net output #1: loss = 5006.03 (* 1 = 5006.03 loss)
I0826 18:21:08.042707  4567 sgd_solver.cpp:106] Iteration 3900, lr = 1e-05
I0826 18:22:25.640933  4567 solver.cpp:228] Iteration 3950, loss = 6143.02
I0826 18:22:25.641033  4567 solver.cpp:244]     Train net output #0: accuracy = 0.939416
I0826 18:22:25.641046  4567 solver.cpp:244]     Train net output #1: loss = 6143.02 (* 1 = 6143.02 loss)
I0826 18:22:25.641052  4567 sgd_solver.cpp:106] Iteration 3950, lr = 1e-05
I0826 18:23:43.326989  4567 solver.cpp:454] Snapshotting to binary proto file portrait_one_stage3_iter_4000.caffemodel
I0826 18:23:43.329710  4567 sgd_solver.cpp:273] Snapshotting solver state to binary proto file portrait_one_stage3_iter_4000.solverstate
I0826 18:23:43.330693  4567 solver.cpp:337] Iteration 4000, Testing net (#0)
I0826 18:23:51.489281  4567 solver.cpp:404]     Test net output #0: accuracy = 0.922355
I0826 18:23:51.489316  4567 solver.cpp:404]     Test net output #1: loss = 8184.84 (* 1 = 8184.84 loss)
I0826 18:23:52.865558  4567 solver.cpp:228] Iteration 4000, loss = 4137.22
I0826 18:23:52.865592  4567 solver.cpp:244]     Train net output #0: accuracy = 0.95962
I0826 18:23:52.865600  4567 solver.cpp:244]     Train net output #1: loss = 4137.22 (* 1 = 4137.22 loss)
I0826 18:23:52.865607  4567 sgd_solver.cpp:106] Iteration 4000, lr = 1e-06
I0826 18:25:09.679157  4567 solver.cpp:228] Iteration 4050, loss = 7014.03
I0826 18:25:09.679241  4567 solver.cpp:244]     Train net output #0: accuracy = 0.929918
I0826 18:25:09.679252  4567 solver.cpp:244]     Train net output #1: loss = 7014.03 (* 1 = 7014.03 loss)
I0826 18:25:09.679258  4567 sgd_solver.cpp:106] Iteration 4050, lr = 1e-06
I0826 18:26:27.870986  4567 solver.cpp:228] Iteration 4100, loss = 3666.91
I0826 18:26:27.871067  4567 solver.cpp:244]     Train net output #0: accuracy = 0.963726
I0826 18:26:27.871078  4567 solver.cpp:244]     Train net output #1: loss = 3666.91 (* 1 = 3666.91 loss)
I0826 18:26:27.871085  4567 sgd_solver.cpp:106] Iteration 4100, lr = 1e-06
I0826 18:27:46.038211  4567 solver.cpp:228] Iteration 4150, loss = 8069.71
I0826 18:27:46.038296  4567 solver.cpp:244]     Train net output #0: accuracy = 0.920436
I0826 18:27:46.038310  4567 solver.cpp:244]     Train net output #1: loss = 8069.71 (* 1 = 8069.71 loss)
I0826 18:27:46.038317  4567 sgd_solver.cpp:106] Iteration 4150, lr = 1e-06
I0826 18:29:03.034757  4567 solver.cpp:337] Iteration 4200, Testing net (#0)
I0826 18:29:11.101722  4567 solver.cpp:404]     Test net output #0: accuracy = 0.932688
I0826 18:29:11.101763  4567 solver.cpp:404]     Test net output #1: loss = 7183.98 (* 1 = 7183.98 loss)
I0826 18:29:12.545449  4567 solver.cpp:228] Iteration 4200, loss = 8150.3
I0826 18:29:12.545482  4567 solver.cpp:244]     Train net output #0: accuracy = 0.918535
I0826 18:29:12.545491  4567 solver.cpp:244]     Train net output #1: loss = 8150.3 (* 1 = 8150.3 loss)
I0826 18:29:12.545497  4567 sgd_solver.cpp:106] Iteration 4200, lr = 1e-06
I0826 18:30:30.557271  4567 solver.cpp:228] Iteration 4250, loss = 4323.74
I0826 18:30:30.557400  4567 solver.cpp:244]     Train net output #0: accuracy = 0.957635
I0826 18:30:30.557418  4567 solver.cpp:244]     Train net output #1: loss = 4323.74 (* 1 = 4323.74 loss)
I0826 18:30:30.557430  4567 sgd_solver.cpp:106] Iteration 4250, lr = 1e-06
I0826 18:31:50.300845  4567 solver.cpp:228] Iteration 4300, loss = 9108.98
I0826 18:31:50.300922  4567 solver.cpp:244]     Train net output #0: accuracy = 0.910003
I0826 18:31:50.300935  4567 solver.cpp:244]     Train net output #1: loss = 9108.98 (* 1 = 9108.98 loss)
I0826 18:31:50.300940  4567 sgd_solver.cpp:106] Iteration 4300, lr = 1e-06
I0826 18:33:09.391661  4567 solver.cpp:228] Iteration 4350, loss = 4801.26
I0826 18:33:09.391762  4567 solver.cpp:244]     Train net output #0: accuracy = 0.953619
I0826 18:33:09.391774  4567 solver.cpp:244]     Train net output #1: loss = 4801.26 (* 1 = 4801.26 loss)
I0826 18:33:09.391782  4567 sgd_solver.cpp:106] Iteration 4350, lr = 1e-06
I0826 18:34:26.273819  4567 solver.cpp:337] Iteration 4400, Testing net (#0)
I0826 18:34:34.322481  4567 solver.cpp:404]     Test net output #0: accuracy = 0.930027
I0826 18:34:34.322536  4567 solver.cpp:404]     Test net output #1: loss = 7357.7 (* 1 = 7357.7 loss)
I0826 18:34:35.753370  4567 solver.cpp:228] Iteration 4400, loss = 7441.13
I0826 18:34:35.753415  4567 solver.cpp:244]     Train net output #0: accuracy = 0.928653
I0826 18:34:35.753429  4567 solver.cpp:244]     Train net output #1: loss = 7441.13 (* 1 = 7441.13 loss)
I0826 18:34:35.753438  4567 sgd_solver.cpp:106] Iteration 4400, lr = 1e-06
I0826 18:35:53.709597  4567 solver.cpp:228] Iteration 4450, loss = 3645.41
I0826 18:35:53.709674  4567 solver.cpp:244]     Train net output #0: accuracy = 0.96451
I0826 18:35:53.709686  4567 solver.cpp:244]     Train net output #1: loss = 3645.41 (* 1 = 3645.41 loss)
I0826 18:35:53.709692  4567 sgd_solver.cpp:106] Iteration 4450, lr = 1e-06
I0826 18:37:11.826727  4567 solver.cpp:228] Iteration 4500, loss = 6925.98
I0826 18:37:11.826812  4567 solver.cpp:244]     Train net output #0: accuracy = 0.932361
I0826 18:37:11.826823  4567 solver.cpp:244]     Train net output #1: loss = 6925.98 (* 1 = 6925.98 loss)
I0826 18:37:11.826830  4567 sgd_solver.cpp:106] Iteration 4500, lr = 1e-06
I0826 18:38:30.209317  4567 solver.cpp:228] Iteration 4550, loss = 5266.85
I0826 18:38:30.209398  4567 solver.cpp:244]     Train net output #0: accuracy = 0.947825
I0826 18:38:30.209408  4567 solver.cpp:244]     Train net output #1: loss = 5266.85 (* 1 = 5266.85 loss)
I0826 18:38:30.209415  4567 sgd_solver.cpp:106] Iteration 4550, lr = 1e-06
I0826 18:39:47.124713  4567 solver.cpp:337] Iteration 4600, Testing net (#0)
I0826 18:39:55.418637  4567 solver.cpp:404]     Test net output #0: accuracy = 0.933272
I0826 18:39:55.418691  4567 solver.cpp:404]     Test net output #1: loss = 7033.97 (* 1 = 7033.97 loss)
I0826 18:39:56.816738  4567 solver.cpp:228] Iteration 4600, loss = 4234.93
I0826 18:39:56.816788  4567 solver.cpp:244]     Train net output #0: accuracy = 0.958539
I0826 18:39:56.816804  4567 solver.cpp:244]     Train net output #1: loss = 4234.93 (* 1 = 4234.93 loss)
I0826 18:39:56.816812  4567 sgd_solver.cpp:106] Iteration 4600, lr = 1e-06
I0826 18:41:15.592846  4567 solver.cpp:228] Iteration 4650, loss = 7995.15
I0826 18:41:15.592924  4567 solver.cpp:244]     Train net output #0: accuracy = 0.920269
I0826 18:41:15.592936  4567 solver.cpp:244]     Train net output #1: loss = 7995.15 (* 1 = 7995.15 loss)
I0826 18:41:15.592942  4567 sgd_solver.cpp:106] Iteration 4650, lr = 1e-06
I0826 18:42:34.335445  4567 solver.cpp:228] Iteration 4700, loss = 4383.28
I0826 18:42:34.335528  4567 solver.cpp:244]     Train net output #0: accuracy = 0.956035
I0826 18:42:34.335539  4567 solver.cpp:244]     Train net output #1: loss = 4383.28 (* 1 = 4383.28 loss)
I0826 18:42:34.335546  4567 sgd_solver.cpp:106] Iteration 4700, lr = 1e-06
I0826 18:43:52.350373  4567 solver.cpp:228] Iteration 4750, loss = 8629.39
I0826 18:43:52.350481  4567 solver.cpp:244]     Train net output #0: accuracy = 0.917456
I0826 18:43:52.350497  4567 solver.cpp:244]     Train net output #1: loss = 8629.39 (* 1 = 8629.39 loss)
I0826 18:43:52.350504  4567 sgd_solver.cpp:106] Iteration 4750, lr = 1e-06
I0826 18:45:11.413645  4567 solver.cpp:337] Iteration 4800, Testing net (#0)
I0826 18:45:19.715586  4567 solver.cpp:404]     Test net output #0: accuracy = 0.932617
I0826 18:45:19.715627  4567 solver.cpp:404]     Test net output #1: loss = 7083.07 (* 1 = 7083.07 loss)
I0826 18:45:21.158843  4567 solver.cpp:228] Iteration 4800, loss = 4555.96
I0826 18:45:21.158879  4567 solver.cpp:244]     Train net output #0: accuracy = 0.955378
I0826 18:45:21.158888  4567 solver.cpp:244]     Train net output #1: loss = 4555.96 (* 1 = 4555.96 loss)
I0826 18:45:21.158895  4567 sgd_solver.cpp:106] Iteration 4800, lr = 1e-06
I0826 18:46:39.567131  4567 solver.cpp:228] Iteration 4850, loss = 6234.83
I0826 18:46:39.567208  4567 solver.cpp:244]     Train net output #0: accuracy = 0.941029
I0826 18:46:39.567219  4567 solver.cpp:244]     Train net output #1: loss = 6234.83 (* 1 = 6234.83 loss)
I0826 18:46:39.567225  4567 sgd_solver.cpp:106] Iteration 4850, lr = 1e-06
I0826 18:47:57.254194  4567 solver.cpp:228] Iteration 4900, loss = 3827.95
I0826 18:47:57.254276  4567 solver.cpp:244]     Train net output #0: accuracy = 0.962832
I0826 18:47:57.254287  4567 solver.cpp:244]     Train net output #1: loss = 3827.95 (* 1 = 3827.95 loss)
I0826 18:47:57.254294  4567 sgd_solver.cpp:106] Iteration 4900, lr = 1e-06
I0826 18:49:14.989619  4567 solver.cpp:228] Iteration 4950, loss = 5109.2
I0826 18:49:14.989722  4567 solver.cpp:244]     Train net output #0: accuracy = 0.950326
I0826 18:49:14.989737  4567 solver.cpp:244]     Train net output #1: loss = 5109.2 (* 1 = 5109.2 loss)
I0826 18:49:14.989748  4567 sgd_solver.cpp:106] Iteration 4950, lr = 1e-06
I0826 18:50:31.897627  4567 solver.cpp:337] Iteration 5000, Testing net (#0)
I0826 18:50:40.108930  4567 solver.cpp:404]     Test net output #0: accuracy = 0.933546
I0826 18:50:40.108973  4567 solver.cpp:404]     Test net output #1: loss = 6952.84 (* 1 = 6952.84 loss)
I0826 18:50:41.511404  4567 solver.cpp:228] Iteration 5000, loss = 6688.82
I0826 18:50:41.511450  4567 solver.cpp:244]     Train net output #0: accuracy = 0.931921
I0826 18:50:41.511463  4567 solver.cpp:244]     Train net output #1: loss = 6688.82 (* 1 = 6688.82 loss)
I0826 18:50:41.511471  4567 sgd_solver.cpp:106] Iteration 5000, lr = 1e-06
I0826 18:51:59.053038  4567 solver.cpp:228] Iteration 5050, loss = 3995.06
I0826 18:51:59.053114  4567 solver.cpp:244]     Train net output #0: accuracy = 0.961204
I0826 18:51:59.053127  4567 solver.cpp:244]     Train net output #1: loss = 3995.06 (* 1 = 3995.06 loss)
I0826 18:51:59.053133  4567 sgd_solver.cpp:106] Iteration 5050, lr = 1e-06
I0826 18:53:17.434131  4567 solver.cpp:228] Iteration 5100, loss = 9044.01
I0826 18:53:17.434208  4567 solver.cpp:244]     Train net output #0: accuracy = 0.910262
I0826 18:53:17.434221  4567 solver.cpp:244]     Train net output #1: loss = 9044.01 (* 1 = 9044.01 loss)
I0826 18:53:17.434227  4567 sgd_solver.cpp:106] Iteration 5100, lr = 1e-06
I0826 18:54:36.997128  4567 solver.cpp:228] Iteration 5150, loss = 4888.7
I0826 18:54:36.997222  4567 solver.cpp:244]     Train net output #0: accuracy = 0.952732
I0826 18:54:36.997236  4567 solver.cpp:244]     Train net output #1: loss = 4888.7 (* 1 = 4888.7 loss)
I0826 18:54:36.997246  4567 sgd_solver.cpp:106] Iteration 5150, lr = 1e-06
I0826 18:55:54.012650  4567 solver.cpp:337] Iteration 5200, Testing net (#0)
I0826 18:56:02.125211  4567 solver.cpp:404]     Test net output #0: accuracy = 0.934968
I0826 18:56:02.125258  4567 solver.cpp:404]     Test net output #1: loss = 6829.32 (* 1 = 6829.32 loss)
I0826 18:56:03.461482  4567 solver.cpp:228] Iteration 5200, loss = 8530.66
I0826 18:56:03.461519  4567 solver.cpp:244]     Train net output #0: accuracy = 0.919239
I0826 18:56:03.461529  4567 solver.cpp:244]     Train net output #1: loss = 8530.66 (* 1 = 8530.66 loss)
I0826 18:56:03.461536  4567 sgd_solver.cpp:106] Iteration 5200, lr = 1e-06
I0826 18:57:21.185163  4567 solver.cpp:228] Iteration 5250, loss = 4859.28
I0826 18:57:21.185263  4567 solver.cpp:244]     Train net output #0: accuracy = 0.953277
I0826 18:57:21.185276  4567 solver.cpp:244]     Train net output #1: loss = 4859.28 (* 1 = 4859.28 loss)
I0826 18:57:21.185282  4567 sgd_solver.cpp:106] Iteration 5250, lr = 1e-06
I0826 18:58:38.458601  4567 solver.cpp:228] Iteration 5300, loss = 5715.58
I0826 18:58:38.458688  4567 solver.cpp:244]     Train net output #0: accuracy = 0.94428
I0826 18:58:38.458700  4567 solver.cpp:244]     Train net output #1: loss = 5715.58 (* 1 = 5715.58 loss)
I0826 18:58:38.458708  4567 sgd_solver.cpp:106] Iteration 5300, lr = 1e-06
I0826 18:59:59.570170  4567 solver.cpp:228] Iteration 5350, loss = 6703.35
I0826 18:59:59.570250  4567 solver.cpp:244]     Train net output #0: accuracy = 0.935372
I0826 18:59:59.570264  4567 solver.cpp:244]     Train net output #1: loss = 6703.35 (* 1 = 6703.35 loss)
I0826 18:59:59.570273  4567 sgd_solver.cpp:106] Iteration 5350, lr = 1e-06
I0826 19:01:27.572839  4567 solver.cpp:337] Iteration 5400, Testing net (#0)
I0826 19:01:35.834041  4567 solver.cpp:404]     Test net output #0: accuracy = 0.932221
I0826 19:01:35.834085  4567 solver.cpp:404]     Test net output #1: loss = 7082.85 (* 1 = 7082.85 loss)
I0826 19:01:37.251456  4567 solver.cpp:228] Iteration 5400, loss = 3597.51
I0826 19:01:37.251499  4567 solver.cpp:244]     Train net output #0: accuracy = 0.965189
I0826 19:01:37.251514  4567 solver.cpp:244]     Train net output #1: loss = 3597.51 (* 1 = 3597.51 loss)
I0826 19:01:37.251523  4567 sgd_solver.cpp:106] Iteration 5400, lr = 1e-06
I0826 19:02:54.905730  4567 solver.cpp:228] Iteration 5450, loss = 6519.56
I0826 19:02:54.905828  4567 solver.cpp:244]     Train net output #0: accuracy = 0.934549
I0826 19:02:54.905840  4567 solver.cpp:244]     Train net output #1: loss = 6519.56 (* 1 = 6519.56 loss)
I0826 19:02:54.905848  4567 sgd_solver.cpp:106] Iteration 5450, lr = 1e-06
I0826 19:04:12.773437  4567 solver.cpp:228] Iteration 5500, loss = 4085.19
I0826 19:04:12.773526  4567 solver.cpp:244]     Train net output #0: accuracy = 0.958235
I0826 19:04:12.773538  4567 solver.cpp:244]     Train net output #1: loss = 4085.19 (* 1 = 4085.19 loss)
I0826 19:04:12.773545  4567 sgd_solver.cpp:106] Iteration 5500, lr = 1e-06
I0826 19:05:30.211802  4567 solver.cpp:228] Iteration 5550, loss = 8177.75
I0826 19:05:30.211872  4567 solver.cpp:244]     Train net output #0: accuracy = 0.919374
I0826 19:05:30.211884  4567 solver.cpp:244]     Train net output #1: loss = 8177.75 (* 1 = 8177.75 loss)
I0826 19:05:30.211890  4567 sgd_solver.cpp:106] Iteration 5550, lr = 1e-06
I0826 19:06:46.551199  4567 solver.cpp:337] Iteration 5600, Testing net (#0)
I0826 19:06:54.727980  4567 solver.cpp:404]     Test net output #0: accuracy = 0.935453
I0826 19:06:54.728018  4567 solver.cpp:404]     Test net output #1: loss = 6752.89 (* 1 = 6752.89 loss)
I0826 19:06:56.139554  4567 solver.cpp:228] Iteration 5600, loss = 4137.32
I0826 19:06:56.139591  4567 solver.cpp:244]     Train net output #0: accuracy = 0.959288
I0826 19:06:56.139600  4567 solver.cpp:244]     Train net output #1: loss = 4137.32 (* 1 = 4137.32 loss)
I0826 19:06:56.139606  4567 sgd_solver.cpp:106] Iteration 5600, lr = 1e-06
I0826 19:08:14.146770  4567 solver.cpp:228] Iteration 5650, loss = 7556.39
I0826 19:08:14.146844  4567 solver.cpp:244]     Train net output #0: accuracy = 0.927982
I0826 19:08:14.146857  4567 solver.cpp:244]     Train net output #1: loss = 7556.39 (* 1 = 7556.39 loss)
I0826 19:08:14.146863  4567 sgd_solver.cpp:106] Iteration 5650, lr = 1e-06
I0826 19:09:30.703640  4567 solver.cpp:228] Iteration 5700, loss = 6486.61
I0826 19:09:30.703752  4567 solver.cpp:244]     Train net output #0: accuracy = 0.93706
I0826 19:09:30.703769  4567 solver.cpp:244]     Train net output #1: loss = 6486.61 (* 1 = 6486.61 loss)
I0826 19:09:30.703781  4567 sgd_solver.cpp:106] Iteration 5700, lr = 1e-06
I0826 19:10:48.935698  4567 solver.cpp:228] Iteration 5750, loss = 4542.31
I0826 19:10:48.935825  4567 solver.cpp:244]     Train net output #0: accuracy = 0.955568
I0826 19:10:48.935838  4567 solver.cpp:244]     Train net output #1: loss = 4542.31 (* 1 = 4542.31 loss)
I0826 19:10:48.935847  4567 sgd_solver.cpp:106] Iteration 5750, lr = 1e-06
I0826 19:12:06.159592  4567 solver.cpp:337] Iteration 5800, Testing net (#0)
I0826 19:12:14.387465  4567 solver.cpp:404]     Test net output #0: accuracy = 0.934301
I0826 19:12:14.387503  4567 solver.cpp:404]     Test net output #1: loss = 6880.65 (* 1 = 6880.65 loss)
I0826 19:12:15.867496  4567 solver.cpp:228] Iteration 5800, loss = 5919.08
I0826 19:12:15.867530  4567 solver.cpp:244]     Train net output #0: accuracy = 0.94145
I0826 19:12:15.867539  4567 solver.cpp:244]     Train net output #1: loss = 5919.08 (* 1 = 5919.08 loss)
I0826 19:12:15.867547  4567 sgd_solver.cpp:106] Iteration 5800, lr = 1e-06
I0826 19:13:34.094451  4567 solver.cpp:228] Iteration 5850, loss = 3725.9
I0826 19:13:34.094537  4567 solver.cpp:244]     Train net output #0: accuracy = 0.963782
I0826 19:13:34.094553  4567 solver.cpp:244]     Train net output #1: loss = 3725.9 (* 1 = 3725.9 loss)
I0826 19:13:34.094563  4567 sgd_solver.cpp:106] Iteration 5850, lr = 1e-06
I0826 19:14:52.105770  4567 solver.cpp:228] Iteration 5900, loss = 7076.6
I0826 19:14:52.105859  4567 solver.cpp:244]     Train net output #0: accuracy = 0.930297
I0826 19:14:52.105870  4567 solver.cpp:244]     Train net output #1: loss = 7076.6 (* 1 = 7076.6 loss)
I0826 19:14:52.105877  4567 sgd_solver.cpp:106] Iteration 5900, lr = 1e-06
I0826 19:16:09.101814  4567 solver.cpp:228] Iteration 5950, loss = 4238.86
I0826 19:16:09.101886  4567 solver.cpp:244]     Train net output #0: accuracy = 0.957334
I0826 19:16:09.101897  4567 solver.cpp:244]     Train net output #1: loss = 4238.86 (* 1 = 4238.86 loss)
I0826 19:16:09.101904  4567 sgd_solver.cpp:106] Iteration 5950, lr = 1e-06
I0826 19:17:27.433320  4567 solver.cpp:337] Iteration 6000, Testing net (#0)
I0826 19:17:35.389461  4567 solver.cpp:404]     Test net output #0: accuracy = 0.935581
I0826 19:17:35.389511  4567 solver.cpp:404]     Test net output #1: loss = 6749.56 (* 1 = 6749.56 loss)
I0826 19:17:36.848577  4567 solver.cpp:228] Iteration 6000, loss = 7064.61
I0826 19:17:36.848615  4567 solver.cpp:244]     Train net output #0: accuracy = 0.929584
I0826 19:17:36.848624  4567 solver.cpp:244]     Train net output #1: loss = 7064.61 (* 1 = 7064.61 loss)
I0826 19:17:36.848631  4567 sgd_solver.cpp:106] Iteration 6000, lr = 1e-06
I0826 19:18:54.964161  4567 solver.cpp:228] Iteration 6050, loss = 3944.46
I0826 19:18:54.964227  4567 solver.cpp:244]     Train net output #0: accuracy = 0.961365
I0826 19:18:54.964238  4567 solver.cpp:244]     Train net output #1: loss = 3944.46 (* 1 = 3944.46 loss)
I0826 19:18:54.964246  4567 sgd_solver.cpp:106] Iteration 6050, lr = 1e-06
I0826 19:20:13.441206  4567 solver.cpp:228] Iteration 6100, loss = 4911.29
I0826 19:20:13.441295  4567 solver.cpp:244]     Train net output #0: accuracy = 0.951686
I0826 19:20:13.441310  4567 solver.cpp:244]     Train net output #1: loss = 4911.29 (* 1 = 4911.29 loss)
I0826 19:20:13.441320  4567 sgd_solver.cpp:106] Iteration 6100, lr = 1e-06
I0826 19:21:31.907001  4567 solver.cpp:228] Iteration 6150, loss = 8572.6
I0826 19:21:31.907076  4567 solver.cpp:244]     Train net output #0: accuracy = 0.915436
I0826 19:21:31.907088  4567 solver.cpp:244]     Train net output #1: loss = 8572.6 (* 1 = 8572.6 loss)
I0826 19:21:31.907094  4567 sgd_solver.cpp:106] Iteration 6150, lr = 1e-06
I0826 19:22:47.921113  4567 solver.cpp:337] Iteration 6200, Testing net (#0)
I0826 19:22:55.325855  4567 solver.cpp:404]     Test net output #0: accuracy = 0.937025
I0826 19:22:55.325894  4567 solver.cpp:404]     Test net output #1: loss = 6608.75 (* 1 = 6608.75 loss)
I0826 19:22:56.657120  4567 solver.cpp:228] Iteration 6200, loss = 4570.64
I0826 19:22:56.657157  4567 solver.cpp:244]     Train net output #0: accuracy = 0.955791
I0826 19:22:56.657166  4567 solver.cpp:244]     Train net output #1: loss = 4570.64 (* 1 = 4570.64 loss)
I0826 19:22:56.657183  4567 sgd_solver.cpp:106] Iteration 6200, lr = 1e-06
I0826 19:24:15.030827  4567 solver.cpp:228] Iteration 6250, loss = 5935.32
I0826 19:24:15.030956  4567 solver.cpp:244]     Train net output #0: accuracy = 0.943063
I0826 19:24:15.030974  4567 solver.cpp:244]     Train net output #1: loss = 5935.32 (* 1 = 5935.32 loss)
I0826 19:24:15.030983  4567 sgd_solver.cpp:106] Iteration 6250, lr = 1e-06
I0826 19:25:33.394315  4567 solver.cpp:228] Iteration 6300, loss = 3798.3
I0826 19:25:33.394397  4567 solver.cpp:244]     Train net output #0: accuracy = 0.96332
I0826 19:25:33.394408  4567 solver.cpp:244]     Train net output #1: loss = 3798.3 (* 1 = 3798.3 loss)
I0826 19:25:33.394415  4567 sgd_solver.cpp:106] Iteration 6300, lr = 1e-06
I0826 19:26:51.803453  4567 solver.cpp:228] Iteration 6350, loss = 6680.56
I0826 19:26:51.803527  4567 solver.cpp:244]     Train net output #0: accuracy = 0.932561
I0826 19:26:51.803539  4567 solver.cpp:244]     Train net output #1: loss = 6680.56 (* 1 = 6680.56 loss)
I0826 19:26:51.803546  4567 sgd_solver.cpp:106] Iteration 6350, lr = 1e-06
I0826 19:28:08.827718  4567 solver.cpp:337] Iteration 6400, Testing net (#0)
I0826 19:28:16.814314  4567 solver.cpp:404]     Test net output #0: accuracy = 0.932733
I0826 19:28:16.814355  4567 solver.cpp:404]     Test net output #1: loss = 7049.76 (* 1 = 7049.76 loss)
I0826 19:28:18.248874  4567 solver.cpp:228] Iteration 6400, loss = 3575.87
I0826 19:28:18.248914  4567 solver.cpp:244]     Train net output #0: accuracy = 0.965173
I0826 19:28:18.248924  4567 solver.cpp:244]     Train net output #1: loss = 3575.87 (* 1 = 3575.87 loss)
I0826 19:28:18.248931  4567 sgd_solver.cpp:106] Iteration 6400, lr = 1e-06
I0826 19:29:36.745223  4567 solver.cpp:228] Iteration 6450, loss = 7126.79
I0826 19:29:36.745317  4567 solver.cpp:244]     Train net output #0: accuracy = 0.931469
I0826 19:29:36.745337  4567 solver.cpp:244]     Train net output #1: loss = 7126.79 (* 1 = 7126.79 loss)
I0826 19:29:36.745348  4567 sgd_solver.cpp:106] Iteration 6450, lr = 1e-06
I0826 19:30:54.812405  4567 solver.cpp:228] Iteration 6500, loss = 7772.25
I0826 19:30:54.812496  4567 solver.cpp:244]     Train net output #0: accuracy = 0.923833
I0826 19:30:54.812511  4567 solver.cpp:244]     Train net output #1: loss = 7772.25 (* 1 = 7772.25 loss)
I0826 19:30:54.812521  4567 sgd_solver.cpp:106] Iteration 6500, lr = 1e-06
I0826 19:32:12.658586  4567 solver.cpp:228] Iteration 6550, loss = 4180.17
I0826 19:32:12.658663  4567 solver.cpp:244]     Train net output #0: accuracy = 0.959101
I0826 19:32:12.658674  4567 solver.cpp:244]     Train net output #1: loss = 4180.17 (* 1 = 4180.17 loss)
I0826 19:32:12.658680  4567 sgd_solver.cpp:106] Iteration 6550, lr = 1e-06
I0826 19:33:28.621186  4567 solver.cpp:337] Iteration 6600, Testing net (#0)
I0826 19:33:36.585863  4567 solver.cpp:404]     Test net output #0: accuracy = 0.9365
I0826 19:33:36.585904  4567 solver.cpp:404]     Test net output #1: loss = 6647.14 (* 1 = 6647.14 loss)
I0826 19:33:37.980670  4567 solver.cpp:228] Iteration 6600, loss = 8416.66
I0826 19:33:37.980700  4567 solver.cpp:244]     Train net output #0: accuracy = 0.917468
I0826 19:33:37.980710  4567 solver.cpp:244]     Train net output #1: loss = 8416.66 (* 1 = 8416.66 loss)
I0826 19:33:37.980716  4567 sgd_solver.cpp:106] Iteration 6600, lr = 1e-06
I0826 19:34:58.322816  4567 solver.cpp:228] Iteration 6650, loss = 4437.97
I0826 19:34:58.322909  4567 solver.cpp:244]     Train net output #0: accuracy = 0.957289
I0826 19:34:58.322926  4567 solver.cpp:244]     Train net output #1: loss = 4437.97 (* 1 = 4437.97 loss)
I0826 19:34:58.322934  4567 sgd_solver.cpp:106] Iteration 6650, lr = 1e-06
I0826 19:36:16.565719  4567 solver.cpp:228] Iteration 6700, loss = 6837.66
I0826 19:36:16.565814  4567 solver.cpp:244]     Train net output #0: accuracy = 0.93358
I0826 19:36:16.565826  4567 solver.cpp:244]     Train net output #1: loss = 6837.66 (* 1 = 6837.66 loss)
I0826 19:36:16.565834  4567 sgd_solver.cpp:106] Iteration 6700, lr = 1e-06
I0826 19:37:34.728971  4567 solver.cpp:228] Iteration 6750, loss = 3440.87
I0826 19:37:34.729076  4567 solver.cpp:244]     Train net output #0: accuracy = 0.965945
I0826 19:37:34.729089  4567 solver.cpp:244]     Train net output #1: loss = 3440.87 (* 1 = 3440.87 loss)
I0826 19:37:34.729095  4567 sgd_solver.cpp:106] Iteration 6750, lr = 1e-06
I0826 19:38:52.506304  4567 solver.cpp:337] Iteration 6800, Testing net (#0)
I0826 19:39:00.407902  4567 solver.cpp:404]     Test net output #0: accuracy = 0.934067
I0826 19:39:00.407943  4567 solver.cpp:404]     Test net output #1: loss = 6874.24 (* 1 = 6874.24 loss)
I0826 19:39:01.776645  4567 solver.cpp:228] Iteration 6800, loss = 6620.77
I0826 19:39:01.776686  4567 solver.cpp:244]     Train net output #0: accuracy = 0.934004
I0826 19:39:01.776696  4567 solver.cpp:244]     Train net output #1: loss = 6620.77 (* 1 = 6620.77 loss)
I0826 19:39:01.776703  4567 sgd_solver.cpp:106] Iteration 6800, lr = 1e-06
I0826 19:40:19.295385  4567 solver.cpp:228] Iteration 6850, loss = 5483.52
I0826 19:40:19.295481  4567 solver.cpp:244]     Train net output #0: accuracy = 0.945716
I0826 19:40:19.295500  4567 solver.cpp:244]     Train net output #1: loss = 5483.52 (* 1 = 5483.52 loss)
I0826 19:40:19.295509  4567 sgd_solver.cpp:106] Iteration 6850, lr = 1e-06
I0826 19:41:37.102892  4567 solver.cpp:228] Iteration 6900, loss = 3930.39
I0826 19:41:37.102989  4567 solver.cpp:244]     Train net output #0: accuracy = 0.960921
I0826 19:41:37.103001  4567 solver.cpp:244]     Train net output #1: loss = 3930.39 (* 1 = 3930.39 loss)
I0826 19:41:37.103009  4567 sgd_solver.cpp:106] Iteration 6900, lr = 1e-06
I0826 19:42:55.651759  4567 solver.cpp:228] Iteration 6950, loss = 7927.77
I0826 19:42:55.651845  4567 solver.cpp:244]     Train net output #0: accuracy = 0.91952
I0826 19:42:55.651856  4567 solver.cpp:244]     Train net output #1: loss = 7927.77 (* 1 = 7927.77 loss)
I0826 19:42:55.651862  4567 sgd_solver.cpp:106] Iteration 6950, lr = 1e-06
I0826 19:44:12.566463  4567 solver.cpp:337] Iteration 7000, Testing net (#0)
I0826 19:44:20.279342  4567 solver.cpp:404]     Test net output #0: accuracy = 0.936221
I0826 19:44:20.279383  4567 solver.cpp:404]     Test net output #1: loss = 6682.26 (* 1 = 6682.26 loss)
I0826 19:44:21.634481  4567 solver.cpp:228] Iteration 7000, loss = 4143.34
I0826 19:44:21.634516  4567 solver.cpp:244]     Train net output #0: accuracy = 0.958207
I0826 19:44:21.634526  4567 solver.cpp:244]     Train net output #1: loss = 4143.34 (* 1 = 4143.34 loss)
I0826 19:44:21.634531  4567 sgd_solver.cpp:106] Iteration 7000, lr = 1e-06
I0826 19:45:39.839336  4567 solver.cpp:228] Iteration 7050, loss = 7830.1
I0826 19:45:39.839414  4567 solver.cpp:244]     Train net output #0: accuracy = 0.926271
I0826 19:45:39.839426  4567 solver.cpp:244]     Train net output #1: loss = 7830.1 (* 1 = 7830.1 loss)
I0826 19:45:39.839432  4567 sgd_solver.cpp:106] Iteration 7050, lr = 1e-06
I0826 19:46:58.554494  4567 solver.cpp:228] Iteration 7100, loss = 4524.61
I0826 19:46:58.554576  4567 solver.cpp:244]     Train net output #0: accuracy = 0.955896
I0826 19:46:58.554589  4567 solver.cpp:244]     Train net output #1: loss = 4524.61 (* 1 = 4524.61 loss)
I0826 19:46:58.554594  4567 sgd_solver.cpp:106] Iteration 7100, lr = 1e-06
I0826 19:48:16.754134  4567 solver.cpp:228] Iteration 7150, loss = 6054.29
I0826 19:48:16.754202  4567 solver.cpp:244]     Train net output #0: accuracy = 0.941988
I0826 19:48:16.754214  4567 solver.cpp:244]     Train net output #1: loss = 6054.29 (* 1 = 6054.29 loss)
I0826 19:48:16.754220  4567 sgd_solver.cpp:106] Iteration 7150, lr = 1e-06
I0826 19:49:32.871332  4567 solver.cpp:337] Iteration 7200, Testing net (#0)
I0826 19:49:40.750771  4567 solver.cpp:404]     Test net output #0: accuracy = 0.936135
I0826 19:49:40.750823  4567 solver.cpp:404]     Test net output #1: loss = 6706.04 (* 1 = 6706.04 loss)
I0826 19:49:42.150985  4567 solver.cpp:228] Iteration 7200, loss = 3554.95
I0826 19:49:42.151032  4567 solver.cpp:244]     Train net output #0: accuracy = 0.965435
I0826 19:49:42.151048  4567 solver.cpp:244]     Train net output #1: loss = 3554.95 (* 1 = 3554.95 loss)
I0826 19:49:42.151075  4567 sgd_solver.cpp:106] Iteration 7200, lr = 1e-06
I0826 19:50:59.742903  4567 solver.cpp:228] Iteration 7250, loss = 4338.27
I0826 19:50:59.743017  4567 solver.cpp:244]     Train net output #0: accuracy = 0.957132
I0826 19:50:59.743029  4567 solver.cpp:244]     Train net output #1: loss = 4338.27 (* 1 = 4338.27 loss)
I0826 19:50:59.743037  4567 sgd_solver.cpp:106] Iteration 7250, lr = 1e-06
I0826 19:52:17.300940  4567 solver.cpp:228] Iteration 7300, loss = 6437.91
I0826 19:52:17.301013  4567 solver.cpp:244]     Train net output #0: accuracy = 0.93484
I0826 19:52:17.301024  4567 solver.cpp:244]     Train net output #1: loss = 6437.91 (* 1 = 6437.91 loss)
I0826 19:52:17.301031  4567 sgd_solver.cpp:106] Iteration 7300, lr = 1e-06
I0826 19:53:37.540132  4567 solver.cpp:228] Iteration 7350, loss = 3993.55
I0826 19:53:37.540195  4567 solver.cpp:244]     Train net output #0: accuracy = 0.960535
I0826 19:53:37.540206  4567 solver.cpp:244]     Train net output #1: loss = 3993.55 (* 1 = 3993.55 loss)
I0826 19:53:37.540213  4567 sgd_solver.cpp:106] Iteration 7350, lr = 1e-06
I0826 19:54:53.310186  4567 solver.cpp:337] Iteration 7400, Testing net (#0)
I0826 19:55:01.547324  4567 solver.cpp:404]     Test net output #0: accuracy = 0.933991
I0826 19:55:01.547363  4567 solver.cpp:404]     Test net output #1: loss = 6950.59 (* 1 = 6950.59 loss)
I0826 19:55:02.985949  4567 solver.cpp:228] Iteration 7400, loss = 7821.91
I0826 19:55:02.985986  4567 solver.cpp:244]     Train net output #0: accuracy = 0.92233
I0826 19:55:02.985996  4567 solver.cpp:244]     Train net output #1: loss = 7821.91 (* 1 = 7821.91 loss)
I0826 19:55:02.986003  4567 sgd_solver.cpp:106] Iteration 7400, lr = 1e-06
I0826 19:56:20.852325  4567 solver.cpp:228] Iteration 7450, loss = 4669.1
I0826 19:56:20.852397  4567 solver.cpp:244]     Train net output #0: accuracy = 0.954519
I0826 19:56:20.852408  4567 solver.cpp:244]     Train net output #1: loss = 4669.1 (* 1 = 4669.1 loss)
I0826 19:56:20.852416  4567 sgd_solver.cpp:106] Iteration 7450, lr = 1e-06
I0826 19:57:38.799448  4567 solver.cpp:228] Iteration 7500, loss = 8523.36
I0826 19:57:38.800951  4567 solver.cpp:244]     Train net output #0: accuracy = 0.91946
I0826 19:57:38.800962  4567 solver.cpp:244]     Train net output #1: loss = 8523.36 (* 1 = 8523.36 loss)
I0826 19:57:38.800969  4567 sgd_solver.cpp:106] Iteration 7500, lr = 1e-06
I0826 19:58:57.550629  4567 solver.cpp:228] Iteration 7550, loss = 4627.55
I0826 19:58:57.550719  4567 solver.cpp:244]     Train net output #0: accuracy = 0.954944
I0826 19:58:57.550734  4567 solver.cpp:244]     Train net output #1: loss = 4627.55 (* 1 = 4627.55 loss)
I0826 19:58:57.550742  4567 sgd_solver.cpp:106] Iteration 7550, lr = 1e-06
I0826 20:00:15.143097  4567 solver.cpp:337] Iteration 7600, Testing net (#0)
I0826 20:00:23.215488  4567 solver.cpp:404]     Test net output #0: accuracy = 0.936494
I0826 20:00:23.215528  4567 solver.cpp:404]     Test net output #1: loss = 6647.91 (* 1 = 6647.91 loss)
I0826 20:00:24.665381  4567 solver.cpp:228] Iteration 7600, loss = 5521.36
I0826 20:00:24.665417  4567 solver.cpp:244]     Train net output #0: accuracy = 0.946584
I0826 20:00:24.665426  4567 solver.cpp:244]     Train net output #1: loss = 5521.36 (* 1 = 5521.36 loss)
I0826 20:00:24.665433  4567 sgd_solver.cpp:106] Iteration 7600, lr = 1e-06
I0826 20:01:43.087512  4567 solver.cpp:228] Iteration 7650, loss = 6257.23
I0826 20:01:43.087586  4567 solver.cpp:244]     Train net output #0: accuracy = 0.939892
I0826 20:01:43.087599  4567 solver.cpp:244]     Train net output #1: loss = 6257.23 (* 1 = 6257.23 loss)
I0826 20:01:43.087606  4567 sgd_solver.cpp:106] Iteration 7650, lr = 1e-06
I0826 20:03:02.670377  4567 solver.cpp:228] Iteration 7700, loss = 3575.73
I0826 20:03:02.670455  4567 solver.cpp:244]     Train net output #0: accuracy = 0.965171
I0826 20:03:02.670466  4567 solver.cpp:244]     Train net output #1: loss = 3575.73 (* 1 = 3575.73 loss)
I0826 20:03:02.670474  4567 sgd_solver.cpp:106] Iteration 7700, lr = 1e-06
I0826 20:04:20.048948  4567 solver.cpp:228] Iteration 7750, loss = 6583.68
I0826 20:04:20.049064  4567 solver.cpp:244]     Train net output #0: accuracy = 0.933742
I0826 20:04:20.049077  4567 solver.cpp:244]     Train net output #1: loss = 6583.68 (* 1 = 6583.68 loss)
I0826 20:04:20.049083  4567 sgd_solver.cpp:106] Iteration 7750, lr = 1e-06
I0826 20:05:37.308420  4567 solver.cpp:337] Iteration 7800, Testing net (#0)
I0826 20:05:44.711251  4567 solver.cpp:404]     Test net output #0: accuracy = 0.935723
I0826 20:05:44.711292  4567 solver.cpp:404]     Test net output #1: loss = 6743.3 (* 1 = 6743.3 loss)
I0826 20:05:46.043390  4567 solver.cpp:228] Iteration 7800, loss = 3970.64
I0826 20:05:46.043427  4567 solver.cpp:244]     Train net output #0: accuracy = 0.96008
I0826 20:05:46.043437  4567 solver.cpp:244]     Train net output #1: loss = 3970.64 (* 1 = 3970.64 loss)
I0826 20:05:46.043443  4567 sgd_solver.cpp:106] Iteration 7800, lr = 1e-06
I0826 20:07:04.429261  4567 solver.cpp:228] Iteration 7850, loss = 7944.46
I0826 20:07:04.429348  4567 solver.cpp:244]     Train net output #0: accuracy = 0.920705
I0826 20:07:04.429360  4567 solver.cpp:244]     Train net output #1: loss = 7944.46 (* 1 = 7944.46 loss)
I0826 20:07:04.429366  4567 sgd_solver.cpp:106] Iteration 7850, lr = 1e-06
I0826 20:08:22.823143  4567 solver.cpp:228] Iteration 7900, loss = 4013.69
I0826 20:08:22.823223  4567 solver.cpp:244]     Train net output #0: accuracy = 0.960789
I0826 20:08:22.823235  4567 solver.cpp:244]     Train net output #1: loss = 4013.69 (* 1 = 4013.69 loss)
I0826 20:08:22.823241  4567 sgd_solver.cpp:106] Iteration 7900, lr = 1e-06
I0826 20:09:46.418895  4567 solver.cpp:228] Iteration 7950, loss = 7197.3
I0826 20:09:46.418982  4567 solver.cpp:244]     Train net output #0: accuracy = 0.931131
I0826 20:09:46.418993  4567 solver.cpp:244]     Train net output #1: loss = 7197.3 (* 1 = 7197.3 loss)
I0826 20:09:46.418999  4567 sgd_solver.cpp:106] Iteration 7950, lr = 1e-06
I0826 20:11:03.347276  4567 solver.cpp:454] Snapshotting to binary proto file portrait_one_stage3_iter_8000.caffemodel
I0826 20:11:03.352622  4567 sgd_solver.cpp:273] Snapshotting solver state to binary proto file portrait_one_stage3_iter_8000.solverstate
I0826 20:11:03.353596  4567 solver.cpp:337] Iteration 8000, Testing net (#0)
I0826 20:11:11.442431  4567 solver.cpp:404]     Test net output #0: accuracy = 0.936629
I0826 20:11:11.442474  4567 solver.cpp:404]     Test net output #1: loss = 6635.79 (* 1 = 6635.79 loss)
I0826 20:11:12.965612  4567 solver.cpp:228] Iteration 8000, loss = 6565.2
I0826 20:11:12.965651  4567 solver.cpp:244]     Train net output #0: accuracy = 0.93701
I0826 20:11:12.965662  4567 solver.cpp:244]     Train net output #1: loss = 6565.2 (* 1 = 6565.2 loss)
I0826 20:11:12.965668  4567 sgd_solver.cpp:106] Iteration 8000, lr = 1e-07
I0826 20:12:30.982364  4567 solver.cpp:228] Iteration 8050, loss = 4091.41
I0826 20:12:30.982445  4567 solver.cpp:244]     Train net output #0: accuracy = 0.959524
I0826 20:12:30.982455  4567 solver.cpp:244]     Train net output #1: loss = 4091.41 (* 1 = 4091.41 loss)
I0826 20:12:30.982461  4567 sgd_solver.cpp:106] Iteration 8050, lr = 1e-07
I0826 20:13:51.129921  4567 solver.cpp:228] Iteration 8100, loss = 5520.71
I0826 20:13:51.130012  4567 solver.cpp:244]     Train net output #0: accuracy = 0.945213
I0826 20:13:51.130026  4567 solver.cpp:244]     Train net output #1: loss = 5520.71 (* 1 = 5520.71 loss)
I0826 20:13:51.130035  4567 sgd_solver.cpp:106] Iteration 8100, lr = 1e-07
I0826 20:15:09.268543  4567 solver.cpp:228] Iteration 8150, loss = 3520.02
I0826 20:15:09.268637  4567 solver.cpp:244]     Train net output #0: accuracy = 0.966378
I0826 20:15:09.268648  4567 solver.cpp:244]     Train net output #1: loss = 3520.02 (* 1 = 3520.02 loss)
I0826 20:15:09.268656  4567 sgd_solver.cpp:106] Iteration 8150, lr = 1e-07
I0826 20:16:26.361455  4567 solver.cpp:337] Iteration 8200, Testing net (#0)
I0826 20:16:34.492362  4567 solver.cpp:404]     Test net output #0: accuracy = 0.937765
I0826 20:16:34.492413  4567 solver.cpp:404]     Test net output #1: loss = 6572.43 (* 1 = 6572.43 loss)
I0826 20:16:35.829898  4567 solver.cpp:228] Iteration 8200, loss = 6817.19
I0826 20:16:35.829936  4567 solver.cpp:244]     Train net output #0: accuracy = 0.932417
I0826 20:16:35.829949  4567 solver.cpp:244]     Train net output #1: loss = 6817.19 (* 1 = 6817.19 loss)
I0826 20:16:35.829957  4567 sgd_solver.cpp:106] Iteration 8200, lr = 1e-07
I0826 20:17:54.049644  4567 solver.cpp:228] Iteration 8250, loss = 3917.27
I0826 20:17:54.049749  4567 solver.cpp:244]     Train net output #0: accuracy = 0.960408
I0826 20:17:54.049762  4567 solver.cpp:244]     Train net output #1: loss = 3917.27 (* 1 = 3917.27 loss)
I0826 20:17:54.049768  4567 sgd_solver.cpp:106] Iteration 8250, lr = 1e-07
I0826 20:19:12.596253  4567 solver.cpp:228] Iteration 8300, loss = 6891.99
I0826 20:19:12.596328  4567 solver.cpp:244]     Train net output #0: accuracy = 0.93195
I0826 20:19:12.596339  4567 solver.cpp:244]     Train net output #1: loss = 6891.99 (* 1 = 6891.99 loss)
I0826 20:19:12.596346  4567 sgd_solver.cpp:106] Iteration 8300, lr = 1e-07
I0826 20:20:30.860810  4567 solver.cpp:228] Iteration 8350, loss = 3918.14
I0826 20:20:30.860883  4567 solver.cpp:244]     Train net output #0: accuracy = 0.961734
I0826 20:20:30.860894  4567 solver.cpp:244]     Train net output #1: loss = 3918.14 (* 1 = 3918.14 loss)
I0826 20:20:30.860901  4567 sgd_solver.cpp:106] Iteration 8350, lr = 1e-07
I0826 20:21:48.332765  4567 solver.cpp:337] Iteration 8400, Testing net (#0)
I0826 20:21:56.585140  4567 solver.cpp:404]     Test net output #0: accuracy = 0.933956
I0826 20:21:56.585186  4567 solver.cpp:404]     Test net output #1: loss = 6952.81 (* 1 = 6952.81 loss)
I0826 20:21:58.012426  4567 solver.cpp:228] Iteration 8400, loss = 4112.42
I0826 20:21:58.012464  4567 solver.cpp:244]     Train net output #0: accuracy = 0.958925
I0826 20:21:58.012473  4567 solver.cpp:244]     Train net output #1: loss = 4112.42 (* 1 = 4112.42 loss)
I0826 20:21:58.012480  4567 sgd_solver.cpp:106] Iteration 8400, lr = 1e-07
I0826 20:23:15.986721  4567 solver.cpp:228] Iteration 8450, loss = 8529.68
I0826 20:23:15.986805  4567 solver.cpp:244]     Train net output #0: accuracy = 0.917925
I0826 20:23:15.986816  4567 solver.cpp:244]     Train net output #1: loss = 8529.68 (* 1 = 8529.68 loss)
I0826 20:23:15.986824  4567 sgd_solver.cpp:106] Iteration 8450, lr = 1e-07
I0826 20:24:32.986578  4567 solver.cpp:228] Iteration 8500, loss = 4263.6
I0826 20:24:32.986665  4567 solver.cpp:244]     Train net output #0: accuracy = 0.958573
I0826 20:24:32.986675  4567 solver.cpp:244]     Train net output #1: loss = 4263.6 (* 1 = 4263.6 loss)
I0826 20:24:32.986682  4567 sgd_solver.cpp:106] Iteration 8500, lr = 1e-07
I0826 20:25:49.267143  4567 solver.cpp:228] Iteration 8550, loss = 5814.17
I0826 20:25:49.267217  4567 solver.cpp:244]     Train net output #0: accuracy = 0.943714
I0826 20:25:49.267230  4567 solver.cpp:244]     Train net output #1: loss = 5814.17 (* 1 = 5814.17 loss)
I0826 20:25:49.267236  4567 sgd_solver.cpp:106] Iteration 8550, lr = 1e-07
I0826 20:27:06.241966  4567 solver.cpp:337] Iteration 8600, Testing net (#0)
I0826 20:27:14.369860  4567 solver.cpp:404]     Test net output #0: accuracy = 0.937483
I0826 20:27:14.369895  4567 solver.cpp:404]     Test net output #1: loss = 6570.02 (* 1 = 6570.02 loss)
I0826 20:27:15.832815  4567 solver.cpp:228] Iteration 8600, loss = 3721.66
I0826 20:27:15.832854  4567 solver.cpp:244]     Train net output #0: accuracy = 0.96384
I0826 20:27:15.832864  4567 solver.cpp:244]     Train net output #1: loss = 3721.66 (* 1 = 3721.66 loss)
I0826 20:27:15.832870  4567 sgd_solver.cpp:106] Iteration 8600, lr = 1e-07
I0826 20:28:33.980276  4567 solver.cpp:228] Iteration 8650, loss = 6383.12
I0826 20:28:33.980350  4567 solver.cpp:244]     Train net output #0: accuracy = 0.936554
I0826 20:28:33.980360  4567 solver.cpp:244]     Train net output #1: loss = 6383.12 (* 1 = 6383.12 loss)
I0826 20:28:33.980367  4567 sgd_solver.cpp:106] Iteration 8650, lr = 1e-07
I0826 20:29:53.107362  4567 solver.cpp:228] Iteration 8700, loss = 3509.54
I0826 20:29:53.107472  4567 solver.cpp:244]     Train net output #0: accuracy = 0.965023
I0826 20:29:53.107489  4567 solver.cpp:244]     Train net output #1: loss = 3509.54 (* 1 = 3509.54 loss)
I0826 20:29:53.107496  4567 sgd_solver.cpp:106] Iteration 8700, lr = 1e-07
I0826 20:31:11.303899  4567 solver.cpp:228] Iteration 8750, loss = 6591.97
I0826 20:31:11.303994  4567 solver.cpp:244]     Train net output #0: accuracy = 0.937167
I0826 20:31:11.304006  4567 solver.cpp:244]     Train net output #1: loss = 6591.97 (* 1 = 6591.97 loss)
I0826 20:31:11.304013  4567 sgd_solver.cpp:106] Iteration 8750, lr = 1e-07
I0826 20:32:29.669263  4567 solver.cpp:337] Iteration 8800, Testing net (#0)
I0826 20:32:37.968637  4567 solver.cpp:404]     Test net output #0: accuracy = 0.937458
I0826 20:32:37.968688  4567 solver.cpp:404]     Test net output #1: loss = 6595.45 (* 1 = 6595.45 loss)
I0826 20:32:39.430922  4567 solver.cpp:228] Iteration 8800, loss = 7374.39
I0826 20:32:39.430958  4567 solver.cpp:244]     Train net output #0: accuracy = 0.926139
I0826 20:32:39.430968  4567 solver.cpp:244]     Train net output #1: loss = 7374.39 (* 1 = 7374.39 loss)
I0826 20:32:39.430974  4567 sgd_solver.cpp:106] Iteration 8800, lr = 1e-07
I0826 20:33:57.952895  4567 solver.cpp:228] Iteration 8850, loss = 4055.2
I0826 20:33:57.952971  4567 solver.cpp:244]     Train net output #0: accuracy = 0.960576
I0826 20:33:57.952983  4567 solver.cpp:244]     Train net output #1: loss = 4055.2 (* 1 = 4055.2 loss)
I0826 20:33:57.952991  4567 sgd_solver.cpp:106] Iteration 8850, lr = 1e-07
I0826 20:35:15.518748  4567 solver.cpp:228] Iteration 8900, loss = 7861.62
I0826 20:35:15.518824  4567 solver.cpp:244]     Train net output #0: accuracy = 0.923196
I0826 20:35:15.518836  4567 solver.cpp:244]     Train net output #1: loss = 7861.62 (* 1 = 7861.62 loss)
I0826 20:35:15.518842  4567 sgd_solver.cpp:106] Iteration 8900, lr = 1e-07
I0826 20:36:35.149754  4567 solver.cpp:228] Iteration 8950, loss = 4175.41
I0826 20:36:35.149835  4567 solver.cpp:244]     Train net output #0: accuracy = 0.960046
I0826 20:36:35.149847  4567 solver.cpp:244]     Train net output #1: loss = 4175.41 (* 1 = 4175.41 loss)
I0826 20:36:35.149852  4567 sgd_solver.cpp:106] Iteration 8950, lr = 1e-07
I0826 20:37:51.366976  4567 solver.cpp:337] Iteration 9000, Testing net (#0)
I0826 20:37:59.296355  4567 solver.cpp:404]     Test net output #0: accuracy = 0.937088
I0826 20:37:59.296397  4567 solver.cpp:404]     Test net output #1: loss = 6588.88 (* 1 = 6588.88 loss)
I0826 20:38:00.740563  4567 solver.cpp:228] Iteration 9000, loss = 6600.51
I0826 20:38:00.740609  4567 solver.cpp:244]     Train net output #0: accuracy = 0.93736
I0826 20:38:00.740622  4567 solver.cpp:244]     Train net output #1: loss = 6600.51 (* 1 = 6600.51 loss)
I0826 20:38:00.740631  4567 sgd_solver.cpp:106] Iteration 9000, lr = 1e-07
I0826 20:39:19.859975  4567 solver.cpp:228] Iteration 9050, loss = 3470.69
I0826 20:39:19.860070  4567 solver.cpp:244]     Train net output #0: accuracy = 0.965856
I0826 20:39:19.860082  4567 solver.cpp:244]     Train net output #1: loss = 3470.69 (* 1 = 3470.69 loss)
I0826 20:39:19.860091  4567 sgd_solver.cpp:106] Iteration 9050, lr = 1e-07
I0826 20:40:38.147050  4567 solver.cpp:228] Iteration 9100, loss = 6600.68
I0826 20:40:38.147150  4567 solver.cpp:244]     Train net output #0: accuracy = 0.934838
I0826 20:40:38.147167  4567 solver.cpp:244]     Train net output #1: loss = 6600.68 (* 1 = 6600.68 loss)
I0826 20:40:38.147179  4567 sgd_solver.cpp:106] Iteration 9100, lr = 1e-07
I0826 20:41:55.158200  4567 solver.cpp:228] Iteration 9150, loss = 5821.05
I0826 20:41:55.158280  4567 solver.cpp:244]     Train net output #0: accuracy = 0.942982
I0826 20:41:55.158293  4567 solver.cpp:244]     Train net output #1: loss = 5821.05 (* 1 = 5821.05 loss)
I0826 20:41:55.158298  4567 sgd_solver.cpp:106] Iteration 9150, lr = 1e-07
I0826 20:43:11.272795  4567 solver.cpp:337] Iteration 9200, Testing net (#0)
I0826 20:43:19.119612  4567 solver.cpp:404]     Test net output #0: accuracy = 0.937764
I0826 20:43:19.119660  4567 solver.cpp:404]     Test net output #1: loss = 6578.04 (* 1 = 6578.04 loss)
I0826 20:43:20.512764  4567 solver.cpp:228] Iteration 9200, loss = 3831.57
I0826 20:43:20.512800  4567 solver.cpp:244]     Train net output #0: accuracy = 0.962623
I0826 20:43:20.512809  4567 solver.cpp:244]     Train net output #1: loss = 3831.57 (* 1 = 3831.57 loss)
I0826 20:43:20.512815  4567 sgd_solver.cpp:106] Iteration 9200, lr = 1e-07
I0826 20:44:39.361129  4567 solver.cpp:228] Iteration 9250, loss = 7943.42
I0826 20:44:39.361232  4567 solver.cpp:244]     Train net output #0: accuracy = 0.919772
I0826 20:44:39.361243  4567 solver.cpp:244]     Train net output #1: loss = 7943.42 (* 1 = 7943.42 loss)
I0826 20:44:39.361250  4567 sgd_solver.cpp:106] Iteration 9250, lr = 1e-07
I0826 20:45:55.600599  4567 solver.cpp:228] Iteration 9300, loss = 3786.29
I0826 20:45:55.600697  4567 solver.cpp:244]     Train net output #0: accuracy = 0.960871
I0826 20:45:55.600713  4567 solver.cpp:244]     Train net output #1: loss = 3786.29 (* 1 = 3786.29 loss)
I0826 20:45:55.600723  4567 sgd_solver.cpp:106] Iteration 9300, lr = 1e-07
I0826 20:47:14.402968  4567 solver.cpp:228] Iteration 9350, loss = 7440.53
I0826 20:47:14.403053  4567 solver.cpp:244]     Train net output #0: accuracy = 0.929205
I0826 20:47:14.403065  4567 solver.cpp:244]     Train net output #1: loss = 7440.53 (* 1 = 7440.53 loss)
I0826 20:47:14.403074  4567 sgd_solver.cpp:106] Iteration 9350, lr = 1e-07
I0826 20:48:31.042299  4567 solver.cpp:337] Iteration 9400, Testing net (#0)
I0826 20:48:39.184630  4567 solver.cpp:404]     Test net output #0: accuracy = 0.933666
I0826 20:48:39.184684  4567 solver.cpp:404]     Test net output #1: loss = 6993.1 (* 1 = 6993.1 loss)
I0826 20:48:40.625851  4567 solver.cpp:228] Iteration 9400, loss = 4565.46
I0826 20:48:40.625890  4567 solver.cpp:244]     Train net output #0: accuracy = 0.954605
I0826 20:48:40.625900  4567 solver.cpp:244]     Train net output #1: loss = 4565.46 (* 1 = 4565.46 loss)
I0826 20:48:40.625906  4567 sgd_solver.cpp:106] Iteration 9400, lr = 1e-07
I0826 20:49:58.912412  4567 solver.cpp:228] Iteration 9450, loss = 6007.91
I0826 20:49:58.912528  4567 solver.cpp:244]     Train net output #0: accuracy = 0.942245
I0826 20:49:58.912542  4567 solver.cpp:244]     Train net output #1: loss = 6007.91 (* 1 = 6007.91 loss)
I0826 20:49:58.912549  4567 sgd_solver.cpp:106] Iteration 9450, lr = 1e-07
I0826 20:51:17.965183  4567 solver.cpp:228] Iteration 9500, loss = 3834.27
I0826 20:51:17.965279  4567 solver.cpp:244]     Train net output #0: accuracy = 0.963097
I0826 20:51:17.965291  4567 solver.cpp:244]     Train net output #1: loss = 3834.27 (* 1 = 3834.27 loss)
I0826 20:51:17.965298  4567 sgd_solver.cpp:106] Iteration 9500, lr = 1e-07
I0826 20:52:36.323726  4567 solver.cpp:228] Iteration 9550, loss = 3539.03
I0826 20:52:36.323814  4567 solver.cpp:244]     Train net output #0: accuracy = 0.964741
I0826 20:52:36.323827  4567 solver.cpp:244]     Train net output #1: loss = 3539.03 (* 1 = 3539.03 loss)
I0826 20:52:36.323834  4567 sgd_solver.cpp:106] Iteration 9550, lr = 1e-07
I0826 20:53:51.733003  4567 solver.cpp:337] Iteration 9600, Testing net (#0)
I0826 20:53:59.870915  4567 solver.cpp:404]     Test net output #0: accuracy = 0.937395
I0826 20:53:59.870967  4567 solver.cpp:404]     Test net output #1: loss = 6571.96 (* 1 = 6571.96 loss)
I0826 20:54:01.247434  4567 solver.cpp:228] Iteration 9600, loss = 6462.05
I0826 20:54:01.247480  4567 solver.cpp:244]     Train net output #0: accuracy = 0.93485
I0826 20:54:01.247494  4567 solver.cpp:244]     Train net output #1: loss = 6462.05 (* 1 = 6462.05 loss)
I0826 20:54:01.247503  4567 sgd_solver.cpp:106] Iteration 9600, lr = 1e-07
I0826 20:55:19.834450  4567 solver.cpp:228] Iteration 9650, loss = 4011.65
I0826 20:55:19.834540  4567 solver.cpp:244]     Train net output #0: accuracy = 0.960321
I0826 20:55:19.834556  4567 solver.cpp:244]     Train net output #1: loss = 4011.65 (* 1 = 4011.65 loss)
I0826 20:55:19.834565  4567 sgd_solver.cpp:106] Iteration 9650, lr = 1e-07
I0826 20:56:37.402292  4567 solver.cpp:228] Iteration 9700, loss = 7464.03
I0826 20:56:37.402426  4567 solver.cpp:244]     Train net output #0: accuracy = 0.925818
I0826 20:56:37.402442  4567 solver.cpp:244]     Train net output #1: loss = 7464.03 (* 1 = 7464.03 loss)
I0826 20:56:37.402451  4567 sgd_solver.cpp:106] Iteration 9700, lr = 1e-07
I0826 20:57:55.436231  4567 solver.cpp:228] Iteration 9750, loss = 4238.85
I0826 20:57:55.436329  4567 solver.cpp:244]     Train net output #0: accuracy = 0.958041
I0826 20:57:55.436345  4567 solver.cpp:244]     Train net output #1: loss = 4238.85 (* 1 = 4238.85 loss)
I0826 20:57:55.436354  4567 sgd_solver.cpp:106] Iteration 9750, lr = 1e-07
I0826 20:59:12.399760  4567 solver.cpp:337] Iteration 9800, Testing net (#0)
I0826 20:59:20.566045  4567 solver.cpp:404]     Test net output #0: accuracy = 0.938102
I0826 20:59:20.566082  4567 solver.cpp:404]     Test net output #1: loss = 6533.26 (* 1 = 6533.26 loss)
I0826 20:59:21.998452  4567 solver.cpp:228] Iteration 9800, loss = 8109.82
I0826 20:59:21.998489  4567 solver.cpp:244]     Train net output #0: accuracy = 0.922968
I0826 20:59:21.998498  4567 solver.cpp:244]     Train net output #1: loss = 8109.82 (* 1 = 8109.82 loss)
I0826 20:59:21.998505  4567 sgd_solver.cpp:106] Iteration 9800, lr = 1e-07
I0826 21:00:40.482960  4567 solver.cpp:228] Iteration 9850, loss = 4490.73
I0826 21:00:40.483042  4567 solver.cpp:244]     Train net output #0: accuracy = 0.956159
I0826 21:00:40.483053  4567 solver.cpp:244]     Train net output #1: loss = 4490.73 (* 1 = 4490.73 loss)
I0826 21:00:40.483060  4567 sgd_solver.cpp:106] Iteration 9850, lr = 1e-07
I0826 21:01:58.813302  4567 solver.cpp:228] Iteration 9900, loss = 5253.15
I0826 21:01:58.813383  4567 solver.cpp:244]     Train net output #0: accuracy = 0.949121
I0826 21:01:58.813395  4567 solver.cpp:244]     Train net output #1: loss = 5253.15 (* 1 = 5253.15 loss)
I0826 21:01:58.813400  4567 sgd_solver.cpp:106] Iteration 9900, lr = 1e-07
I0826 21:03:17.486337  4567 solver.cpp:228] Iteration 9950, loss = 6192.07
I0826 21:03:17.486414  4567 solver.cpp:244]     Train net output #0: accuracy = 0.939507
I0826 21:03:17.486425  4567 solver.cpp:244]     Train net output #1: loss = 6192.07 (* 1 = 6192.07 loss)
I0826 21:03:17.486433  4567 sgd_solver.cpp:106] Iteration 9950, lr = 1e-07
I0826 21:04:34.377707  4567 solver.cpp:337] Iteration 10000, Testing net (#0)
I0826 21:04:42.570057  4567 solver.cpp:404]     Test net output #0: accuracy = 0.937497
I0826 21:04:42.570096  4567 solver.cpp:404]     Test net output #1: loss = 6551.09 (* 1 = 6551.09 loss)
I0826 21:04:43.973361  4567 solver.cpp:228] Iteration 10000, loss = 3487.48
I0826 21:04:43.973398  4567 solver.cpp:244]     Train net output #0: accuracy = 0.965936
I0826 21:04:43.973408  4567 solver.cpp:244]     Train net output #1: loss = 3487.48 (* 1 = 3487.48 loss)
I0826 21:04:43.973414  4567 sgd_solver.cpp:106] Iteration 10000, lr = 1e-07
I0826 21:06:02.262017  4567 solver.cpp:228] Iteration 10050, loss = 6525.99
I0826 21:06:02.262101  4567 solver.cpp:244]     Train net output #0: accuracy = 0.93454
I0826 21:06:02.262114  4567 solver.cpp:244]     Train net output #1: loss = 6525.99 (* 1 = 6525.99 loss)
I0826 21:06:02.262120  4567 sgd_solver.cpp:106] Iteration 10050, lr = 1e-07
I0826 21:07:20.742980  4567 solver.cpp:228] Iteration 10100, loss = 3986.49
I0826 21:07:20.743058  4567 solver.cpp:244]     Train net output #0: accuracy = 0.960137
I0826 21:07:20.743069  4567 solver.cpp:244]     Train net output #1: loss = 3986.49 (* 1 = 3986.49 loss)
I0826 21:07:20.743077  4567 sgd_solver.cpp:106] Iteration 10100, lr = 1e-07
I0826 21:08:38.589727  4567 solver.cpp:228] Iteration 10150, loss = 7868.88
I0826 21:08:38.589795  4567 solver.cpp:244]     Train net output #0: accuracy = 0.921295
I0826 21:08:38.589807  4567 solver.cpp:244]     Train net output #1: loss = 7868.88 (* 1 = 7868.88 loss)
I0826 21:08:38.589813  4567 sgd_solver.cpp:106] Iteration 10150, lr = 1e-07
I0826 21:09:57.555893  4567 solver.cpp:337] Iteration 10200, Testing net (#0)
I0826 21:10:07.455932  4567 solver.cpp:404]     Test net output #0: accuracy = 0.937742
I0826 21:10:07.455981  4567 solver.cpp:404]     Test net output #1: loss = 6579.67 (* 1 = 6579.67 loss)
I0826 21:10:08.926087  4567 solver.cpp:228] Iteration 10200, loss = 3734.46
I0826 21:10:08.926137  4567 solver.cpp:244]     Train net output #0: accuracy = 0.963719
I0826 21:10:08.927624  4567 solver.cpp:244]     Train net output #1: loss = 3734.46 (* 1 = 3734.46 loss)
I0826 21:10:08.927639  4567 sgd_solver.cpp:106] Iteration 10200, lr = 1e-07
I0826 21:11:31.890512  4567 solver.cpp:228] Iteration 10250, loss = 7283.38
I0826 21:11:31.890597  4567 solver.cpp:244]     Train net output #0: accuracy = 0.930182
I0826 21:11:31.890609  4567 solver.cpp:244]     Train net output #1: loss = 7283.38 (* 1 = 7283.38 loss)
I0826 21:11:31.890615  4567 sgd_solver.cpp:106] Iteration 10250, lr = 1e-07
I0826 21:12:50.461781  4567 solver.cpp:228] Iteration 10300, loss = 6919.34
I0826 21:12:50.461872  4567 solver.cpp:244]     Train net output #0: accuracy = 0.933734
I0826 21:12:50.461889  4567 solver.cpp:244]     Train net output #1: loss = 6919.34 (* 1 = 6919.34 loss)
I0826 21:12:50.461899  4567 sgd_solver.cpp:106] Iteration 10300, lr = 1e-07
I0826 21:14:09.147074  4567 solver.cpp:228] Iteration 10350, loss = 4165.48
I0826 21:14:09.147153  4567 solver.cpp:244]     Train net output #0: accuracy = 0.959402
I0826 21:14:09.147164  4567 solver.cpp:244]     Train net output #1: loss = 4165.48 (* 1 = 4165.48 loss)
I0826 21:14:09.147171  4567 sgd_solver.cpp:106] Iteration 10350, lr = 1e-07
I0826 21:15:24.657836  4567 solver.cpp:337] Iteration 10400, Testing net (#0)
I0826 21:15:32.615726  4567 solver.cpp:404]     Test net output #0: accuracy = 0.934095
I0826 21:15:32.615772  4567 solver.cpp:404]     Test net output #1: loss = 6955.13 (* 1 = 6955.13 loss)
I0826 21:15:33.950091  4567 solver.cpp:228] Iteration 10400, loss = 5433.61
I0826 21:15:33.950127  4567 solver.cpp:244]     Train net output #0: accuracy = 0.946108
I0826 21:15:33.950136  4567 solver.cpp:244]     Train net output #1: loss = 5433.61 (* 1 = 5433.61 loss)
I0826 21:15:33.950145  4567 sgd_solver.cpp:106] Iteration 10400, lr = 1e-07
I0826 21:16:51.862689  4567 solver.cpp:228] Iteration 10450, loss = 3547.08
I0826 21:16:51.862754  4567 solver.cpp:244]     Train net output #0: accuracy = 0.965898
I0826 21:16:51.862766  4567 solver.cpp:244]     Train net output #1: loss = 3547.08 (* 1 = 3547.08 loss)
I0826 21:16:51.862773  4567 sgd_solver.cpp:106] Iteration 10450, lr = 1e-07
I0826 21:18:10.230419  4567 solver.cpp:228] Iteration 10500, loss = 6783.37
I0826 21:18:10.230507  4567 solver.cpp:244]     Train net output #0: accuracy = 0.93254
I0826 21:18:10.230523  4567 solver.cpp:244]     Train net output #1: loss = 6783.37 (* 1 = 6783.37 loss)
I0826 21:18:10.230532  4567 sgd_solver.cpp:106] Iteration 10500, lr = 1e-07
I0826 21:19:28.073092  4567 solver.cpp:228] Iteration 10550, loss = 3757.17
I0826 21:19:28.073163  4567 solver.cpp:244]     Train net output #0: accuracy = 0.962591
I0826 21:19:28.073174  4567 solver.cpp:244]     Train net output #1: loss = 3757.17 (* 1 = 3757.17 loss)
I0826 21:19:28.073181  4567 sgd_solver.cpp:106] Iteration 10550, lr = 1e-07
I0826 21:20:47.128242  4567 solver.cpp:337] Iteration 10600, Testing net (#0)
I0826 21:20:55.314249  4567 solver.cpp:404]     Test net output #0: accuracy = 0.93716
I0826 21:20:55.314290  4567 solver.cpp:404]     Test net output #1: loss = 6598.66 (* 1 = 6598.66 loss)
I0826 21:20:56.737308  4567 solver.cpp:228] Iteration 10600, loss = 6787.52
I0826 21:20:56.737350  4567 solver.cpp:244]     Train net output #0: accuracy = 0.932664
I0826 21:20:56.737360  4567 solver.cpp:244]     Train net output #1: loss = 6787.52 (* 1 = 6787.52 loss)
I0826 21:20:56.737368  4567 sgd_solver.cpp:106] Iteration 10600, lr = 1e-07
I0826 21:22:19.781450  4567 solver.cpp:228] Iteration 10650, loss = 4488.94
I0826 21:22:19.781524  4567 solver.cpp:244]     Train net output #0: accuracy = 0.956336
I0826 21:22:19.781536  4567 solver.cpp:244]     Train net output #1: loss = 4488.94 (* 1 = 4488.94 loss)
I0826 21:22:19.781543  4567 sgd_solver.cpp:106] Iteration 10650, lr = 1e-07
I0826 21:23:37.968260  4567 solver.cpp:228] Iteration 10700, loss = 3696.77
I0826 21:23:37.968355  4567 solver.cpp:244]     Train net output #0: accuracy = 0.963095
I0826 21:23:37.968367  4567 solver.cpp:244]     Train net output #1: loss = 3696.77 (* 1 = 3696.77 loss)
I0826 21:23:37.968374  4567 sgd_solver.cpp:106] Iteration 10700, lr = 1e-07
I0826 21:24:56.267171  4567 solver.cpp:228] Iteration 10750, loss = 8394.66
I0826 21:24:56.267248  4567 solver.cpp:244]     Train net output #0: accuracy = 0.918323
I0826 21:24:56.267259  4567 solver.cpp:244]     Train net output #1: loss = 8394.66 (* 1 = 8394.66 loss)
I0826 21:24:56.267267  4567 sgd_solver.cpp:106] Iteration 10750, lr = 1e-07
I0826 21:26:12.957767  4567 solver.cpp:337] Iteration 10800, Testing net (#0)
I0826 21:26:21.122382  4567 solver.cpp:404]     Test net output #0: accuracy = 0.938037
I0826 21:26:21.122431  4567 solver.cpp:404]     Test net output #1: loss = 6543.11 (* 1 = 6543.11 loss)
I0826 21:26:22.564769  4567 solver.cpp:228] Iteration 10800, loss = 4252.24
I0826 21:26:22.564816  4567 solver.cpp:244]     Train net output #0: accuracy = 0.95839
I0826 21:26:22.564831  4567 solver.cpp:244]     Train net output #1: loss = 4252.24 (* 1 = 4252.24 loss)
I0826 21:26:22.564839  4567 sgd_solver.cpp:106] Iteration 10800, lr = 1e-07
I0826 21:27:41.167294  4567 solver.cpp:228] Iteration 10850, loss = 5997.53
I0826 21:27:41.167381  4567 solver.cpp:244]     Train net output #0: accuracy = 0.941968
I0826 21:27:41.167392  4567 solver.cpp:244]     Train net output #1: loss = 5997.53 (* 1 = 5997.53 loss)
I0826 21:27:41.167399  4567 sgd_solver.cpp:106] Iteration 10850, lr = 1e-07
I0826 21:29:00.101462  4567 solver.cpp:228] Iteration 10900, loss = 3601.82
I0826 21:29:00.101538  4567 solver.cpp:244]     Train net output #0: accuracy = 0.965055
I0826 21:29:00.101549  4567 solver.cpp:244]     Train net output #1: loss = 3601.82 (* 1 = 3601.82 loss)
I0826 21:29:00.101557  4567 sgd_solver.cpp:106] Iteration 10900, lr = 1e-07
I0826 21:30:18.236891  4567 solver.cpp:228] Iteration 10950, loss = 6540.45
I0826 21:30:18.236979  4567 solver.cpp:244]     Train net output #0: accuracy = 0.936476
I0826 21:30:18.236990  4567 solver.cpp:244]     Train net output #1: loss = 6540.45 (* 1 = 6540.45 loss)
I0826 21:30:18.236997  4567 sgd_solver.cpp:106] Iteration 10950, lr = 1e-07
I0826 21:31:34.011740  4567 solver.cpp:337] Iteration 11000, Testing net (#0)
I0826 21:31:42.044330  4567 solver.cpp:404]     Test net output #0: accuracy = 0.93822
I0826 21:31:42.044373  4567 solver.cpp:404]     Test net output #1: loss = 6486.03 (* 1 = 6486.03 loss)
I0826 21:31:43.373795  4567 solver.cpp:228] Iteration 11000, loss = 3617.35
I0826 21:31:43.373843  4567 solver.cpp:244]     Train net output #0: accuracy = 0.964405
I0826 21:31:43.373853  4567 solver.cpp:244]     Train net output #1: loss = 3617.35 (* 1 = 3617.35 loss)
I0826 21:31:43.373860  4567 sgd_solver.cpp:106] Iteration 11000, lr = 1e-07
I0826 21:33:02.214071  4567 solver.cpp:228] Iteration 11050, loss = 6000.11
I0826 21:33:02.214153  4567 solver.cpp:244]     Train net output #0: accuracy = 0.94269
I0826 21:33:02.214164  4567 solver.cpp:244]     Train net output #1: loss = 6000.11 (* 1 = 6000.11 loss)
I0826 21:33:02.214169  4567 sgd_solver.cpp:106] Iteration 11050, lr = 1e-07
I0826 21:34:20.100731  4567 solver.cpp:228] Iteration 11100, loss = 7312.8
I0826 21:34:20.100810  4567 solver.cpp:244]     Train net output #0: accuracy = 0.92704
I0826 21:34:20.100821  4567 solver.cpp:244]     Train net output #1: loss = 7312.8 (* 1 = 7312.8 loss)
I0826 21:34:20.100826  4567 sgd_solver.cpp:106] Iteration 11100, lr = 1e-07
I0826 21:35:37.766701  4567 solver.cpp:228] Iteration 11150, loss = 4156.93
I0826 21:35:37.766793  4567 solver.cpp:244]     Train net output #0: accuracy = 0.959306
I0826 21:35:37.766810  4567 solver.cpp:244]     Train net output #1: loss = 4156.93 (* 1 = 4156.93 loss)
I0826 21:35:37.766821  4567 sgd_solver.cpp:106] Iteration 11150, lr = 1e-07
I0826 21:36:52.939527  4567 solver.cpp:337] Iteration 11200, Testing net (#0)
I0826 21:37:01.088527  4567 solver.cpp:404]     Test net output #0: accuracy = 0.937227
I0826 21:37:01.088577  4567 solver.cpp:404]     Test net output #1: loss = 6640.33 (* 1 = 6640.33 loss)
I0826 21:37:02.538148  4567 solver.cpp:228] Iteration 11200, loss = 8284.54
I0826 21:37:02.538183  4567 solver.cpp:244]     Train net output #0: accuracy = 0.919747
I0826 21:37:02.538192  4567 solver.cpp:244]     Train net output #1: loss = 8284.54 (* 1 = 8284.54 loss)
I0826 21:37:02.538198  4567 sgd_solver.cpp:106] Iteration 11200, lr = 1e-07
I0826 21:38:20.689683  4567 solver.cpp:228] Iteration 11250, loss = 4341.78
I0826 21:38:20.689793  4567 solver.cpp:244]     Train net output #0: accuracy = 0.958823
I0826 21:38:20.689807  4567 solver.cpp:244]     Train net output #1: loss = 4341.78 (* 1 = 4341.78 loss)
I0826 21:38:20.689815  4567 sgd_solver.cpp:106] Iteration 11250, lr = 1e-07
I0826 21:39:37.416118  4567 solver.cpp:228] Iteration 11300, loss = 6275.11
I0826 21:39:37.416185  4567 solver.cpp:244]     Train net output #0: accuracy = 0.940457
I0826 21:39:37.416196  4567 solver.cpp:244]     Train net output #1: loss = 6275.11 (* 1 = 6275.11 loss)
I0826 21:39:37.416203  4567 sgd_solver.cpp:106] Iteration 11300, lr = 1e-07
I0826 21:40:56.063175  4567 solver.cpp:228] Iteration 11350, loss = 3373.32
I0826 21:40:56.063256  4567 solver.cpp:244]     Train net output #0: accuracy = 0.966725
I0826 21:40:56.063266  4567 solver.cpp:244]     Train net output #1: loss = 3373.32 (* 1 = 3373.32 loss)
I0826 21:40:56.063273  4567 sgd_solver.cpp:106] Iteration 11350, lr = 1e-07
I0826 21:42:12.746071  4567 solver.cpp:337] Iteration 11400, Testing net (#0)
I0826 21:42:20.914558  4567 solver.cpp:404]     Test net output #0: accuracy = 0.934122
I0826 21:42:20.914599  4567 solver.cpp:404]     Test net output #1: loss = 6956.81 (* 1 = 6956.81 loss)
I0826 21:42:22.379847  4567 solver.cpp:228] Iteration 11400, loss = 6648.22
I0826 21:42:22.379895  4567 solver.cpp:244]     Train net output #0: accuracy = 0.934821
I0826 21:42:22.379909  4567 solver.cpp:244]     Train net output #1: loss = 6648.22 (* 1 = 6648.22 loss)
I0826 21:42:22.379920  4567 sgd_solver.cpp:106] Iteration 11400, lr = 1e-07
I0826 21:43:41.125936  4567 solver.cpp:228] Iteration 11450, loss = 6139.35
I0826 21:43:41.126008  4567 solver.cpp:244]     Train net output #0: accuracy = 0.939471
I0826 21:43:41.126019  4567 solver.cpp:244]     Train net output #1: loss = 6139.35 (* 1 = 6139.35 loss)
I0826 21:43:41.126025  4567 sgd_solver.cpp:106] Iteration 11450, lr = 1e-07
I0826 21:45:00.392909  4567 solver.cpp:228] Iteration 11500, loss = 3798.25
I0826 21:45:00.393003  4567 solver.cpp:244]     Train net output #0: accuracy = 0.963132
I0826 21:45:00.393019  4567 solver.cpp:244]     Train net output #1: loss = 3798.25 (* 1 = 3798.25 loss)
I0826 21:45:00.393028  4567 sgd_solver.cpp:106] Iteration 11500, lr = 1e-07
I0826 21:46:19.933030  4567 solver.cpp:228] Iteration 11550, loss = 8226.66
I0826 21:46:19.933110  4567 solver.cpp:244]     Train net output #0: accuracy = 0.916722
I0826 21:46:19.933125  4567 solver.cpp:244]     Train net output #1: loss = 8226.66 (* 1 = 8226.66 loss)
I0826 21:46:19.933135  4567 sgd_solver.cpp:106] Iteration 11550, lr = 1e-07
I0826 21:47:37.004312  4567 solver.cpp:337] Iteration 11600, Testing net (#0)
I0826 21:47:45.234019  4567 solver.cpp:404]     Test net output #0: accuracy = 0.936944
I0826 21:47:45.234074  4567 solver.cpp:404]     Test net output #1: loss = 6621.63 (* 1 = 6621.63 loss)
I0826 21:47:46.672641  4567 solver.cpp:228] Iteration 11600, loss = 3900.92
I0826 21:47:46.672678  4567 solver.cpp:244]     Train net output #0: accuracy = 0.960575
I0826 21:47:46.672688  4567 solver.cpp:244]     Train net output #1: loss = 3900.92 (* 1 = 3900.92 loss)
I0826 21:47:46.672695  4567 sgd_solver.cpp:106] Iteration 11600, lr = 1e-07
I0826 21:49:03.743306  4567 solver.cpp:228] Iteration 11650, loss = 7580.55
I0826 21:49:03.743389  4567 solver.cpp:244]     Train net output #0: accuracy = 0.927553
I0826 21:49:03.743402  4567 solver.cpp:244]     Train net output #1: loss = 7580.55 (* 1 = 7580.55 loss)
I0826 21:49:03.743407  4567 sgd_solver.cpp:106] Iteration 11650, lr = 1e-07
I0826 21:50:21.149483  4567 solver.cpp:228] Iteration 11700, loss = 4547.26
I0826 21:50:21.149597  4567 solver.cpp:244]     Train net output #0: accuracy = 0.9553
I0826 21:50:21.149610  4567 solver.cpp:244]     Train net output #1: loss = 4547.26 (* 1 = 4547.26 loss)
I0826 21:50:21.149616  4567 sgd_solver.cpp:106] Iteration 11700, lr = 1e-07
I0826 21:51:39.953631  4567 solver.cpp:228] Iteration 11750, loss = 5968.51
I0826 21:51:39.953713  4567 solver.cpp:244]     Train net output #0: accuracy = 0.942513
I0826 21:51:39.953724  4567 solver.cpp:244]     Train net output #1: loss = 5968.51 (* 1 = 5968.51 loss)
I0826 21:51:39.953732  4567 sgd_solver.cpp:106] Iteration 11750, lr = 1e-07
I0826 21:52:56.804682  4567 solver.cpp:337] Iteration 11800, Testing net (#0)
I0826 21:53:05.009562  4567 solver.cpp:404]     Test net output #0: accuracy = 0.938097
I0826 21:53:05.009605  4567 solver.cpp:404]     Test net output #1: loss = 6533.79 (* 1 = 6533.79 loss)
I0826 21:53:06.421994  4567 solver.cpp:228] Iteration 11800, loss = 4341.25
I0826 21:53:06.422030  4567 solver.cpp:244]     Train net output #0: accuracy = 0.957711
I0826 21:53:06.422039  4567 solver.cpp:244]     Train net output #1: loss = 4341.25 (* 1 = 4341.25 loss)
I0826 21:53:06.422046  4567 sgd_solver.cpp:106] Iteration 11800, lr = 1e-07
I0826 21:54:25.014683  4567 solver.cpp:228] Iteration 11850, loss = 3172.57
I0826 21:54:25.014775  4567 solver.cpp:244]     Train net output #0: accuracy = 0.968367
I0826 21:54:25.014788  4567 solver.cpp:244]     Train net output #1: loss = 3172.57 (* 1 = 3172.57 loss)
I0826 21:54:25.014796  4567 sgd_solver.cpp:106] Iteration 11850, lr = 1e-07
I0826 21:55:43.062927  4567 solver.cpp:228] Iteration 11900, loss = 6380.59
I0826 21:55:43.062999  4567 solver.cpp:244]     Train net output #0: accuracy = 0.935431
I0826 21:55:43.063009  4567 solver.cpp:244]     Train net output #1: loss = 6380.59 (* 1 = 6380.59 loss)
I0826 21:55:43.063016  4567 sgd_solver.cpp:106] Iteration 11900, lr = 1e-07
I0826 21:56:59.565882  4567 solver.cpp:228] Iteration 11950, loss = 3995.18
I0826 21:56:59.565963  4567 solver.cpp:244]     Train net output #0: accuracy = 0.959907
I0826 21:56:59.565974  4567 solver.cpp:244]     Train net output #1: loss = 3995.18 (* 1 = 3995.18 loss)
I0826 21:56:59.565980  4567 sgd_solver.cpp:106] Iteration 11950, lr = 1e-07
I0826 21:58:16.228430  4567 solver.cpp:454] Snapshotting to binary proto file portrait_one_stage3_iter_12000.caffemodel
I0826 21:58:16.245766  4567 sgd_solver.cpp:273] Snapshotting solver state to binary proto file portrait_one_stage3_iter_12000.solverstate
I0826 21:58:16.247033  4567 solver.cpp:337] Iteration 12000, Testing net (#0)
I0826 21:58:24.574039  4567 solver.cpp:404]     Test net output #0: accuracy = 0.938608
I0826 21:58:24.574085  4567 solver.cpp:404]     Test net output #1: loss = 6445.42 (* 1 = 6445.42 loss)
I0826 21:58:26.043984  4567 solver.cpp:228] Iteration 12000, loss = 7477.98
I0826 21:58:26.044021  4567 solver.cpp:244]     Train net output #0: accuracy = 0.925899
I0826 21:58:26.044031  4567 solver.cpp:244]     Train net output #1: loss = 7477.98 (* 1 = 7477.98 loss)
I0826 21:58:26.044046  4567 sgd_solver.cpp:106] Iteration 12000, lr = 1e-08
I0826 21:59:44.949471  4567 solver.cpp:228] Iteration 12050, loss = 4156.67
I0826 21:59:44.949550  4567 solver.cpp:244]     Train net output #0: accuracy = 0.958932
I0826 21:59:44.949563  4567 solver.cpp:244]     Train net output #1: loss = 4156.67 (* 1 = 4156.67 loss)
I0826 21:59:44.949569  4567 sgd_solver.cpp:106] Iteration 12050, lr = 1e-08
I0826 22:01:02.857305  4567 solver.cpp:228] Iteration 12100, loss = 8040.36
I0826 22:01:02.857385  4567 solver.cpp:244]     Train net output #0: accuracy = 0.924971
I0826 22:01:02.857401  4567 solver.cpp:244]     Train net output #1: loss = 8040.36 (* 1 = 8040.36 loss)
I0826 22:01:02.857410  4567 sgd_solver.cpp:106] Iteration 12100, lr = 1e-08
I0826 22:02:21.331020  4567 solver.cpp:228] Iteration 12150, loss = 4618.41
I0826 22:02:21.331142  4567 solver.cpp:244]     Train net output #0: accuracy = 0.954571
I0826 22:02:21.331159  4567 solver.cpp:244]     Train net output #1: loss = 4618.41 (* 1 = 4618.41 loss)
I0826 22:02:21.331167  4567 sgd_solver.cpp:106] Iteration 12150, lr = 1e-08
I0826 22:03:38.104866  4567 solver.cpp:337] Iteration 12200, Testing net (#0)
I0826 22:03:46.188583  4567 solver.cpp:404]     Test net output #0: accuracy = 0.937502
I0826 22:03:46.188632  4567 solver.cpp:404]     Test net output #1: loss = 6612.97 (* 1 = 6612.97 loss)
I0826 22:03:47.609452  4567 solver.cpp:228] Iteration 12200, loss = 5129.7
I0826 22:03:47.609493  4567 solver.cpp:244]     Train net output #0: accuracy = 0.949961
I0826 22:03:47.609501  4567 solver.cpp:244]     Train net output #1: loss = 5129.7 (* 1 = 5129.7 loss)
I0826 22:03:47.609508  4567 sgd_solver.cpp:106] Iteration 12200, lr = 1e-08
I0826 22:05:12.626243  4567 solver.cpp:228] Iteration 12250, loss = 6249.15
I0826 22:05:12.626317  4567 solver.cpp:244]     Train net output #0: accuracy = 0.939004
I0826 22:05:12.626328  4567 solver.cpp:244]     Train net output #1: loss = 6249.15 (* 1 = 6249.15 loss)
I0826 22:05:12.626335  4567 sgd_solver.cpp:106] Iteration 12250, lr = 1e-08
I0826 22:06:33.025534  4567 solver.cpp:228] Iteration 12300, loss = 3529.4
I0826 22:06:33.025629  4567 solver.cpp:244]     Train net output #0: accuracy = 0.965515
I0826 22:06:33.025645  4567 solver.cpp:244]     Train net output #1: loss = 3529.4 (* 1 = 3529.4 loss)
I0826 22:06:33.025655  4567 sgd_solver.cpp:106] Iteration 12300, lr = 1e-08
I0826 22:07:52.128633  4567 solver.cpp:228] Iteration 12350, loss = 6484.44
I0826 22:07:52.128728  4567 solver.cpp:244]     Train net output #0: accuracy = 0.934346
I0826 22:07:52.128749  4567 solver.cpp:244]     Train net output #1: loss = 6484.44 (* 1 = 6484.44 loss)
I0826 22:07:52.128762  4567 sgd_solver.cpp:106] Iteration 12350, lr = 1e-08
I0826 22:09:07.913354  4567 solver.cpp:337] Iteration 12400, Testing net (#0)
I0826 22:09:16.014277  4567 solver.cpp:404]     Test net output #0: accuracy = 0.934266
I0826 22:09:16.014318  4567 solver.cpp:404]     Test net output #1: loss = 6944.23 (* 1 = 6944.23 loss)
I0826 22:09:17.347355  4567 solver.cpp:228] Iteration 12400, loss = 4000.14
I0826 22:09:17.347389  4567 solver.cpp:244]     Train net output #0: accuracy = 0.959676
I0826 22:09:17.347398  4567 solver.cpp:244]     Train net output #1: loss = 4000.14 (* 1 = 4000.14 loss)
I0826 22:09:17.347405  4567 sgd_solver.cpp:106] Iteration 12400, lr = 1e-08
I0826 22:10:35.622968  4567 solver.cpp:228] Iteration 12450, loss = 7724.13
I0826 22:10:35.623064  4567 solver.cpp:244]     Train net output #0: accuracy = 0.923038
I0826 22:10:35.623080  4567 solver.cpp:244]     Train net output #1: loss = 7724.13 (* 1 = 7724.13 loss)
I0826 22:10:35.623090  4567 sgd_solver.cpp:106] Iteration 12450, lr = 1e-08
I0826 22:11:53.674710  4567 solver.cpp:228] Iteration 12500, loss = 3682.87
I0826 22:11:53.674787  4567 solver.cpp:244]     Train net output #0: accuracy = 0.964166
I0826 22:11:53.674798  4567 solver.cpp:244]     Train net output #1: loss = 3682.87 (* 1 = 3682.87 loss)
I0826 22:11:53.674806  4567 sgd_solver.cpp:106] Iteration 12500, lr = 1e-08
I0826 22:13:12.264341  4567 solver.cpp:228] Iteration 12550, loss = 7513.09
I0826 22:13:12.264422  4567 solver.cpp:244]     Train net output #0: accuracy = 0.928268
I0826 22:13:12.264432  4567 solver.cpp:244]     Train net output #1: loss = 7513.09 (* 1 = 7513.09 loss)
I0826 22:13:12.264439  4567 sgd_solver.cpp:106] Iteration 12550, lr = 1e-08
I0826 22:14:29.048123  4567 solver.cpp:337] Iteration 12600, Testing net (#0)
I0826 22:14:37.260463  4567 solver.cpp:404]     Test net output #0: accuracy = 0.936445
I0826 22:14:37.260514  4567 solver.cpp:404]     Test net output #1: loss = 6679.27 (* 1 = 6679.27 loss)
I0826 22:14:38.644675  4567 solver.cpp:228] Iteration 12600, loss = 7581.49
I0826 22:14:38.644717  4567 solver.cpp:244]     Train net output #0: accuracy = 0.927615
I0826 22:14:38.644727  4567 solver.cpp:244]     Train net output #1: loss = 7581.49 (* 1 = 7581.49 loss)
I0826 22:14:38.644734  4567 sgd_solver.cpp:106] Iteration 12600, lr = 1e-08
I0826 22:15:55.866955  4567 solver.cpp:228] Iteration 12650, loss = 4030.9
I0826 22:15:55.867069  4567 solver.cpp:244]     Train net output #0: accuracy = 0.960707
I0826 22:15:55.867082  4567 solver.cpp:244]     Train net output #1: loss = 4030.9 (* 1 = 4030.9 loss)
I0826 22:15:55.867090  4567 sgd_solver.cpp:106] Iteration 12650, lr = 1e-08
I0826 22:17:13.901345  4567 solver.cpp:228] Iteration 12700, loss = 5418.88
I0826 22:17:13.901425  4567 solver.cpp:244]     Train net output #0: accuracy = 0.945986
I0826 22:17:13.901437  4567 solver.cpp:244]     Train net output #1: loss = 5418.88 (* 1 = 5418.88 loss)
I0826 22:17:13.901444  4567 sgd_solver.cpp:106] Iteration 12700, lr = 1e-08
I0826 22:18:32.327353  4567 solver.cpp:228] Iteration 12750, loss = 3491.85
I0826 22:18:32.327450  4567 solver.cpp:244]     Train net output #0: accuracy = 0.966734
I0826 22:18:32.327461  4567 solver.cpp:244]     Train net output #1: loss = 3491.85 (* 1 = 3491.85 loss)
I0826 22:18:32.327471  4567 sgd_solver.cpp:106] Iteration 12750, lr = 1e-08
I0826 22:19:49.095162  4567 solver.cpp:337] Iteration 12800, Testing net (#0)
I0826 22:19:56.819437  4567 solver.cpp:404]     Test net output #0: accuracy = 0.937998
I0826 22:19:56.819473  4567 solver.cpp:404]     Test net output #1: loss = 6537.73 (* 1 = 6537.73 loss)
I0826 22:19:58.234588  4567 solver.cpp:228] Iteration 12800, loss = 6659.9
I0826 22:19:58.234623  4567 solver.cpp:244]     Train net output #0: accuracy = 0.93296
I0826 22:19:58.234633  4567 solver.cpp:244]     Train net output #1: loss = 6659.9 (* 1 = 6659.9 loss)
I0826 22:19:58.234639  4567 sgd_solver.cpp:106] Iteration 12800, lr = 1e-08
I0826 22:21:15.480813  4567 solver.cpp:228] Iteration 12850, loss = 3673.15
I0826 22:21:15.480895  4567 solver.cpp:244]     Train net output #0: accuracy = 0.96293
I0826 22:21:15.480906  4567 solver.cpp:244]     Train net output #1: loss = 3673.15 (* 1 = 3673.15 loss)
I0826 22:21:15.480914  4567 sgd_solver.cpp:106] Iteration 12850, lr = 1e-08
I0826 22:22:32.896900  4567 solver.cpp:228] Iteration 12900, loss = 6944.05
I0826 22:22:32.896991  4567 solver.cpp:244]     Train net output #0: accuracy = 0.931703
I0826 22:22:32.897006  4567 solver.cpp:244]     Train net output #1: loss = 6944.05 (* 1 = 6944.05 loss)
I0826 22:22:32.897017  4567 sgd_solver.cpp:106] Iteration 12900, lr = 1e-08
I0826 22:23:51.147339  4567 solver.cpp:228] Iteration 12950, loss = 4924.17
I0826 22:23:51.147405  4567 solver.cpp:244]     Train net output #0: accuracy = 0.951831
I0826 22:23:51.147415  4567 solver.cpp:244]     Train net output #1: loss = 4924.17 (* 1 = 4924.17 loss)
I0826 22:23:51.147423  4567 sgd_solver.cpp:106] Iteration 12950, lr = 1e-08
I0826 22:25:07.602022  4567 solver.cpp:337] Iteration 13000, Testing net (#0)
I0826 22:25:15.152729  4567 solver.cpp:404]     Test net output #0: accuracy = 0.938828
I0826 22:25:15.152770  4567 solver.cpp:404]     Test net output #1: loss = 6428.07 (* 1 = 6428.07 loss)
I0826 22:25:16.482448  4567 solver.cpp:228] Iteration 13000, loss = 3671.71
I0826 22:25:16.482491  4567 solver.cpp:244]     Train net output #0: accuracy = 0.96311
I0826 22:25:16.482503  4567 solver.cpp:244]     Train net output #1: loss = 3671.71 (* 1 = 3671.71 loss)
I0826 22:25:16.482511  4567 sgd_solver.cpp:106] Iteration 13000, lr = 1e-08
I0826 22:26:33.617090  4567 solver.cpp:228] Iteration 13050, loss = 7985.95
I0826 22:26:33.617167  4567 solver.cpp:244]     Train net output #0: accuracy = 0.922602
I0826 22:26:33.617185  4567 solver.cpp:244]     Train net output #1: loss = 7985.95 (* 1 = 7985.95 loss)
I0826 22:26:33.617197  4567 sgd_solver.cpp:106] Iteration 13050, lr = 1e-08
I0826 22:27:51.775468  4567 solver.cpp:228] Iteration 13100, loss = 4310.99
I0826 22:27:51.775544  4567 solver.cpp:244]     Train net output #0: accuracy = 0.958164
I0826 22:27:51.775555  4567 solver.cpp:244]     Train net output #1: loss = 4310.99 (* 1 = 4310.99 loss)
I0826 22:27:51.775563  4567 sgd_solver.cpp:106] Iteration 13100, lr = 1e-08
I0826 22:29:09.752755  4567 solver.cpp:228] Iteration 13150, loss = 6042.07
I0826 22:29:09.752879  4567 solver.cpp:244]     Train net output #0: accuracy = 0.941002
I0826 22:29:09.752895  4567 solver.cpp:244]     Train net output #1: loss = 6042.07 (* 1 = 6042.07 loss)
I0826 22:29:09.752905  4567 sgd_solver.cpp:106] Iteration 13150, lr = 1e-08
I0826 22:30:25.886678  4567 solver.cpp:337] Iteration 13200, Testing net (#0)
I0826 22:30:33.818778  4567 solver.cpp:404]     Test net output #0: accuracy = 0.937668
I0826 22:30:33.818820  4567 solver.cpp:404]     Test net output #1: loss = 6599.24 (* 1 = 6599.24 loss)
I0826 22:30:35.233247  4567 solver.cpp:228] Iteration 13200, loss = 3512.13
I0826 22:30:35.233297  4567 solver.cpp:244]     Train net output #0: accuracy = 0.96539
I0826 22:30:35.233316  4567 solver.cpp:244]     Train net output #1: loss = 3512.13 (* 1 = 3512.13 loss)
I0826 22:30:35.233331  4567 sgd_solver.cpp:106] Iteration 13200, lr = 1e-08
I0826 22:31:52.949177  4567 solver.cpp:228] Iteration 13250, loss = 6208.93
I0826 22:31:52.949271  4567 solver.cpp:244]     Train net output #0: accuracy = 0.940499
I0826 22:31:52.949283  4567 solver.cpp:244]     Train net output #1: loss = 6208.93 (* 1 = 6208.93 loss)
I0826 22:31:52.949293  4567 sgd_solver.cpp:106] Iteration 13250, lr = 1e-08
I0826 22:33:10.903810  4567 solver.cpp:228] Iteration 13300, loss = 3538.7
I0826 22:33:10.903900  4567 solver.cpp:244]     Train net output #0: accuracy = 0.964896
I0826 22:33:10.903913  4567 solver.cpp:244]     Train net output #1: loss = 3538.7 (* 1 = 3538.7 loss)
I0826 22:33:10.903919  4567 sgd_solver.cpp:106] Iteration 13300, lr = 1e-08
I0826 22:34:29.398068  4567 solver.cpp:228] Iteration 13350, loss = 5360.39
I0826 22:34:29.398147  4567 solver.cpp:244]     Train net output #0: accuracy = 0.948269
I0826 22:34:29.398159  4567 solver.cpp:244]     Train net output #1: loss = 5360.39 (* 1 = 5360.39 loss)
I0826 22:34:29.398166  4567 sgd_solver.cpp:106] Iteration 13350, lr = 1e-08
I0826 22:35:47.545316  4567 solver.cpp:337] Iteration 13400, Testing net (#0)
I0826 22:35:55.986518  4567 solver.cpp:404]     Test net output #0: accuracy = 0.934423
I0826 22:35:55.986562  4567 solver.cpp:404]     Test net output #1: loss = 6930.1 (* 1 = 6930.1 loss)
I0826 22:35:57.441864  4567 solver.cpp:228] Iteration 13400, loss = 7480.09
I0826 22:35:57.441911  4567 solver.cpp:244]     Train net output #0: accuracy = 0.9254
I0826 22:35:57.441926  4567 solver.cpp:244]     Train net output #1: loss = 7480.09 (* 1 = 7480.09 loss)
I0826 22:35:57.441934  4567 sgd_solver.cpp:106] Iteration 13400, lr = 1e-08
I0826 22:37:15.454980  4567 solver.cpp:228] Iteration 13450, loss = 3892.24
I0826 22:37:15.455057  4567 solver.cpp:244]     Train net output #0: accuracy = 0.961313
I0826 22:37:15.455073  4567 solver.cpp:244]     Train net output #1: loss = 3892.24 (* 1 = 3892.24 loss)
I0826 22:37:15.455080  4567 sgd_solver.cpp:106] Iteration 13450, lr = 1e-08
I0826 22:38:34.070987  4567 solver.cpp:228] Iteration 13500, loss = 8123.67
I0826 22:38:34.071063  4567 solver.cpp:244]     Train net output #0: accuracy = 0.921404
I0826 22:38:34.071074  4567 solver.cpp:244]     Train net output #1: loss = 8123.67 (* 1 = 8123.67 loss)
I0826 22:38:34.071081  4567 sgd_solver.cpp:106] Iteration 13500, lr = 1e-08
I0826 22:39:51.911834  4567 solver.cpp:228] Iteration 13550, loss = 4132.71
I0826 22:39:51.911908  4567 solver.cpp:244]     Train net output #0: accuracy = 0.960358
I0826 22:39:51.911919  4567 solver.cpp:244]     Train net output #1: loss = 4132.71 (* 1 = 4132.71 loss)
I0826 22:39:51.911927  4567 sgd_solver.cpp:106] Iteration 13550, lr = 1e-08
I0826 22:41:08.547327  4567 solver.cpp:337] Iteration 13600, Testing net (#0)
I0826 22:41:16.692651  4567 solver.cpp:404]     Test net output #0: accuracy = 0.936359
I0826 22:41:16.692690  4567 solver.cpp:404]     Test net output #1: loss = 6689.7 (* 1 = 6689.7 loss)
I0826 22:41:18.143016  4567 solver.cpp:228] Iteration 13600, loss = 6143.64
I0826 22:41:18.143059  4567 solver.cpp:244]     Train net output #0: accuracy = 0.941896
I0826 22:41:18.143074  4567 solver.cpp:244]     Train net output #1: loss = 6143.64 (* 1 = 6143.64 loss)
I0826 22:41:18.143105  4567 sgd_solver.cpp:106] Iteration 13600, lr = 1e-08
I0826 22:42:36.728359  4567 solver.cpp:228] Iteration 13650, loss = 3493.34
I0826 22:42:36.728469  4567 solver.cpp:244]     Train net output #0: accuracy = 0.965903
I0826 22:42:36.728482  4567 solver.cpp:244]     Train net output #1: loss = 3493.34 (* 1 = 3493.34 loss)
I0826 22:42:36.728489  4567 sgd_solver.cpp:106] Iteration 13650, lr = 1e-08
I0826 22:43:54.974007  4567 solver.cpp:228] Iteration 13700, loss = 6629.21
I0826 22:43:54.974092  4567 solver.cpp:244]     Train net output #0: accuracy = 0.934425
I0826 22:43:54.974103  4567 solver.cpp:244]     Train net output #1: loss = 6629.21 (* 1 = 6629.21 loss)
I0826 22:43:54.974110  4567 sgd_solver.cpp:106] Iteration 13700, lr = 1e-08
I0826 22:45:13.388751  4567 solver.cpp:228] Iteration 13750, loss = 6394.83
I0826 22:45:13.388837  4567 solver.cpp:244]     Train net output #0: accuracy = 0.93685
I0826 22:45:13.388851  4567 solver.cpp:244]     Train net output #1: loss = 6394.83 (* 1 = 6394.83 loss)
I0826 22:45:13.388861  4567 sgd_solver.cpp:106] Iteration 13750, lr = 1e-08
I0826 22:46:30.408644  4567 solver.cpp:337] Iteration 13800, Testing net (#0)
I0826 22:46:39.112437  4567 solver.cpp:404]     Test net output #0: accuracy = 0.937451
I0826 22:46:39.112481  4567 solver.cpp:404]     Test net output #1: loss = 6593.22 (* 1 = 6593.22 loss)
I0826 22:46:40.504216  4567 solver.cpp:228] Iteration 13800, loss = 3792.55
I0826 22:46:40.504254  4567 solver.cpp:244]     Train net output #0: accuracy = 0.963398
I0826 22:46:40.504263  4567 solver.cpp:244]     Train net output #1: loss = 3792.55 (* 1 = 3792.55 loss)
I0826 22:46:40.504271  4567 sgd_solver.cpp:106] Iteration 13800, lr = 1e-08
I0826 22:47:58.437352  4567 solver.cpp:228] Iteration 13850, loss = 8377.32
I0826 22:47:58.437443  4567 solver.cpp:244]     Train net output #0: accuracy = 0.916716
I0826 22:47:58.437459  4567 solver.cpp:244]     Train net output #1: loss = 8377.32 (* 1 = 8377.32 loss)
I0826 22:47:58.437469  4567 sgd_solver.cpp:106] Iteration 13850, lr = 1e-08
I0826 22:49:16.465140  4567 solver.cpp:228] Iteration 13900, loss = 4145.21
I0826 22:49:16.465229  4567 solver.cpp:244]     Train net output #0: accuracy = 0.958932
I0826 22:49:16.465245  4567 solver.cpp:244]     Train net output #1: loss = 4145.21 (* 1 = 4145.21 loss)
I0826 22:49:16.465255  4567 sgd_solver.cpp:106] Iteration 13900, lr = 1e-08
I0826 22:50:33.145920  4567 solver.cpp:228] Iteration 13950, loss = 7565.44
I0826 22:50:33.145995  4567 solver.cpp:244]     Train net output #0: accuracy = 0.927522
I0826 22:50:33.146008  4567 solver.cpp:244]     Train net output #1: loss = 7565.44 (* 1 = 7565.44 loss)
I0826 22:50:33.146014  4567 sgd_solver.cpp:106] Iteration 13950, lr = 1e-08
I0826 22:51:48.886580  4567 solver.cpp:337] Iteration 14000, Testing net (#0)
I0826 22:51:57.182704  4567 solver.cpp:404]     Test net output #0: accuracy = 0.9393
I0826 22:51:57.182747  4567 solver.cpp:404]     Test net output #1: loss = 6380.51 (* 1 = 6380.51 loss)
I0826 22:51:58.632450  4567 solver.cpp:228] Iteration 14000, loss = 4508.58
I0826 22:51:58.632488  4567 solver.cpp:244]     Train net output #0: accuracy = 0.955778
I0826 22:51:58.632498  4567 solver.cpp:244]     Train net output #1: loss = 4508.58 (* 1 = 4508.58 loss)
I0826 22:51:58.632505  4567 sgd_solver.cpp:106] Iteration 14000, lr = 1e-08
I0826 22:53:16.494602  4567 solver.cpp:228] Iteration 14050, loss = 5906.13
I0826 22:53:16.494689  4567 solver.cpp:244]     Train net output #0: accuracy = 0.942668
I0826 22:53:16.494701  4567 solver.cpp:244]     Train net output #1: loss = 5906.13 (* 1 = 5906.13 loss)
I0826 22:53:16.494709  4567 sgd_solver.cpp:106] Iteration 14050, lr = 1e-08
I0826 22:54:33.968345  4567 solver.cpp:228] Iteration 14100, loss = 4605.64
I0826 22:54:33.968423  4567 solver.cpp:244]     Train net output #0: accuracy = 0.956152
I0826 22:54:33.968436  4567 solver.cpp:244]     Train net output #1: loss = 4605.64 (* 1 = 4605.64 loss)
I0826 22:54:33.968442  4567 sgd_solver.cpp:106] Iteration 14100, lr = 1e-08
I0826 22:55:52.522663  4567 solver.cpp:228] Iteration 14150, loss = 3127.48
I0826 22:55:52.522796  4567 solver.cpp:244]     Train net output #0: accuracy = 0.969024
I0826 22:55:52.522815  4567 solver.cpp:244]     Train net output #1: loss = 3127.48 (* 1 = 3127.48 loss)
I0826 22:55:52.522826  4567 sgd_solver.cpp:106] Iteration 14150, lr = 1e-08
I0826 22:57:11.324249  4567 solver.cpp:337] Iteration 14200, Testing net (#0)
I0826 22:57:19.420969  4567 solver.cpp:404]     Test net output #0: accuracy = 0.937382
I0826 22:57:19.421007  4567 solver.cpp:404]     Test net output #1: loss = 6644.07 (* 1 = 6644.07 loss)
I0826 22:57:20.832849  4567 solver.cpp:228] Iteration 14200, loss = 6605.9
I0826 22:57:20.832890  4567 solver.cpp:244]     Train net output #0: accuracy = 0.9337
I0826 22:57:20.832906  4567 solver.cpp:244]     Train net output #1: loss = 6605.9 (* 1 = 6605.9 loss)
I0826 22:57:20.832916  4567 sgd_solver.cpp:106] Iteration 14200, lr = 1e-08
I0826 22:58:39.069977  4567 solver.cpp:228] Iteration 14250, loss = 3925.06
I0826 22:58:39.070047  4567 solver.cpp:244]     Train net output #0: accuracy = 0.96014
I0826 22:58:39.070060  4567 solver.cpp:244]     Train net output #1: loss = 3925.06 (* 1 = 3925.06 loss)
I0826 22:58:39.070066  4567 sgd_solver.cpp:106] Iteration 14250, lr = 1e-08
I0826 22:59:59.759318  4567 solver.cpp:228] Iteration 14300, loss = 7364.54
I0826 22:59:59.759438  4567 solver.cpp:244]     Train net output #0: accuracy = 0.927378
I0826 22:59:59.759455  4567 solver.cpp:244]     Train net output #1: loss = 7364.54 (* 1 = 7364.54 loss)
I0826 22:59:59.759466  4567 sgd_solver.cpp:106] Iteration 14300, lr = 1e-08
I0826 23:01:19.194744  4567 solver.cpp:228] Iteration 14350, loss = 4175.51
I0826 23:01:19.194831  4567 solver.cpp:244]     Train net output #0: accuracy = 0.958774
I0826 23:01:19.194844  4567 solver.cpp:244]     Train net output #1: loss = 4175.51 (* 1 = 4175.51 loss)
I0826 23:01:19.194852  4567 sgd_solver.cpp:106] Iteration 14350, lr = 1e-08
I0826 23:02:35.438907  4567 solver.cpp:337] Iteration 14400, Testing net (#0)
I0826 23:02:43.667727  4567 solver.cpp:404]     Test net output #0: accuracy = 0.934963
I0826 23:02:43.667779  4567 solver.cpp:404]     Test net output #1: loss = 6863.2 (* 1 = 6863.2 loss)
I0826 23:02:45.024397  4567 solver.cpp:228] Iteration 14400, loss = 7581.18
I0826 23:02:45.024433  4567 solver.cpp:244]     Train net output #0: accuracy = 0.927809
I0826 23:02:45.024446  4567 solver.cpp:244]     Train net output #1: loss = 7581.18 (* 1 = 7581.18 loss)
I0826 23:02:45.024453  4567 sgd_solver.cpp:106] Iteration 14400, lr = 1e-08
I0826 23:04:06.403959  4567 solver.cpp:228] Iteration 14450, loss = 4399.08
I0826 23:04:06.404042  4567 solver.cpp:244]     Train net output #0: accuracy = 0.956637
I0826 23:04:06.404052  4567 solver.cpp:244]     Train net output #1: loss = 4399.08 (* 1 = 4399.08 loss)
I0826 23:04:06.404059  4567 sgd_solver.cpp:106] Iteration 14450, lr = 1e-08
I0826 23:05:34.340715  4567 solver.cpp:228] Iteration 14500, loss = 5181.71
I0826 23:05:34.340808  4567 solver.cpp:244]     Train net output #0: accuracy = 0.949869
I0826 23:05:34.340823  4567 solver.cpp:244]     Train net output #1: loss = 5181.71 (* 1 = 5181.71 loss)
I0826 23:05:34.340834  4567 sgd_solver.cpp:106] Iteration 14500, lr = 1e-08
I0826 23:06:58.512804  4567 solver.cpp:228] Iteration 14550, loss = 5914.54
I0826 23:06:58.512876  4567 solver.cpp:244]     Train net output #0: accuracy = 0.94289
I0826 23:06:58.512887  4567 solver.cpp:244]     Train net output #1: loss = 5914.54 (* 1 = 5914.54 loss)
I0826 23:06:58.512894  4567 sgd_solver.cpp:106] Iteration 14550, lr = 1e-08
I0826 23:08:15.421548  4567 solver.cpp:337] Iteration 14600, Testing net (#0)
I0826 23:08:23.478670  4567 solver.cpp:404]     Test net output #0: accuracy = 0.93634
I0826 23:08:23.478713  4567 solver.cpp:404]     Test net output #1: loss = 6692.22 (* 1 = 6692.22 loss)
I0826 23:08:24.814595  4567 solver.cpp:228] Iteration 14600, loss = 3539.32
I0826 23:08:24.814635  4567 solver.cpp:244]     Train net output #0: accuracy = 0.965408
I0826 23:08:24.814645  4567 solver.cpp:244]     Train net output #1: loss = 3539.32 (* 1 = 3539.32 loss)
I0826 23:08:24.814659  4567 sgd_solver.cpp:106] Iteration 14600, lr = 1e-08
I0826 23:09:44.466068  4567 solver.cpp:228] Iteration 14650, loss = 6530.89
I0826 23:09:44.466176  4567 solver.cpp:244]     Train net output #0: accuracy = 0.934158
I0826 23:09:44.466188  4567 solver.cpp:244]     Train net output #1: loss = 6530.89 (* 1 = 6530.89 loss)
I0826 23:09:44.466195  4567 sgd_solver.cpp:106] Iteration 14650, lr = 1e-08
I0826 23:11:01.320339  4567 solver.cpp:228] Iteration 14700, loss = 4023.25
I0826 23:11:01.320422  4567 solver.cpp:244]     Train net output #0: accuracy = 0.95934
I0826 23:11:01.320433  4567 solver.cpp:244]     Train net output #1: loss = 4023.25 (* 1 = 4023.25 loss)
I0826 23:11:01.320441  4567 sgd_solver.cpp:106] Iteration 14700, lr = 1e-08
I0826 23:12:19.201733  4567 solver.cpp:228] Iteration 14750, loss = 7723.14
I0826 23:12:19.201819  4567 solver.cpp:244]     Train net output #0: accuracy = 0.923092
I0826 23:12:19.201839  4567 solver.cpp:244]     Train net output #1: loss = 7723.14 (* 1 = 7723.14 loss)
I0826 23:12:19.201850  4567 sgd_solver.cpp:106] Iteration 14750, lr = 1e-08
I0826 23:13:34.906512  4567 solver.cpp:337] Iteration 14800, Testing net (#0)
I0826 23:13:42.939232  4567 solver.cpp:404]     Test net output #0: accuracy = 0.936978
I0826 23:13:42.939275  4567 solver.cpp:404]     Test net output #1: loss = 6643.09 (* 1 = 6643.09 loss)
I0826 23:13:44.364681  4567 solver.cpp:228] Iteration 14800, loss = 3794.99
I0826 23:13:44.364730  4567 solver.cpp:244]     Train net output #0: accuracy = 0.962977
I0826 23:13:44.364744  4567 solver.cpp:244]     Train net output #1: loss = 3794.99 (* 1 = 3794.99 loss)
I0826 23:13:44.364755  4567 sgd_solver.cpp:106] Iteration 14800, lr = 1e-08
I0826 23:15:02.523586  4567 solver.cpp:228] Iteration 14850, loss = 7159.18
I0826 23:15:02.523665  4567 solver.cpp:244]     Train net output #0: accuracy = 0.931263
I0826 23:15:02.523676  4567 solver.cpp:244]     Train net output #1: loss = 7159.18 (* 1 = 7159.18 loss)
I0826 23:15:02.523684  4567 sgd_solver.cpp:106] Iteration 14850, lr = 1e-08
I0826 23:16:20.554741  4567 solver.cpp:228] Iteration 14900, loss = 8044.93
I0826 23:16:20.554831  4567 solver.cpp:244]     Train net output #0: accuracy = 0.920899
I0826 23:16:20.554847  4567 solver.cpp:244]     Train net output #1: loss = 8044.93 (* 1 = 8044.93 loss)
I0826 23:16:20.554857  4567 sgd_solver.cpp:106] Iteration 14900, lr = 1e-08
I0826 23:17:39.650238  4567 solver.cpp:228] Iteration 14950, loss = 4015.16
I0826 23:17:39.650327  4567 solver.cpp:244]     Train net output #0: accuracy = 0.960689
I0826 23:17:39.650342  4567 solver.cpp:244]     Train net output #1: loss = 4015.16 (* 1 = 4015.16 loss)
I0826 23:17:39.650352  4567 sgd_solver.cpp:106] Iteration 14950, lr = 1e-08
I0826 23:18:58.297188  4567 solver.cpp:337] Iteration 15000, Testing net (#0)
I0826 23:19:05.928532  4567 solver.cpp:404]     Test net output #0: accuracy = 0.93906
I0826 23:19:05.928573  4567 solver.cpp:404]     Test net output #1: loss = 6424.16 (* 1 = 6424.16 loss)
I0826 23:19:07.264564  4567 solver.cpp:228] Iteration 15000, loss = 5337.84
I0826 23:19:07.264600  4567 solver.cpp:244]     Train net output #0: accuracy = 0.947192
I0826 23:19:07.264611  4567 solver.cpp:244]     Train net output #1: loss = 5337.84 (* 1 = 5337.84 loss)
I0826 23:19:07.264617  4567 sgd_solver.cpp:106] Iteration 15000, lr = 1e-08
I0826 23:20:24.333588  4567 solver.cpp:228] Iteration 15050, loss = 3558.92
I0826 23:20:24.333689  4567 solver.cpp:244]     Train net output #0: accuracy = 0.965685
I0826 23:20:24.333701  4567 solver.cpp:244]     Train net output #1: loss = 3558.92 (* 1 = 3558.92 loss)
I0826 23:20:24.333709  4567 sgd_solver.cpp:106] Iteration 15050, lr = 1e-08
I0826 23:21:43.472975  4567 solver.cpp:228] Iteration 15100, loss = 6361.79
I0826 23:21:43.473060  4567 solver.cpp:244]     Train net output #0: accuracy = 0.936571
I0826 23:21:43.473073  4567 solver.cpp:244]     Train net output #1: loss = 6361.79 (* 1 = 6361.79 loss)
I0826 23:21:43.473079  4567 sgd_solver.cpp:106] Iteration 15100, lr = 1e-08
I0826 23:23:01.863814  4567 solver.cpp:228] Iteration 15150, loss = 3575.37
I0826 23:23:01.863919  4567 solver.cpp:244]     Train net output #0: accuracy = 0.964176
I0826 23:23:01.863930  4567 solver.cpp:244]     Train net output #1: loss = 3575.37 (* 1 = 3575.37 loss)
I0826 23:23:01.863939  4567 sgd_solver.cpp:106] Iteration 15150, lr = 1e-08
I0826 23:24:18.731973  4567 solver.cpp:337] Iteration 15200, Testing net (#0)
I0826 23:24:26.838620  4567 solver.cpp:404]     Test net output #0: accuracy = 0.937182
I0826 23:24:26.838660  4567 solver.cpp:404]     Test net output #1: loss = 6682.01 (* 1 = 6682.01 loss)
I0826 23:24:28.274085  4567 solver.cpp:228] Iteration 15200, loss = 7129.38
I0826 23:24:28.274123  4567 solver.cpp:244]     Train net output #0: accuracy = 0.930051
I0826 23:24:28.274133  4567 solver.cpp:244]     Train net output #1: loss = 7129.38 (* 1 = 7129.38 loss)
I0826 23:24:28.274140  4567 sgd_solver.cpp:106] Iteration 15200, lr = 1e-08
I0826 23:25:48.532918  4567 solver.cpp:228] Iteration 15250, loss = 5532.24
I0826 23:25:48.533007  4567 solver.cpp:244]     Train net output #0: accuracy = 0.945641
I0826 23:25:48.533021  4567 solver.cpp:244]     Train net output #1: loss = 5532.24 (* 1 = 5532.24 loss)
I0826 23:25:48.533030  4567 sgd_solver.cpp:106] Iteration 15250, lr = 1e-08
I0826 23:27:05.477620  4567 solver.cpp:228] Iteration 15300, loss = 3960.34
I0826 23:27:05.477710  4567 solver.cpp:244]     Train net output #0: accuracy = 0.960939
I0826 23:27:05.477721  4567 solver.cpp:244]     Train net output #1: loss = 3960.34 (* 1 = 3960.34 loss)
I0826 23:27:05.477728  4567 sgd_solver.cpp:106] Iteration 15300, lr = 1e-08
I0826 23:28:22.497465  4567 solver.cpp:228] Iteration 15350, loss = 8296.99
I0826 23:28:22.497539  4567 solver.cpp:244]     Train net output #0: accuracy = 0.919629
I0826 23:28:22.497550  4567 solver.cpp:244]     Train net output #1: loss = 8296.99 (* 1 = 8296.99 loss)
I0826 23:28:22.497558  4567 sgd_solver.cpp:106] Iteration 15350, lr = 1e-08
I0826 23:29:39.278158  4567 solver.cpp:337] Iteration 15400, Testing net (#0)
I0826 23:29:47.474340  4567 solver.cpp:404]     Test net output #0: accuracy = 0.935923
I0826 23:29:47.474378  4567 solver.cpp:404]     Test net output #1: loss = 6727.81 (* 1 = 6727.81 loss)
I0826 23:29:48.896476  4567 solver.cpp:228] Iteration 15400, loss = 4216.06
I0826 23:29:48.896518  4567 solver.cpp:244]     Train net output #0: accuracy = 0.958338
I0826 23:29:48.896533  4567 solver.cpp:244]     Train net output #1: loss = 4216.06 (* 1 = 4216.06 loss)
I0826 23:29:48.896543  4567 sgd_solver.cpp:106] Iteration 15400, lr = 1e-08
I0826 23:31:06.781718  4567 solver.cpp:228] Iteration 15450, loss = 6478.54
I0826 23:31:06.781797  4567 solver.cpp:244]     Train net output #0: accuracy = 0.936869
I0826 23:31:06.781810  4567 solver.cpp:244]     Train net output #1: loss = 6478.54 (* 1 = 6478.54 loss)
I0826 23:31:06.781817  4567 sgd_solver.cpp:106] Iteration 15450, lr = 1e-08
I0826 23:32:25.179972  4567 solver.cpp:228] Iteration 15500, loss = 3549.13
I0826 23:32:25.180047  4567 solver.cpp:244]     Train net output #0: accuracy = 0.965745
I0826 23:32:25.180058  4567 solver.cpp:244]     Train net output #1: loss = 3549.13 (* 1 = 3549.13 loss)
I0826 23:32:25.180066  4567 sgd_solver.cpp:106] Iteration 15500, lr = 1e-08
I0826 23:33:43.246033  4567 solver.cpp:228] Iteration 15550, loss = 6206.04
I0826 23:33:43.246107  4567 solver.cpp:244]     Train net output #0: accuracy = 0.940362
I0826 23:33:43.246119  4567 solver.cpp:244]     Train net output #1: loss = 6206.04 (* 1 = 6206.04 loss)
I0826 23:33:43.246126  4567 sgd_solver.cpp:106] Iteration 15550, lr = 1e-08
I0826 23:34:59.179924  4567 solver.cpp:337] Iteration 15600, Testing net (#0)
I0826 23:35:07.296104  4567 solver.cpp:404]     Test net output #0: accuracy = 0.936099
I0826 23:35:07.296144  4567 solver.cpp:404]     Test net output #1: loss = 6751.68 (* 1 = 6751.68 loss)
I0826 23:35:08.683862  4567 solver.cpp:228] Iteration 15600, loss = 3685.74
I0826 23:35:08.683902  4567 solver.cpp:244]     Train net output #0: accuracy = 0.963311
I0826 23:35:08.683923  4567 solver.cpp:244]     Train net output #1: loss = 3685.74 (* 1 = 3685.74 loss)
I0826 23:35:08.683931  4567 sgd_solver.cpp:106] Iteration 15600, lr = 1e-08
I0826 23:36:26.784167  4567 solver.cpp:228] Iteration 15650, loss = 4612.76
I0826 23:36:26.784265  4567 solver.cpp:244]     Train net output #0: accuracy = 0.955767
I0826 23:36:26.784276  4567 solver.cpp:244]     Train net output #1: loss = 4612.76 (* 1 = 4612.76 loss)
I0826 23:36:26.784283  4567 sgd_solver.cpp:106] Iteration 15650, lr = 1e-08
I0826 23:37:46.740119  4567 solver.cpp:228] Iteration 15700, loss = 7212.43
I0826 23:37:46.740198  4567 solver.cpp:244]     Train net output #0: accuracy = 0.927787
I0826 23:37:46.740209  4567 solver.cpp:244]     Train net output #1: loss = 7212.43 (* 1 = 7212.43 loss)
I0826 23:37:46.740217  4567 sgd_solver.cpp:106] Iteration 15700, lr = 1e-08
I0826 23:39:04.612432  4567 solver.cpp:228] Iteration 15750, loss = 3968.61
I0826 23:39:04.612506  4567 solver.cpp:244]     Train net output #0: accuracy = 0.960165
I0826 23:39:04.612519  4567 solver.cpp:244]     Train net output #1: loss = 3968.61 (* 1 = 3968.61 loss)
I0826 23:39:04.612526  4567 sgd_solver.cpp:106] Iteration 15750, lr = 1e-08
I0826 23:40:21.185390  4567 solver.cpp:337] Iteration 15800, Testing net (#0)
I0826 23:40:29.142271  4567 solver.cpp:404]     Test net output #0: accuracy = 0.936889
I0826 23:40:29.142313  4567 solver.cpp:404]     Test net output #1: loss = 6624.12 (* 1 = 6624.12 loss)
I0826 23:40:30.605716  4567 solver.cpp:228] Iteration 15800, loss = 8164.42
I0826 23:40:30.605753  4567 solver.cpp:244]     Train net output #0: accuracy = 0.921416
I0826 23:40:30.605763  4567 solver.cpp:244]     Train net output #1: loss = 8164.42 (* 1 = 8164.42 loss)
I0826 23:40:30.605770  4567 sgd_solver.cpp:106] Iteration 15800, lr = 1e-08
I0826 23:41:48.891793  4567 solver.cpp:228] Iteration 15850, loss = 4232.11
I0826 23:41:48.891862  4567 solver.cpp:244]     Train net output #0: accuracy = 0.958923
I0826 23:41:48.891873  4567 solver.cpp:244]     Train net output #1: loss = 4232.11 (* 1 = 4232.11 loss)
I0826 23:41:48.891880  4567 sgd_solver.cpp:106] Iteration 15850, lr = 1e-08
I0826 23:43:06.514673  4567 solver.cpp:228] Iteration 15900, loss = 6160.23
I0826 23:43:06.514755  4567 solver.cpp:244]     Train net output #0: accuracy = 0.941502
I0826 23:43:06.514772  4567 solver.cpp:244]     Train net output #1: loss = 6160.23 (* 1 = 6160.23 loss)
I0826 23:43:06.514783  4567 sgd_solver.cpp:106] Iteration 15900, lr = 1e-08
I0826 23:44:23.754523  4567 solver.cpp:228] Iteration 15950, loss = 3583.29
I0826 23:44:23.754595  4567 solver.cpp:244]     Train net output #0: accuracy = 0.964839
I0826 23:44:23.754608  4567 solver.cpp:244]     Train net output #1: loss = 3583.29 (* 1 = 3583.29 loss)
I0826 23:44:23.754616  4567 sgd_solver.cpp:106] Iteration 15950, lr = 1e-08
I0826 23:45:41.542189  4567 solver.cpp:454] Snapshotting to binary proto file portrait_one_stage3_iter_16000.caffemodel
I0826 23:45:41.547116  4567 sgd_solver.cpp:273] Snapshotting solver state to binary proto file portrait_one_stage3_iter_16000.solverstate
I0826 23:45:42.631975  4567 solver.cpp:317] Iteration 16000, loss = 6233.99
I0826 23:45:42.632021  4567 solver.cpp:337] Iteration 16000, Testing net (#0)
I0826 23:45:50.812680  4567 solver.cpp:404]     Test net output #0: accuracy = 0.939106
I0826 23:45:50.812721  4567 solver.cpp:404]     Test net output #1: loss = 6418.12 (* 1 = 6418.12 loss)
I0826 23:45:50.812727  4567 solver.cpp:322] Optimization Done.
I0826 23:45:50.812738  4567 caffe.cpp:254] Optimization Done.
