I0818 19:33:26.906795 23166 caffe.cpp:217] Using GPUs 1
I0818 19:33:26.930011 23166 caffe.cpp:222] GPU 1: GeForce GTX TITAN X
I0818 19:33:27.126579 23166 solver.cpp:48] Initializing solver from parameters: 
test_iter: 15
test_interval: 200
base_lr: 1e-05
display: 50
max_iter: 8000
lr_policy: "step"
gamma: 0.5
momentum: 0.9
weight_decay: 0
stepsize: 1000
snapshot: 2000
snapshot_prefix: "portrait_two_stage"
solver_mode: GPU
device_id: 1
net: "portrait_train_test_two_stages.prototxt"
train_state {
  level: 0
  stage: ""
}
I0818 19:33:27.126682 23166 solver.cpp:91] Creating training net from net file: portrait_train_test_two_stages.prototxt
I0818 19:33:27.127360 23166 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0818 19:33:27.127553 23166 net.cpp:58] Initializing net from parameters: 
name: "segmentation"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "SegData"
  top: "image"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 200
  }
  data_param {
    source: "/raid/xuehan/segmentation_train_split"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "image"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 50
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv1_1_bn"
  type: "BatchNorm"
  bottom: "conv1_1"
  top: "conv1_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv1_1_bn_scale"
  type: "Scale"
  bottom: "conv1_1_bn"
  top: "conv1_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_1_relu"
  type: "ReLU"
  bottom: "conv1_1_bn"
  top: "conv1_1_bn"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_1_bn"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv2_1_bn"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv2_1_bn_scale"
  type: "Scale"
  bottom: "conv2_1_bn"
  top: "conv2_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1_relu"
  type: "ReLU"
  bottom: "conv2_1_bn"
  top: "conv2_1_bn"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_1_bn"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv3_1_bn"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv3_1_bn_scale"
  type: "Scale"
  bottom: "conv3_1_bn"
  top: "conv3_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1_relu"
  type: "ReLU"
  bottom: "conv3_1_bn"
  top: "conv3_1_bn"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_1_bn"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv4_1_bn"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv4_1_bn_scale"
  type: "Scale"
  bottom: "conv4_1_bn"
  top: "conv4_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1_relu"
  type: "ReLU"
  bottom: "conv4_1_bn"
  top: "conv4_1_bn"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_1_bn"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv5_1_bn"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv5_1_bn_scale"
  type: "Scale"
  bottom: "conv5_1_bn"
  top: "conv5_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_1_relu"
  type: "ReLU"
  bottom: "conv5_1_bn"
  top: "conv5_1_bn"
}
layer {
  name: "score_1"
  type: "Convolution"
  bottom: "conv5_1_bn"
  top: "score_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 4
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "upscore_1"
  type: "Deconvolution"
  bottom: "score_1"
  top: "upscore_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 4
    bias_term: false
    pad: 0
    kernel_size: 32
    stride: 16
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "cropscore_1"
  type: "Crop"
  bottom: "upscore_1"
  bottom: "image"
  top: "cropscore_1"
  crop_param {
    axis: 2
    offset: 60
  }
}
layer {
  name: "loss_1"
  type: "SoftmaxWithLoss"
  bottom: "cropscore_1"
  bottom: "label"
  top: "loss_1"
  loss_weight: 1
  loss_param {
    normalize: false
  }
}
layer {
  name: "accuracy_1"
  type: "Accuracy"
  bottom: "cropscore_1"
  bottom: "label"
  top: "accuracy_1"
}
layer {
  name: "concat_2"
  type: "Concat"
  bottom: "pool4"
  bottom: "score_1"
  top: "concat_2"
  concat_param {
    axis: 1
  }
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "concat_2"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv5_2_bn"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv5_2_bn_scale"
  type: "Scale"
  bottom: "conv5_2_bn"
  top: "conv5_2_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_2_relu"
  type: "ReLU"
  bottom: "conv5_2_bn"
  top: "conv5_2_bn"
}
layer {
  name: "conv6_2"
  type: "Convolution"
  bottom: "conv5_2_bn"
  top: "conv6_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv6_2_bn"
  type: "BatchNorm"
  bottom: "conv6_2"
  top: "conv6_2_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv6_2_bn_scale"
  type: "Scale"
  bottom: "conv6_2_bn"
  top: "conv6_2_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv6_2_relu"
  type: "ReLU"
  bottom: "conv6_2_bn"
  top: "conv6_2_bn"
}
layer {
  name: "conv7_2"
  type: "Convolution"
  bottom: "conv6_2_bn"
  top: "conv7_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv7_2_bn"
  type: "BatchNorm"
  bottom: "conv7_2"
  top: "conv7_2_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv7_2_bn_scale"
  type: "Scale"
  bottom: "conv7_2_bn"
  top: "conv7_2_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv7_2_relu"
  type: "ReLU"
  bottom: "conv7_2_bn"
  top: "conv7_2_bn"
}
layer {
  name: "score_2"
  type: "Convolution"
  bottom: "conv7_2_bn"
  top: "score_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 4
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "upscore_2"
  type: "Deconvolution"
  bottom: "score_2"
  top: "upscore_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 4
    bias_term: false
    pad: 0
    kernel_size: 32
    stride: 16
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "cropscore_2"
  type: "Crop"
  bottom: "upscore_2"
  bottom: "image"
  top: "cropscore_2"
  crop_param {
    axis: 2
    offset: 12
  }
}
layer {
  name: "loss_2"
  type: "SoftmaxWithLoss"
  bottom: "cropscore_2"
  bottom: "label"
  top: "loss_2"
  loss_weight: 1
  loss_param {
    normalize: false
  }
}
layer {
  name: "accuracy_2"
  type: "Accuracy"
  bottom: "cropscore_2"
  bottom: "label"
  top: "accuracy_2"
}
I0818 19:33:27.127743 23166 layer_factory.hpp:77] Creating layer data
I0818 19:33:27.128162 23166 net.cpp:100] Creating Layer data
I0818 19:33:27.128173 23166 net.cpp:408] data -> image
I0818 19:33:27.128190 23166 net.cpp:408] data -> label
I0818 19:33:27.129127 23170 db_lmdb.cpp:35] Opened lmdb /raid/xuehan/segmentation_train_split
I0818 19:33:27.129303 23166 seg_data_layer.cpp:38] 200 200 4
I0818 19:33:27.136611 23166 seg_data_layer.cpp:51] output data size: 64,3,200,200
I0818 19:33:27.136672 23166 seg_data_layer.cpp:63] output label size: 64,1,200,200
I0818 19:33:27.189291 23166 net.cpp:150] Setting up data
I0818 19:33:27.189322 23166 net.cpp:157] Top shape: 64 3 200 200 (7680000)
I0818 19:33:27.189327 23166 net.cpp:157] Top shape: 64 1 200 200 (2560000)
I0818 19:33:27.189329 23166 net.cpp:165] Memory required for data: 40960000
I0818 19:33:27.189338 23166 layer_factory.hpp:77] Creating layer image_data_0_split
I0818 19:33:27.189350 23166 net.cpp:100] Creating Layer image_data_0_split
I0818 19:33:27.189355 23166 net.cpp:434] image_data_0_split <- image
I0818 19:33:27.189366 23166 net.cpp:408] image_data_0_split -> image_data_0_split_0
I0818 19:33:27.189374 23166 net.cpp:408] image_data_0_split -> image_data_0_split_1
I0818 19:33:27.189379 23166 net.cpp:408] image_data_0_split -> image_data_0_split_2
I0818 19:33:27.189430 23166 net.cpp:150] Setting up image_data_0_split
I0818 19:33:27.189436 23166 net.cpp:157] Top shape: 64 3 200 200 (7680000)
I0818 19:33:27.189440 23166 net.cpp:157] Top shape: 64 3 200 200 (7680000)
I0818 19:33:27.189443 23166 net.cpp:157] Top shape: 64 3 200 200 (7680000)
I0818 19:33:27.189445 23166 net.cpp:165] Memory required for data: 133120000
I0818 19:33:27.189448 23166 layer_factory.hpp:77] Creating layer label_data_1_split
I0818 19:33:27.189453 23166 net.cpp:100] Creating Layer label_data_1_split
I0818 19:33:27.189456 23166 net.cpp:434] label_data_1_split <- label
I0818 19:33:27.189461 23166 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0818 19:33:27.189466 23166 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0818 19:33:27.189471 23166 net.cpp:408] label_data_1_split -> label_data_1_split_2
I0818 19:33:27.189473 23166 net.cpp:408] label_data_1_split -> label_data_1_split_3
I0818 19:33:27.189513 23166 net.cpp:150] Setting up label_data_1_split
I0818 19:33:27.189517 23166 net.cpp:157] Top shape: 64 1 200 200 (2560000)
I0818 19:33:27.189527 23166 net.cpp:157] Top shape: 64 1 200 200 (2560000)
I0818 19:33:27.189538 23166 net.cpp:157] Top shape: 64 1 200 200 (2560000)
I0818 19:33:27.189540 23166 net.cpp:157] Top shape: 64 1 200 200 (2560000)
I0818 19:33:27.189543 23166 net.cpp:165] Memory required for data: 174080000
I0818 19:33:27.189545 23166 layer_factory.hpp:77] Creating layer conv1_1
I0818 19:33:27.189559 23166 net.cpp:100] Creating Layer conv1_1
I0818 19:33:27.189563 23166 net.cpp:434] conv1_1 <- image_data_0_split_0
I0818 19:33:27.189568 23166 net.cpp:408] conv1_1 -> conv1_1
I0818 19:33:27.189726 23166 net.cpp:150] Setting up conv1_1
I0818 19:33:27.189733 23166 net.cpp:157] Top shape: 64 8 298 298 (45467648)
I0818 19:33:27.189736 23166 net.cpp:165] Memory required for data: 355950592
I0818 19:33:27.189745 23166 layer_factory.hpp:77] Creating layer conv1_1_bn
I0818 19:33:27.189752 23166 net.cpp:100] Creating Layer conv1_1_bn
I0818 19:33:27.189755 23166 net.cpp:434] conv1_1_bn <- conv1_1
I0818 19:33:27.189759 23166 net.cpp:408] conv1_1_bn -> conv1_1_bn
I0818 19:33:27.190330 23166 net.cpp:150] Setting up conv1_1_bn
I0818 19:33:27.190340 23166 net.cpp:157] Top shape: 64 8 298 298 (45467648)
I0818 19:33:27.190343 23166 net.cpp:165] Memory required for data: 537821184
I0818 19:33:27.190352 23166 layer_factory.hpp:77] Creating layer conv1_1_bn_scale
I0818 19:33:27.190361 23166 net.cpp:100] Creating Layer conv1_1_bn_scale
I0818 19:33:27.190364 23166 net.cpp:434] conv1_1_bn_scale <- conv1_1_bn
I0818 19:33:27.190368 23166 net.cpp:395] conv1_1_bn_scale -> conv1_1_bn (in-place)
I0818 19:33:27.190400 23166 layer_factory.hpp:77] Creating layer conv1_1_bn_scale
I0818 19:33:27.190958 23166 net.cpp:150] Setting up conv1_1_bn_scale
I0818 19:33:27.190968 23166 net.cpp:157] Top shape: 64 8 298 298 (45467648)
I0818 19:33:27.190971 23166 net.cpp:165] Memory required for data: 719691776
I0818 19:33:27.190981 23166 layer_factory.hpp:77] Creating layer conv1_1_relu
I0818 19:33:27.190987 23166 net.cpp:100] Creating Layer conv1_1_relu
I0818 19:33:27.190991 23166 net.cpp:434] conv1_1_relu <- conv1_1_bn
I0818 19:33:27.190995 23166 net.cpp:395] conv1_1_relu -> conv1_1_bn (in-place)
I0818 19:33:27.191000 23166 net.cpp:150] Setting up conv1_1_relu
I0818 19:33:27.191004 23166 net.cpp:157] Top shape: 64 8 298 298 (45467648)
I0818 19:33:27.191006 23166 net.cpp:165] Memory required for data: 901562368
I0818 19:33:27.191009 23166 layer_factory.hpp:77] Creating layer pool1
I0818 19:33:27.191015 23166 net.cpp:100] Creating Layer pool1
I0818 19:33:27.191016 23166 net.cpp:434] pool1 <- conv1_1_bn
I0818 19:33:27.191022 23166 net.cpp:408] pool1 -> pool1
I0818 19:33:27.194345 23166 net.cpp:150] Setting up pool1
I0818 19:33:27.194355 23166 net.cpp:157] Top shape: 64 8 149 149 (11366912)
I0818 19:33:27.194357 23166 net.cpp:165] Memory required for data: 947030016
I0818 19:33:27.194360 23166 layer_factory.hpp:77] Creating layer conv2_1
I0818 19:33:27.194370 23166 net.cpp:100] Creating Layer conv2_1
I0818 19:33:27.194373 23166 net.cpp:434] conv2_1 <- pool1
I0818 19:33:27.194377 23166 net.cpp:408] conv2_1 -> conv2_1
I0818 19:33:27.194960 23166 net.cpp:150] Setting up conv2_1
I0818 19:33:27.194970 23166 net.cpp:157] Top shape: 64 16 149 149 (22733824)
I0818 19:33:27.194972 23166 net.cpp:165] Memory required for data: 1037965312
I0818 19:33:27.194977 23166 layer_factory.hpp:77] Creating layer conv2_1_bn
I0818 19:33:27.194983 23166 net.cpp:100] Creating Layer conv2_1_bn
I0818 19:33:27.194986 23166 net.cpp:434] conv2_1_bn <- conv2_1
I0818 19:33:27.194990 23166 net.cpp:408] conv2_1_bn -> conv2_1_bn
I0818 19:33:27.195540 23166 net.cpp:150] Setting up conv2_1_bn
I0818 19:33:27.195549 23166 net.cpp:157] Top shape: 64 16 149 149 (22733824)
I0818 19:33:27.195552 23166 net.cpp:165] Memory required for data: 1128900608
I0818 19:33:27.195562 23166 layer_factory.hpp:77] Creating layer conv2_1_bn_scale
I0818 19:33:27.195569 23166 net.cpp:100] Creating Layer conv2_1_bn_scale
I0818 19:33:27.195572 23166 net.cpp:434] conv2_1_bn_scale <- conv2_1_bn
I0818 19:33:27.195576 23166 net.cpp:395] conv2_1_bn_scale -> conv2_1_bn (in-place)
I0818 19:33:27.195616 23166 layer_factory.hpp:77] Creating layer conv2_1_bn_scale
I0818 19:33:27.195708 23166 net.cpp:150] Setting up conv2_1_bn_scale
I0818 19:33:27.195715 23166 net.cpp:157] Top shape: 64 16 149 149 (22733824)
I0818 19:33:27.195718 23166 net.cpp:165] Memory required for data: 1219835904
I0818 19:33:27.195722 23166 layer_factory.hpp:77] Creating layer conv2_1_relu
I0818 19:33:27.195729 23166 net.cpp:100] Creating Layer conv2_1_relu
I0818 19:33:27.195731 23166 net.cpp:434] conv2_1_relu <- conv2_1_bn
I0818 19:33:27.195735 23166 net.cpp:395] conv2_1_relu -> conv2_1_bn (in-place)
I0818 19:33:27.195739 23166 net.cpp:150] Setting up conv2_1_relu
I0818 19:33:27.195744 23166 net.cpp:157] Top shape: 64 16 149 149 (22733824)
I0818 19:33:27.195746 23166 net.cpp:165] Memory required for data: 1310771200
I0818 19:33:27.195749 23166 layer_factory.hpp:77] Creating layer pool2
I0818 19:33:27.195754 23166 net.cpp:100] Creating Layer pool2
I0818 19:33:27.195755 23166 net.cpp:434] pool2 <- conv2_1_bn
I0818 19:33:27.195760 23166 net.cpp:408] pool2 -> pool2
I0818 19:33:27.195785 23166 net.cpp:150] Setting up pool2
I0818 19:33:27.195790 23166 net.cpp:157] Top shape: 64 16 75 75 (5760000)
I0818 19:33:27.195791 23166 net.cpp:165] Memory required for data: 1333811200
I0818 19:33:27.195794 23166 layer_factory.hpp:77] Creating layer conv3_1
I0818 19:33:27.195802 23166 net.cpp:100] Creating Layer conv3_1
I0818 19:33:27.195806 23166 net.cpp:434] conv3_1 <- pool2
I0818 19:33:27.195811 23166 net.cpp:408] conv3_1 -> conv3_1
I0818 19:33:27.196435 23166 net.cpp:150] Setting up conv3_1
I0818 19:33:27.196445 23166 net.cpp:157] Top shape: 64 32 75 75 (11520000)
I0818 19:33:27.196449 23166 net.cpp:165] Memory required for data: 1379891200
I0818 19:33:27.196454 23166 layer_factory.hpp:77] Creating layer conv3_1_bn
I0818 19:33:27.196460 23166 net.cpp:100] Creating Layer conv3_1_bn
I0818 19:33:27.196463 23166 net.cpp:434] conv3_1_bn <- conv3_1
I0818 19:33:27.196468 23166 net.cpp:408] conv3_1_bn -> conv3_1_bn
I0818 19:33:27.196597 23166 net.cpp:150] Setting up conv3_1_bn
I0818 19:33:27.196604 23166 net.cpp:157] Top shape: 64 32 75 75 (11520000)
I0818 19:33:27.196605 23166 net.cpp:165] Memory required for data: 1425971200
I0818 19:33:27.196611 23166 layer_factory.hpp:77] Creating layer conv3_1_bn_scale
I0818 19:33:27.196616 23166 net.cpp:100] Creating Layer conv3_1_bn_scale
I0818 19:33:27.196619 23166 net.cpp:434] conv3_1_bn_scale <- conv3_1_bn
I0818 19:33:27.196624 23166 net.cpp:395] conv3_1_bn_scale -> conv3_1_bn (in-place)
I0818 19:33:27.196650 23166 layer_factory.hpp:77] Creating layer conv3_1_bn_scale
I0818 19:33:27.196730 23166 net.cpp:150] Setting up conv3_1_bn_scale
I0818 19:33:27.196737 23166 net.cpp:157] Top shape: 64 32 75 75 (11520000)
I0818 19:33:27.196739 23166 net.cpp:165] Memory required for data: 1472051200
I0818 19:33:27.196746 23166 layer_factory.hpp:77] Creating layer conv3_1_relu
I0818 19:33:27.196753 23166 net.cpp:100] Creating Layer conv3_1_relu
I0818 19:33:27.196756 23166 net.cpp:434] conv3_1_relu <- conv3_1_bn
I0818 19:33:27.196760 23166 net.cpp:395] conv3_1_relu -> conv3_1_bn (in-place)
I0818 19:33:27.196769 23166 net.cpp:150] Setting up conv3_1_relu
I0818 19:33:27.196773 23166 net.cpp:157] Top shape: 64 32 75 75 (11520000)
I0818 19:33:27.196775 23166 net.cpp:165] Memory required for data: 1518131200
I0818 19:33:27.196779 23166 layer_factory.hpp:77] Creating layer pool3
I0818 19:33:27.196782 23166 net.cpp:100] Creating Layer pool3
I0818 19:33:27.196785 23166 net.cpp:434] pool3 <- conv3_1_bn
I0818 19:33:27.196789 23166 net.cpp:408] pool3 -> pool3
I0818 19:33:27.196815 23166 net.cpp:150] Setting up pool3
I0818 19:33:27.196820 23166 net.cpp:157] Top shape: 64 32 38 38 (2957312)
I0818 19:33:27.196822 23166 net.cpp:165] Memory required for data: 1529960448
I0818 19:33:27.196825 23166 layer_factory.hpp:77] Creating layer conv4_1
I0818 19:33:27.196832 23166 net.cpp:100] Creating Layer conv4_1
I0818 19:33:27.196835 23166 net.cpp:434] conv4_1 <- pool3
I0818 19:33:27.196840 23166 net.cpp:408] conv4_1 -> conv4_1
I0818 19:33:27.197368 23166 net.cpp:150] Setting up conv4_1
I0818 19:33:27.197381 23166 net.cpp:157] Top shape: 64 64 38 38 (5914624)
I0818 19:33:27.197383 23166 net.cpp:165] Memory required for data: 1553618944
I0818 19:33:27.197387 23166 layer_factory.hpp:77] Creating layer conv4_1_bn
I0818 19:33:27.197392 23166 net.cpp:100] Creating Layer conv4_1_bn
I0818 19:33:27.197394 23166 net.cpp:434] conv4_1_bn <- conv4_1
I0818 19:33:27.197399 23166 net.cpp:408] conv4_1_bn -> conv4_1_bn
I0818 19:33:27.197523 23166 net.cpp:150] Setting up conv4_1_bn
I0818 19:33:27.197530 23166 net.cpp:157] Top shape: 64 64 38 38 (5914624)
I0818 19:33:27.197531 23166 net.cpp:165] Memory required for data: 1577277440
I0818 19:33:27.197537 23166 layer_factory.hpp:77] Creating layer conv4_1_bn_scale
I0818 19:33:27.197543 23166 net.cpp:100] Creating Layer conv4_1_bn_scale
I0818 19:33:27.197546 23166 net.cpp:434] conv4_1_bn_scale <- conv4_1_bn
I0818 19:33:27.197551 23166 net.cpp:395] conv4_1_bn_scale -> conv4_1_bn (in-place)
I0818 19:33:27.197576 23166 layer_factory.hpp:77] Creating layer conv4_1_bn_scale
I0818 19:33:27.197654 23166 net.cpp:150] Setting up conv4_1_bn_scale
I0818 19:33:27.197659 23166 net.cpp:157] Top shape: 64 64 38 38 (5914624)
I0818 19:33:27.197660 23166 net.cpp:165] Memory required for data: 1600935936
I0818 19:33:27.197665 23166 layer_factory.hpp:77] Creating layer conv4_1_relu
I0818 19:33:27.197670 23166 net.cpp:100] Creating Layer conv4_1_relu
I0818 19:33:27.197674 23166 net.cpp:434] conv4_1_relu <- conv4_1_bn
I0818 19:33:27.197677 23166 net.cpp:395] conv4_1_relu -> conv4_1_bn (in-place)
I0818 19:33:27.197681 23166 net.cpp:150] Setting up conv4_1_relu
I0818 19:33:27.197685 23166 net.cpp:157] Top shape: 64 64 38 38 (5914624)
I0818 19:33:27.197687 23166 net.cpp:165] Memory required for data: 1624594432
I0818 19:33:27.197690 23166 layer_factory.hpp:77] Creating layer pool4
I0818 19:33:27.197696 23166 net.cpp:100] Creating Layer pool4
I0818 19:33:27.197700 23166 net.cpp:434] pool4 <- conv4_1_bn
I0818 19:33:27.197703 23166 net.cpp:408] pool4 -> pool4
I0818 19:33:27.197742 23166 net.cpp:150] Setting up pool4
I0818 19:33:27.197748 23166 net.cpp:157] Top shape: 64 64 19 19 (1478656)
I0818 19:33:27.197751 23166 net.cpp:165] Memory required for data: 1630509056
I0818 19:33:27.197754 23166 layer_factory.hpp:77] Creating layer pool4_pool4_0_split
I0818 19:33:27.197758 23166 net.cpp:100] Creating Layer pool4_pool4_0_split
I0818 19:33:27.197762 23166 net.cpp:434] pool4_pool4_0_split <- pool4
I0818 19:33:27.197765 23166 net.cpp:408] pool4_pool4_0_split -> pool4_pool4_0_split_0
I0818 19:33:27.197772 23166 net.cpp:408] pool4_pool4_0_split -> pool4_pool4_0_split_1
I0818 19:33:27.197793 23166 net.cpp:150] Setting up pool4_pool4_0_split
I0818 19:33:27.197798 23166 net.cpp:157] Top shape: 64 64 19 19 (1478656)
I0818 19:33:27.197800 23166 net.cpp:157] Top shape: 64 64 19 19 (1478656)
I0818 19:33:27.197803 23166 net.cpp:165] Memory required for data: 1642338304
I0818 19:33:27.197805 23166 layer_factory.hpp:77] Creating layer conv5_1
I0818 19:33:27.197813 23166 net.cpp:100] Creating Layer conv5_1
I0818 19:33:27.197815 23166 net.cpp:434] conv5_1 <- pool4_pool4_0_split_0
I0818 19:33:27.197820 23166 net.cpp:408] conv5_1 -> conv5_1
I0818 19:33:27.199527 23166 net.cpp:150] Setting up conv5_1
I0818 19:33:27.199534 23166 net.cpp:157] Top shape: 64 128 19 19 (2957312)
I0818 19:33:27.199537 23166 net.cpp:165] Memory required for data: 1654167552
I0818 19:33:27.199542 23166 layer_factory.hpp:77] Creating layer conv5_1_bn
I0818 19:33:27.199547 23166 net.cpp:100] Creating Layer conv5_1_bn
I0818 19:33:27.199549 23166 net.cpp:434] conv5_1_bn <- conv5_1
I0818 19:33:27.199558 23166 net.cpp:408] conv5_1_bn -> conv5_1_bn
I0818 19:33:27.200137 23166 net.cpp:150] Setting up conv5_1_bn
I0818 19:33:27.200147 23166 net.cpp:157] Top shape: 64 128 19 19 (2957312)
I0818 19:33:27.200150 23166 net.cpp:165] Memory required for data: 1665996800
I0818 19:33:27.200156 23166 layer_factory.hpp:77] Creating layer conv5_1_bn_scale
I0818 19:33:27.200161 23166 net.cpp:100] Creating Layer conv5_1_bn_scale
I0818 19:33:27.200170 23166 net.cpp:434] conv5_1_bn_scale <- conv5_1_bn
I0818 19:33:27.200179 23166 net.cpp:395] conv5_1_bn_scale -> conv5_1_bn (in-place)
I0818 19:33:27.200211 23166 layer_factory.hpp:77] Creating layer conv5_1_bn_scale
I0818 19:33:27.200283 23166 net.cpp:150] Setting up conv5_1_bn_scale
I0818 19:33:27.200287 23166 net.cpp:157] Top shape: 64 128 19 19 (2957312)
I0818 19:33:27.200290 23166 net.cpp:165] Memory required for data: 1677826048
I0818 19:33:27.200294 23166 layer_factory.hpp:77] Creating layer conv5_1_relu
I0818 19:33:27.200299 23166 net.cpp:100] Creating Layer conv5_1_relu
I0818 19:33:27.200302 23166 net.cpp:434] conv5_1_relu <- conv5_1_bn
I0818 19:33:27.200307 23166 net.cpp:395] conv5_1_relu -> conv5_1_bn (in-place)
I0818 19:33:27.200312 23166 net.cpp:150] Setting up conv5_1_relu
I0818 19:33:27.200316 23166 net.cpp:157] Top shape: 64 128 19 19 (2957312)
I0818 19:33:27.200320 23166 net.cpp:165] Memory required for data: 1689655296
I0818 19:33:27.200321 23166 layer_factory.hpp:77] Creating layer score_1
I0818 19:33:27.200328 23166 net.cpp:100] Creating Layer score_1
I0818 19:33:27.200331 23166 net.cpp:434] score_1 <- conv5_1_bn
I0818 19:33:27.200336 23166 net.cpp:408] score_1 -> score_1
I0818 19:33:27.200496 23166 net.cpp:150] Setting up score_1
I0818 19:33:27.200502 23166 net.cpp:157] Top shape: 64 4 19 19 (92416)
I0818 19:33:27.200505 23166 net.cpp:165] Memory required for data: 1690024960
I0818 19:33:27.200510 23166 layer_factory.hpp:77] Creating layer score_1_score_1_0_split
I0818 19:33:27.200515 23166 net.cpp:100] Creating Layer score_1_score_1_0_split
I0818 19:33:27.200517 23166 net.cpp:434] score_1_score_1_0_split <- score_1
I0818 19:33:27.200522 23166 net.cpp:408] score_1_score_1_0_split -> score_1_score_1_0_split_0
I0818 19:33:27.200527 23166 net.cpp:408] score_1_score_1_0_split -> score_1_score_1_0_split_1
I0818 19:33:27.200553 23166 net.cpp:150] Setting up score_1_score_1_0_split
I0818 19:33:27.200557 23166 net.cpp:157] Top shape: 64 4 19 19 (92416)
I0818 19:33:27.200562 23166 net.cpp:157] Top shape: 64 4 19 19 (92416)
I0818 19:33:27.200563 23166 net.cpp:165] Memory required for data: 1690764288
I0818 19:33:27.200567 23166 layer_factory.hpp:77] Creating layer upscore_1
I0818 19:33:27.200574 23166 net.cpp:100] Creating Layer upscore_1
I0818 19:33:27.200577 23166 net.cpp:434] upscore_1 <- score_1_score_1_0_split_0
I0818 19:33:27.200582 23166 net.cpp:408] upscore_1 -> upscore_1
I0818 19:33:27.201050 23166 net.cpp:150] Setting up upscore_1
I0818 19:33:27.201055 23166 net.cpp:157] Top shape: 64 4 320 320 (26214400)
I0818 19:33:27.201057 23166 net.cpp:165] Memory required for data: 1795621888
I0818 19:33:27.201066 23166 layer_factory.hpp:77] Creating layer cropscore_1
I0818 19:33:27.201072 23166 net.cpp:100] Creating Layer cropscore_1
I0818 19:33:27.201076 23166 net.cpp:434] cropscore_1 <- upscore_1
I0818 19:33:27.201079 23166 net.cpp:434] cropscore_1 <- image_data_0_split_1
I0818 19:33:27.201083 23166 net.cpp:408] cropscore_1 -> cropscore_1
I0818 19:33:27.201102 23166 net.cpp:150] Setting up cropscore_1
I0818 19:33:27.201107 23166 net.cpp:157] Top shape: 64 4 200 200 (10240000)
I0818 19:33:27.201109 23166 net.cpp:165] Memory required for data: 1836581888
I0818 19:33:27.201112 23166 layer_factory.hpp:77] Creating layer cropscore_1_cropscore_1_0_split
I0818 19:33:27.201119 23166 net.cpp:100] Creating Layer cropscore_1_cropscore_1_0_split
I0818 19:33:27.201122 23166 net.cpp:434] cropscore_1_cropscore_1_0_split <- cropscore_1
I0818 19:33:27.201128 23166 net.cpp:408] cropscore_1_cropscore_1_0_split -> cropscore_1_cropscore_1_0_split_0
I0818 19:33:27.201133 23166 net.cpp:408] cropscore_1_cropscore_1_0_split -> cropscore_1_cropscore_1_0_split_1
I0818 19:33:27.201154 23166 net.cpp:150] Setting up cropscore_1_cropscore_1_0_split
I0818 19:33:27.201160 23166 net.cpp:157] Top shape: 64 4 200 200 (10240000)
I0818 19:33:27.201164 23166 net.cpp:157] Top shape: 64 4 200 200 (10240000)
I0818 19:33:27.201165 23166 net.cpp:165] Memory required for data: 1918501888
I0818 19:33:27.201171 23166 layer_factory.hpp:77] Creating layer loss_1
I0818 19:33:27.201180 23166 net.cpp:100] Creating Layer loss_1
I0818 19:33:27.201184 23166 net.cpp:434] loss_1 <- cropscore_1_cropscore_1_0_split_0
I0818 19:33:27.201187 23166 net.cpp:434] loss_1 <- label_data_1_split_0
I0818 19:33:27.201191 23166 net.cpp:408] loss_1 -> loss_1
I0818 19:33:27.201202 23166 layer_factory.hpp:77] Creating layer loss_1
I0818 19:33:27.219584 23166 net.cpp:150] Setting up loss_1
I0818 19:33:27.219612 23166 net.cpp:157] Top shape: (1)
I0818 19:33:27.219615 23166 net.cpp:160]     with loss weight 1
I0818 19:33:27.219633 23166 net.cpp:165] Memory required for data: 1918501892
I0818 19:33:27.219637 23166 layer_factory.hpp:77] Creating layer accuracy_1
I0818 19:33:27.219653 23166 net.cpp:100] Creating Layer accuracy_1
I0818 19:33:27.219658 23166 net.cpp:434] accuracy_1 <- cropscore_1_cropscore_1_0_split_1
I0818 19:33:27.219665 23166 net.cpp:434] accuracy_1 <- label_data_1_split_1
I0818 19:33:27.219669 23166 net.cpp:408] accuracy_1 -> accuracy_1
I0818 19:33:27.219677 23166 net.cpp:150] Setting up accuracy_1
I0818 19:33:27.219681 23166 net.cpp:157] Top shape: (1)
I0818 19:33:27.219683 23166 net.cpp:165] Memory required for data: 1918501896
I0818 19:33:27.219686 23166 layer_factory.hpp:77] Creating layer concat_2
I0818 19:33:27.219697 23166 net.cpp:100] Creating Layer concat_2
I0818 19:33:27.219702 23166 net.cpp:434] concat_2 <- pool4_pool4_0_split_1
I0818 19:33:27.219705 23166 net.cpp:434] concat_2 <- score_1_score_1_0_split_1
I0818 19:33:27.219709 23166 net.cpp:408] concat_2 -> concat_2
I0818 19:33:27.219735 23166 net.cpp:150] Setting up concat_2
I0818 19:33:27.219740 23166 net.cpp:157] Top shape: 64 68 19 19 (1571072)
I0818 19:33:27.219743 23166 net.cpp:165] Memory required for data: 1924786184
I0818 19:33:27.219746 23166 layer_factory.hpp:77] Creating layer conv5_2
I0818 19:33:27.219754 23166 net.cpp:100] Creating Layer conv5_2
I0818 19:33:27.219758 23166 net.cpp:434] conv5_2 <- concat_2
I0818 19:33:27.219763 23166 net.cpp:408] conv5_2 -> conv5_2
I0818 19:33:27.220736 23166 net.cpp:150] Setting up conv5_2
I0818 19:33:27.220743 23166 net.cpp:157] Top shape: 64 64 17 17 (1183744)
I0818 19:33:27.220746 23166 net.cpp:165] Memory required for data: 1929521160
I0818 19:33:27.220751 23166 layer_factory.hpp:77] Creating layer conv5_2_bn
I0818 19:33:27.220757 23166 net.cpp:100] Creating Layer conv5_2_bn
I0818 19:33:27.220760 23166 net.cpp:434] conv5_2_bn <- conv5_2
I0818 19:33:27.220764 23166 net.cpp:408] conv5_2_bn -> conv5_2_bn
I0818 19:33:27.220904 23166 net.cpp:150] Setting up conv5_2_bn
I0818 19:33:27.220911 23166 net.cpp:157] Top shape: 64 64 17 17 (1183744)
I0818 19:33:27.220913 23166 net.cpp:165] Memory required for data: 1934256136
I0818 19:33:27.220918 23166 layer_factory.hpp:77] Creating layer conv5_2_bn_scale
I0818 19:33:27.220924 23166 net.cpp:100] Creating Layer conv5_2_bn_scale
I0818 19:33:27.220927 23166 net.cpp:434] conv5_2_bn_scale <- conv5_2_bn
I0818 19:33:27.220932 23166 net.cpp:395] conv5_2_bn_scale -> conv5_2_bn (in-place)
I0818 19:33:27.220960 23166 layer_factory.hpp:77] Creating layer conv5_2_bn_scale
I0818 19:33:27.221040 23166 net.cpp:150] Setting up conv5_2_bn_scale
I0818 19:33:27.221045 23166 net.cpp:157] Top shape: 64 64 17 17 (1183744)
I0818 19:33:27.221047 23166 net.cpp:165] Memory required for data: 1938991112
I0818 19:33:27.221051 23166 layer_factory.hpp:77] Creating layer conv5_2_relu
I0818 19:33:27.221056 23166 net.cpp:100] Creating Layer conv5_2_relu
I0818 19:33:27.221060 23166 net.cpp:434] conv5_2_relu <- conv5_2_bn
I0818 19:33:27.221065 23166 net.cpp:395] conv5_2_relu -> conv5_2_bn (in-place)
I0818 19:33:27.221068 23166 net.cpp:150] Setting up conv5_2_relu
I0818 19:33:27.221072 23166 net.cpp:157] Top shape: 64 64 17 17 (1183744)
I0818 19:33:27.221074 23166 net.cpp:165] Memory required for data: 1943726088
I0818 19:33:27.221077 23166 layer_factory.hpp:77] Creating layer conv6_2
I0818 19:33:27.221086 23166 net.cpp:100] Creating Layer conv6_2
I0818 19:33:27.221087 23166 net.cpp:434] conv6_2 <- conv5_2_bn
I0818 19:33:27.221099 23166 net.cpp:408] conv6_2 -> conv6_2
I0818 19:33:27.222044 23166 net.cpp:150] Setting up conv6_2
I0818 19:33:27.222053 23166 net.cpp:157] Top shape: 64 64 15 15 (921600)
I0818 19:33:27.222054 23166 net.cpp:165] Memory required for data: 1947412488
I0818 19:33:27.222059 23166 layer_factory.hpp:77] Creating layer conv6_2_bn
I0818 19:33:27.222064 23166 net.cpp:100] Creating Layer conv6_2_bn
I0818 19:33:27.222066 23166 net.cpp:434] conv6_2_bn <- conv6_2
I0818 19:33:27.222072 23166 net.cpp:408] conv6_2_bn -> conv6_2_bn
I0818 19:33:27.222203 23166 net.cpp:150] Setting up conv6_2_bn
I0818 19:33:27.222209 23166 net.cpp:157] Top shape: 64 64 15 15 (921600)
I0818 19:33:27.222211 23166 net.cpp:165] Memory required for data: 1951098888
I0818 19:33:27.222218 23166 layer_factory.hpp:77] Creating layer conv6_2_bn_scale
I0818 19:33:27.222223 23166 net.cpp:100] Creating Layer conv6_2_bn_scale
I0818 19:33:27.222226 23166 net.cpp:434] conv6_2_bn_scale <- conv6_2_bn
I0818 19:33:27.222229 23166 net.cpp:395] conv6_2_bn_scale -> conv6_2_bn (in-place)
I0818 19:33:27.222255 23166 layer_factory.hpp:77] Creating layer conv6_2_bn_scale
I0818 19:33:27.222332 23166 net.cpp:150] Setting up conv6_2_bn_scale
I0818 19:33:27.222337 23166 net.cpp:157] Top shape: 64 64 15 15 (921600)
I0818 19:33:27.222339 23166 net.cpp:165] Memory required for data: 1954785288
I0818 19:33:27.222344 23166 layer_factory.hpp:77] Creating layer conv6_2_relu
I0818 19:33:27.222348 23166 net.cpp:100] Creating Layer conv6_2_relu
I0818 19:33:27.222352 23166 net.cpp:434] conv6_2_relu <- conv6_2_bn
I0818 19:33:27.222357 23166 net.cpp:395] conv6_2_relu -> conv6_2_bn (in-place)
I0818 19:33:27.222360 23166 net.cpp:150] Setting up conv6_2_relu
I0818 19:33:27.222364 23166 net.cpp:157] Top shape: 64 64 15 15 (921600)
I0818 19:33:27.222368 23166 net.cpp:165] Memory required for data: 1958471688
I0818 19:33:27.222369 23166 layer_factory.hpp:77] Creating layer conv7_2
I0818 19:33:27.222376 23166 net.cpp:100] Creating Layer conv7_2
I0818 19:33:27.222379 23166 net.cpp:434] conv7_2 <- conv6_2_bn
I0818 19:33:27.222383 23166 net.cpp:408] conv7_2 -> conv7_2
I0818 19:33:27.224089 23166 net.cpp:150] Setting up conv7_2
I0818 19:33:27.224095 23166 net.cpp:157] Top shape: 64 128 13 13 (1384448)
I0818 19:33:27.224098 23166 net.cpp:165] Memory required for data: 1964009480
I0818 19:33:27.224102 23166 layer_factory.hpp:77] Creating layer conv7_2_bn
I0818 19:33:27.224107 23166 net.cpp:100] Creating Layer conv7_2_bn
I0818 19:33:27.224109 23166 net.cpp:434] conv7_2_bn <- conv7_2
I0818 19:33:27.224113 23166 net.cpp:408] conv7_2_bn -> conv7_2_bn
I0818 19:33:27.224236 23166 net.cpp:150] Setting up conv7_2_bn
I0818 19:33:27.224242 23166 net.cpp:157] Top shape: 64 128 13 13 (1384448)
I0818 19:33:27.224244 23166 net.cpp:165] Memory required for data: 1969547272
I0818 19:33:27.224249 23166 layer_factory.hpp:77] Creating layer conv7_2_bn_scale
I0818 19:33:27.224254 23166 net.cpp:100] Creating Layer conv7_2_bn_scale
I0818 19:33:27.224257 23166 net.cpp:434] conv7_2_bn_scale <- conv7_2_bn
I0818 19:33:27.224261 23166 net.cpp:395] conv7_2_bn_scale -> conv7_2_bn (in-place)
I0818 19:33:27.224289 23166 layer_factory.hpp:77] Creating layer conv7_2_bn_scale
I0818 19:33:27.224354 23166 net.cpp:150] Setting up conv7_2_bn_scale
I0818 19:33:27.224359 23166 net.cpp:157] Top shape: 64 128 13 13 (1384448)
I0818 19:33:27.224361 23166 net.cpp:165] Memory required for data: 1975085064
I0818 19:33:27.224365 23166 layer_factory.hpp:77] Creating layer conv7_2_relu
I0818 19:33:27.224370 23166 net.cpp:100] Creating Layer conv7_2_relu
I0818 19:33:27.224373 23166 net.cpp:434] conv7_2_relu <- conv7_2_bn
I0818 19:33:27.224377 23166 net.cpp:395] conv7_2_relu -> conv7_2_bn (in-place)
I0818 19:33:27.224381 23166 net.cpp:150] Setting up conv7_2_relu
I0818 19:33:27.224385 23166 net.cpp:157] Top shape: 64 128 13 13 (1384448)
I0818 19:33:27.224386 23166 net.cpp:165] Memory required for data: 1980622856
I0818 19:33:27.224390 23166 layer_factory.hpp:77] Creating layer score_2
I0818 19:33:27.224397 23166 net.cpp:100] Creating Layer score_2
I0818 19:33:27.224405 23166 net.cpp:434] score_2 <- conv7_2_bn
I0818 19:33:27.224416 23166 net.cpp:408] score_2 -> score_2
I0818 19:33:27.224578 23166 net.cpp:150] Setting up score_2
I0818 19:33:27.224584 23166 net.cpp:157] Top shape: 64 4 13 13 (43264)
I0818 19:33:27.224586 23166 net.cpp:165] Memory required for data: 1980795912
I0818 19:33:27.224591 23166 layer_factory.hpp:77] Creating layer upscore_2
I0818 19:33:27.224598 23166 net.cpp:100] Creating Layer upscore_2
I0818 19:33:27.224601 23166 net.cpp:434] upscore_2 <- score_2
I0818 19:33:27.224606 23166 net.cpp:408] upscore_2 -> upscore_2
I0818 19:33:27.225096 23166 net.cpp:150] Setting up upscore_2
I0818 19:33:27.225102 23166 net.cpp:157] Top shape: 64 4 224 224 (12845056)
I0818 19:33:27.225106 23166 net.cpp:165] Memory required for data: 2032176136
I0818 19:33:27.225108 23166 layer_factory.hpp:77] Creating layer cropscore_2
I0818 19:33:27.225114 23166 net.cpp:100] Creating Layer cropscore_2
I0818 19:33:27.225117 23166 net.cpp:434] cropscore_2 <- upscore_2
I0818 19:33:27.225121 23166 net.cpp:434] cropscore_2 <- image_data_0_split_2
I0818 19:33:27.225126 23166 net.cpp:408] cropscore_2 -> cropscore_2
I0818 19:33:27.225143 23166 net.cpp:150] Setting up cropscore_2
I0818 19:33:27.225147 23166 net.cpp:157] Top shape: 64 4 200 200 (10240000)
I0818 19:33:27.225150 23166 net.cpp:165] Memory required for data: 2073136136
I0818 19:33:27.225152 23166 layer_factory.hpp:77] Creating layer cropscore_2_cropscore_2_0_split
I0818 19:33:27.225157 23166 net.cpp:100] Creating Layer cropscore_2_cropscore_2_0_split
I0818 19:33:27.225160 23166 net.cpp:434] cropscore_2_cropscore_2_0_split <- cropscore_2
I0818 19:33:27.225164 23166 net.cpp:408] cropscore_2_cropscore_2_0_split -> cropscore_2_cropscore_2_0_split_0
I0818 19:33:27.225168 23166 net.cpp:408] cropscore_2_cropscore_2_0_split -> cropscore_2_cropscore_2_0_split_1
I0818 19:33:27.225191 23166 net.cpp:150] Setting up cropscore_2_cropscore_2_0_split
I0818 19:33:27.225196 23166 net.cpp:157] Top shape: 64 4 200 200 (10240000)
I0818 19:33:27.225199 23166 net.cpp:157] Top shape: 64 4 200 200 (10240000)
I0818 19:33:27.225203 23166 net.cpp:165] Memory required for data: 2155056136
I0818 19:33:27.225204 23166 layer_factory.hpp:77] Creating layer loss_2
I0818 19:33:27.225209 23166 net.cpp:100] Creating Layer loss_2
I0818 19:33:27.225213 23166 net.cpp:434] loss_2 <- cropscore_2_cropscore_2_0_split_0
I0818 19:33:27.225216 23166 net.cpp:434] loss_2 <- label_data_1_split_2
I0818 19:33:27.225222 23166 net.cpp:408] loss_2 -> loss_2
I0818 19:33:27.225229 23166 layer_factory.hpp:77] Creating layer loss_2
I0818 19:33:27.243549 23166 net.cpp:150] Setting up loss_2
I0818 19:33:27.243600 23166 net.cpp:157] Top shape: (1)
I0818 19:33:27.243603 23166 net.cpp:160]     with loss weight 1
I0818 19:33:27.243613 23166 net.cpp:165] Memory required for data: 2155056140
I0818 19:33:27.243618 23166 layer_factory.hpp:77] Creating layer accuracy_2
I0818 19:33:27.243628 23166 net.cpp:100] Creating Layer accuracy_2
I0818 19:33:27.243633 23166 net.cpp:434] accuracy_2 <- cropscore_2_cropscore_2_0_split_1
I0818 19:33:27.243638 23166 net.cpp:434] accuracy_2 <- label_data_1_split_3
I0818 19:33:27.243643 23166 net.cpp:408] accuracy_2 -> accuracy_2
I0818 19:33:27.243652 23166 net.cpp:150] Setting up accuracy_2
I0818 19:33:27.243655 23166 net.cpp:157] Top shape: (1)
I0818 19:33:27.243659 23166 net.cpp:165] Memory required for data: 2155056144
I0818 19:33:27.243661 23166 net.cpp:228] accuracy_2 does not need backward computation.
I0818 19:33:27.243664 23166 net.cpp:226] loss_2 needs backward computation.
I0818 19:33:27.243667 23166 net.cpp:226] cropscore_2_cropscore_2_0_split needs backward computation.
I0818 19:33:27.243670 23166 net.cpp:226] cropscore_2 needs backward computation.
I0818 19:33:27.243674 23166 net.cpp:226] upscore_2 needs backward computation.
I0818 19:33:27.243677 23166 net.cpp:226] score_2 needs backward computation.
I0818 19:33:27.243680 23166 net.cpp:226] conv7_2_relu needs backward computation.
I0818 19:33:27.243683 23166 net.cpp:226] conv7_2_bn_scale needs backward computation.
I0818 19:33:27.243693 23166 net.cpp:226] conv7_2_bn needs backward computation.
I0818 19:33:27.243705 23166 net.cpp:226] conv7_2 needs backward computation.
I0818 19:33:27.243707 23166 net.cpp:226] conv6_2_relu needs backward computation.
I0818 19:33:27.243710 23166 net.cpp:226] conv6_2_bn_scale needs backward computation.
I0818 19:33:27.243712 23166 net.cpp:226] conv6_2_bn needs backward computation.
I0818 19:33:27.243716 23166 net.cpp:226] conv6_2 needs backward computation.
I0818 19:33:27.243718 23166 net.cpp:226] conv5_2_relu needs backward computation.
I0818 19:33:27.243721 23166 net.cpp:226] conv5_2_bn_scale needs backward computation.
I0818 19:33:27.243723 23166 net.cpp:226] conv5_2_bn needs backward computation.
I0818 19:33:27.243726 23166 net.cpp:226] conv5_2 needs backward computation.
I0818 19:33:27.243729 23166 net.cpp:226] concat_2 needs backward computation.
I0818 19:33:27.243733 23166 net.cpp:228] accuracy_1 does not need backward computation.
I0818 19:33:27.243736 23166 net.cpp:226] loss_1 needs backward computation.
I0818 19:33:27.243741 23166 net.cpp:226] cropscore_1_cropscore_1_0_split needs backward computation.
I0818 19:33:27.243743 23166 net.cpp:226] cropscore_1 needs backward computation.
I0818 19:33:27.243748 23166 net.cpp:226] upscore_1 needs backward computation.
I0818 19:33:27.243752 23166 net.cpp:226] score_1_score_1_0_split needs backward computation.
I0818 19:33:27.243754 23166 net.cpp:226] score_1 needs backward computation.
I0818 19:33:27.243757 23166 net.cpp:226] conv5_1_relu needs backward computation.
I0818 19:33:27.243760 23166 net.cpp:226] conv5_1_bn_scale needs backward computation.
I0818 19:33:27.243763 23166 net.cpp:226] conv5_1_bn needs backward computation.
I0818 19:33:27.243767 23166 net.cpp:226] conv5_1 needs backward computation.
I0818 19:33:27.243769 23166 net.cpp:226] pool4_pool4_0_split needs backward computation.
I0818 19:33:27.243772 23166 net.cpp:226] pool4 needs backward computation.
I0818 19:33:27.243775 23166 net.cpp:226] conv4_1_relu needs backward computation.
I0818 19:33:27.243778 23166 net.cpp:226] conv4_1_bn_scale needs backward computation.
I0818 19:33:27.243780 23166 net.cpp:226] conv4_1_bn needs backward computation.
I0818 19:33:27.243784 23166 net.cpp:226] conv4_1 needs backward computation.
I0818 19:33:27.243788 23166 net.cpp:226] pool3 needs backward computation.
I0818 19:33:27.243790 23166 net.cpp:226] conv3_1_relu needs backward computation.
I0818 19:33:27.243793 23166 net.cpp:226] conv3_1_bn_scale needs backward computation.
I0818 19:33:27.243795 23166 net.cpp:226] conv3_1_bn needs backward computation.
I0818 19:33:27.243798 23166 net.cpp:226] conv3_1 needs backward computation.
I0818 19:33:27.243801 23166 net.cpp:226] pool2 needs backward computation.
I0818 19:33:27.243803 23166 net.cpp:226] conv2_1_relu needs backward computation.
I0818 19:33:27.243806 23166 net.cpp:226] conv2_1_bn_scale needs backward computation.
I0818 19:33:27.243809 23166 net.cpp:226] conv2_1_bn needs backward computation.
I0818 19:33:27.243813 23166 net.cpp:226] conv2_1 needs backward computation.
I0818 19:33:27.243815 23166 net.cpp:226] pool1 needs backward computation.
I0818 19:33:27.243818 23166 net.cpp:226] conv1_1_relu needs backward computation.
I0818 19:33:27.243820 23166 net.cpp:226] conv1_1_bn_scale needs backward computation.
I0818 19:33:27.243824 23166 net.cpp:226] conv1_1_bn needs backward computation.
I0818 19:33:27.243825 23166 net.cpp:226] conv1_1 needs backward computation.
I0818 19:33:27.243829 23166 net.cpp:228] label_data_1_split does not need backward computation.
I0818 19:33:27.243834 23166 net.cpp:228] image_data_0_split does not need backward computation.
I0818 19:33:27.243836 23166 net.cpp:228] data does not need backward computation.
I0818 19:33:27.243839 23166 net.cpp:270] This network produces output accuracy_1
I0818 19:33:27.243842 23166 net.cpp:270] This network produces output accuracy_2
I0818 19:33:27.243845 23166 net.cpp:270] This network produces output loss_1
I0818 19:33:27.243847 23166 net.cpp:270] This network produces output loss_2
I0818 19:33:27.243876 23166 net.cpp:283] Network initialization done.
I0818 19:33:27.244632 23166 solver.cpp:181] Creating test net (#0) specified by net file: portrait_train_test_two_stages.prototxt
I0818 19:33:27.244683 23166 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0818 19:33:27.244868 23166 net.cpp:58] Initializing net from parameters: 
name: "segmentation"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "SegData"
  top: "image"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 200
  }
  data_param {
    source: "/raid/xuehan/segmentation_test_split"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "image"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 50
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv1_1_bn"
  type: "BatchNorm"
  bottom: "conv1_1"
  top: "conv1_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv1_1_bn_scale"
  type: "Scale"
  bottom: "conv1_1_bn"
  top: "conv1_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_1_relu"
  type: "ReLU"
  bottom: "conv1_1_bn"
  top: "conv1_1_bn"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_1_bn"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv2_1_bn"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv2_1_bn_scale"
  type: "Scale"
  bottom: "conv2_1_bn"
  top: "conv2_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1_relu"
  type: "ReLU"
  bottom: "conv2_1_bn"
  top: "conv2_1_bn"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_1_bn"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv3_1_bn"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv3_1_bn_scale"
  type: "Scale"
  bottom: "conv3_1_bn"
  top: "conv3_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1_relu"
  type: "ReLU"
  bottom: "conv3_1_bn"
  top: "conv3_1_bn"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_1_bn"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv4_1_bn"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv4_1_bn_scale"
  type: "Scale"
  bottom: "conv4_1_bn"
  top: "conv4_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1_relu"
  type: "ReLU"
  bottom: "conv4_1_bn"
  top: "conv4_1_bn"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_1_bn"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv5_1_bn"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv5_1_bn_scale"
  type: "Scale"
  bottom: "conv5_1_bn"
  top: "conv5_1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_1_relu"
  type: "ReLU"
  bottom: "conv5_1_bn"
  top: "conv5_1_bn"
}
layer {
  name: "score_1"
  type: "Convolution"
  bottom: "conv5_1_bn"
  top: "score_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 4
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "upscore_1"
  type: "Deconvolution"
  bottom: "score_1"
  top: "upscore_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 4
    bias_term: false
    pad: 0
    kernel_size: 32
    stride: 16
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "cropscore_1"
  type: "Crop"
  bottom: "upscore_1"
  bottom: "image"
  top: "cropscore_1"
  crop_param {
    axis: 2
    offset: 60
  }
}
layer {
  name: "loss_1"
  type: "SoftmaxWithLoss"
  bottom: "cropscore_1"
  bottom: "label"
  top: "loss_1"
  loss_weight: 1
  loss_param {
    normalize: false
  }
}
layer {
  name: "accuracy_1"
  type: "Accuracy"
  bottom: "cropscore_1"
  bottom: "label"
  top: "accuracy_1"
}
layer {
  name: "concat_2"
  type: "Concat"
  bottom: "pool4"
  bottom: "score_1"
  top: "concat_2"
  concat_param {
    axis: 1
  }
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "concat_2"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv5_2_bn"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv5_2_bn_scale"
  type: "Scale"
  bottom: "conv5_2_bn"
  top: "conv5_2_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_2_relu"
  type: "ReLU"
  bottom: "conv5_2_bn"
  top: "conv5_2_bn"
}
layer {
  name: "conv6_2"
  type: "Convolution"
  bottom: "conv5_2_bn"
  top: "conv6_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv6_2_bn"
  type: "BatchNorm"
  bottom: "conv6_2"
  top: "conv6_2_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv6_2_bn_scale"
  type: "Scale"
  bottom: "conv6_2_bn"
  top: "conv6_2_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv6_2_relu"
  type: "ReLU"
  bottom: "conv6_2_bn"
  top: "conv6_2_bn"
}
layer {
  name: "conv7_2"
  type: "Convolution"
  bottom: "conv6_2_bn"
  top: "conv7_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv7_2_bn"
  type: "BatchNorm"
  bottom: "conv7_2"
  top: "conv7_2_bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "conv7_2_bn_scale"
  type: "Scale"
  bottom: "conv7_2_bn"
  top: "conv7_2_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv7_2_relu"
  type: "ReLU"
  bottom: "conv7_2_bn"
  top: "conv7_2_bn"
}
layer {
  name: "score_2"
  type: "Convolution"
  bottom: "conv7_2_bn"
  top: "score_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 4
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "upscore_2"
  type: "Deconvolution"
  bottom: "score_2"
  top: "upscore_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 4
    bias_term: false
    pad: 0
    kernel_size: 32
    stride: 16
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "cropscore_2"
  type: "Crop"
  bottom: "upscore_2"
  bottom: "image"
  top: "cropscore_2"
  crop_param {
    axis: 2
    offset: 12
  }
}
layer {
  name: "loss_2"
  type: "SoftmaxWithLoss"
  bottom: "cropscore_2"
  bottom: "label"
  top: "loss_2"
  loss_weight: 1
  loss_param {
    normalize: false
  }
}
layer {
  name: "accuracy_2"
  type: "Accuracy"
  bottom: "cropscore_2"
  bottom: "label"
  top: "accuracy_2"
}
I0818 19:33:27.245030 23166 layer_factory.hpp:77] Creating layer data
I0818 19:33:27.245121 23166 net.cpp:100] Creating Layer data
I0818 19:33:27.245127 23166 net.cpp:408] data -> image
I0818 19:33:27.245136 23166 net.cpp:408] data -> label
I0818 19:33:27.246213 23172 db_lmdb.cpp:35] Opened lmdb /raid/xuehan/segmentation_test_split
I0818 19:33:27.246381 23166 seg_data_layer.cpp:38] 200 200 4
I0818 19:33:27.246466 23166 seg_data_layer.cpp:51] output data size: 64,3,200,200
I0818 19:33:27.246511 23166 seg_data_layer.cpp:63] output label size: 64,1,200,200
I0818 19:33:27.299233 23166 net.cpp:150] Setting up data
I0818 19:33:27.299263 23166 net.cpp:157] Top shape: 64 3 200 200 (7680000)
I0818 19:33:27.299268 23166 net.cpp:157] Top shape: 64 1 200 200 (2560000)
I0818 19:33:27.299270 23166 net.cpp:165] Memory required for data: 40960000
I0818 19:33:27.299275 23166 layer_factory.hpp:77] Creating layer image_data_0_split
I0818 19:33:27.299288 23166 net.cpp:100] Creating Layer image_data_0_split
I0818 19:33:27.299290 23166 net.cpp:434] image_data_0_split <- image
I0818 19:33:27.299296 23166 net.cpp:408] image_data_0_split -> image_data_0_split_0
I0818 19:33:27.299304 23166 net.cpp:408] image_data_0_split -> image_data_0_split_1
I0818 19:33:27.299311 23166 net.cpp:408] image_data_0_split -> image_data_0_split_2
I0818 19:33:27.299412 23166 net.cpp:150] Setting up image_data_0_split
I0818 19:33:27.299418 23166 net.cpp:157] Top shape: 64 3 200 200 (7680000)
I0818 19:33:27.299422 23166 net.cpp:157] Top shape: 64 3 200 200 (7680000)
I0818 19:33:27.299427 23166 net.cpp:157] Top shape: 64 3 200 200 (7680000)
I0818 19:33:27.299428 23166 net.cpp:165] Memory required for data: 133120000
I0818 19:33:27.299432 23166 layer_factory.hpp:77] Creating layer label_data_1_split
I0818 19:33:27.299437 23166 net.cpp:100] Creating Layer label_data_1_split
I0818 19:33:27.299440 23166 net.cpp:434] label_data_1_split <- label
I0818 19:33:27.299444 23166 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0818 19:33:27.299448 23166 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0818 19:33:27.299453 23166 net.cpp:408] label_data_1_split -> label_data_1_split_2
I0818 19:33:27.299458 23166 net.cpp:408] label_data_1_split -> label_data_1_split_3
I0818 19:33:27.299504 23166 net.cpp:150] Setting up label_data_1_split
I0818 19:33:27.299507 23166 net.cpp:157] Top shape: 64 1 200 200 (2560000)
I0818 19:33:27.299510 23166 net.cpp:157] Top shape: 64 1 200 200 (2560000)
I0818 19:33:27.299513 23166 net.cpp:157] Top shape: 64 1 200 200 (2560000)
I0818 19:33:27.299517 23166 net.cpp:157] Top shape: 64 1 200 200 (2560000)
I0818 19:33:27.299520 23166 net.cpp:165] Memory required for data: 174080000
I0818 19:33:27.299522 23166 layer_factory.hpp:77] Creating layer conv1_1
I0818 19:33:27.299532 23166 net.cpp:100] Creating Layer conv1_1
I0818 19:33:27.299542 23166 net.cpp:434] conv1_1 <- image_data_0_split_0
I0818 19:33:27.299556 23166 net.cpp:408] conv1_1 -> conv1_1
I0818 19:33:27.299698 23166 net.cpp:150] Setting up conv1_1
I0818 19:33:27.299705 23166 net.cpp:157] Top shape: 64 8 298 298 (45467648)
I0818 19:33:27.299706 23166 net.cpp:165] Memory required for data: 355950592
I0818 19:33:27.299713 23166 layer_factory.hpp:77] Creating layer conv1_1_bn
I0818 19:33:27.299720 23166 net.cpp:100] Creating Layer conv1_1_bn
I0818 19:33:27.299721 23166 net.cpp:434] conv1_1_bn <- conv1_1
I0818 19:33:27.299727 23166 net.cpp:408] conv1_1_bn -> conv1_1_bn
I0818 19:33:27.300318 23166 net.cpp:150] Setting up conv1_1_bn
I0818 19:33:27.300328 23166 net.cpp:157] Top shape: 64 8 298 298 (45467648)
I0818 19:33:27.300330 23166 net.cpp:165] Memory required for data: 537821184
I0818 19:33:27.300339 23166 layer_factory.hpp:77] Creating layer conv1_1_bn_scale
I0818 19:33:27.300345 23166 net.cpp:100] Creating Layer conv1_1_bn_scale
I0818 19:33:27.300348 23166 net.cpp:434] conv1_1_bn_scale <- conv1_1_bn
I0818 19:33:27.300354 23166 net.cpp:395] conv1_1_bn_scale -> conv1_1_bn (in-place)
I0818 19:33:27.300386 23166 layer_factory.hpp:77] Creating layer conv1_1_bn_scale
I0818 19:33:27.300952 23166 net.cpp:150] Setting up conv1_1_bn_scale
I0818 19:33:27.300962 23166 net.cpp:157] Top shape: 64 8 298 298 (45467648)
I0818 19:33:27.300966 23166 net.cpp:165] Memory required for data: 719691776
I0818 19:33:27.300974 23166 layer_factory.hpp:77] Creating layer conv1_1_relu
I0818 19:33:27.300981 23166 net.cpp:100] Creating Layer conv1_1_relu
I0818 19:33:27.300986 23166 net.cpp:434] conv1_1_relu <- conv1_1_bn
I0818 19:33:27.300990 23166 net.cpp:395] conv1_1_relu -> conv1_1_bn (in-place)
I0818 19:33:27.300997 23166 net.cpp:150] Setting up conv1_1_relu
I0818 19:33:27.300999 23166 net.cpp:157] Top shape: 64 8 298 298 (45467648)
I0818 19:33:27.301002 23166 net.cpp:165] Memory required for data: 901562368
I0818 19:33:27.301004 23166 layer_factory.hpp:77] Creating layer pool1
I0818 19:33:27.301010 23166 net.cpp:100] Creating Layer pool1
I0818 19:33:27.301013 23166 net.cpp:434] pool1 <- conv1_1_bn
I0818 19:33:27.301017 23166 net.cpp:408] pool1 -> pool1
I0818 19:33:27.304193 23166 net.cpp:150] Setting up pool1
I0818 19:33:27.304208 23166 net.cpp:157] Top shape: 64 8 149 149 (11366912)
I0818 19:33:27.304210 23166 net.cpp:165] Memory required for data: 947030016
I0818 19:33:27.304214 23166 layer_factory.hpp:77] Creating layer conv2_1
I0818 19:33:27.304224 23166 net.cpp:100] Creating Layer conv2_1
I0818 19:33:27.304227 23166 net.cpp:434] conv2_1 <- pool1
I0818 19:33:27.304232 23166 net.cpp:408] conv2_1 -> conv2_1
I0818 19:33:27.304397 23166 net.cpp:150] Setting up conv2_1
I0818 19:33:27.304404 23166 net.cpp:157] Top shape: 64 16 149 149 (22733824)
I0818 19:33:27.304417 23166 net.cpp:165] Memory required for data: 1037965312
I0818 19:33:27.304422 23166 layer_factory.hpp:77] Creating layer conv2_1_bn
I0818 19:33:27.304427 23166 net.cpp:100] Creating Layer conv2_1_bn
I0818 19:33:27.304430 23166 net.cpp:434] conv2_1_bn <- conv2_1
I0818 19:33:27.304436 23166 net.cpp:408] conv2_1_bn -> conv2_1_bn
I0818 19:33:27.304595 23166 net.cpp:150] Setting up conv2_1_bn
I0818 19:33:27.304601 23166 net.cpp:157] Top shape: 64 16 149 149 (22733824)
I0818 19:33:27.304603 23166 net.cpp:165] Memory required for data: 1128900608
I0818 19:33:27.304613 23166 layer_factory.hpp:77] Creating layer conv2_1_bn_scale
I0818 19:33:27.304618 23166 net.cpp:100] Creating Layer conv2_1_bn_scale
I0818 19:33:27.304621 23166 net.cpp:434] conv2_1_bn_scale <- conv2_1_bn
I0818 19:33:27.304625 23166 net.cpp:395] conv2_1_bn_scale -> conv2_1_bn (in-place)
I0818 19:33:27.304654 23166 layer_factory.hpp:77] Creating layer conv2_1_bn_scale
I0818 19:33:27.304762 23166 net.cpp:150] Setting up conv2_1_bn_scale
I0818 19:33:27.304769 23166 net.cpp:157] Top shape: 64 16 149 149 (22733824)
I0818 19:33:27.304771 23166 net.cpp:165] Memory required for data: 1219835904
I0818 19:33:27.304776 23166 layer_factory.hpp:77] Creating layer conv2_1_relu
I0818 19:33:27.304781 23166 net.cpp:100] Creating Layer conv2_1_relu
I0818 19:33:27.304790 23166 net.cpp:434] conv2_1_relu <- conv2_1_bn
I0818 19:33:27.304800 23166 net.cpp:395] conv2_1_relu -> conv2_1_bn (in-place)
I0818 19:33:27.304805 23166 net.cpp:150] Setting up conv2_1_relu
I0818 19:33:27.304808 23166 net.cpp:157] Top shape: 64 16 149 149 (22733824)
I0818 19:33:27.304811 23166 net.cpp:165] Memory required for data: 1310771200
I0818 19:33:27.304813 23166 layer_factory.hpp:77] Creating layer pool2
I0818 19:33:27.304818 23166 net.cpp:100] Creating Layer pool2
I0818 19:33:27.304821 23166 net.cpp:434] pool2 <- conv2_1_bn
I0818 19:33:27.304826 23166 net.cpp:408] pool2 -> pool2
I0818 19:33:27.304853 23166 net.cpp:150] Setting up pool2
I0818 19:33:27.304858 23166 net.cpp:157] Top shape: 64 16 75 75 (5760000)
I0818 19:33:27.304860 23166 net.cpp:165] Memory required for data: 1333811200
I0818 19:33:27.304863 23166 layer_factory.hpp:77] Creating layer conv3_1
I0818 19:33:27.304872 23166 net.cpp:100] Creating Layer conv3_1
I0818 19:33:27.304874 23166 net.cpp:434] conv3_1 <- pool2
I0818 19:33:27.304878 23166 net.cpp:408] conv3_1 -> conv3_1
I0818 19:33:27.305110 23166 net.cpp:150] Setting up conv3_1
I0818 19:33:27.305115 23166 net.cpp:157] Top shape: 64 32 75 75 (11520000)
I0818 19:33:27.305119 23166 net.cpp:165] Memory required for data: 1379891200
I0818 19:33:27.305122 23166 layer_factory.hpp:77] Creating layer conv3_1_bn
I0818 19:33:27.305127 23166 net.cpp:100] Creating Layer conv3_1_bn
I0818 19:33:27.305130 23166 net.cpp:434] conv3_1_bn <- conv3_1
I0818 19:33:27.305135 23166 net.cpp:408] conv3_1_bn -> conv3_1_bn
I0818 19:33:27.305279 23166 net.cpp:150] Setting up conv3_1_bn
I0818 19:33:27.305285 23166 net.cpp:157] Top shape: 64 32 75 75 (11520000)
I0818 19:33:27.305287 23166 net.cpp:165] Memory required for data: 1425971200
I0818 19:33:27.305294 23166 layer_factory.hpp:77] Creating layer conv3_1_bn_scale
I0818 19:33:27.305299 23166 net.cpp:100] Creating Layer conv3_1_bn_scale
I0818 19:33:27.305302 23166 net.cpp:434] conv3_1_bn_scale <- conv3_1_bn
I0818 19:33:27.305307 23166 net.cpp:395] conv3_1_bn_scale -> conv3_1_bn (in-place)
I0818 19:33:27.305335 23166 layer_factory.hpp:77] Creating layer conv3_1_bn_scale
I0818 19:33:27.305426 23166 net.cpp:150] Setting up conv3_1_bn_scale
I0818 19:33:27.305431 23166 net.cpp:157] Top shape: 64 32 75 75 (11520000)
I0818 19:33:27.305434 23166 net.cpp:165] Memory required for data: 1472051200
I0818 19:33:27.305443 23166 layer_factory.hpp:77] Creating layer conv3_1_relu
I0818 19:33:27.305449 23166 net.cpp:100] Creating Layer conv3_1_relu
I0818 19:33:27.305451 23166 net.cpp:434] conv3_1_relu <- conv3_1_bn
I0818 19:33:27.305454 23166 net.cpp:395] conv3_1_relu -> conv3_1_bn (in-place)
I0818 19:33:27.305459 23166 net.cpp:150] Setting up conv3_1_relu
I0818 19:33:27.305462 23166 net.cpp:157] Top shape: 64 32 75 75 (11520000)
I0818 19:33:27.305465 23166 net.cpp:165] Memory required for data: 1518131200
I0818 19:33:27.305467 23166 layer_factory.hpp:77] Creating layer pool3
I0818 19:33:27.305474 23166 net.cpp:100] Creating Layer pool3
I0818 19:33:27.305476 23166 net.cpp:434] pool3 <- conv3_1_bn
I0818 19:33:27.305480 23166 net.cpp:408] pool3 -> pool3
I0818 19:33:27.305508 23166 net.cpp:150] Setting up pool3
I0818 19:33:27.305513 23166 net.cpp:157] Top shape: 64 32 38 38 (2957312)
I0818 19:33:27.305516 23166 net.cpp:165] Memory required for data: 1529960448
I0818 19:33:27.305518 23166 layer_factory.hpp:77] Creating layer conv4_1
I0818 19:33:27.305524 23166 net.cpp:100] Creating Layer conv4_1
I0818 19:33:27.305527 23166 net.cpp:434] conv4_1 <- pool3
I0818 19:33:27.305531 23166 net.cpp:408] conv4_1 -> conv4_1
I0818 19:33:27.306090 23166 net.cpp:150] Setting up conv4_1
I0818 19:33:27.306098 23166 net.cpp:157] Top shape: 64 64 38 38 (5914624)
I0818 19:33:27.306102 23166 net.cpp:165] Memory required for data: 1553618944
I0818 19:33:27.306105 23166 layer_factory.hpp:77] Creating layer conv4_1_bn
I0818 19:33:27.306112 23166 net.cpp:100] Creating Layer conv4_1_bn
I0818 19:33:27.306115 23166 net.cpp:434] conv4_1_bn <- conv4_1
I0818 19:33:27.306119 23166 net.cpp:408] conv4_1_bn -> conv4_1_bn
I0818 19:33:27.306267 23166 net.cpp:150] Setting up conv4_1_bn
I0818 19:33:27.306272 23166 net.cpp:157] Top shape: 64 64 38 38 (5914624)
I0818 19:33:27.306275 23166 net.cpp:165] Memory required for data: 1577277440
I0818 19:33:27.306282 23166 layer_factory.hpp:77] Creating layer conv4_1_bn_scale
I0818 19:33:27.306285 23166 net.cpp:100] Creating Layer conv4_1_bn_scale
I0818 19:33:27.306288 23166 net.cpp:434] conv4_1_bn_scale <- conv4_1_bn
I0818 19:33:27.306293 23166 net.cpp:395] conv4_1_bn_scale -> conv4_1_bn (in-place)
I0818 19:33:27.306321 23166 layer_factory.hpp:77] Creating layer conv4_1_bn_scale
I0818 19:33:27.306402 23166 net.cpp:150] Setting up conv4_1_bn_scale
I0818 19:33:27.306407 23166 net.cpp:157] Top shape: 64 64 38 38 (5914624)
I0818 19:33:27.306409 23166 net.cpp:165] Memory required for data: 1600935936
I0818 19:33:27.306414 23166 layer_factory.hpp:77] Creating layer conv4_1_relu
I0818 19:33:27.306419 23166 net.cpp:100] Creating Layer conv4_1_relu
I0818 19:33:27.306422 23166 net.cpp:434] conv4_1_relu <- conv4_1_bn
I0818 19:33:27.306427 23166 net.cpp:395] conv4_1_relu -> conv4_1_bn (in-place)
I0818 19:33:27.306430 23166 net.cpp:150] Setting up conv4_1_relu
I0818 19:33:27.306434 23166 net.cpp:157] Top shape: 64 64 38 38 (5914624)
I0818 19:33:27.306437 23166 net.cpp:165] Memory required for data: 1624594432
I0818 19:33:27.306439 23166 layer_factory.hpp:77] Creating layer pool4
I0818 19:33:27.306443 23166 net.cpp:100] Creating Layer pool4
I0818 19:33:27.306447 23166 net.cpp:434] pool4 <- conv4_1_bn
I0818 19:33:27.306452 23166 net.cpp:408] pool4 -> pool4
I0818 19:33:27.306478 23166 net.cpp:150] Setting up pool4
I0818 19:33:27.306481 23166 net.cpp:157] Top shape: 64 64 19 19 (1478656)
I0818 19:33:27.306484 23166 net.cpp:165] Memory required for data: 1630509056
I0818 19:33:27.306488 23166 layer_factory.hpp:77] Creating layer pool4_pool4_0_split
I0818 19:33:27.306493 23166 net.cpp:100] Creating Layer pool4_pool4_0_split
I0818 19:33:27.306495 23166 net.cpp:434] pool4_pool4_0_split <- pool4
I0818 19:33:27.306499 23166 net.cpp:408] pool4_pool4_0_split -> pool4_pool4_0_split_0
I0818 19:33:27.306504 23166 net.cpp:408] pool4_pool4_0_split -> pool4_pool4_0_split_1
I0818 19:33:27.306526 23166 net.cpp:150] Setting up pool4_pool4_0_split
I0818 19:33:27.306530 23166 net.cpp:157] Top shape: 64 64 19 19 (1478656)
I0818 19:33:27.306535 23166 net.cpp:157] Top shape: 64 64 19 19 (1478656)
I0818 19:33:27.306537 23166 net.cpp:165] Memory required for data: 1642338304
I0818 19:33:27.306540 23166 layer_factory.hpp:77] Creating layer conv5_1
I0818 19:33:27.306545 23166 net.cpp:100] Creating Layer conv5_1
I0818 19:33:27.306548 23166 net.cpp:434] conv5_1 <- pool4_pool4_0_split_0
I0818 19:33:27.306555 23166 net.cpp:408] conv5_1 -> conv5_1
I0818 19:33:27.308331 23166 net.cpp:150] Setting up conv5_1
I0818 19:33:27.308338 23166 net.cpp:157] Top shape: 64 128 19 19 (2957312)
I0818 19:33:27.308341 23166 net.cpp:165] Memory required for data: 1654167552
I0818 19:33:27.308344 23166 layer_factory.hpp:77] Creating layer conv5_1_bn
I0818 19:33:27.308351 23166 net.cpp:100] Creating Layer conv5_1_bn
I0818 19:33:27.308354 23166 net.cpp:434] conv5_1_bn <- conv5_1
I0818 19:33:27.308358 23166 net.cpp:408] conv5_1_bn -> conv5_1_bn
I0818 19:33:27.308495 23166 net.cpp:150] Setting up conv5_1_bn
I0818 19:33:27.308501 23166 net.cpp:157] Top shape: 64 128 19 19 (2957312)
I0818 19:33:27.308504 23166 net.cpp:165] Memory required for data: 1665996800
I0818 19:33:27.308509 23166 layer_factory.hpp:77] Creating layer conv5_1_bn_scale
I0818 19:33:27.308514 23166 net.cpp:100] Creating Layer conv5_1_bn_scale
I0818 19:33:27.308516 23166 net.cpp:434] conv5_1_bn_scale <- conv5_1_bn
I0818 19:33:27.308521 23166 net.cpp:395] conv5_1_bn_scale -> conv5_1_bn (in-place)
I0818 19:33:27.308549 23166 layer_factory.hpp:77] Creating layer conv5_1_bn_scale
I0818 19:33:27.308631 23166 net.cpp:150] Setting up conv5_1_bn_scale
I0818 19:33:27.308636 23166 net.cpp:157] Top shape: 64 128 19 19 (2957312)
I0818 19:33:27.308640 23166 net.cpp:165] Memory required for data: 1677826048
I0818 19:33:27.308647 23166 layer_factory.hpp:77] Creating layer conv5_1_relu
I0818 19:33:27.308658 23166 net.cpp:100] Creating Layer conv5_1_relu
I0818 19:33:27.308661 23166 net.cpp:434] conv5_1_relu <- conv5_1_bn
I0818 19:33:27.308666 23166 net.cpp:395] conv5_1_relu -> conv5_1_bn (in-place)
I0818 19:33:27.308671 23166 net.cpp:150] Setting up conv5_1_relu
I0818 19:33:27.308675 23166 net.cpp:157] Top shape: 64 128 19 19 (2957312)
I0818 19:33:27.308677 23166 net.cpp:165] Memory required for data: 1689655296
I0818 19:33:27.308679 23166 layer_factory.hpp:77] Creating layer score_1
I0818 19:33:27.308686 23166 net.cpp:100] Creating Layer score_1
I0818 19:33:27.308689 23166 net.cpp:434] score_1 <- conv5_1_bn
I0818 19:33:27.308696 23166 net.cpp:408] score_1 -> score_1
I0818 19:33:27.308863 23166 net.cpp:150] Setting up score_1
I0818 19:33:27.308869 23166 net.cpp:157] Top shape: 64 4 19 19 (92416)
I0818 19:33:27.308871 23166 net.cpp:165] Memory required for data: 1690024960
I0818 19:33:27.308876 23166 layer_factory.hpp:77] Creating layer score_1_score_1_0_split
I0818 19:33:27.308881 23166 net.cpp:100] Creating Layer score_1_score_1_0_split
I0818 19:33:27.308883 23166 net.cpp:434] score_1_score_1_0_split <- score_1
I0818 19:33:27.308888 23166 net.cpp:408] score_1_score_1_0_split -> score_1_score_1_0_split_0
I0818 19:33:27.308893 23166 net.cpp:408] score_1_score_1_0_split -> score_1_score_1_0_split_1
I0818 19:33:27.308918 23166 net.cpp:150] Setting up score_1_score_1_0_split
I0818 19:33:27.308923 23166 net.cpp:157] Top shape: 64 4 19 19 (92416)
I0818 19:33:27.308926 23166 net.cpp:157] Top shape: 64 4 19 19 (92416)
I0818 19:33:27.308928 23166 net.cpp:165] Memory required for data: 1690764288
I0818 19:33:27.308931 23166 layer_factory.hpp:77] Creating layer upscore_1
I0818 19:33:27.308938 23166 net.cpp:100] Creating Layer upscore_1
I0818 19:33:27.308941 23166 net.cpp:434] upscore_1 <- score_1_score_1_0_split_0
I0818 19:33:27.308946 23166 net.cpp:408] upscore_1 -> upscore_1
I0818 19:33:27.309442 23166 net.cpp:150] Setting up upscore_1
I0818 19:33:27.309448 23166 net.cpp:157] Top shape: 64 4 320 320 (26214400)
I0818 19:33:27.309451 23166 net.cpp:165] Memory required for data: 1795621888
I0818 19:33:27.309460 23166 layer_factory.hpp:77] Creating layer cropscore_1
I0818 19:33:27.309466 23166 net.cpp:100] Creating Layer cropscore_1
I0818 19:33:27.309469 23166 net.cpp:434] cropscore_1 <- upscore_1
I0818 19:33:27.309473 23166 net.cpp:434] cropscore_1 <- image_data_0_split_1
I0818 19:33:27.309478 23166 net.cpp:408] cropscore_1 -> cropscore_1
I0818 19:33:27.309494 23166 net.cpp:150] Setting up cropscore_1
I0818 19:33:27.309499 23166 net.cpp:157] Top shape: 64 4 200 200 (10240000)
I0818 19:33:27.309501 23166 net.cpp:165] Memory required for data: 1836581888
I0818 19:33:27.309504 23166 layer_factory.hpp:77] Creating layer cropscore_1_cropscore_1_0_split
I0818 19:33:27.309512 23166 net.cpp:100] Creating Layer cropscore_1_cropscore_1_0_split
I0818 19:33:27.309515 23166 net.cpp:434] cropscore_1_cropscore_1_0_split <- cropscore_1
I0818 19:33:27.309520 23166 net.cpp:408] cropscore_1_cropscore_1_0_split -> cropscore_1_cropscore_1_0_split_0
I0818 19:33:27.309525 23166 net.cpp:408] cropscore_1_cropscore_1_0_split -> cropscore_1_cropscore_1_0_split_1
I0818 19:33:27.309548 23166 net.cpp:150] Setting up cropscore_1_cropscore_1_0_split
I0818 19:33:27.309554 23166 net.cpp:157] Top shape: 64 4 200 200 (10240000)
I0818 19:33:27.309557 23166 net.cpp:157] Top shape: 64 4 200 200 (10240000)
I0818 19:33:27.309561 23166 net.cpp:165] Memory required for data: 1918501888
I0818 19:33:27.309562 23166 layer_factory.hpp:77] Creating layer loss_1
I0818 19:33:27.309567 23166 net.cpp:100] Creating Layer loss_1
I0818 19:33:27.309571 23166 net.cpp:434] loss_1 <- cropscore_1_cropscore_1_0_split_0
I0818 19:33:27.309574 23166 net.cpp:434] loss_1 <- label_data_1_split_0
I0818 19:33:27.309578 23166 net.cpp:408] loss_1 -> loss_1
I0818 19:33:27.309588 23166 layer_factory.hpp:77] Creating layer loss_1
I0818 19:33:27.327919 23166 net.cpp:150] Setting up loss_1
I0818 19:33:27.327955 23166 net.cpp:157] Top shape: (1)
I0818 19:33:27.327966 23166 net.cpp:160]     with loss weight 1
I0818 19:33:27.327976 23166 net.cpp:165] Memory required for data: 1918501892
I0818 19:33:27.327981 23166 layer_factory.hpp:77] Creating layer accuracy_1
I0818 19:33:27.327991 23166 net.cpp:100] Creating Layer accuracy_1
I0818 19:33:27.327996 23166 net.cpp:434] accuracy_1 <- cropscore_1_cropscore_1_0_split_1
I0818 19:33:27.328001 23166 net.cpp:434] accuracy_1 <- label_data_1_split_1
I0818 19:33:27.328006 23166 net.cpp:408] accuracy_1 -> accuracy_1
I0818 19:33:27.328014 23166 net.cpp:150] Setting up accuracy_1
I0818 19:33:27.328018 23166 net.cpp:157] Top shape: (1)
I0818 19:33:27.328021 23166 net.cpp:165] Memory required for data: 1918501896
I0818 19:33:27.328023 23166 layer_factory.hpp:77] Creating layer concat_2
I0818 19:33:27.328028 23166 net.cpp:100] Creating Layer concat_2
I0818 19:33:27.328032 23166 net.cpp:434] concat_2 <- pool4_pool4_0_split_1
I0818 19:33:27.328037 23166 net.cpp:434] concat_2 <- score_1_score_1_0_split_1
I0818 19:33:27.328040 23166 net.cpp:408] concat_2 -> concat_2
I0818 19:33:27.328066 23166 net.cpp:150] Setting up concat_2
I0818 19:33:27.328071 23166 net.cpp:157] Top shape: 64 68 19 19 (1571072)
I0818 19:33:27.328074 23166 net.cpp:165] Memory required for data: 1924786184
I0818 19:33:27.328078 23166 layer_factory.hpp:77] Creating layer conv5_2
I0818 19:33:27.328085 23166 net.cpp:100] Creating Layer conv5_2
I0818 19:33:27.328088 23166 net.cpp:434] conv5_2 <- concat_2
I0818 19:33:27.328094 23166 net.cpp:408] conv5_2 -> conv5_2
I0818 19:33:27.329601 23166 net.cpp:150] Setting up conv5_2
I0818 19:33:27.329610 23166 net.cpp:157] Top shape: 64 64 17 17 (1183744)
I0818 19:33:27.329613 23166 net.cpp:165] Memory required for data: 1929521160
I0818 19:33:27.329618 23166 layer_factory.hpp:77] Creating layer conv5_2_bn
I0818 19:33:27.329624 23166 net.cpp:100] Creating Layer conv5_2_bn
I0818 19:33:27.329627 23166 net.cpp:434] conv5_2_bn <- conv5_2
I0818 19:33:27.329632 23166 net.cpp:408] conv5_2_bn -> conv5_2_bn
I0818 19:33:27.329797 23166 net.cpp:150] Setting up conv5_2_bn
I0818 19:33:27.329803 23166 net.cpp:157] Top shape: 64 64 17 17 (1183744)
I0818 19:33:27.329807 23166 net.cpp:165] Memory required for data: 1934256136
I0818 19:33:27.329813 23166 layer_factory.hpp:77] Creating layer conv5_2_bn_scale
I0818 19:33:27.329820 23166 net.cpp:100] Creating Layer conv5_2_bn_scale
I0818 19:33:27.329823 23166 net.cpp:434] conv5_2_bn_scale <- conv5_2_bn
I0818 19:33:27.329828 23166 net.cpp:395] conv5_2_bn_scale -> conv5_2_bn (in-place)
I0818 19:33:27.329859 23166 layer_factory.hpp:77] Creating layer conv5_2_bn_scale
I0818 19:33:27.329946 23166 net.cpp:150] Setting up conv5_2_bn_scale
I0818 19:33:27.329951 23166 net.cpp:157] Top shape: 64 64 17 17 (1183744)
I0818 19:33:27.329953 23166 net.cpp:165] Memory required for data: 1938991112
I0818 19:33:27.329957 23166 layer_factory.hpp:77] Creating layer conv5_2_relu
I0818 19:33:27.329963 23166 net.cpp:100] Creating Layer conv5_2_relu
I0818 19:33:27.329967 23166 net.cpp:434] conv5_2_relu <- conv5_2_bn
I0818 19:33:27.329972 23166 net.cpp:395] conv5_2_relu -> conv5_2_bn (in-place)
I0818 19:33:27.329977 23166 net.cpp:150] Setting up conv5_2_relu
I0818 19:33:27.329979 23166 net.cpp:157] Top shape: 64 64 17 17 (1183744)
I0818 19:33:27.329982 23166 net.cpp:165] Memory required for data: 1943726088
I0818 19:33:27.329985 23166 layer_factory.hpp:77] Creating layer conv6_2
I0818 19:33:27.329991 23166 net.cpp:100] Creating Layer conv6_2
I0818 19:33:27.329993 23166 net.cpp:434] conv6_2 <- conv5_2_bn
I0818 19:33:27.329999 23166 net.cpp:408] conv6_2 -> conv6_2
I0818 19:33:27.330942 23166 net.cpp:150] Setting up conv6_2
I0818 19:33:27.330950 23166 net.cpp:157] Top shape: 64 64 15 15 (921600)
I0818 19:33:27.330951 23166 net.cpp:165] Memory required for data: 1947412488
I0818 19:33:27.330955 23166 layer_factory.hpp:77] Creating layer conv6_2_bn
I0818 19:33:27.330961 23166 net.cpp:100] Creating Layer conv6_2_bn
I0818 19:33:27.330965 23166 net.cpp:434] conv6_2_bn <- conv6_2
I0818 19:33:27.330974 23166 net.cpp:408] conv6_2_bn -> conv6_2_bn
I0818 19:33:27.331127 23166 net.cpp:150] Setting up conv6_2_bn
I0818 19:33:27.331133 23166 net.cpp:157] Top shape: 64 64 15 15 (921600)
I0818 19:33:27.331135 23166 net.cpp:165] Memory required for data: 1951098888
I0818 19:33:27.331140 23166 layer_factory.hpp:77] Creating layer conv6_2_bn_scale
I0818 19:33:27.331146 23166 net.cpp:100] Creating Layer conv6_2_bn_scale
I0818 19:33:27.331148 23166 net.cpp:434] conv6_2_bn_scale <- conv6_2_bn
I0818 19:33:27.331152 23166 net.cpp:395] conv6_2_bn_scale -> conv6_2_bn (in-place)
I0818 19:33:27.331184 23166 layer_factory.hpp:77] Creating layer conv6_2_bn_scale
I0818 19:33:27.331264 23166 net.cpp:150] Setting up conv6_2_bn_scale
I0818 19:33:27.331269 23166 net.cpp:157] Top shape: 64 64 15 15 (921600)
I0818 19:33:27.331270 23166 net.cpp:165] Memory required for data: 1954785288
I0818 19:33:27.331275 23166 layer_factory.hpp:77] Creating layer conv6_2_relu
I0818 19:33:27.331279 23166 net.cpp:100] Creating Layer conv6_2_relu
I0818 19:33:27.331282 23166 net.cpp:434] conv6_2_relu <- conv6_2_bn
I0818 19:33:27.331288 23166 net.cpp:395] conv6_2_relu -> conv6_2_bn (in-place)
I0818 19:33:27.331293 23166 net.cpp:150] Setting up conv6_2_relu
I0818 19:33:27.331296 23166 net.cpp:157] Top shape: 64 64 15 15 (921600)
I0818 19:33:27.331300 23166 net.cpp:165] Memory required for data: 1958471688
I0818 19:33:27.331302 23166 layer_factory.hpp:77] Creating layer conv7_2
I0818 19:33:27.331310 23166 net.cpp:100] Creating Layer conv7_2
I0818 19:33:27.331312 23166 net.cpp:434] conv7_2 <- conv6_2_bn
I0818 19:33:27.331316 23166 net.cpp:408] conv7_2 -> conv7_2
I0818 19:33:27.333106 23166 net.cpp:150] Setting up conv7_2
I0818 19:33:27.333113 23166 net.cpp:157] Top shape: 64 128 13 13 (1384448)
I0818 19:33:27.333115 23166 net.cpp:165] Memory required for data: 1964009480
I0818 19:33:27.333119 23166 layer_factory.hpp:77] Creating layer conv7_2_bn
I0818 19:33:27.333125 23166 net.cpp:100] Creating Layer conv7_2_bn
I0818 19:33:27.333128 23166 net.cpp:434] conv7_2_bn <- conv7_2
I0818 19:33:27.333133 23166 net.cpp:408] conv7_2_bn -> conv7_2_bn
I0818 19:33:27.333274 23166 net.cpp:150] Setting up conv7_2_bn
I0818 19:33:27.333279 23166 net.cpp:157] Top shape: 64 128 13 13 (1384448)
I0818 19:33:27.333281 23166 net.cpp:165] Memory required for data: 1969547272
I0818 19:33:27.333287 23166 layer_factory.hpp:77] Creating layer conv7_2_bn_scale
I0818 19:33:27.333293 23166 net.cpp:100] Creating Layer conv7_2_bn_scale
I0818 19:33:27.333297 23166 net.cpp:434] conv7_2_bn_scale <- conv7_2_bn
I0818 19:33:27.333300 23166 net.cpp:395] conv7_2_bn_scale -> conv7_2_bn (in-place)
I0818 19:33:27.333328 23166 layer_factory.hpp:77] Creating layer conv7_2_bn_scale
I0818 19:33:27.333401 23166 net.cpp:150] Setting up conv7_2_bn_scale
I0818 19:33:27.333406 23166 net.cpp:157] Top shape: 64 128 13 13 (1384448)
I0818 19:33:27.333410 23166 net.cpp:165] Memory required for data: 1975085064
I0818 19:33:27.333413 23166 layer_factory.hpp:77] Creating layer conv7_2_relu
I0818 19:33:27.333418 23166 net.cpp:100] Creating Layer conv7_2_relu
I0818 19:33:27.333421 23166 net.cpp:434] conv7_2_relu <- conv7_2_bn
I0818 19:33:27.333425 23166 net.cpp:395] conv7_2_relu -> conv7_2_bn (in-place)
I0818 19:33:27.333430 23166 net.cpp:150] Setting up conv7_2_relu
I0818 19:33:27.333433 23166 net.cpp:157] Top shape: 64 128 13 13 (1384448)
I0818 19:33:27.333436 23166 net.cpp:165] Memory required for data: 1980622856
I0818 19:33:27.333438 23166 layer_factory.hpp:77] Creating layer score_2
I0818 19:33:27.333446 23166 net.cpp:100] Creating Layer score_2
I0818 19:33:27.333449 23166 net.cpp:434] score_2 <- conv7_2_bn
I0818 19:33:27.333454 23166 net.cpp:408] score_2 -> score_2
I0818 19:33:27.333631 23166 net.cpp:150] Setting up score_2
I0818 19:33:27.333638 23166 net.cpp:157] Top shape: 64 4 13 13 (43264)
I0818 19:33:27.333642 23166 net.cpp:165] Memory required for data: 1980795912
I0818 19:33:27.333645 23166 layer_factory.hpp:77] Creating layer upscore_2
I0818 19:33:27.333652 23166 net.cpp:100] Creating Layer upscore_2
I0818 19:33:27.333659 23166 net.cpp:434] upscore_2 <- score_2
I0818 19:33:27.333670 23166 net.cpp:408] upscore_2 -> upscore_2
I0818 19:33:27.334185 23166 net.cpp:150] Setting up upscore_2
I0818 19:33:27.334193 23166 net.cpp:157] Top shape: 64 4 224 224 (12845056)
I0818 19:33:27.334195 23166 net.cpp:165] Memory required for data: 2032176136
I0818 19:33:27.334199 23166 layer_factory.hpp:77] Creating layer cropscore_2
I0818 19:33:27.334206 23166 net.cpp:100] Creating Layer cropscore_2
I0818 19:33:27.334209 23166 net.cpp:434] cropscore_2 <- upscore_2
I0818 19:33:27.334213 23166 net.cpp:434] cropscore_2 <- image_data_0_split_2
I0818 19:33:27.334218 23166 net.cpp:408] cropscore_2 -> cropscore_2
I0818 19:33:27.334235 23166 net.cpp:150] Setting up cropscore_2
I0818 19:33:27.334240 23166 net.cpp:157] Top shape: 64 4 200 200 (10240000)
I0818 19:33:27.334242 23166 net.cpp:165] Memory required for data: 2073136136
I0818 19:33:27.334245 23166 layer_factory.hpp:77] Creating layer cropscore_2_cropscore_2_0_split
I0818 19:33:27.334249 23166 net.cpp:100] Creating Layer cropscore_2_cropscore_2_0_split
I0818 19:33:27.334252 23166 net.cpp:434] cropscore_2_cropscore_2_0_split <- cropscore_2
I0818 19:33:27.334257 23166 net.cpp:408] cropscore_2_cropscore_2_0_split -> cropscore_2_cropscore_2_0_split_0
I0818 19:33:27.334261 23166 net.cpp:408] cropscore_2_cropscore_2_0_split -> cropscore_2_cropscore_2_0_split_1
I0818 19:33:27.334286 23166 net.cpp:150] Setting up cropscore_2_cropscore_2_0_split
I0818 19:33:27.334291 23166 net.cpp:157] Top shape: 64 4 200 200 (10240000)
I0818 19:33:27.334295 23166 net.cpp:157] Top shape: 64 4 200 200 (10240000)
I0818 19:33:27.334297 23166 net.cpp:165] Memory required for data: 2155056136
I0818 19:33:27.334300 23166 layer_factory.hpp:77] Creating layer loss_2
I0818 19:33:27.334306 23166 net.cpp:100] Creating Layer loss_2
I0818 19:33:27.334307 23166 net.cpp:434] loss_2 <- cropscore_2_cropscore_2_0_split_0
I0818 19:33:27.334311 23166 net.cpp:434] loss_2 <- label_data_1_split_2
I0818 19:33:27.334316 23166 net.cpp:408] loss_2 -> loss_2
I0818 19:33:27.334322 23166 layer_factory.hpp:77] Creating layer loss_2
I0818 19:33:27.352627 23166 net.cpp:150] Setting up loss_2
I0818 19:33:27.352654 23166 net.cpp:157] Top shape: (1)
I0818 19:33:27.352658 23166 net.cpp:160]     with loss weight 1
I0818 19:33:27.352669 23166 net.cpp:165] Memory required for data: 2155056140
I0818 19:33:27.352672 23166 layer_factory.hpp:77] Creating layer accuracy_2
I0818 19:33:27.352681 23166 net.cpp:100] Creating Layer accuracy_2
I0818 19:33:27.352685 23166 net.cpp:434] accuracy_2 <- cropscore_2_cropscore_2_0_split_1
I0818 19:33:27.352694 23166 net.cpp:434] accuracy_2 <- label_data_1_split_3
I0818 19:33:27.352699 23166 net.cpp:408] accuracy_2 -> accuracy_2
I0818 19:33:27.352707 23166 net.cpp:150] Setting up accuracy_2
I0818 19:33:27.352711 23166 net.cpp:157] Top shape: (1)
I0818 19:33:27.352713 23166 net.cpp:165] Memory required for data: 2155056144
I0818 19:33:27.352716 23166 net.cpp:228] accuracy_2 does not need backward computation.
I0818 19:33:27.352720 23166 net.cpp:226] loss_2 needs backward computation.
I0818 19:33:27.352723 23166 net.cpp:226] cropscore_2_cropscore_2_0_split needs backward computation.
I0818 19:33:27.352726 23166 net.cpp:226] cropscore_2 needs backward computation.
I0818 19:33:27.352730 23166 net.cpp:226] upscore_2 needs backward computation.
I0818 19:33:27.352733 23166 net.cpp:226] score_2 needs backward computation.
I0818 19:33:27.352736 23166 net.cpp:226] conv7_2_relu needs backward computation.
I0818 19:33:27.352740 23166 net.cpp:226] conv7_2_bn_scale needs backward computation.
I0818 19:33:27.352741 23166 net.cpp:226] conv7_2_bn needs backward computation.
I0818 19:33:27.352744 23166 net.cpp:226] conv7_2 needs backward computation.
I0818 19:33:27.352747 23166 net.cpp:226] conv6_2_relu needs backward computation.
I0818 19:33:27.352751 23166 net.cpp:226] conv6_2_bn_scale needs backward computation.
I0818 19:33:27.352753 23166 net.cpp:226] conv6_2_bn needs backward computation.
I0818 19:33:27.352756 23166 net.cpp:226] conv6_2 needs backward computation.
I0818 19:33:27.352773 23166 net.cpp:226] conv5_2_relu needs backward computation.
I0818 19:33:27.352777 23166 net.cpp:226] conv5_2_bn_scale needs backward computation.
I0818 19:33:27.352779 23166 net.cpp:226] conv5_2_bn needs backward computation.
I0818 19:33:27.352782 23166 net.cpp:226] conv5_2 needs backward computation.
I0818 19:33:27.352785 23166 net.cpp:226] concat_2 needs backward computation.
I0818 19:33:27.352788 23166 net.cpp:228] accuracy_1 does not need backward computation.
I0818 19:33:27.352792 23166 net.cpp:226] loss_1 needs backward computation.
I0818 19:33:27.352795 23166 net.cpp:226] cropscore_1_cropscore_1_0_split needs backward computation.
I0818 19:33:27.352798 23166 net.cpp:226] cropscore_1 needs backward computation.
I0818 19:33:27.352802 23166 net.cpp:226] upscore_1 needs backward computation.
I0818 19:33:27.352805 23166 net.cpp:226] score_1_score_1_0_split needs backward computation.
I0818 19:33:27.352808 23166 net.cpp:226] score_1 needs backward computation.
I0818 19:33:27.352813 23166 net.cpp:226] conv5_1_relu needs backward computation.
I0818 19:33:27.352815 23166 net.cpp:226] conv5_1_bn_scale needs backward computation.
I0818 19:33:27.352818 23166 net.cpp:226] conv5_1_bn needs backward computation.
I0818 19:33:27.352821 23166 net.cpp:226] conv5_1 needs backward computation.
I0818 19:33:27.352824 23166 net.cpp:226] pool4_pool4_0_split needs backward computation.
I0818 19:33:27.352828 23166 net.cpp:226] pool4 needs backward computation.
I0818 19:33:27.352830 23166 net.cpp:226] conv4_1_relu needs backward computation.
I0818 19:33:27.352833 23166 net.cpp:226] conv4_1_bn_scale needs backward computation.
I0818 19:33:27.352836 23166 net.cpp:226] conv4_1_bn needs backward computation.
I0818 19:33:27.352839 23166 net.cpp:226] conv4_1 needs backward computation.
I0818 19:33:27.352843 23166 net.cpp:226] pool3 needs backward computation.
I0818 19:33:27.352845 23166 net.cpp:226] conv3_1_relu needs backward computation.
I0818 19:33:27.352849 23166 net.cpp:226] conv3_1_bn_scale needs backward computation.
I0818 19:33:27.352851 23166 net.cpp:226] conv3_1_bn needs backward computation.
I0818 19:33:27.352854 23166 net.cpp:226] conv3_1 needs backward computation.
I0818 19:33:27.352856 23166 net.cpp:226] pool2 needs backward computation.
I0818 19:33:27.352859 23166 net.cpp:226] conv2_1_relu needs backward computation.
I0818 19:33:27.352862 23166 net.cpp:226] conv2_1_bn_scale needs backward computation.
I0818 19:33:27.352865 23166 net.cpp:226] conv2_1_bn needs backward computation.
I0818 19:33:27.352869 23166 net.cpp:226] conv2_1 needs backward computation.
I0818 19:33:27.352870 23166 net.cpp:226] pool1 needs backward computation.
I0818 19:33:27.352874 23166 net.cpp:226] conv1_1_relu needs backward computation.
I0818 19:33:27.352876 23166 net.cpp:226] conv1_1_bn_scale needs backward computation.
I0818 19:33:27.352880 23166 net.cpp:226] conv1_1_bn needs backward computation.
I0818 19:33:27.352882 23166 net.cpp:226] conv1_1 needs backward computation.
I0818 19:33:27.352886 23166 net.cpp:228] label_data_1_split does not need backward computation.
I0818 19:33:27.352890 23166 net.cpp:228] image_data_0_split does not need backward computation.
I0818 19:33:27.352893 23166 net.cpp:228] data does not need backward computation.
I0818 19:33:27.352895 23166 net.cpp:270] This network produces output accuracy_1
I0818 19:33:27.352898 23166 net.cpp:270] This network produces output accuracy_2
I0818 19:33:27.352901 23166 net.cpp:270] This network produces output loss_1
I0818 19:33:27.352905 23166 net.cpp:270] This network produces output loss_2
I0818 19:33:27.352929 23166 net.cpp:283] Network initialization done.
I0818 19:33:27.353070 23166 solver.cpp:60] Solver scaffolding done.
I0818 19:33:27.354393 23166 caffe.cpp:251] Starting Optimization
I0818 19:33:27.354400 23166 solver.cpp:279] Solving segmentation
I0818 19:33:27.354403 23166 solver.cpp:280] Learning Rate Policy: step
I0818 19:33:27.355654 23166 solver.cpp:337] Iteration 0, Testing net (#0)
I0818 19:33:34.199435 23166 solver.cpp:454] Snapshotting to binary proto file portrait_two_stage_iter_0.caffemodel
I0818 19:33:34.203871 23166 sgd_solver.cpp:273] Snapshotting solver state to binary proto file portrait_two_stage_iter_0.solverstate
I0818 19:33:42.005014 23166 solver.cpp:404]     Test net output #0: accuracy_1 = 0.25328
I0818 19:33:42.005050 23166 solver.cpp:404]     Test net output #1: accuracy_2 = 0.248365
I0818 19:33:42.005059 23166 solver.cpp:404]     Test net output #2: loss_1 = 2.60334e+06 (* 1 = 2.60334e+06 loss)
I0818 19:33:42.005064 23166 solver.cpp:404]     Test net output #3: loss_2 = 2.6258e+06 (* 1 = 2.6258e+06 loss)
I0818 19:33:43.379462 23166 solver.cpp:228] Iteration 0, loss = 110904
I0818 19:33:43.379495 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.253252
I0818 19:33:43.379500 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.249633
I0818 19:33:43.379508 23166 solver.cpp:244]     Train net output #2: loss_1 = 55452.2 (* 1 = 55452.2 loss)
I0818 19:33:43.379513 23166 solver.cpp:244]     Train net output #3: loss_2 = 55452.1 (* 1 = 55452.1 loss)
I0818 19:33:43.379526 23166 sgd_solver.cpp:106] Iteration 0, lr = 1e-05
I0818 19:34:52.205940 23166 solver.cpp:228] Iteration 50, loss = 65669.4
I0818 19:34:52.206012 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.647684
I0818 19:34:52.206017 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.587878
I0818 19:34:52.206025 23166 solver.cpp:244]     Train net output #2: loss_1 = 32425.6 (* 1 = 32425.6 loss)
I0818 19:34:52.206030 23166 solver.cpp:244]     Train net output #3: loss_2 = 33243.8 (* 1 = 33243.8 loss)
I0818 19:34:52.206037 23166 sgd_solver.cpp:106] Iteration 50, lr = 1e-05
I0818 19:36:00.973690 23166 solver.cpp:228] Iteration 100, loss = 77689.5
I0818 19:36:00.973785 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.610101
I0818 19:36:00.973793 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.591568
I0818 19:36:00.973800 23166 solver.cpp:244]     Train net output #2: loss_1 = 40544.4 (* 1 = 40544.4 loss)
I0818 19:36:00.973806 23166 solver.cpp:244]     Train net output #3: loss_2 = 37145 (* 1 = 37145 loss)
I0818 19:36:00.973812 23166 sgd_solver.cpp:106] Iteration 100, lr = 1e-05
I0818 19:37:10.217808 23166 solver.cpp:228] Iteration 150, loss = 50803.6
I0818 19:37:10.217883 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.785841
I0818 19:37:10.217890 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.780367
I0818 19:37:10.217897 23166 solver.cpp:244]     Train net output #2: loss_1 = 25399.3 (* 1 = 25399.3 loss)
I0818 19:37:10.217902 23166 solver.cpp:244]     Train net output #3: loss_2 = 25404.3 (* 1 = 25404.3 loss)
I0818 19:37:10.217908 23166 sgd_solver.cpp:106] Iteration 150, lr = 1e-05
I0818 19:38:17.956430 23166 solver.cpp:337] Iteration 200, Testing net (#0)
I0818 19:38:32.302264 23166 solver.cpp:404]     Test net output #0: accuracy_1 = 0.543882
I0818 19:38:32.302300 23166 solver.cpp:404]     Test net output #1: accuracy_2 = 0.618633
I0818 19:38:32.302309 23166 solver.cpp:404]     Test net output #2: loss_1 = 61523.7 (* 1 = 61523.7 loss)
I0818 19:38:32.302315 23166 solver.cpp:404]     Test net output #3: loss_2 = 42860.3 (* 1 = 42860.3 loss)
I0818 19:38:33.475113 23166 solver.cpp:228] Iteration 200, loss = 50424.5
I0818 19:38:33.475148 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.733067
I0818 19:38:33.475153 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.822348
I0818 19:38:33.475160 23166 solver.cpp:244]     Train net output #2: loss_1 = 27216.4 (* 1 = 27216.4 loss)
I0818 19:38:33.475167 23166 solver.cpp:244]     Train net output #3: loss_2 = 23208.1 (* 1 = 23208.1 loss)
I0818 19:38:33.475172 23166 sgd_solver.cpp:106] Iteration 200, lr = 1e-05
I0818 19:39:42.645148 23166 solver.cpp:228] Iteration 250, loss = 54151.4
I0818 19:39:42.645220 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.762242
I0818 19:39:42.645226 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.682254
I0818 19:39:42.645233 23166 solver.cpp:244]     Train net output #2: loss_1 = 25111.2 (* 1 = 25111.2 loss)
I0818 19:39:42.645246 23166 solver.cpp:244]     Train net output #3: loss_2 = 29040.2 (* 1 = 29040.2 loss)
I0818 19:39:42.645252 23166 sgd_solver.cpp:106] Iteration 250, lr = 1e-05
I0818 19:40:51.635496 23166 solver.cpp:228] Iteration 300, loss = 57402
I0818 19:40:51.635607 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.715851
I0818 19:40:51.635614 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.716484
I0818 19:40:51.635622 23166 solver.cpp:244]     Train net output #2: loss_1 = 28678.3 (* 1 = 28678.3 loss)
I0818 19:40:51.635627 23166 solver.cpp:244]     Train net output #3: loss_2 = 28723.8 (* 1 = 28723.8 loss)
I0818 19:40:51.635633 23166 sgd_solver.cpp:106] Iteration 300, lr = 1e-05
I0818 19:42:00.831239 23166 solver.cpp:228] Iteration 350, loss = 46003.5
I0818 19:42:00.831318 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.755942
I0818 19:42:00.831326 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.805281
I0818 19:42:00.831332 23166 solver.cpp:244]     Train net output #2: loss_1 = 25710.2 (* 1 = 25710.2 loss)
I0818 19:42:00.831338 23166 solver.cpp:244]     Train net output #3: loss_2 = 20293.4 (* 1 = 20293.4 loss)
I0818 19:42:00.831344 23166 sgd_solver.cpp:106] Iteration 350, lr = 1e-05
I0818 19:43:08.856859 23166 solver.cpp:337] Iteration 400, Testing net (#0)
I0818 19:43:22.936214 23166 solver.cpp:404]     Test net output #0: accuracy_1 = 0.529863
I0818 19:43:22.936250 23166 solver.cpp:404]     Test net output #1: accuracy_2 = 0.57215
I0818 19:43:22.936259 23166 solver.cpp:404]     Test net output #2: loss_1 = 61199.4 (* 1 = 61199.4 loss)
I0818 19:43:22.936264 23166 solver.cpp:404]     Test net output #3: loss_2 = 64261.8 (* 1 = 64261.8 loss)
I0818 19:43:24.114621 23166 solver.cpp:228] Iteration 400, loss = 46848
I0818 19:43:24.114652 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.764352
I0818 19:43:24.114658 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.821437
I0818 19:43:24.114665 23166 solver.cpp:244]     Train net output #2: loss_1 = 25673.8 (* 1 = 25673.8 loss)
I0818 19:43:24.114671 23166 solver.cpp:244]     Train net output #3: loss_2 = 21174.2 (* 1 = 21174.2 loss)
I0818 19:43:24.114677 23166 sgd_solver.cpp:106] Iteration 400, lr = 1e-05
I0818 19:44:33.282284 23166 solver.cpp:228] Iteration 450, loss = 51527.7
I0818 19:44:33.282379 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.675366
I0818 19:44:33.282387 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.736829
I0818 19:44:33.282393 23166 solver.cpp:244]     Train net output #2: loss_1 = 28265.7 (* 1 = 28265.7 loss)
I0818 19:44:33.282399 23166 solver.cpp:244]     Train net output #3: loss_2 = 23262 (* 1 = 23262 loss)
I0818 19:44:33.282405 23166 sgd_solver.cpp:106] Iteration 450, lr = 1e-05
I0818 19:45:42.428522 23166 solver.cpp:228] Iteration 500, loss = 46165.4
I0818 19:45:42.428614 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.80187
I0818 19:45:42.428622 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.765704
I0818 19:45:42.428629 23166 solver.cpp:244]     Train net output #2: loss_1 = 23426.9 (* 1 = 23426.9 loss)
I0818 19:45:42.428634 23166 solver.cpp:244]     Train net output #3: loss_2 = 22738.4 (* 1 = 22738.4 loss)
I0818 19:45:42.428640 23166 sgd_solver.cpp:106] Iteration 500, lr = 1e-05
I0818 19:46:51.477144 23166 solver.cpp:228] Iteration 550, loss = 62927.6
I0818 19:46:51.477218 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.699291
I0818 19:46:51.477226 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.685385
I0818 19:46:51.477232 23166 solver.cpp:244]     Train net output #2: loss_1 = 32443.6 (* 1 = 32443.6 loss)
I0818 19:46:51.477237 23166 solver.cpp:244]     Train net output #3: loss_2 = 30484 (* 1 = 30484 loss)
I0818 19:46:51.477243 23166 sgd_solver.cpp:106] Iteration 550, lr = 1e-05
I0818 19:47:59.571744 23166 solver.cpp:337] Iteration 600, Testing net (#0)
I0818 19:48:13.725850 23166 solver.cpp:404]     Test net output #0: accuracy_1 = 0.679113
I0818 19:48:13.725898 23166 solver.cpp:404]     Test net output #1: accuracy_2 = 0.622646
I0818 19:48:13.725905 23166 solver.cpp:404]     Test net output #2: loss_1 = 50785.7 (* 1 = 50785.7 loss)
I0818 19:48:13.725911 23166 solver.cpp:404]     Test net output #3: loss_2 = 47821 (* 1 = 47821 loss)
I0818 19:48:14.894498 23166 solver.cpp:228] Iteration 600, loss = 39724.5
I0818 19:48:14.894532 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.832532
I0818 19:48:14.894538 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.830723
I0818 19:48:14.894546 23166 solver.cpp:244]     Train net output #2: loss_1 = 19731.1 (* 1 = 19731.1 loss)
I0818 19:48:14.894551 23166 solver.cpp:244]     Train net output #3: loss_2 = 19993.4 (* 1 = 19993.4 loss)
I0818 19:48:14.894556 23166 sgd_solver.cpp:106] Iteration 600, lr = 1e-05
I0818 19:49:23.955219 23166 solver.cpp:228] Iteration 650, loss = 35920.4
I0818 19:49:23.955312 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.810922
I0818 19:49:23.955318 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.825463
I0818 19:49:23.955325 23166 solver.cpp:244]     Train net output #2: loss_1 = 18455.1 (* 1 = 18455.1 loss)
I0818 19:49:23.955330 23166 solver.cpp:244]     Train net output #3: loss_2 = 17465.3 (* 1 = 17465.3 loss)
I0818 19:49:23.955337 23166 sgd_solver.cpp:106] Iteration 650, lr = 1e-05
I0818 19:50:33.201949 23166 solver.cpp:228] Iteration 700, loss = 38253.6
I0818 19:50:33.202044 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.822464
I0818 19:50:33.202049 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.831373
I0818 19:50:33.202057 23166 solver.cpp:244]     Train net output #2: loss_1 = 20168 (* 1 = 20168 loss)
I0818 19:50:33.202064 23166 solver.cpp:244]     Train net output #3: loss_2 = 18085.5 (* 1 = 18085.5 loss)
I0818 19:50:33.202069 23166 sgd_solver.cpp:106] Iteration 700, lr = 1e-05
I0818 19:51:42.294343 23166 solver.cpp:228] Iteration 750, loss = 46042.4
I0818 19:51:42.294414 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.765215
I0818 19:51:42.294420 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.764843
I0818 19:51:42.294427 23166 solver.cpp:244]     Train net output #2: loss_1 = 23992.6 (* 1 = 23992.6 loss)
I0818 19:51:42.294433 23166 solver.cpp:244]     Train net output #3: loss_2 = 22049.8 (* 1 = 22049.8 loss)
I0818 19:51:42.294440 23166 sgd_solver.cpp:106] Iteration 750, lr = 1e-05
I0818 19:52:50.313778 23166 solver.cpp:337] Iteration 800, Testing net (#0)
I0818 19:53:04.512435 23166 solver.cpp:404]     Test net output #0: accuracy_1 = 0.630629
I0818 19:53:04.512470 23166 solver.cpp:404]     Test net output #1: accuracy_2 = 0.677438
I0818 19:53:04.512478 23166 solver.cpp:404]     Test net output #2: loss_1 = 56786.2 (* 1 = 56786.2 loss)
I0818 19:53:04.512485 23166 solver.cpp:404]     Test net output #3: loss_2 = 47844.6 (* 1 = 47844.6 loss)
I0818 19:53:05.708655 23166 solver.cpp:228] Iteration 800, loss = 56421
I0818 19:53:05.708689 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.704586
I0818 19:53:05.708695 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.737972
I0818 19:53:05.708703 23166 solver.cpp:244]     Train net output #2: loss_1 = 29825.3 (* 1 = 29825.3 loss)
I0818 19:53:05.708708 23166 solver.cpp:244]     Train net output #3: loss_2 = 26595.7 (* 1 = 26595.7 loss)
I0818 19:53:05.708714 23166 sgd_solver.cpp:106] Iteration 800, lr = 1e-05
I0818 19:54:14.859328 23166 solver.cpp:228] Iteration 850, loss = 38663.9
I0818 19:54:14.859402 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.808554
I0818 19:54:14.859410 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.83461
I0818 19:54:14.859416 23166 solver.cpp:244]     Train net output #2: loss_1 = 21249.3 (* 1 = 21249.3 loss)
I0818 19:54:14.859422 23166 solver.cpp:244]     Train net output #3: loss_2 = 17414.6 (* 1 = 17414.6 loss)
I0818 19:54:14.859428 23166 sgd_solver.cpp:106] Iteration 850, lr = 1e-05
I0818 19:55:24.092239 23166 solver.cpp:228] Iteration 900, loss = 46386.6
I0818 19:55:24.092365 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.724357
I0818 19:55:24.092371 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.775195
I0818 19:55:24.092380 23166 solver.cpp:244]     Train net output #2: loss_1 = 24770.8 (* 1 = 24770.8 loss)
I0818 19:55:24.092384 23166 solver.cpp:244]     Train net output #3: loss_2 = 21615.8 (* 1 = 21615.8 loss)
I0818 19:55:24.092391 23166 sgd_solver.cpp:106] Iteration 900, lr = 1e-05
I0818 19:56:33.329299 23166 solver.cpp:228] Iteration 950, loss = 36556.5
I0818 19:56:33.329347 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.829805
I0818 19:56:33.329354 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.833549
I0818 19:56:33.329361 23166 solver.cpp:244]     Train net output #2: loss_1 = 19435 (* 1 = 19435 loss)
I0818 19:56:33.329366 23166 solver.cpp:244]     Train net output #3: loss_2 = 17121.5 (* 1 = 17121.5 loss)
I0818 19:56:33.329372 23166 sgd_solver.cpp:106] Iteration 950, lr = 1e-05
I0818 19:57:41.300788 23166 solver.cpp:337] Iteration 1000, Testing net (#0)
I0818 19:57:55.582307 23166 solver.cpp:404]     Test net output #0: accuracy_1 = 0.649102
I0818 19:57:55.582345 23166 solver.cpp:404]     Test net output #1: accuracy_2 = 0.617345
I0818 19:57:55.582353 23166 solver.cpp:404]     Test net output #2: loss_1 = 48698.7 (* 1 = 48698.7 loss)
I0818 19:57:55.582358 23166 solver.cpp:404]     Test net output #3: loss_2 = 66312.8 (* 1 = 66312.8 loss)
I0818 19:57:56.760218 23166 solver.cpp:228] Iteration 1000, loss = 53523.1
I0818 19:57:56.760252 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.740521
I0818 19:57:56.760258 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.739584
I0818 19:57:56.760265 23166 solver.cpp:244]     Train net output #2: loss_1 = 27300.4 (* 1 = 27300.4 loss)
I0818 19:57:56.760272 23166 solver.cpp:244]     Train net output #3: loss_2 = 26222.6 (* 1 = 26222.6 loss)
I0818 19:57:56.760277 23166 sgd_solver.cpp:106] Iteration 1000, lr = 5e-06
I0818 19:59:06.092456 23166 solver.cpp:228] Iteration 1050, loss = 30264.6
I0818 19:59:06.092535 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.845298
I0818 19:59:06.092541 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.874323
I0818 19:59:06.092550 23166 solver.cpp:244]     Train net output #2: loss_1 = 16790.4 (* 1 = 16790.4 loss)
I0818 19:59:06.092555 23166 solver.cpp:244]     Train net output #3: loss_2 = 13474.2 (* 1 = 13474.2 loss)
I0818 19:59:06.092561 23166 sgd_solver.cpp:106] Iteration 1050, lr = 5e-06
I0818 20:00:15.200610 23166 solver.cpp:228] Iteration 1100, loss = 34003.7
I0818 20:00:15.200656 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.824342
I0818 20:00:15.200664 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.847564
I0818 20:00:15.200670 23166 solver.cpp:244]     Train net output #2: loss_1 = 18406.9 (* 1 = 18406.9 loss)
I0818 20:00:15.200675 23166 solver.cpp:244]     Train net output #3: loss_2 = 15596.7 (* 1 = 15596.7 loss)
I0818 20:00:15.200681 23166 sgd_solver.cpp:106] Iteration 1100, lr = 5e-06
I0818 20:01:24.481521 23166 solver.cpp:228] Iteration 1150, loss = 47187.1
I0818 20:01:24.481595 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.757097
I0818 20:01:24.481601 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.786698
I0818 20:01:24.481609 23166 solver.cpp:244]     Train net output #2: loss_1 = 25333.8 (* 1 = 25333.8 loss)
I0818 20:01:24.481614 23166 solver.cpp:244]     Train net output #3: loss_2 = 21853.2 (* 1 = 21853.2 loss)
I0818 20:01:24.481621 23166 sgd_solver.cpp:106] Iteration 1150, lr = 5e-06
I0818 20:02:32.393389 23166 solver.cpp:337] Iteration 1200, Testing net (#0)
I0818 20:02:46.627035 23166 solver.cpp:404]     Test net output #0: accuracy_1 = 0.761137
I0818 20:02:46.627070 23166 solver.cpp:404]     Test net output #1: accuracy_2 = 0.797684
I0818 20:02:46.627079 23166 solver.cpp:404]     Test net output #2: loss_1 = 25263.1 (* 1 = 25263.1 loss)
I0818 20:02:46.627084 23166 solver.cpp:404]     Test net output #3: loss_2 = 21215.5 (* 1 = 21215.5 loss)
I0818 20:02:47.806136 23166 solver.cpp:228] Iteration 1200, loss = 38748.1
I0818 20:02:47.806170 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.798359
I0818 20:02:47.806175 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.822862
I0818 20:02:47.806182 23166 solver.cpp:244]     Train net output #2: loss_1 = 20631.5 (* 1 = 20631.5 loss)
I0818 20:02:47.806187 23166 solver.cpp:244]     Train net output #3: loss_2 = 18116.6 (* 1 = 18116.6 loss)
I0818 20:02:47.806193 23166 sgd_solver.cpp:106] Iteration 1200, lr = 5e-06
I0818 20:03:57.107039 23166 solver.cpp:228] Iteration 1250, loss = 38407.6
I0818 20:03:57.107139 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.795157
I0818 20:03:57.107146 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.817383
I0818 20:03:57.107154 23166 solver.cpp:244]     Train net output #2: loss_1 = 20388.4 (* 1 = 20388.4 loss)
I0818 20:03:57.107159 23166 solver.cpp:244]     Train net output #3: loss_2 = 18019.2 (* 1 = 18019.2 loss)
I0818 20:03:57.107167 23166 sgd_solver.cpp:106] Iteration 1250, lr = 5e-06
I0818 20:05:06.359597 23166 solver.cpp:228] Iteration 1300, loss = 31451.2
I0818 20:05:06.359691 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.841934
I0818 20:05:06.359699 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.87039
I0818 20:05:06.359705 23166 solver.cpp:244]     Train net output #2: loss_1 = 17150 (* 1 = 17150 loss)
I0818 20:05:06.359711 23166 solver.cpp:244]     Train net output #3: loss_2 = 14301.2 (* 1 = 14301.2 loss)
I0818 20:05:06.359717 23166 sgd_solver.cpp:106] Iteration 1300, lr = 5e-06
I0818 20:06:15.555512 23166 solver.cpp:228] Iteration 1350, loss = 30926.5
I0818 20:06:15.555603 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.834169
I0818 20:06:15.555609 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.861593
I0818 20:06:15.555618 23166 solver.cpp:244]     Train net output #2: loss_1 = 16649.8 (* 1 = 16649.8 loss)
I0818 20:06:15.555624 23166 solver.cpp:244]     Train net output #3: loss_2 = 14276.7 (* 1 = 14276.7 loss)
I0818 20:06:15.555629 23166 sgd_solver.cpp:106] Iteration 1350, lr = 5e-06
I0818 20:07:23.585542 23166 solver.cpp:337] Iteration 1400, Testing net (#0)
I0818 20:07:37.879108 23166 solver.cpp:404]     Test net output #0: accuracy_1 = 0.772442
I0818 20:07:37.879143 23166 solver.cpp:404]     Test net output #1: accuracy_2 = 0.789182
I0818 20:07:37.879151 23166 solver.cpp:404]     Test net output #2: loss_1 = 23297.4 (* 1 = 23297.4 loss)
I0818 20:07:37.879158 23166 solver.cpp:404]     Test net output #3: loss_2 = 21250.9 (* 1 = 21250.9 loss)
I0818 20:07:39.079345 23166 solver.cpp:228] Iteration 1400, loss = 30237.4
I0818 20:07:39.079372 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.843857
I0818 20:07:39.079378 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.861225
I0818 20:07:39.079385 23166 solver.cpp:244]     Train net output #2: loss_1 = 16374.7 (* 1 = 16374.7 loss)
I0818 20:07:39.079391 23166 solver.cpp:244]     Train net output #3: loss_2 = 13862.7 (* 1 = 13862.7 loss)
I0818 20:07:39.079397 23166 sgd_solver.cpp:106] Iteration 1400, lr = 5e-06
I0818 20:08:48.202292 23166 solver.cpp:228] Iteration 1450, loss = 40162
I0818 20:08:48.202345 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.791595
I0818 20:08:48.202353 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.816069
I0818 20:08:48.202359 23166 solver.cpp:244]     Train net output #2: loss_1 = 21545.3 (* 1 = 21545.3 loss)
I0818 20:08:48.202365 23166 solver.cpp:244]     Train net output #3: loss_2 = 18616.8 (* 1 = 18616.8 loss)
I0818 20:08:48.202371 23166 sgd_solver.cpp:106] Iteration 1450, lr = 5e-06
I0818 20:09:57.761385 23166 solver.cpp:228] Iteration 1500, loss = 30622.4
I0818 20:09:57.761461 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.842291
I0818 20:09:57.761467 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.869392
I0818 20:09:57.761476 23166 solver.cpp:244]     Train net output #2: loss_1 = 16627.1 (* 1 = 16627.1 loss)
I0818 20:09:57.761489 23166 solver.cpp:244]     Train net output #3: loss_2 = 13995.3 (* 1 = 13995.3 loss)
I0818 20:09:57.761497 23166 sgd_solver.cpp:106] Iteration 1500, lr = 5e-06
I0818 20:11:07.196018 23166 solver.cpp:228] Iteration 1550, loss = 26198
I0818 20:11:07.196110 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.858374
I0818 20:11:07.196117 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.891317
I0818 20:11:07.196125 23166 solver.cpp:244]     Train net output #2: loss_1 = 14767.2 (* 1 = 14767.2 loss)
I0818 20:11:07.196130 23166 solver.cpp:244]     Train net output #3: loss_2 = 11430.8 (* 1 = 11430.8 loss)
I0818 20:11:07.196135 23166 sgd_solver.cpp:106] Iteration 1550, lr = 5e-06
I0818 20:12:15.596662 23166 solver.cpp:337] Iteration 1600, Testing net (#0)
I0818 20:12:29.929002 23166 solver.cpp:404]     Test net output #0: accuracy_1 = 0.782339
I0818 20:12:29.929036 23166 solver.cpp:404]     Test net output #1: accuracy_2 = 0.798256
I0818 20:12:29.929045 23166 solver.cpp:404]     Test net output #2: loss_1 = 22443.7 (* 1 = 22443.7 loss)
I0818 20:12:29.929051 23166 solver.cpp:404]     Test net output #3: loss_2 = 20330.5 (* 1 = 20330.5 loss)
I0818 20:12:31.124430 23166 solver.cpp:228] Iteration 1600, loss = 41697
I0818 20:12:31.124464 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.770577
I0818 20:12:31.124470 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.810025
I0818 20:12:31.124477 23166 solver.cpp:244]     Train net output #2: loss_1 = 22694.9 (* 1 = 22694.9 loss)
I0818 20:12:31.124482 23166 solver.cpp:244]     Train net output #3: loss_2 = 19002.1 (* 1 = 19002.1 loss)
I0818 20:12:31.124488 23166 sgd_solver.cpp:106] Iteration 1600, lr = 5e-06
I0818 20:13:40.243850 23166 solver.cpp:228] Iteration 1650, loss = 36254.7
I0818 20:13:40.243927 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.807449
I0818 20:13:40.243933 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.840442
I0818 20:13:40.243940 23166 solver.cpp:244]     Train net output #2: loss_1 = 19548.8 (* 1 = 19548.8 loss)
I0818 20:13:40.243947 23166 solver.cpp:244]     Train net output #3: loss_2 = 16705.8 (* 1 = 16705.8 loss)
I0818 20:13:40.243952 23166 sgd_solver.cpp:106] Iteration 1650, lr = 5e-06
I0818 20:14:49.437397 23166 solver.cpp:228] Iteration 1700, loss = 37653.2
I0818 20:14:49.437500 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.804939
I0818 20:14:49.437507 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.81433
I0818 20:14:49.437515 23166 solver.cpp:244]     Train net output #2: loss_1 = 19395.8 (* 1 = 19395.8 loss)
I0818 20:14:49.437520 23166 solver.cpp:244]     Train net output #3: loss_2 = 18257.4 (* 1 = 18257.4 loss)
I0818 20:14:49.437525 23166 sgd_solver.cpp:106] Iteration 1700, lr = 5e-06
I0818 20:15:58.552779 23166 solver.cpp:228] Iteration 1750, loss = 26274
I0818 20:15:58.552877 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.856667
I0818 20:15:58.552884 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.891589
I0818 20:15:58.552892 23166 solver.cpp:244]     Train net output #2: loss_1 = 15046.8 (* 1 = 15046.8 loss)
I0818 20:15:58.552897 23166 solver.cpp:244]     Train net output #3: loss_2 = 11227.2 (* 1 = 11227.2 loss)
I0818 20:15:58.552903 23166 sgd_solver.cpp:106] Iteration 1750, lr = 5e-06
I0818 20:17:06.512073 23166 solver.cpp:337] Iteration 1800, Testing net (#0)
I0818 20:17:20.776137 23166 solver.cpp:404]     Test net output #0: accuracy_1 = 0.794947
I0818 20:17:20.776173 23166 solver.cpp:404]     Test net output #1: accuracy_2 = 0.819621
I0818 20:17:20.776182 23166 solver.cpp:404]     Test net output #2: loss_1 = 20572.9 (* 1 = 20572.9 loss)
I0818 20:17:20.776188 23166 solver.cpp:404]     Test net output #3: loss_2 = 17672.8 (* 1 = 17672.8 loss)
I0818 20:17:21.970700 23166 solver.cpp:228] Iteration 1800, loss = 26380.9
I0818 20:17:21.970736 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.860295
I0818 20:17:21.970751 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.890222
I0818 20:17:21.970758 23166 solver.cpp:244]     Train net output #2: loss_1 = 14756.5 (* 1 = 14756.5 loss)
I0818 20:17:21.970764 23166 solver.cpp:244]     Train net output #3: loss_2 = 11624.4 (* 1 = 11624.4 loss)
I0818 20:17:21.970770 23166 sgd_solver.cpp:106] Iteration 1800, lr = 5e-06
I0818 20:18:31.144788 23166 solver.cpp:228] Iteration 1850, loss = 22004.5
I0818 20:18:31.144884 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.882443
I0818 20:18:31.144892 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.909368
I0818 20:18:31.144899 23166 solver.cpp:244]     Train net output #2: loss_1 = 12384.6 (* 1 = 12384.6 loss)
I0818 20:18:31.144904 23166 solver.cpp:244]     Train net output #3: loss_2 = 9619.81 (* 1 = 9619.81 loss)
I0818 20:18:31.144911 23166 sgd_solver.cpp:106] Iteration 1850, lr = 5e-06
I0818 20:19:40.230670 23166 solver.cpp:228] Iteration 1900, loss = 33360.3
I0818 20:19:40.230767 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.823267
I0818 20:19:40.230773 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.857766
I0818 20:19:40.230782 23166 solver.cpp:244]     Train net output #2: loss_1 = 18702.7 (* 1 = 18702.7 loss)
I0818 20:19:40.230787 23166 solver.cpp:244]     Train net output #3: loss_2 = 14657.6 (* 1 = 14657.6 loss)
I0818 20:19:40.230792 23166 sgd_solver.cpp:106] Iteration 1900, lr = 5e-06
I0818 20:20:49.386142 23166 solver.cpp:228] Iteration 1950, loss = 38250.8
I0818 20:20:49.386198 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.791844
I0818 20:20:49.386204 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.840361
I0818 20:20:49.386211 23166 solver.cpp:244]     Train net output #2: loss_1 = 21291.3 (* 1 = 21291.3 loss)
I0818 20:20:49.386216 23166 solver.cpp:244]     Train net output #3: loss_2 = 16959.4 (* 1 = 16959.4 loss)
I0818 20:20:49.386222 23166 sgd_solver.cpp:106] Iteration 1950, lr = 5e-06
I0818 20:21:57.332243 23166 solver.cpp:454] Snapshotting to binary proto file portrait_two_stage_iter_2000.caffemodel
I0818 20:21:57.336375 23166 sgd_solver.cpp:273] Snapshotting solver state to binary proto file portrait_two_stage_iter_2000.solverstate
I0818 20:21:57.337821 23166 solver.cpp:337] Iteration 2000, Testing net (#0)
I0818 20:22:11.515193 23166 solver.cpp:404]     Test net output #0: accuracy_1 = 0.803564
I0818 20:22:11.515228 23166 solver.cpp:404]     Test net output #1: accuracy_2 = 0.783889
I0818 20:22:11.515235 23166 solver.cpp:404]     Test net output #2: loss_1 = 20241.9 (* 1 = 20241.9 loss)
I0818 20:22:11.515240 23166 solver.cpp:404]     Test net output #3: loss_2 = 20882.8 (* 1 = 20882.8 loss)
I0818 20:22:12.706879 23166 solver.cpp:228] Iteration 2000, loss = 21639.4
I0818 20:22:12.706914 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.88064
I0818 20:22:12.706919 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.919895
I0818 20:22:12.706928 23166 solver.cpp:244]     Train net output #2: loss_1 = 13026.5 (* 1 = 13026.5 loss)
I0818 20:22:12.706933 23166 solver.cpp:244]     Train net output #3: loss_2 = 8612.95 (* 1 = 8612.95 loss)
I0818 20:22:12.706939 23166 sgd_solver.cpp:106] Iteration 2000, lr = 2.5e-06
I0818 20:23:21.873917 23166 solver.cpp:228] Iteration 2050, loss = 28407.7
I0818 20:23:21.874009 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.842556
I0818 20:23:21.874017 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.886398
I0818 20:23:21.874023 23166 solver.cpp:244]     Train net output #2: loss_1 = 16962.3 (* 1 = 16962.3 loss)
I0818 20:23:21.874029 23166 solver.cpp:244]     Train net output #3: loss_2 = 11445.3 (* 1 = 11445.3 loss)
I0818 20:23:21.874035 23166 sgd_solver.cpp:106] Iteration 2050, lr = 2.5e-06
I0818 20:24:30.911794 23166 solver.cpp:228] Iteration 2100, loss = 31626.6
I0818 20:24:30.911887 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.837925
I0818 20:24:30.911895 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.859877
I0818 20:24:30.911911 23166 solver.cpp:244]     Train net output #2: loss_1 = 17123.6 (* 1 = 17123.6 loss)
I0818 20:24:30.911916 23166 solver.cpp:244]     Train net output #3: loss_2 = 14503 (* 1 = 14503 loss)
I0818 20:24:30.911921 23166 sgd_solver.cpp:106] Iteration 2100, lr = 2.5e-06
I0818 20:25:40.085708 23166 solver.cpp:228] Iteration 2150, loss = 26489.8
I0818 20:25:40.085829 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.848704
I0818 20:25:40.085836 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.879848
I0818 20:25:40.085844 23166 solver.cpp:244]     Train net output #2: loss_1 = 14562.2 (* 1 = 14562.2 loss)
I0818 20:25:40.085850 23166 solver.cpp:244]     Train net output #3: loss_2 = 11927.7 (* 1 = 11927.7 loss)
I0818 20:25:40.085855 23166 sgd_solver.cpp:106] Iteration 2150, lr = 2.5e-06
I0818 20:26:48.079311 23166 solver.cpp:337] Iteration 2200, Testing net (#0)
I0818 20:27:02.283136 23166 solver.cpp:404]     Test net output #0: accuracy_1 = 0.832518
I0818 20:27:02.283171 23166 solver.cpp:404]     Test net output #1: accuracy_2 = 0.796979
I0818 20:27:02.283179 23166 solver.cpp:404]     Test net output #2: loss_1 = 17187.3 (* 1 = 17187.3 loss)
I0818 20:27:02.283185 23166 solver.cpp:404]     Test net output #3: loss_2 = 19950.2 (* 1 = 19950.2 loss)
I0818 20:27:03.475332 23166 solver.cpp:228] Iteration 2200, loss = 23401.1
I0818 20:27:03.475364 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.867378
I0818 20:27:03.475369 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.903875
I0818 20:27:03.475376 23166 solver.cpp:244]     Train net output #2: loss_1 = 13901.7 (* 1 = 13901.7 loss)
I0818 20:27:03.475383 23166 solver.cpp:244]     Train net output #3: loss_2 = 9499.35 (* 1 = 9499.35 loss)
I0818 20:27:03.475389 23166 sgd_solver.cpp:106] Iteration 2200, lr = 2.5e-06
I0818 20:28:12.642941 23166 solver.cpp:228] Iteration 2250, loss = 19984.3
I0818 20:28:12.643034 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.887765
I0818 20:28:12.643040 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.925724
I0818 20:28:12.643049 23166 solver.cpp:244]     Train net output #2: loss_1 = 11951.9 (* 1 = 11951.9 loss)
I0818 20:28:12.643054 23166 solver.cpp:244]     Train net output #3: loss_2 = 8032.35 (* 1 = 8032.35 loss)
I0818 20:28:12.643060 23166 sgd_solver.cpp:106] Iteration 2250, lr = 2.5e-06
I0818 20:29:21.836212 23166 solver.cpp:228] Iteration 2300, loss = 22711
I0818 20:29:21.836304 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.876374
I0818 20:29:21.836311 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.911833
I0818 20:29:21.836318 23166 solver.cpp:244]     Train net output #2: loss_1 = 13265.2 (* 1 = 13265.2 loss)
I0818 20:29:21.836324 23166 solver.cpp:244]     Train net output #3: loss_2 = 9445.78 (* 1 = 9445.78 loss)
I0818 20:29:21.836330 23166 sgd_solver.cpp:106] Iteration 2300, lr = 2.5e-06
I0818 20:30:30.914837 23166 solver.cpp:228] Iteration 2350, loss = 31202.2
I0818 20:30:30.914929 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.830256
I0818 20:30:30.914937 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.863767
I0818 20:30:30.914943 23166 solver.cpp:244]     Train net output #2: loss_1 = 17430 (* 1 = 17430 loss)
I0818 20:30:30.914949 23166 solver.cpp:244]     Train net output #3: loss_2 = 13772.2 (* 1 = 13772.2 loss)
I0818 20:30:30.914955 23166 sgd_solver.cpp:106] Iteration 2350, lr = 2.5e-06
I0818 20:31:38.906720 23166 solver.cpp:337] Iteration 2400, Testing net (#0)
I0818 20:31:53.124014 23166 solver.cpp:404]     Test net output #0: accuracy_1 = 0.78752
I0818 20:31:53.124049 23166 solver.cpp:404]     Test net output #1: accuracy_2 = 0.828954
I0818 20:31:53.124058 23166 solver.cpp:404]     Test net output #2: loss_1 = 21535.1 (* 1 = 21535.1 loss)
I0818 20:31:53.124063 23166 solver.cpp:404]     Test net output #3: loss_2 = 17292.5 (* 1 = 17292.5 loss)
I0818 20:31:54.321375 23166 solver.cpp:228] Iteration 2400, loss = 25912.1
I0818 20:31:54.321413 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.857675
I0818 20:31:54.321429 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.890197
I0818 20:31:54.321437 23166 solver.cpp:244]     Train net output #2: loss_1 = 14465.7 (* 1 = 14465.7 loss)
I0818 20:31:54.321442 23166 solver.cpp:244]     Train net output #3: loss_2 = 11446.4 (* 1 = 11446.4 loss)
I0818 20:31:54.321449 23166 sgd_solver.cpp:106] Iteration 2400, lr = 2.5e-06
I0818 20:33:03.473709 23166 solver.cpp:228] Iteration 2450, loss = 17627.2
I0818 20:33:03.473786 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.90562
I0818 20:33:03.473793 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.934221
I0818 20:33:03.473800 23166 solver.cpp:244]     Train net output #2: loss_1 = 10658.5 (* 1 = 10658.5 loss)
I0818 20:33:03.473806 23166 solver.cpp:244]     Train net output #3: loss_2 = 6968.73 (* 1 = 6968.73 loss)
I0818 20:33:03.473812 23166 sgd_solver.cpp:106] Iteration 2450, lr = 2.5e-06
I0818 20:34:12.983247 23166 solver.cpp:228] Iteration 2500, loss = 21347.7
I0818 20:34:12.983327 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.872141
I0818 20:34:12.983335 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.928423
I0818 20:34:12.983342 23166 solver.cpp:244]     Train net output #2: loss_1 = 13632 (* 1 = 13632 loss)
I0818 20:34:12.983347 23166 solver.cpp:244]     Train net output #3: loss_2 = 7715.7 (* 1 = 7715.7 loss)
I0818 20:34:12.983353 23166 sgd_solver.cpp:106] Iteration 2500, lr = 2.5e-06
I0818 20:35:22.382875 23166 solver.cpp:228] Iteration 2550, loss = 25549
I0818 20:35:22.382969 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.861558
I0818 20:35:22.382975 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.892287
I0818 20:35:22.382983 23166 solver.cpp:244]     Train net output #2: loss_1 = 14367.7 (* 1 = 14367.7 loss)
I0818 20:35:22.382989 23166 solver.cpp:244]     Train net output #3: loss_2 = 11181.4 (* 1 = 11181.4 loss)
I0818 20:35:22.382995 23166 sgd_solver.cpp:106] Iteration 2550, lr = 2.5e-06
I0818 20:36:30.381947 23166 solver.cpp:337] Iteration 2600, Testing net (#0)
I0818 20:36:44.681071 23166 solver.cpp:404]     Test net output #0: accuracy_1 = 0.848516
I0818 20:36:44.681102 23166 solver.cpp:404]     Test net output #1: accuracy_2 = 0.864557
I0818 20:36:44.681112 23166 solver.cpp:404]     Test net output #2: loss_1 = 15694.3 (* 1 = 15694.3 loss)
I0818 20:36:44.681118 23166 solver.cpp:404]     Test net output #3: loss_2 = 13724.8 (* 1 = 13724.8 loss)
I0818 20:36:45.884511 23166 solver.cpp:228] Iteration 2600, loss = 24321.1
I0818 20:36:45.884546 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.865054
I0818 20:36:45.884552 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.892569
I0818 20:36:45.884558 23166 solver.cpp:244]     Train net output #2: loss_1 = 13748 (* 1 = 13748 loss)
I0818 20:36:45.884563 23166 solver.cpp:244]     Train net output #3: loss_2 = 10573.1 (* 1 = 10573.1 loss)
I0818 20:36:45.884570 23166 sgd_solver.cpp:106] Iteration 2600, lr = 2.5e-06
I0818 20:37:55.062816 23166 solver.cpp:228] Iteration 2650, loss = 28023
I0818 20:37:55.062894 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.846465
I0818 20:37:55.062901 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.882993
I0818 20:37:55.062908 23166 solver.cpp:244]     Train net output #2: loss_1 = 15875.9 (* 1 = 15875.9 loss)
I0818 20:37:55.062914 23166 solver.cpp:244]     Train net output #3: loss_2 = 12147 (* 1 = 12147 loss)
I0818 20:37:55.062919 23166 sgd_solver.cpp:106] Iteration 2650, lr = 2.5e-06
I0818 20:39:04.185111 23166 solver.cpp:228] Iteration 2700, loss = 19806.6
I0818 20:39:04.185149 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.891423
I0818 20:39:04.185155 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.924769
I0818 20:39:04.185163 23166 solver.cpp:244]     Train net output #2: loss_1 = 11871.6 (* 1 = 11871.6 loss)
I0818 20:39:04.185168 23166 solver.cpp:244]     Train net output #3: loss_2 = 7935.05 (* 1 = 7935.05 loss)
I0818 20:39:04.185174 23166 sgd_solver.cpp:106] Iteration 2700, lr = 2.5e-06
I0818 20:40:13.349272 23166 solver.cpp:228] Iteration 2750, loss = 21578.1
I0818 20:40:13.349354 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.868686
I0818 20:40:13.349362 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.922025
I0818 20:40:13.349370 23166 solver.cpp:244]     Train net output #2: loss_1 = 13579.1 (* 1 = 13579.1 loss)
I0818 20:40:13.349375 23166 solver.cpp:244]     Train net output #3: loss_2 = 7999.01 (* 1 = 7999.01 loss)
I0818 20:40:13.349380 23166 sgd_solver.cpp:106] Iteration 2750, lr = 2.5e-06
I0818 20:41:21.287467 23166 solver.cpp:337] Iteration 2800, Testing net (#0)
I0818 20:41:35.539585 23166 solver.cpp:404]     Test net output #0: accuracy_1 = 0.855897
I0818 20:41:35.539621 23166 solver.cpp:404]     Test net output #1: accuracy_2 = 0.857917
I0818 20:41:35.539630 23166 solver.cpp:404]     Test net output #2: loss_1 = 14988.4 (* 1 = 14988.4 loss)
I0818 20:41:35.539635 23166 solver.cpp:404]     Test net output #3: loss_2 = 14468.8 (* 1 = 14468.8 loss)
I0818 20:41:36.742516 23166 solver.cpp:228] Iteration 2800, loss = 28642.2
I0818 20:41:36.742549 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.847029
I0818 20:41:36.742554 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.865635
I0818 20:41:36.742563 23166 solver.cpp:244]     Train net output #2: loss_1 = 15714.8 (* 1 = 15714.8 loss)
I0818 20:41:36.742568 23166 solver.cpp:244]     Train net output #3: loss_2 = 12927.4 (* 1 = 12927.4 loss)
I0818 20:41:36.742574 23166 sgd_solver.cpp:106] Iteration 2800, lr = 2.5e-06
I0818 20:42:45.947896 23166 solver.cpp:228] Iteration 2850, loss = 21783.1
I0818 20:42:45.947984 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.872547
I0818 20:42:45.947990 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.912833
I0818 20:42:45.947998 23166 solver.cpp:244]     Train net output #2: loss_1 = 12956.9 (* 1 = 12956.9 loss)
I0818 20:42:45.948004 23166 solver.cpp:244]     Train net output #3: loss_2 = 8826.19 (* 1 = 8826.19 loss)
I0818 20:42:45.948009 23166 sgd_solver.cpp:106] Iteration 2850, lr = 2.5e-06
I0818 20:43:55.087234 23166 solver.cpp:228] Iteration 2900, loss = 16944.6
I0818 20:43:55.087301 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.909302
I0818 20:43:55.087308 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.933961
I0818 20:43:55.087316 23166 solver.cpp:244]     Train net output #2: loss_1 = 10056.9 (* 1 = 10056.9 loss)
I0818 20:43:55.087321 23166 solver.cpp:244]     Train net output #3: loss_2 = 6887.72 (* 1 = 6887.72 loss)
I0818 20:43:55.087327 23166 sgd_solver.cpp:106] Iteration 2900, lr = 2.5e-06
I0818 20:45:04.298952 23166 solver.cpp:228] Iteration 2950, loss = 21212
I0818 20:45:04.299041 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.872017
I0818 20:45:04.299048 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.926887
I0818 20:45:04.299055 23166 solver.cpp:244]     Train net output #2: loss_1 = 13450.1 (* 1 = 13450.1 loss)
I0818 20:45:04.299062 23166 solver.cpp:244]     Train net output #3: loss_2 = 7761.82 (* 1 = 7761.82 loss)
I0818 20:45:04.299067 23166 sgd_solver.cpp:106] Iteration 2950, lr = 2.5e-06
I0818 20:46:12.232434 23166 solver.cpp:337] Iteration 3000, Testing net (#0)
I0818 20:46:26.483492 23166 solver.cpp:404]     Test net output #0: accuracy_1 = 0.842921
I0818 20:46:26.483526 23166 solver.cpp:404]     Test net output #1: accuracy_2 = 0.84423
I0818 20:46:26.483536 23166 solver.cpp:404]     Test net output #2: loss_1 = 15935.1 (* 1 = 15935.1 loss)
I0818 20:46:26.483541 23166 solver.cpp:404]     Test net output #3: loss_2 = 15364.2 (* 1 = 15364.2 loss)
I0818 20:46:27.683171 23166 solver.cpp:228] Iteration 3000, loss = 26684.7
I0818 20:46:27.683203 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.856147
I0818 20:46:27.683209 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.880844
I0818 20:46:27.683217 23166 solver.cpp:244]     Train net output #2: loss_1 = 14708.2 (* 1 = 14708.2 loss)
I0818 20:46:27.683221 23166 solver.cpp:244]     Train net output #3: loss_2 = 11976.5 (* 1 = 11976.5 loss)
I0818 20:46:27.683238 23166 sgd_solver.cpp:106] Iteration 3000, lr = 1.25e-06
I0818 20:47:36.911090 23166 solver.cpp:228] Iteration 3050, loss = 25753.2
I0818 20:47:36.911162 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.863698
I0818 20:47:36.911170 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.89117
I0818 20:47:36.911176 23166 solver.cpp:244]     Train net output #2: loss_1 = 14392.8 (* 1 = 14392.8 loss)
I0818 20:47:36.911181 23166 solver.cpp:244]     Train net output #3: loss_2 = 11360.4 (* 1 = 11360.4 loss)
I0818 20:47:36.911188 23166 sgd_solver.cpp:106] Iteration 3050, lr = 1.25e-06
I0818 20:48:45.982086 23166 solver.cpp:228] Iteration 3100, loss = 27932.7
I0818 20:48:45.982146 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.846075
I0818 20:48:45.982153 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.885075
I0818 20:48:45.982161 23166 solver.cpp:244]     Train net output #2: loss_1 = 15857.2 (* 1 = 15857.2 loss)
I0818 20:48:45.982167 23166 solver.cpp:244]     Train net output #3: loss_2 = 12075.5 (* 1 = 12075.5 loss)
I0818 20:48:45.982172 23166 sgd_solver.cpp:106] Iteration 3100, lr = 1.25e-06
I0818 20:49:55.200326 23166 solver.cpp:228] Iteration 3150, loss = 17140.8
I0818 20:49:55.200407 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.902521
I0818 20:49:55.200412 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.934773
I0818 20:49:55.200420 23166 solver.cpp:244]     Train net output #2: loss_1 = 10542.7 (* 1 = 10542.7 loss)
I0818 20:49:55.200426 23166 solver.cpp:244]     Train net output #3: loss_2 = 6598.17 (* 1 = 6598.17 loss)
I0818 20:49:55.200433 23166 sgd_solver.cpp:106] Iteration 3150, lr = 1.25e-06
I0818 20:51:03.147521 23166 solver.cpp:337] Iteration 3200, Testing net (#0)
I0818 20:51:17.392509 23166 solver.cpp:404]     Test net output #0: accuracy_1 = 0.865021
I0818 20:51:17.392545 23166 solver.cpp:404]     Test net output #1: accuracy_2 = 0.870084
I0818 20:51:17.392554 23166 solver.cpp:404]     Test net output #2: loss_1 = 13963.1 (* 1 = 13963.1 loss)
I0818 20:51:17.392560 23166 solver.cpp:404]     Test net output #3: loss_2 = 13105.4 (* 1 = 13105.4 loss)
I0818 20:51:18.574175 23166 solver.cpp:228] Iteration 3200, loss = 18502.2
I0818 20:51:18.574209 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.888071
I0818 20:51:18.574215 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.932175
I0818 20:51:18.574223 23166 solver.cpp:244]     Train net output #2: loss_1 = 11606.1 (* 1 = 11606.1 loss)
I0818 20:51:18.574229 23166 solver.cpp:244]     Train net output #3: loss_2 = 6896.11 (* 1 = 6896.11 loss)
I0818 20:51:18.574234 23166 sgd_solver.cpp:106] Iteration 3200, lr = 1.25e-06
I0818 20:52:27.762449 23166 solver.cpp:228] Iteration 3250, loss = 24303
I0818 20:52:27.762522 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.865968
I0818 20:52:27.762529 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.894123
I0818 20:52:27.762537 23166 solver.cpp:244]     Train net output #2: loss_1 = 13788.1 (* 1 = 13788.1 loss)
I0818 20:52:27.762542 23166 solver.cpp:244]     Train net output #3: loss_2 = 10514.9 (* 1 = 10514.9 loss)
I0818 20:52:27.762547 23166 sgd_solver.cpp:106] Iteration 3250, lr = 1.25e-06
I0818 20:53:36.936668 23166 solver.cpp:228] Iteration 3300, loss = 20874.4
I0818 20:53:36.936743 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.884482
I0818 20:53:36.936748 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.912711
I0818 20:53:36.936756 23166 solver.cpp:244]     Train net output #2: loss_1 = 12110.6 (* 1 = 12110.6 loss)
I0818 20:53:36.936761 23166 solver.cpp:244]     Train net output #3: loss_2 = 8763.8 (* 1 = 8763.8 loss)
I0818 20:53:36.936769 23166 sgd_solver.cpp:106] Iteration 3300, lr = 1.25e-06
I0818 20:54:46.006767 23166 solver.cpp:228] Iteration 3350, loss = 16343.3
I0818 20:54:46.006868 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.909762
I0818 20:54:46.006878 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.94102
I0818 20:54:46.006886 23166 solver.cpp:244]     Train net output #2: loss_1 = 9988.93 (* 1 = 9988.93 loss)
I0818 20:54:46.006891 23166 solver.cpp:244]     Train net output #3: loss_2 = 6354.42 (* 1 = 6354.42 loss)
I0818 20:54:46.006897 23166 sgd_solver.cpp:106] Iteration 3350, lr = 1.25e-06
I0818 20:55:54.075032 23166 solver.cpp:337] Iteration 3400, Testing net (#0)
I0818 20:56:08.302656 23166 solver.cpp:404]     Test net output #0: accuracy_1 = 0.860341
I0818 20:56:08.302693 23166 solver.cpp:404]     Test net output #1: accuracy_2 = 0.875333
I0818 20:56:08.302701 23166 solver.cpp:404]     Test net output #2: loss_1 = 14237.8 (* 1 = 14237.8 loss)
I0818 20:56:08.302707 23166 solver.cpp:404]     Test net output #3: loss_2 = 12683.9 (* 1 = 12683.9 loss)
I0818 20:56:09.489919 23166 solver.cpp:228] Iteration 3400, loss = 16856.2
I0818 20:56:09.489954 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.897033
I0818 20:56:09.489959 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.945562
I0818 20:56:09.489966 23166 solver.cpp:244]     Train net output #2: loss_1 = 11042.8 (* 1 = 11042.8 loss)
I0818 20:56:09.489972 23166 solver.cpp:244]     Train net output #3: loss_2 = 5813.46 (* 1 = 5813.46 loss)
I0818 20:56:09.489979 23166 sgd_solver.cpp:106] Iteration 3400, lr = 1.25e-06
I0818 20:57:18.625427 23166 solver.cpp:228] Iteration 3450, loss = 17855.3
I0818 20:57:18.625497 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.895131
I0818 20:57:18.625504 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.939615
I0818 20:57:18.625511 23166 solver.cpp:244]     Train net output #2: loss_1 = 11214.8 (* 1 = 11214.8 loss)
I0818 20:57:18.625517 23166 solver.cpp:244]     Train net output #3: loss_2 = 6640.49 (* 1 = 6640.49 loss)
I0818 20:57:18.625524 23166 sgd_solver.cpp:106] Iteration 3450, lr = 1.25e-06
I0818 20:58:27.821563 23166 solver.cpp:228] Iteration 3500, loss = 20235.5
I0818 20:58:27.821656 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.887815
I0818 20:58:27.821663 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.912981
I0818 20:58:27.821671 23166 solver.cpp:244]     Train net output #2: loss_1 = 11427 (* 1 = 11427 loss)
I0818 20:58:27.821676 23166 solver.cpp:244]     Train net output #3: loss_2 = 8808.47 (* 1 = 8808.47 loss)
I0818 20:58:27.821682 23166 sgd_solver.cpp:106] Iteration 3500, lr = 1.25e-06
I0818 20:59:36.914926 23166 solver.cpp:228] Iteration 3550, loss = 29411.4
I0818 20:59:36.915012 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.832051
I0818 20:59:36.915019 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.878289
I0818 20:59:36.915026 23166 solver.cpp:244]     Train net output #2: loss_1 = 17143.3 (* 1 = 17143.3 loss)
I0818 20:59:36.915032 23166 solver.cpp:244]     Train net output #3: loss_2 = 12268.1 (* 1 = 12268.1 loss)
I0818 20:59:36.915038 23166 sgd_solver.cpp:106] Iteration 3550, lr = 1.25e-06
I0818 21:00:44.930879 23166 solver.cpp:337] Iteration 3600, Testing net (#0)
I0818 21:00:59.177964 23166 solver.cpp:404]     Test net output #0: accuracy_1 = 0.855604
I0818 21:00:59.177999 23166 solver.cpp:404]     Test net output #1: accuracy_2 = 0.871541
I0818 21:00:59.178007 23166 solver.cpp:404]     Test net output #2: loss_1 = 14784.4 (* 1 = 14784.4 loss)
I0818 21:00:59.178012 23166 solver.cpp:404]     Test net output #3: loss_2 = 12871.2 (* 1 = 12871.2 loss)
I0818 21:01:00.372596 23166 solver.cpp:228] Iteration 3600, loss = 14190
I0818 21:01:00.372629 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.918741
I0818 21:01:00.372634 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.948007
I0818 21:01:00.372642 23166 solver.cpp:244]     Train net output #2: loss_1 = 8758.23 (* 1 = 8758.23 loss)
I0818 21:01:00.372648 23166 solver.cpp:244]     Train net output #3: loss_2 = 5431.82 (* 1 = 5431.82 loss)
I0818 21:01:00.372653 23166 sgd_solver.cpp:106] Iteration 3600, lr = 1.25e-06
I0818 21:02:09.549044 23166 solver.cpp:228] Iteration 3650, loss = 19852.9
I0818 21:02:09.549149 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.88488
I0818 21:02:09.549156 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.927339
I0818 21:02:09.549163 23166 solver.cpp:244]     Train net output #2: loss_1 = 12331.9 (* 1 = 12331.9 loss)
I0818 21:02:09.549170 23166 solver.cpp:244]     Train net output #3: loss_2 = 7521.06 (* 1 = 7521.06 loss)
I0818 21:02:09.549175 23166 sgd_solver.cpp:106] Iteration 3650, lr = 1.25e-06
I0818 21:03:18.682761 23166 solver.cpp:228] Iteration 3700, loss = 26903.8
I0818 21:03:18.682857 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.852281
I0818 21:03:18.682864 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.88064
I0818 21:03:18.682871 23166 solver.cpp:244]     Train net output #2: loss_1 = 14850.9 (* 1 = 14850.9 loss)
I0818 21:03:18.682878 23166 solver.cpp:244]     Train net output #3: loss_2 = 12053 (* 1 = 12053 loss)
I0818 21:03:18.682884 23166 sgd_solver.cpp:106] Iteration 3700, lr = 1.25e-06
I0818 21:04:27.900127 23166 solver.cpp:228] Iteration 3750, loss = 19590.2
I0818 21:04:27.900220 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.894378
I0818 21:04:27.900226 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.917415
I0818 21:04:27.900234 23166 solver.cpp:244]     Train net output #2: loss_1 = 11123.4 (* 1 = 11123.4 loss)
I0818 21:04:27.900239 23166 solver.cpp:244]     Train net output #3: loss_2 = 8466.83 (* 1 = 8466.83 loss)
I0818 21:04:27.900246 23166 sgd_solver.cpp:106] Iteration 3750, lr = 1.25e-06
I0818 21:05:35.829358 23166 solver.cpp:337] Iteration 3800, Testing net (#0)
I0818 21:05:50.085469 23166 solver.cpp:404]     Test net output #0: accuracy_1 = 0.866784
I0818 21:05:50.085502 23166 solver.cpp:404]     Test net output #1: accuracy_2 = 0.857742
I0818 21:05:50.085511 23166 solver.cpp:404]     Test net output #2: loss_1 = 13882.7 (* 1 = 13882.7 loss)
I0818 21:05:50.085516 23166 solver.cpp:404]     Test net output #3: loss_2 = 13835.8 (* 1 = 13835.8 loss)
I0818 21:05:51.276819 23166 solver.cpp:228] Iteration 3800, loss = 22669.7
I0818 21:05:51.276854 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.874494
I0818 21:05:51.276859 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.906505
I0818 21:05:51.276865 23166 solver.cpp:244]     Train net output #2: loss_1 = 13123 (* 1 = 13123 loss)
I0818 21:05:51.276871 23166 solver.cpp:244]     Train net output #3: loss_2 = 9546.72 (* 1 = 9546.72 loss)
I0818 21:05:51.276877 23166 sgd_solver.cpp:106] Iteration 3800, lr = 1.25e-06
I0818 21:07:00.515693 23166 solver.cpp:228] Iteration 3850, loss = 17559
I0818 21:07:00.515770 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.894461
I0818 21:07:00.515776 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.939411
I0818 21:07:00.515784 23166 solver.cpp:244]     Train net output #2: loss_1 = 11147.5 (* 1 = 11147.5 loss)
I0818 21:07:00.515789 23166 solver.cpp:244]     Train net output #3: loss_2 = 6411.46 (* 1 = 6411.46 loss)
I0818 21:07:00.515796 23166 sgd_solver.cpp:106] Iteration 3850, lr = 1.25e-06
I0818 21:08:09.646082 23166 solver.cpp:228] Iteration 3900, loss = 17321.2
I0818 21:08:09.646173 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.896293
I0818 21:08:09.646179 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.941113
I0818 21:08:09.646186 23166 solver.cpp:244]     Train net output #2: loss_1 = 10970.7 (* 1 = 10970.7 loss)
I0818 21:08:09.646193 23166 solver.cpp:244]     Train net output #3: loss_2 = 6350.55 (* 1 = 6350.55 loss)
I0818 21:08:09.646198 23166 sgd_solver.cpp:106] Iteration 3900, lr = 1.25e-06
I0818 21:09:18.819355 23166 solver.cpp:228] Iteration 3950, loss = 20473.5
I0818 21:09:18.819409 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.891697
I0818 21:09:18.819416 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.906601
I0818 21:09:18.819422 23166 solver.cpp:244]     Train net output #2: loss_1 = 11188.8 (* 1 = 11188.8 loss)
I0818 21:09:18.819428 23166 solver.cpp:244]     Train net output #3: loss_2 = 9284.63 (* 1 = 9284.63 loss)
I0818 21:09:18.819443 23166 sgd_solver.cpp:106] Iteration 3950, lr = 1.25e-06
I0818 21:10:26.755965 23166 solver.cpp:454] Snapshotting to binary proto file portrait_two_stage_iter_4000.caffemodel
I0818 21:10:26.760052 23166 sgd_solver.cpp:273] Snapshotting solver state to binary proto file portrait_two_stage_iter_4000.solverstate
I0818 21:10:26.761487 23166 solver.cpp:337] Iteration 4000, Testing net (#0)
I0818 21:10:40.965101 23166 solver.cpp:404]     Test net output #0: accuracy_1 = 0.868262
I0818 21:10:40.965136 23166 solver.cpp:404]     Test net output #1: accuracy_2 = 0.865017
I0818 21:10:40.965144 23166 solver.cpp:404]     Test net output #2: loss_1 = 13674.4 (* 1 = 13674.4 loss)
I0818 21:10:40.965150 23166 solver.cpp:404]     Test net output #3: loss_2 = 13246.9 (* 1 = 13246.9 loss)
I0818 21:10:42.143759 23166 solver.cpp:228] Iteration 4000, loss = 28199.6
I0818 21:10:42.143793 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.840591
I0818 21:10:42.143798 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.874053
I0818 21:10:42.143805 23166 solver.cpp:244]     Train net output #2: loss_1 = 15866.2 (* 1 = 15866.2 loss)
I0818 21:10:42.143810 23166 solver.cpp:244]     Train net output #3: loss_2 = 12333.4 (* 1 = 12333.4 loss)
I0818 21:10:42.143817 23166 sgd_solver.cpp:106] Iteration 4000, lr = 6.25e-07
I0818 21:11:51.283339 23166 solver.cpp:228] Iteration 4050, loss = 14694.4
I0818 21:11:51.283421 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.917729
I0818 21:11:51.283428 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.944079
I0818 21:11:51.283437 23166 solver.cpp:244]     Train net output #2: loss_1 = 9001.14 (* 1 = 9001.14 loss)
I0818 21:11:51.283442 23166 solver.cpp:244]     Train net output #3: loss_2 = 5693.25 (* 1 = 5693.25 loss)
I0818 21:11:51.283448 23166 sgd_solver.cpp:106] Iteration 4050, lr = 6.25e-07
I0818 21:13:00.423454 23166 solver.cpp:228] Iteration 4100, loss = 17106.9
I0818 21:13:00.423530 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.902986
I0818 21:13:00.423537 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.935994
I0818 21:13:00.423544 23166 solver.cpp:244]     Train net output #2: loss_1 = 10407.8 (* 1 = 10407.8 loss)
I0818 21:13:00.423549 23166 solver.cpp:244]     Train net output #3: loss_2 = 6699.08 (* 1 = 6699.08 loss)
I0818 21:13:00.423557 23166 sgd_solver.cpp:106] Iteration 4100, lr = 6.25e-07
I0818 21:14:09.543004 23166 solver.cpp:228] Iteration 4150, loss = 26216.7
I0818 21:14:09.543076 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.858205
I0818 21:14:09.543083 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.884619
I0818 21:14:09.543090 23166 solver.cpp:244]     Train net output #2: loss_1 = 14614.4 (* 1 = 14614.4 loss)
I0818 21:14:09.543097 23166 solver.cpp:244]     Train net output #3: loss_2 = 11602.3 (* 1 = 11602.3 loss)
I0818 21:14:09.543102 23166 sgd_solver.cpp:106] Iteration 4150, lr = 6.25e-07
I0818 21:15:17.470500 23166 solver.cpp:337] Iteration 4200, Testing net (#0)
I0818 21:15:31.683318 23166 solver.cpp:404]     Test net output #0: accuracy_1 = 0.874691
I0818 21:15:31.683353 23166 solver.cpp:404]     Test net output #1: accuracy_2 = 0.895413
I0818 21:15:31.683362 23166 solver.cpp:404]     Test net output #2: loss_1 = 13050.2 (* 1 = 13050.2 loss)
I0818 21:15:31.683367 23166 solver.cpp:404]     Test net output #3: loss_2 = 10776.9 (* 1 = 10776.9 loss)
I0818 21:15:32.860834 23166 solver.cpp:228] Iteration 4200, loss = 22203.3
I0818 21:15:32.860868 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.885027
I0818 21:15:32.860873 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.902783
I0818 21:15:32.860880 23166 solver.cpp:244]     Train net output #2: loss_1 = 11734.1 (* 1 = 11734.1 loss)
I0818 21:15:32.860887 23166 solver.cpp:244]     Train net output #3: loss_2 = 10469.2 (* 1 = 10469.2 loss)
I0818 21:15:32.860893 23166 sgd_solver.cpp:106] Iteration 4200, lr = 6.25e-07
I0818 21:16:41.923013 23166 solver.cpp:228] Iteration 4250, loss = 26398.6
I0818 21:16:41.923115 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.858264
I0818 21:16:41.923122 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.88685
I0818 21:16:41.923130 23166 solver.cpp:244]     Train net output #2: loss_1 = 14675.4 (* 1 = 14675.4 loss)
I0818 21:16:41.923135 23166 solver.cpp:244]     Train net output #3: loss_2 = 11723.2 (* 1 = 11723.2 loss)
I0818 21:16:41.923141 23166 sgd_solver.cpp:106] Iteration 4250, lr = 6.25e-07
I0818 21:17:51.049558 23166 solver.cpp:228] Iteration 4300, loss = 15061.9
I0818 21:17:51.049655 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.912327
I0818 21:17:51.049662 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.947494
I0818 21:17:51.049669 23166 solver.cpp:244]     Train net output #2: loss_1 = 9576.75 (* 1 = 9576.75 loss)
I0818 21:17:51.049676 23166 solver.cpp:244]     Train net output #3: loss_2 = 5485.12 (* 1 = 5485.12 loss)
I0818 21:17:51.049682 23166 sgd_solver.cpp:106] Iteration 4300, lr = 6.25e-07
I0818 21:19:00.093531 23166 solver.cpp:228] Iteration 4350, loss = 17379.6
I0818 21:19:00.093622 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.898206
I0818 21:19:00.093629 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.939214
I0818 21:19:00.093636 23166 solver.cpp:244]     Train net output #2: loss_1 = 10954.7 (* 1 = 10954.7 loss)
I0818 21:19:00.093642 23166 solver.cpp:244]     Train net output #3: loss_2 = 6424.85 (* 1 = 6424.85 loss)
I0818 21:19:00.093648 23166 sgd_solver.cpp:106] Iteration 4350, lr = 6.25e-07
I0818 21:20:08.088668 23166 solver.cpp:337] Iteration 4400, Testing net (#0)
I0818 21:20:22.314591 23166 solver.cpp:404]     Test net output #0: accuracy_1 = 0.869911
I0818 21:20:22.314628 23166 solver.cpp:404]     Test net output #1: accuracy_2 = 0.895805
I0818 21:20:22.314636 23166 solver.cpp:404]     Test net output #2: loss_1 = 13296.2 (* 1 = 13296.2 loss)
I0818 21:20:22.314642 23166 solver.cpp:404]     Test net output #3: loss_2 = 10616.4 (* 1 = 10616.4 loss)
I0818 21:20:23.498870 23166 solver.cpp:228] Iteration 4400, loss = 21338.2
I0818 21:20:23.498903 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.885962
I0818 21:20:23.498908 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.907119
I0818 21:20:23.498915 23166 solver.cpp:244]     Train net output #2: loss_1 = 11795.5 (* 1 = 11795.5 loss)
I0818 21:20:23.498921 23166 solver.cpp:244]     Train net output #3: loss_2 = 9542.63 (* 1 = 9542.63 loss)
I0818 21:20:23.498929 23166 sgd_solver.cpp:106] Iteration 4400, lr = 6.25e-07
I0818 21:21:32.560575 23166 solver.cpp:228] Iteration 4450, loss = 29061
I0818 21:21:32.560665 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.841461
I0818 21:21:32.560672 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.874757
I0818 21:21:32.560679 23166 solver.cpp:244]     Train net output #2: loss_1 = 16292.8 (* 1 = 16292.8 loss)
I0818 21:21:32.560685 23166 solver.cpp:244]     Train net output #3: loss_2 = 12768.2 (* 1 = 12768.2 loss)
I0818 21:21:32.560691 23166 sgd_solver.cpp:106] Iteration 4450, lr = 6.25e-07
I0818 21:22:41.680022 23166 solver.cpp:228] Iteration 4500, loss = 15883.2
I0818 21:22:41.680115 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.907875
I0818 21:22:41.680121 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.943015
I0818 21:22:41.680130 23166 solver.cpp:244]     Train net output #2: loss_1 = 9972.56 (* 1 = 9972.56 loss)
I0818 21:22:41.680135 23166 solver.cpp:244]     Train net output #3: loss_2 = 5910.59 (* 1 = 5910.59 loss)
I0818 21:22:41.680141 23166 sgd_solver.cpp:106] Iteration 4500, lr = 6.25e-07
I0818 21:23:50.884925 23166 solver.cpp:228] Iteration 4550, loss = 16631.4
I0818 21:23:50.885005 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.907505
I0818 21:23:50.885012 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.939061
I0818 21:23:50.885020 23166 solver.cpp:244]     Train net output #2: loss_1 = 9958.96 (* 1 = 9958.96 loss)
I0818 21:23:50.885033 23166 solver.cpp:244]     Train net output #3: loss_2 = 6672.44 (* 1 = 6672.44 loss)
I0818 21:23:50.885040 23166 sgd_solver.cpp:106] Iteration 4550, lr = 6.25e-07
I0818 21:24:58.898916 23166 solver.cpp:337] Iteration 4600, Testing net (#0)
I0818 21:25:13.114785 23166 solver.cpp:404]     Test net output #0: accuracy_1 = 0.875127
I0818 21:25:13.114822 23166 solver.cpp:404]     Test net output #1: accuracy_2 = 0.894774
I0818 21:25:13.114830 23166 solver.cpp:404]     Test net output #2: loss_1 = 12994.9 (* 1 = 12994.9 loss)
I0818 21:25:13.114836 23166 solver.cpp:404]     Test net output #3: loss_2 = 10753.6 (* 1 = 10753.6 loss)
I0818 21:25:14.286522 23166 solver.cpp:228] Iteration 4600, loss = 16011.6
I0818 21:25:14.286555 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.909624
I0818 21:25:14.286559 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.940309
I0818 21:25:14.286566 23166 solver.cpp:244]     Train net output #2: loss_1 = 9744.82 (* 1 = 9744.82 loss)
I0818 21:25:14.286572 23166 solver.cpp:244]     Train net output #3: loss_2 = 6266.76 (* 1 = 6266.76 loss)
I0818 21:25:14.286578 23166 sgd_solver.cpp:106] Iteration 4600, lr = 6.25e-07
I0818 21:26:23.398138 23166 solver.cpp:228] Iteration 4650, loss = 20404.7
I0818 21:26:23.398237 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.887431
I0818 21:26:23.398244 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.917845
I0818 21:26:23.398252 23166 solver.cpp:244]     Train net output #2: loss_1 = 11716.7 (* 1 = 11716.7 loss)
I0818 21:26:23.398257 23166 solver.cpp:244]     Train net output #3: loss_2 = 8687.93 (* 1 = 8687.93 loss)
I0818 21:26:23.398263 23166 sgd_solver.cpp:106] Iteration 4650, lr = 6.25e-07
I0818 21:27:32.507597 23166 solver.cpp:228] Iteration 4700, loss = 24210.4
I0818 21:27:32.507669 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.865205
I0818 21:27:32.507675 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.895221
I0818 21:27:32.507683 23166 solver.cpp:244]     Train net output #2: loss_1 = 13769.5 (* 1 = 13769.5 loss)
I0818 21:27:32.507688 23166 solver.cpp:244]     Train net output #3: loss_2 = 10441 (* 1 = 10441 loss)
I0818 21:27:32.507694 23166 sgd_solver.cpp:106] Iteration 4700, lr = 6.25e-07
I0818 21:28:41.671497 23166 solver.cpp:228] Iteration 4750, loss = 14210
I0818 21:28:41.671571 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.914999
I0818 21:28:41.671577 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.95165
I0818 21:28:41.671586 23166 solver.cpp:244]     Train net output #2: loss_1 = 9285.62 (* 1 = 9285.62 loss)
I0818 21:28:41.671591 23166 solver.cpp:244]     Train net output #3: loss_2 = 4924.38 (* 1 = 4924.38 loss)
I0818 21:28:41.671597 23166 sgd_solver.cpp:106] Iteration 4750, lr = 6.25e-07
I0818 21:29:49.647459 23166 solver.cpp:337] Iteration 4800, Testing net (#0)
I0818 21:30:03.883352 23166 solver.cpp:404]     Test net output #0: accuracy_1 = 0.880654
I0818 21:30:03.883386 23166 solver.cpp:404]     Test net output #1: accuracy_2 = 0.902396
I0818 21:30:03.883395 23166 solver.cpp:404]     Test net output #2: loss_1 = 12318.1 (* 1 = 12318.1 loss)
I0818 21:30:03.883401 23166 solver.cpp:404]     Test net output #3: loss_2 = 10111.1 (* 1 = 10111.1 loss)
I0818 21:30:05.054878 23166 solver.cpp:228] Iteration 4800, loss = 16899.5
I0818 21:30:05.054911 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.900198
I0818 21:30:05.054918 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.935286
I0818 21:30:05.054924 23166 solver.cpp:244]     Train net output #2: loss_1 = 10426.5 (* 1 = 10426.5 loss)
I0818 21:30:05.054930 23166 solver.cpp:244]     Train net output #3: loss_2 = 6472.99 (* 1 = 6472.99 loss)
I0818 21:30:05.054937 23166 sgd_solver.cpp:106] Iteration 4800, lr = 6.25e-07
I0818 21:31:14.275504 23166 solver.cpp:228] Iteration 4850, loss = 21286
I0818 21:31:14.275562 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.885904
I0818 21:31:14.275568 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.906828
I0818 21:31:14.275579 23166 solver.cpp:244]     Train net output #2: loss_1 = 11831.1 (* 1 = 11831.1 loss)
I0818 21:31:14.275584 23166 solver.cpp:244]     Train net output #3: loss_2 = 9454.85 (* 1 = 9454.85 loss)
I0818 21:31:14.275591 23166 sgd_solver.cpp:106] Iteration 4850, lr = 6.25e-07
I0818 21:32:23.353927 23166 solver.cpp:228] Iteration 4900, loss = 27092.4
I0818 21:32:23.354025 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.858509
I0818 21:32:23.354032 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.882189
I0818 21:32:23.354039 23166 solver.cpp:244]     Train net output #2: loss_1 = 14784.3 (* 1 = 14784.3 loss)
I0818 21:32:23.354045 23166 solver.cpp:244]     Train net output #3: loss_2 = 12308.1 (* 1 = 12308.1 loss)
I0818 21:32:23.354051 23166 sgd_solver.cpp:106] Iteration 4900, lr = 6.25e-07
I0818 21:33:32.501158 23166 solver.cpp:228] Iteration 4950, loss = 19658.8
I0818 21:33:32.501235 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.885436
I0818 21:33:32.501241 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.916122
I0818 21:33:32.501248 23166 solver.cpp:244]     Train net output #2: loss_1 = 11294.1 (* 1 = 11294.1 loss)
I0818 21:33:32.501255 23166 solver.cpp:244]     Train net output #3: loss_2 = 8364.74 (* 1 = 8364.74 loss)
I0818 21:33:32.501260 23166 sgd_solver.cpp:106] Iteration 4950, lr = 6.25e-07
I0818 21:34:40.652735 23166 solver.cpp:337] Iteration 5000, Testing net (#0)
I0818 21:34:54.913169 23166 solver.cpp:404]     Test net output #0: accuracy_1 = 0.878316
I0818 21:34:54.913204 23166 solver.cpp:404]     Test net output #1: accuracy_2 = 0.905073
I0818 21:34:54.913213 23166 solver.cpp:404]     Test net output #2: loss_1 = 12545.8 (* 1 = 12545.8 loss)
I0818 21:34:54.913218 23166 solver.cpp:404]     Test net output #3: loss_2 = 9829.73 (* 1 = 9829.73 loss)
I0818 21:34:56.084564 23166 solver.cpp:228] Iteration 5000, loss = 17240.7
I0818 21:34:56.084599 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.897642
I0818 21:34:56.084604 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.935464
I0818 21:34:56.084611 23166 solver.cpp:244]     Train net output #2: loss_1 = 10567.4 (* 1 = 10567.4 loss)
I0818 21:34:56.084617 23166 solver.cpp:244]     Train net output #3: loss_2 = 6673.22 (* 1 = 6673.22 loss)
I0818 21:34:56.084624 23166 sgd_solver.cpp:106] Iteration 5000, lr = 3.125e-07
I0818 21:36:05.516990 23166 solver.cpp:228] Iteration 5050, loss = 14765.3
I0818 21:36:05.517081 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.918534
I0818 21:36:05.517087 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.943346
I0818 21:36:05.517094 23166 solver.cpp:244]     Train net output #2: loss_1 = 8908.69 (* 1 = 8908.69 loss)
I0818 21:36:05.517101 23166 solver.cpp:244]     Train net output #3: loss_2 = 5856.57 (* 1 = 5856.57 loss)
I0818 21:36:05.517107 23166 sgd_solver.cpp:106] Iteration 5050, lr = 3.125e-07
I0818 21:37:14.939020 23166 solver.cpp:228] Iteration 5100, loss = 17717.3
I0818 21:37:14.939065 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.906483
I0818 21:37:14.939071 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.921347
I0818 21:37:14.939079 23166 solver.cpp:244]     Train net output #2: loss_1 = 9616.99 (* 1 = 9616.99 loss)
I0818 21:37:14.939085 23166 solver.cpp:244]     Train net output #3: loss_2 = 8100.28 (* 1 = 8100.28 loss)
I0818 21:37:14.939090 23166 sgd_solver.cpp:106] Iteration 5100, lr = 3.125e-07
I0818 21:38:24.148334 23166 solver.cpp:228] Iteration 5150, loss = 25351.9
I0818 21:38:24.148406 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.861251
I0818 21:38:24.148411 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.889459
I0818 21:38:24.148419 23166 solver.cpp:244]     Train net output #2: loss_1 = 14311.9 (* 1 = 14311.9 loss)
I0818 21:38:24.148424 23166 solver.cpp:244]     Train net output #3: loss_2 = 11040 (* 1 = 11040 loss)
I0818 21:38:24.148432 23166 sgd_solver.cpp:106] Iteration 5150, lr = 3.125e-07
I0818 21:39:32.160142 23166 solver.cpp:337] Iteration 5200, Testing net (#0)
I0818 21:39:46.396560 23166 solver.cpp:404]     Test net output #0: accuracy_1 = 0.887778
I0818 21:39:46.396595 23166 solver.cpp:404]     Test net output #1: accuracy_2 = 0.912666
I0818 21:39:46.396603 23166 solver.cpp:404]     Test net output #2: loss_1 = 11644.1 (* 1 = 11644.1 loss)
I0818 21:39:46.396610 23166 solver.cpp:404]     Test net output #3: loss_2 = 9059.2 (* 1 = 9059.2 loss)
I0818 21:39:47.572414 23166 solver.cpp:228] Iteration 5200, loss = 16262.2
I0818 21:39:47.572448 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.904994
I0818 21:39:47.572454 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.944111
I0818 21:39:47.572460 23166 solver.cpp:244]     Train net output #2: loss_1 = 10255.4 (* 1 = 10255.4 loss)
I0818 21:39:47.572466 23166 solver.cpp:244]     Train net output #3: loss_2 = 6006.77 (* 1 = 6006.77 loss)
I0818 21:39:47.572473 23166 sgd_solver.cpp:106] Iteration 5200, lr = 3.125e-07
I0818 21:40:56.667872 23166 solver.cpp:228] Iteration 5250, loss = 13823.5
I0818 21:40:56.667964 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.919551
I0818 21:40:56.667971 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.94712
I0818 21:40:56.667979 23166 solver.cpp:244]     Train net output #2: loss_1 = 8445.67 (* 1 = 8445.67 loss)
I0818 21:40:56.667984 23166 solver.cpp:244]     Train net output #3: loss_2 = 5377.84 (* 1 = 5377.84 loss)
I0818 21:40:56.667990 23166 sgd_solver.cpp:106] Iteration 5250, lr = 3.125e-07
I0818 21:42:05.957005 23166 solver.cpp:228] Iteration 5300, loss = 22252.7
I0818 21:42:05.957053 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.880108
I0818 21:42:05.957059 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.905034
I0818 21:42:05.957067 23166 solver.cpp:244]     Train net output #2: loss_1 = 12506.6 (* 1 = 12506.6 loss)
I0818 21:42:05.957072 23166 solver.cpp:244]     Train net output #3: loss_2 = 9746.05 (* 1 = 9746.05 loss)
I0818 21:42:05.957078 23166 sgd_solver.cpp:106] Iteration 5300, lr = 3.125e-07
I0818 21:43:15.014387 23166 solver.cpp:228] Iteration 5350, loss = 25108.4
I0818 21:43:15.014461 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.866848
I0818 21:43:15.014467 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.895036
I0818 21:43:15.014473 23166 solver.cpp:244]     Train net output #2: loss_1 = 13980 (* 1 = 13980 loss)
I0818 21:43:15.014479 23166 solver.cpp:244]     Train net output #3: loss_2 = 11128.4 (* 1 = 11128.4 loss)
I0818 21:43:15.014485 23166 sgd_solver.cpp:106] Iteration 5350, lr = 3.125e-07
I0818 21:44:23.074371 23166 solver.cpp:337] Iteration 5400, Testing net (#0)
I0818 21:44:37.309763 23166 solver.cpp:404]     Test net output #0: accuracy_1 = 0.879666
I0818 21:44:37.309803 23166 solver.cpp:404]     Test net output #1: accuracy_2 = 0.902077
I0818 21:44:37.309810 23166 solver.cpp:404]     Test net output #2: loss_1 = 12415.9 (* 1 = 12415.9 loss)
I0818 21:44:37.309816 23166 solver.cpp:404]     Test net output #3: loss_2 = 10008.9 (* 1 = 10008.9 loss)
I0818 21:44:38.491518 23166 solver.cpp:228] Iteration 5400, loss = 20754.3
I0818 21:44:38.491550 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.888204
I0818 21:44:38.491556 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.912133
I0818 21:44:38.491564 23166 solver.cpp:244]     Train net output #2: loss_1 = 11824.6 (* 1 = 11824.6 loss)
I0818 21:44:38.491569 23166 solver.cpp:244]     Train net output #3: loss_2 = 8929.68 (* 1 = 8929.68 loss)
I0818 21:44:38.491575 23166 sgd_solver.cpp:106] Iteration 5400, lr = 3.125e-07
I0818 21:45:47.808715 23166 solver.cpp:228] Iteration 5450, loss = 17877.8
I0818 21:45:47.808809 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.894239
I0818 21:45:47.808815 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.932089
I0818 21:45:47.808823 23166 solver.cpp:244]     Train net output #2: loss_1 = 10943.9 (* 1 = 10943.9 loss)
I0818 21:45:47.808830 23166 solver.cpp:244]     Train net output #3: loss_2 = 6933.89 (* 1 = 6933.89 loss)
I0818 21:45:47.808845 23166 sgd_solver.cpp:106] Iteration 5450, lr = 3.125e-07
I0818 21:46:56.977926 23166 solver.cpp:228] Iteration 5500, loss = 15275.3
I0818 21:46:56.978044 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.913256
I0818 21:46:56.978050 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.943964
I0818 21:46:56.978058 23166 solver.cpp:244]     Train net output #2: loss_1 = 9486.42 (* 1 = 9486.42 loss)
I0818 21:46:56.978065 23166 solver.cpp:244]     Train net output #3: loss_2 = 5788.84 (* 1 = 5788.84 loss)
I0818 21:46:56.978070 23166 sgd_solver.cpp:106] Iteration 5500, lr = 3.125e-07
I0818 21:48:06.146877 23166 solver.cpp:228] Iteration 5550, loss = 18187.5
I0818 21:48:06.146971 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.89896
I0818 21:48:06.146978 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.923606
I0818 21:48:06.146986 23166 solver.cpp:244]     Train net output #2: loss_1 = 10375.6 (* 1 = 10375.6 loss)
I0818 21:48:06.146991 23166 solver.cpp:244]     Train net output #3: loss_2 = 7811.91 (* 1 = 7811.91 loss)
I0818 21:48:06.146998 23166 sgd_solver.cpp:106] Iteration 5550, lr = 3.125e-07
I0818 21:49:14.004047 23166 solver.cpp:337] Iteration 5600, Testing net (#0)
I0818 21:49:28.236167 23166 solver.cpp:404]     Test net output #0: accuracy_1 = 0.888743
I0818 21:49:28.236203 23166 solver.cpp:404]     Test net output #1: accuracy_2 = 0.910606
I0818 21:49:28.236212 23166 solver.cpp:404]     Test net output #2: loss_1 = 11582.8 (* 1 = 11582.8 loss)
I0818 21:49:28.236217 23166 solver.cpp:404]     Test net output #3: loss_2 = 9243.05 (* 1 = 9243.05 loss)
I0818 21:49:29.416795 23166 solver.cpp:228] Iteration 5600, loss = 30168.5
I0818 21:49:29.416827 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.838418
I0818 21:49:29.416833 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.863806
I0818 21:49:29.416841 23166 solver.cpp:244]     Train net output #2: loss_1 = 16680.6 (* 1 = 16680.6 loss)
I0818 21:49:29.416846 23166 solver.cpp:244]     Train net output #3: loss_2 = 13487.8 (* 1 = 13487.8 loss)
I0818 21:49:29.416852 23166 sgd_solver.cpp:106] Iteration 5600, lr = 3.125e-07
I0818 21:50:38.551266 23166 solver.cpp:228] Iteration 5650, loss = 13741.2
I0818 21:50:38.551337 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.919201
I0818 21:50:38.551344 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.950883
I0818 21:50:38.551352 23166 solver.cpp:244]     Train net output #2: loss_1 = 8741.87 (* 1 = 8741.87 loss)
I0818 21:50:38.551357 23166 solver.cpp:244]     Train net output #3: loss_2 = 4999.37 (* 1 = 4999.37 loss)
I0818 21:50:38.551363 23166 sgd_solver.cpp:106] Iteration 5650, lr = 3.125e-07
I0818 21:51:47.664177 23166 solver.cpp:228] Iteration 5700, loss = 16187.2
I0818 21:51:47.664224 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.906643
I0818 21:51:47.664230 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.942011
I0818 21:51:47.664237 23166 solver.cpp:244]     Train net output #2: loss_1 = 9967.55 (* 1 = 9967.55 loss)
I0818 21:51:47.664243 23166 solver.cpp:244]     Train net output #3: loss_2 = 6219.66 (* 1 = 6219.66 loss)
I0818 21:51:47.664249 23166 sgd_solver.cpp:106] Iteration 5700, lr = 3.125e-07
I0818 21:52:56.821849 23166 solver.cpp:228] Iteration 5750, loss = 15251.6
I0818 21:52:56.821938 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.90725
I0818 21:52:56.821945 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.94886
I0818 21:52:56.821954 23166 solver.cpp:244]     Train net output #2: loss_1 = 9878.94 (* 1 = 9878.94 loss)
I0818 21:52:56.821959 23166 solver.cpp:244]     Train net output #3: loss_2 = 5372.67 (* 1 = 5372.67 loss)
I0818 21:52:56.821965 23166 sgd_solver.cpp:106] Iteration 5750, lr = 3.125e-07
I0818 21:54:04.724205 23166 solver.cpp:337] Iteration 5800, Testing net (#0)
I0818 21:54:18.956621 23166 solver.cpp:404]     Test net output #0: accuracy_1 = 0.885598
I0818 21:54:18.956655 23166 solver.cpp:404]     Test net output #1: accuracy_2 = 0.90849
I0818 21:54:18.956673 23166 solver.cpp:404]     Test net output #2: loss_1 = 11865.2 (* 1 = 11865.2 loss)
I0818 21:54:18.956679 23166 solver.cpp:404]     Test net output #3: loss_2 = 9396.86 (* 1 = 9396.86 loss)
I0818 21:54:20.144218 23166 solver.cpp:228] Iteration 5800, loss = 22868.8
I0818 21:54:20.144253 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.87462
I0818 21:54:20.144258 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.902427
I0818 21:54:20.144264 23166 solver.cpp:244]     Train net output #2: loss_1 = 12808.6 (* 1 = 12808.6 loss)
I0818 21:54:20.144270 23166 solver.cpp:244]     Train net output #3: loss_2 = 10060.2 (* 1 = 10060.2 loss)
I0818 21:54:20.144276 23166 sgd_solver.cpp:106] Iteration 5800, lr = 3.125e-07
I0818 21:55:29.271728 23166 solver.cpp:228] Iteration 5850, loss = 19522.9
I0818 21:55:29.271823 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.893403
I0818 21:55:29.271831 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.911274
I0818 21:55:29.271838 23166 solver.cpp:244]     Train net output #2: loss_1 = 10876.7 (* 1 = 10876.7 loss)
I0818 21:55:29.271844 23166 solver.cpp:244]     Train net output #3: loss_2 = 8646.16 (* 1 = 8646.16 loss)
I0818 21:55:29.271852 23166 sgd_solver.cpp:106] Iteration 5850, lr = 3.125e-07
I0818 21:56:38.402218 23166 solver.cpp:228] Iteration 5900, loss = 17737.2
I0818 21:56:38.402303 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.899732
I0818 21:56:38.402310 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.930334
I0818 21:56:38.402318 23166 solver.cpp:244]     Train net output #2: loss_1 = 10605.9 (* 1 = 10605.9 loss)
I0818 21:56:38.402323 23166 solver.cpp:244]     Train net output #3: loss_2 = 7131.37 (* 1 = 7131.37 loss)
I0818 21:56:38.402329 23166 sgd_solver.cpp:106] Iteration 5900, lr = 3.125e-07
I0818 21:57:47.531482 23166 solver.cpp:228] Iteration 5950, loss = 13894.4
I0818 21:57:47.531553 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.922222
I0818 21:57:47.531560 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.948448
I0818 21:57:47.531568 23166 solver.cpp:244]     Train net output #2: loss_1 = 8488.87 (* 1 = 8488.87 loss)
I0818 21:57:47.531574 23166 solver.cpp:244]     Train net output #3: loss_2 = 5405.51 (* 1 = 5405.51 loss)
I0818 21:57:47.531579 23166 sgd_solver.cpp:106] Iteration 5950, lr = 3.125e-07
I0818 21:58:55.513743 23166 solver.cpp:454] Snapshotting to binary proto file portrait_two_stage_iter_6000.caffemodel
I0818 21:58:55.517810 23166 sgd_solver.cpp:273] Snapshotting solver state to binary proto file portrait_two_stage_iter_6000.solverstate
I0818 21:58:55.520834 23166 solver.cpp:337] Iteration 6000, Testing net (#0)
I0818 21:59:09.758849 23166 solver.cpp:404]     Test net output #0: accuracy_1 = 0.887905
I0818 21:59:09.758885 23166 solver.cpp:404]     Test net output #1: accuracy_2 = 0.914858
I0818 21:59:09.758894 23166 solver.cpp:404]     Test net output #2: loss_1 = 11699.7 (* 1 = 11699.7 loss)
I0818 21:59:09.758900 23166 solver.cpp:404]     Test net output #3: loss_2 = 8870.61 (* 1 = 8870.61 loss)
I0818 21:59:10.942564 23166 solver.cpp:228] Iteration 6000, loss = 17692.4
I0818 21:59:10.942598 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.902507
I0818 21:59:10.942605 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.923876
I0818 21:59:10.942611 23166 solver.cpp:244]     Train net output #2: loss_1 = 9974.06 (* 1 = 9974.06 loss)
I0818 21:59:10.942616 23166 solver.cpp:244]     Train net output #3: loss_2 = 7718.39 (* 1 = 7718.39 loss)
I0818 21:59:10.942623 23166 sgd_solver.cpp:106] Iteration 6000, lr = 1.5625e-07
I0818 22:00:20.085216 23166 solver.cpp:228] Iteration 6050, loss = 24852.6
I0818 22:00:20.085294 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.864886
I0818 22:00:20.085301 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.889132
I0818 22:00:20.085309 23166 solver.cpp:244]     Train net output #2: loss_1 = 13803 (* 1 = 13803 loss)
I0818 22:00:20.085322 23166 solver.cpp:244]     Train net output #3: loss_2 = 11049.6 (* 1 = 11049.6 loss)
I0818 22:00:20.085330 23166 sgd_solver.cpp:106] Iteration 6050, lr = 1.5625e-07
I0818 22:01:29.207257 23166 solver.cpp:228] Iteration 6100, loss = 18027.7
I0818 22:01:29.207379 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.903683
I0818 22:01:29.207386 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.924587
I0818 22:01:29.207394 23166 solver.cpp:244]     Train net output #2: loss_1 = 10102.5 (* 1 = 10102.5 loss)
I0818 22:01:29.207401 23166 solver.cpp:244]     Train net output #3: loss_2 = 7925.23 (* 1 = 7925.23 loss)
I0818 22:01:29.207406 23166 sgd_solver.cpp:106] Iteration 6100, lr = 1.5625e-07
I0818 22:02:38.348676 23166 solver.cpp:228] Iteration 6150, loss = 16170.4
I0818 22:02:38.348759 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.906068
I0818 22:02:38.348767 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.937992
I0818 22:02:38.348773 23166 solver.cpp:244]     Train net output #2: loss_1 = 9840.56 (* 1 = 9840.56 loss)
I0818 22:02:38.348779 23166 solver.cpp:244]     Train net output #3: loss_2 = 6329.83 (* 1 = 6329.83 loss)
I0818 22:02:38.348785 23166 sgd_solver.cpp:106] Iteration 6150, lr = 1.5625e-07
I0818 22:03:46.382205 23166 solver.cpp:337] Iteration 6200, Testing net (#0)
I0818 22:04:00.644419 23166 solver.cpp:404]     Test net output #0: accuracy_1 = 0.889104
I0818 22:04:00.644455 23166 solver.cpp:404]     Test net output #1: accuracy_2 = 0.914458
I0818 22:04:00.644464 23166 solver.cpp:404]     Test net output #2: loss_1 = 11464.4 (* 1 = 11464.4 loss)
I0818 22:04:00.644469 23166 solver.cpp:404]     Test net output #3: loss_2 = 8842.45 (* 1 = 8842.45 loss)
I0818 22:04:01.814105 23166 solver.cpp:228] Iteration 6200, loss = 14546.2
I0818 22:04:01.814136 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.910111
I0818 22:04:01.814142 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.952557
I0818 22:04:01.814149 23166 solver.cpp:244]     Train net output #2: loss_1 = 9575.39 (* 1 = 9575.39 loss)
I0818 22:04:01.814154 23166 solver.cpp:244]     Train net output #3: loss_2 = 4970.82 (* 1 = 4970.82 loss)
I0818 22:04:01.814162 23166 sgd_solver.cpp:106] Iteration 6200, lr = 1.5625e-07
I0818 22:05:10.941965 23166 solver.cpp:228] Iteration 6250, loss = 29104.1
I0818 22:05:10.942059 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.85176
I0818 22:05:10.942065 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.881794
I0818 22:05:10.942073 23166 solver.cpp:244]     Train net output #2: loss_1 = 16067.2 (* 1 = 16067.2 loss)
I0818 22:05:10.942080 23166 solver.cpp:244]     Train net output #3: loss_2 = 13036.8 (* 1 = 13036.8 loss)
I0818 22:05:10.942085 23166 sgd_solver.cpp:106] Iteration 6250, lr = 1.5625e-07
I0818 22:06:20.213110 23166 solver.cpp:228] Iteration 6300, loss = 20812.5
I0818 22:06:20.213197 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.887716
I0818 22:06:20.213204 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.907407
I0818 22:06:20.213212 23166 solver.cpp:244]     Train net output #2: loss_1 = 11507.4 (* 1 = 11507.4 loss)
I0818 22:06:20.213217 23166 solver.cpp:244]     Train net output #3: loss_2 = 9305.07 (* 1 = 9305.07 loss)
I0818 22:06:20.213223 23166 sgd_solver.cpp:106] Iteration 6300, lr = 1.5625e-07
I0818 22:07:29.456137 23166 solver.cpp:228] Iteration 6350, loss = 18262.2
I0818 22:07:29.456220 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.89862
I0818 22:07:29.456228 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.929859
I0818 22:07:29.456234 23166 solver.cpp:244]     Train net output #2: loss_1 = 10861.8 (* 1 = 10861.8 loss)
I0818 22:07:29.456240 23166 solver.cpp:244]     Train net output #3: loss_2 = 7400.37 (* 1 = 7400.37 loss)
I0818 22:07:29.456246 23166 sgd_solver.cpp:106] Iteration 6350, lr = 1.5625e-07
I0818 22:08:37.509934 23166 solver.cpp:337] Iteration 6400, Testing net (#0)
I0818 22:08:51.731467 23166 solver.cpp:404]     Test net output #0: accuracy_1 = 0.888252
I0818 22:08:51.731511 23166 solver.cpp:404]     Test net output #1: accuracy_2 = 0.911535
I0818 22:08:51.731520 23166 solver.cpp:404]     Test net output #2: loss_1 = 11621.3 (* 1 = 11621.3 loss)
I0818 22:08:51.731525 23166 solver.cpp:404]     Test net output #3: loss_2 = 9139.99 (* 1 = 9139.99 loss)
I0818 22:08:52.907037 23166 solver.cpp:228] Iteration 6400, loss = 13448.3
I0818 22:08:52.907073 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.926852
I0818 22:08:52.907078 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.943945
I0818 22:08:52.907084 23166 solver.cpp:244]     Train net output #2: loss_1 = 7928.28 (* 1 = 7928.28 loss)
I0818 22:08:52.907089 23166 solver.cpp:244]     Train net output #3: loss_2 = 5519.99 (* 1 = 5519.99 loss)
I0818 22:08:52.907095 23166 sgd_solver.cpp:106] Iteration 6400, lr = 1.5625e-07
I0818 22:10:02.073104 23166 solver.cpp:228] Iteration 6450, loss = 16213.8
I0818 22:10:02.073182 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.911132
I0818 22:10:02.073189 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.928759
I0818 22:10:02.073196 23166 solver.cpp:244]     Train net output #2: loss_1 = 9041.92 (* 1 = 9041.92 loss)
I0818 22:10:02.073202 23166 solver.cpp:244]     Train net output #3: loss_2 = 7171.9 (* 1 = 7171.9 loss)
I0818 22:10:02.073209 23166 sgd_solver.cpp:106] Iteration 6450, lr = 1.5625e-07
I0818 22:11:11.127905 23166 solver.cpp:228] Iteration 6500, loss = 23460.9
I0818 22:11:11.127980 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.87393
I0818 22:11:11.127986 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.90161
I0818 22:11:11.127993 23166 solver.cpp:244]     Train net output #2: loss_1 = 13342.5 (* 1 = 13342.5 loss)
I0818 22:11:11.127998 23166 solver.cpp:244]     Train net output #3: loss_2 = 10118.3 (* 1 = 10118.3 loss)
I0818 22:11:11.128005 23166 sgd_solver.cpp:106] Iteration 6500, lr = 1.5625e-07
I0818 22:12:20.231658 23166 solver.cpp:228] Iteration 6550, loss = 21246.5
I0818 22:12:20.231730 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.887443
I0818 22:12:20.231737 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.913041
I0818 22:12:20.231745 23166 solver.cpp:244]     Train net output #2: loss_1 = 11937.4 (* 1 = 11937.4 loss)
I0818 22:12:20.231750 23166 solver.cpp:244]     Train net output #3: loss_2 = 9309.01 (* 1 = 9309.01 loss)
I0818 22:12:20.231756 23166 sgd_solver.cpp:106] Iteration 6550, lr = 1.5625e-07
I0818 22:13:28.148675 23166 solver.cpp:337] Iteration 6600, Testing net (#0)
I0818 22:13:42.375239 23166 solver.cpp:404]     Test net output #0: accuracy_1 = 0.891617
I0818 22:13:42.375274 23166 solver.cpp:404]     Test net output #1: accuracy_2 = 0.916948
I0818 22:13:42.375283 23166 solver.cpp:404]     Test net output #2: loss_1 = 11273.2 (* 1 = 11273.2 loss)
I0818 22:13:42.375288 23166 solver.cpp:404]     Test net output #3: loss_2 = 8631.79 (* 1 = 8631.79 loss)
I0818 22:13:43.555307 23166 solver.cpp:228] Iteration 6600, loss = 15638.3
I0818 22:13:43.555341 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.914218
I0818 22:13:43.555346 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.941579
I0818 22:13:43.555353 23166 solver.cpp:244]     Train net output #2: loss_1 = 9420.43 (* 1 = 9420.43 loss)
I0818 22:13:43.555358 23166 solver.cpp:244]     Train net output #3: loss_2 = 6217.91 (* 1 = 6217.91 loss)
I0818 22:13:43.555364 23166 sgd_solver.cpp:106] Iteration 6600, lr = 1.5625e-07
I0818 22:14:52.792649 23166 solver.cpp:228] Iteration 6650, loss = 16256.1
I0818 22:14:52.792696 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.902355
I0818 22:14:52.792702 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.946136
I0818 22:14:52.792709 23166 solver.cpp:244]     Train net output #2: loss_1 = 10543.6 (* 1 = 10543.6 loss)
I0818 22:14:52.792716 23166 solver.cpp:244]     Train net output #3: loss_2 = 5712.43 (* 1 = 5712.43 loss)
I0818 22:14:52.792721 23166 sgd_solver.cpp:106] Iteration 6650, lr = 1.5625e-07
I0818 22:16:01.851328 23166 solver.cpp:228] Iteration 6700, loss = 23761.4
I0818 22:16:01.851444 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.872235
I0818 22:16:01.851452 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.900935
I0818 22:16:01.851460 23166 solver.cpp:244]     Train net output #2: loss_1 = 13485.2 (* 1 = 13485.2 loss)
I0818 22:16:01.851466 23166 solver.cpp:244]     Train net output #3: loss_2 = 10276.2 (* 1 = 10276.2 loss)
I0818 22:16:01.851472 23166 sgd_solver.cpp:106] Iteration 6700, lr = 1.5625e-07
I0818 22:17:11.016628 23166 solver.cpp:228] Iteration 6750, loss = 18166
I0818 22:17:11.016716 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.90055
I0818 22:17:11.016723 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.920464
I0818 22:17:11.016731 23166 solver.cpp:244]     Train net output #2: loss_1 = 10239.3 (* 1 = 10239.3 loss)
I0818 22:17:11.016737 23166 solver.cpp:244]     Train net output #3: loss_2 = 7926.76 (* 1 = 7926.76 loss)
I0818 22:17:11.016743 23166 sgd_solver.cpp:106] Iteration 6750, lr = 1.5625e-07
I0818 22:18:18.930483 23166 solver.cpp:337] Iteration 6800, Testing net (#0)
I0818 22:18:33.186175 23166 solver.cpp:404]     Test net output #0: accuracy_1 = 0.891782
I0818 22:18:33.186211 23166 solver.cpp:404]     Test net output #1: accuracy_2 = 0.916172
I0818 22:18:33.186219 23166 solver.cpp:404]     Test net output #2: loss_1 = 11301.6 (* 1 = 11301.6 loss)
I0818 22:18:33.186225 23166 solver.cpp:404]     Test net output #3: loss_2 = 8696.23 (* 1 = 8696.23 loss)
I0818 22:18:34.358678 23166 solver.cpp:228] Iteration 6800, loss = 17529.6
I0818 22:18:34.358711 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.901293
I0818 22:18:34.358716 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.930226
I0818 22:18:34.358723 23166 solver.cpp:244]     Train net output #2: loss_1 = 10438.4 (* 1 = 10438.4 loss)
I0818 22:18:34.358728 23166 solver.cpp:244]     Train net output #3: loss_2 = 7091.23 (* 1 = 7091.23 loss)
I0818 22:18:34.358736 23166 sgd_solver.cpp:106] Iteration 6800, lr = 1.5625e-07
I0818 22:19:43.537274 23166 solver.cpp:228] Iteration 6850, loss = 14046.4
I0818 22:19:43.537365 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.918203
I0818 22:19:43.537372 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.946018
I0818 22:19:43.537379 23166 solver.cpp:244]     Train net output #2: loss_1 = 8659.55 (* 1 = 8659.55 loss)
I0818 22:19:43.537385 23166 solver.cpp:244]     Train net output #3: loss_2 = 5386.81 (* 1 = 5386.81 loss)
I0818 22:19:43.537391 23166 sgd_solver.cpp:106] Iteration 6850, lr = 1.5625e-07
I0818 22:20:52.677474 23166 solver.cpp:228] Iteration 6900, loss = 17555.9
I0818 22:20:52.677542 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.899452
I0818 22:20:52.677549 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.932945
I0818 22:20:52.677556 23166 solver.cpp:244]     Train net output #2: loss_1 = 10557.6 (* 1 = 10557.6 loss)
I0818 22:20:52.677561 23166 solver.cpp:244]     Train net output #3: loss_2 = 6998.28 (* 1 = 6998.28 loss)
I0818 22:20:52.677568 23166 sgd_solver.cpp:106] Iteration 6900, lr = 1.5625e-07
I0818 22:22:01.812464 23166 solver.cpp:228] Iteration 6950, loss = 25175.1
I0818 22:22:01.812518 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.863495
I0818 22:22:01.812525 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.893779
I0818 22:22:01.812531 23166 solver.cpp:244]     Train net output #2: loss_1 = 14277.1 (* 1 = 14277.1 loss)
I0818 22:22:01.812537 23166 solver.cpp:244]     Train net output #3: loss_2 = 10898 (* 1 = 10898 loss)
I0818 22:22:01.812544 23166 sgd_solver.cpp:106] Iteration 6950, lr = 1.5625e-07
I0818 22:23:09.734333 23166 solver.cpp:337] Iteration 7000, Testing net (#0)
I0818 22:23:24.011766 23166 solver.cpp:404]     Test net output #0: accuracy_1 = 0.892754
I0818 22:23:24.011798 23166 solver.cpp:404]     Test net output #1: accuracy_2 = 0.916744
I0818 22:23:24.011806 23166 solver.cpp:404]     Test net output #2: loss_1 = 11138.1 (* 1 = 11138.1 loss)
I0818 22:23:24.011821 23166 solver.cpp:404]     Test net output #3: loss_2 = 8596.24 (* 1 = 8596.24 loss)
I0818 22:23:25.189992 23166 solver.cpp:228] Iteration 7000, loss = 19040.8
I0818 22:23:25.190024 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.893639
I0818 22:23:25.190029 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.919741
I0818 22:23:25.190037 23166 solver.cpp:244]     Train net output #2: loss_1 = 10845.4 (* 1 = 10845.4 loss)
I0818 22:23:25.190042 23166 solver.cpp:244]     Train net output #3: loss_2 = 8195.38 (* 1 = 8195.38 loss)
I0818 22:23:25.190048 23166 sgd_solver.cpp:106] Iteration 7000, lr = 7.8125e-08
I0818 22:24:34.256969 23166 solver.cpp:228] Iteration 7050, loss = 14308
I0818 22:24:34.257073 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.919132
I0818 22:24:34.257081 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.947986
I0818 22:24:34.257088 23166 solver.cpp:244]     Train net output #2: loss_1 = 8830.42 (* 1 = 8830.42 loss)
I0818 22:24:34.257093 23166 solver.cpp:244]     Train net output #3: loss_2 = 5477.6 (* 1 = 5477.6 loss)
I0818 22:24:34.257099 23166 sgd_solver.cpp:106] Iteration 7050, lr = 7.8125e-08
I0818 22:25:43.507761 23166 solver.cpp:228] Iteration 7100, loss = 13837.2
I0818 22:25:43.507855 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.919846
I0818 22:25:43.507863 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.949391
I0818 22:25:43.507869 23166 solver.cpp:244]     Train net output #2: loss_1 = 8690.94 (* 1 = 8690.94 loss)
I0818 22:25:43.507875 23166 solver.cpp:244]     Train net output #3: loss_2 = 5146.23 (* 1 = 5146.23 loss)
I0818 22:25:43.507881 23166 sgd_solver.cpp:106] Iteration 7100, lr = 7.8125e-08
I0818 22:26:52.568205 23166 solver.cpp:228] Iteration 7150, loss = 22293.8
I0818 22:26:52.568277 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.881625
I0818 22:26:52.568284 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.903514
I0818 22:26:52.568291 23166 solver.cpp:244]     Train net output #2: loss_1 = 12444.2 (* 1 = 12444.2 loss)
I0818 22:26:52.568297 23166 solver.cpp:244]     Train net output #3: loss_2 = 9849.54 (* 1 = 9849.54 loss)
I0818 22:26:52.568303 23166 sgd_solver.cpp:106] Iteration 7150, lr = 7.8125e-08
I0818 22:28:00.536216 23166 solver.cpp:337] Iteration 7200, Testing net (#0)
I0818 22:28:14.774552 23166 solver.cpp:404]     Test net output #0: accuracy_1 = 0.894328
I0818 22:28:14.774588 23166 solver.cpp:404]     Test net output #1: accuracy_2 = 0.916594
I0818 22:28:14.774596 23166 solver.cpp:404]     Test net output #2: loss_1 = 10993.5 (* 1 = 10993.5 loss)
I0818 22:28:14.774602 23166 solver.cpp:404]     Test net output #3: loss_2 = 8597.62 (* 1 = 8597.62 loss)
I0818 22:28:15.957129 23166 solver.cpp:228] Iteration 7200, loss = 20291.9
I0818 22:28:15.957164 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.889658
I0818 22:28:15.957168 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.911825
I0818 22:28:15.957176 23166 solver.cpp:244]     Train net output #2: loss_1 = 11430.3 (* 1 = 11430.3 loss)
I0818 22:28:15.957181 23166 solver.cpp:244]     Train net output #3: loss_2 = 8861.64 (* 1 = 8861.64 loss)
I0818 22:28:15.957187 23166 sgd_solver.cpp:106] Iteration 7200, lr = 7.8125e-08
I0818 22:29:25.039741 23166 solver.cpp:228] Iteration 7250, loss = 24611.7
I0818 22:29:25.039815 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.862384
I0818 22:29:25.039822 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.895914
I0818 22:29:25.039829 23166 solver.cpp:244]     Train net output #2: loss_1 = 14036.8 (* 1 = 14036.8 loss)
I0818 22:29:25.039834 23166 solver.cpp:244]     Train net output #3: loss_2 = 10574.9 (* 1 = 10574.9 loss)
I0818 22:29:25.039841 23166 sgd_solver.cpp:106] Iteration 7250, lr = 7.8125e-08
I0818 22:30:34.231736 23166 solver.cpp:228] Iteration 7300, loss = 15474.6
I0818 22:30:34.231832 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.913936
I0818 22:30:34.231842 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.939698
I0818 22:30:34.231849 23166 solver.cpp:244]     Train net output #2: loss_1 = 9169.87 (* 1 = 9169.87 loss)
I0818 22:30:34.231855 23166 solver.cpp:244]     Train net output #3: loss_2 = 6304.72 (* 1 = 6304.72 loss)
I0818 22:30:34.231861 23166 sgd_solver.cpp:106] Iteration 7300, lr = 7.8125e-08
I0818 22:31:43.322484 23166 solver.cpp:228] Iteration 7350, loss = 14919.5
I0818 22:31:43.322561 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.914436
I0818 22:31:43.322567 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.942703
I0818 22:31:43.322576 23166 solver.cpp:244]     Train net output #2: loss_1 = 9092.88 (* 1 = 9092.88 loss)
I0818 22:31:43.322580 23166 solver.cpp:244]     Train net output #3: loss_2 = 5826.6 (* 1 = 5826.6 loss)
I0818 22:31:43.322587 23166 sgd_solver.cpp:106] Iteration 7350, lr = 7.8125e-08
I0818 22:32:51.240736 23166 solver.cpp:337] Iteration 7400, Testing net (#0)
I0818 22:33:05.469591 23166 solver.cpp:404]     Test net output #0: accuracy_1 = 0.890949
I0818 22:33:05.469626 23166 solver.cpp:404]     Test net output #1: accuracy_2 = 0.914645
I0818 22:33:05.469635 23166 solver.cpp:404]     Test net output #2: loss_1 = 11337.3 (* 1 = 11337.3 loss)
I0818 22:33:05.469640 23166 solver.cpp:404]     Test net output #3: loss_2 = 8839.82 (* 1 = 8839.82 loss)
I0818 22:33:06.670853 23166 solver.cpp:228] Iteration 7400, loss = 24634.4
I0818 22:33:06.670887 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.866138
I0818 22:33:06.670892 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.889127
I0818 22:33:06.670899 23166 solver.cpp:244]     Train net output #2: loss_1 = 13762 (* 1 = 13762 loss)
I0818 22:33:06.670905 23166 solver.cpp:244]     Train net output #3: loss_2 = 10872.3 (* 1 = 10872.3 loss)
I0818 22:33:06.670912 23166 sgd_solver.cpp:106] Iteration 7400, lr = 7.8125e-08
I0818 22:34:15.782800 23166 solver.cpp:228] Iteration 7450, loss = 16512.7
I0818 22:34:15.782850 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.909477
I0818 22:34:15.782855 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.927374
I0818 22:34:15.782862 23166 solver.cpp:244]     Train net output #2: loss_1 = 9277.36 (* 1 = 9277.36 loss)
I0818 22:34:15.782868 23166 solver.cpp:244]     Train net output #3: loss_2 = 7235.39 (* 1 = 7235.39 loss)
I0818 22:34:15.782874 23166 sgd_solver.cpp:106] Iteration 7450, lr = 7.8125e-08
I0818 22:35:24.837327 23166 solver.cpp:228] Iteration 7500, loss = 14037
I0818 22:35:24.837424 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.91758
I0818 22:35:24.837430 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.947514
I0818 22:35:24.837437 23166 solver.cpp:244]     Train net output #2: loss_1 = 8668.68 (* 1 = 8668.68 loss)
I0818 22:35:24.837443 23166 solver.cpp:244]     Train net output #3: loss_2 = 5368.33 (* 1 = 5368.33 loss)
I0818 22:35:24.837450 23166 sgd_solver.cpp:106] Iteration 7500, lr = 7.8125e-08
I0818 22:36:34.031400 23166 solver.cpp:228] Iteration 7550, loss = 14706.4
I0818 22:36:34.031481 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.914124
I0818 22:36:34.031488 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.947057
I0818 22:36:34.031496 23166 solver.cpp:244]     Train net output #2: loss_1 = 9339.16 (* 1 = 9339.16 loss)
I0818 22:36:34.031502 23166 solver.cpp:244]     Train net output #3: loss_2 = 5367.2 (* 1 = 5367.2 loss)
I0818 22:36:34.031508 23166 sgd_solver.cpp:106] Iteration 7550, lr = 7.8125e-08
I0818 22:37:41.945741 23166 solver.cpp:337] Iteration 7600, Testing net (#0)
I0818 22:37:56.359619 23166 solver.cpp:404]     Test net output #0: accuracy_1 = 0.893775
I0818 22:37:56.359657 23166 solver.cpp:404]     Test net output #1: accuracy_2 = 0.918719
I0818 22:37:56.359664 23166 solver.cpp:404]     Test net output #2: loss_1 = 11091.4 (* 1 = 11091.4 loss)
I0818 22:37:56.359670 23166 solver.cpp:404]     Test net output #3: loss_2 = 8443.46 (* 1 = 8443.46 loss)
I0818 22:37:57.547431 23166 solver.cpp:228] Iteration 7600, loss = 23134.2
I0818 22:37:57.547473 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.872982
I0818 22:37:57.547479 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.902444
I0818 22:37:57.547487 23166 solver.cpp:244]     Train net output #2: loss_1 = 13050.9 (* 1 = 13050.9 loss)
I0818 22:37:57.547492 23166 solver.cpp:244]     Train net output #3: loss_2 = 10083.3 (* 1 = 10083.3 loss)
I0818 22:37:57.547497 23166 sgd_solver.cpp:106] Iteration 7600, lr = 7.8125e-08
I0818 22:39:06.720235 23166 solver.cpp:228] Iteration 7650, loss = 21240.4
I0818 22:39:06.720338 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.886875
I0818 22:39:06.720346 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.909013
I0818 22:39:06.720353 23166 solver.cpp:244]     Train net output #2: loss_1 = 11857.8 (* 1 = 11857.8 loss)
I0818 22:39:06.720360 23166 solver.cpp:244]     Train net output #3: loss_2 = 9382.55 (* 1 = 9382.55 loss)
I0818 22:39:06.720366 23166 sgd_solver.cpp:106] Iteration 7650, lr = 7.8125e-08
I0818 22:40:15.771091 23166 solver.cpp:228] Iteration 7700, loss = 24807.3
I0818 22:40:15.771167 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.868804
I0818 22:40:15.771173 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.890034
I0818 22:40:15.771180 23166 solver.cpp:244]     Train net output #2: loss_1 = 13488 (* 1 = 13488 loss)
I0818 22:40:15.771186 23166 solver.cpp:244]     Train net output #3: loss_2 = 11319.3 (* 1 = 11319.3 loss)
I0818 22:40:15.771193 23166 sgd_solver.cpp:106] Iteration 7700, lr = 7.8125e-08
I0818 22:41:24.909535 23166 solver.cpp:228] Iteration 7750, loss = 14379.4
I0818 22:41:24.909605 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.920502
I0818 22:41:24.909612 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.942142
I0818 22:41:24.909620 23166 solver.cpp:244]     Train net output #2: loss_1 = 8603.18 (* 1 = 8603.18 loss)
I0818 22:41:24.909626 23166 solver.cpp:244]     Train net output #3: loss_2 = 5776.23 (* 1 = 5776.23 loss)
I0818 22:41:24.909631 23166 sgd_solver.cpp:106] Iteration 7750, lr = 7.8125e-08
I0818 22:42:32.862754 23166 solver.cpp:337] Iteration 7800, Testing net (#0)
I0818 22:42:47.115711 23166 solver.cpp:404]     Test net output #0: accuracy_1 = 0.894539
I0818 22:42:47.115747 23166 solver.cpp:404]     Test net output #1: accuracy_2 = 0.918205
I0818 22:42:47.115756 23166 solver.cpp:404]     Test net output #2: loss_1 = 10997.4 (* 1 = 10997.4 loss)
I0818 22:42:47.115762 23166 solver.cpp:404]     Test net output #3: loss_2 = 8468.23 (* 1 = 8468.23 loss)
I0818 22:42:48.291303 23166 solver.cpp:228] Iteration 7800, loss = 15928.5
I0818 22:42:48.291330 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.90561
I0818 22:42:48.291335 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.939994
I0818 22:42:48.291343 23166 solver.cpp:244]     Train net output #2: loss_1 = 9814.4 (* 1 = 9814.4 loss)
I0818 22:42:48.291349 23166 solver.cpp:244]     Train net output #3: loss_2 = 6114.13 (* 1 = 6114.13 loss)
I0818 22:42:48.291355 23166 sgd_solver.cpp:106] Iteration 7800, lr = 7.8125e-08
I0818 22:43:57.425693 23166 solver.cpp:228] Iteration 7850, loss = 22876.2
I0818 22:43:57.425747 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.874224
I0818 22:43:57.425755 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.902651
I0818 22:43:57.425761 23166 solver.cpp:244]     Train net output #2: loss_1 = 13009.2 (* 1 = 13009.2 loss)
I0818 22:43:57.425767 23166 solver.cpp:244]     Train net output #3: loss_2 = 9866.99 (* 1 = 9866.99 loss)
I0818 22:43:57.425773 23166 sgd_solver.cpp:106] Iteration 7850, lr = 7.8125e-08
I0818 22:45:06.560919 23166 solver.cpp:228] Iteration 7900, loss = 17245.7
I0818 22:45:06.561010 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.905407
I0818 22:45:06.561017 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.924526
I0818 22:45:06.561024 23166 solver.cpp:244]     Train net output #2: loss_1 = 9713.07 (* 1 = 9713.07 loss)
I0818 22:45:06.561040 23166 solver.cpp:244]     Train net output #3: loss_2 = 7532.59 (* 1 = 7532.59 loss)
I0818 22:45:06.561046 23166 sgd_solver.cpp:106] Iteration 7900, lr = 7.8125e-08
I0818 22:46:15.678128 23166 solver.cpp:228] Iteration 7950, loss = 13746.1
I0818 22:46:15.678225 23166 solver.cpp:244]     Train net output #0: accuracy_1 = 0.922923
I0818 22:46:15.678232 23166 solver.cpp:244]     Train net output #1: accuracy_2 = 0.946809
I0818 22:46:15.678241 23166 solver.cpp:244]     Train net output #2: loss_1 = 8287.68 (* 1 = 8287.68 loss)
I0818 22:46:15.678246 23166 solver.cpp:244]     Train net output #3: loss_2 = 5458.42 (* 1 = 5458.42 loss)
I0818 22:46:15.678251 23166 sgd_solver.cpp:106] Iteration 7950, lr = 7.8125e-08
I0818 22:47:23.751463 23166 solver.cpp:454] Snapshotting to binary proto file portrait_two_stage_iter_8000.caffemodel
I0818 22:47:23.755517 23166 sgd_solver.cpp:273] Snapshotting solver state to binary proto file portrait_two_stage_iter_8000.solverstate
I0818 22:47:24.708405 23166 solver.cpp:317] Iteration 8000, loss = 13913.4
I0818 22:47:24.708439 23166 solver.cpp:337] Iteration 8000, Testing net (#0)
I0818 22:47:38.957767 23166 solver.cpp:404]     Test net output #0: accuracy_1 = 0.892664
I0818 22:47:38.957803 23166 solver.cpp:404]     Test net output #1: accuracy_2 = 0.916157
I0818 22:47:38.957811 23166 solver.cpp:404]     Test net output #2: loss_1 = 11110.8 (* 1 = 11110.8 loss)
I0818 22:47:38.957818 23166 solver.cpp:404]     Test net output #3: loss_2 = 8627.4 (* 1 = 8627.4 loss)
I0818 22:47:38.957821 23166 solver.cpp:322] Optimization Done.
I0818 22:47:38.957824 23166 caffe.cpp:254] Optimization Done.
